18 L. Steels
A linking pattern relies on the deÔ¨Ånition of the external arguments of subnet-
works supplied by words or constituents. These arguments can be linked to the
external arguments supplied by other subnetworks. For example, the cognitive
operation filter-set-class, which Ô¨Ålters a set of objects based on a class, has
two external arguments: one for the class and the other for the Ô¨Åltered set. The
cognitive operation select-unique-element selecting the unique element out
of a singleton has two external arguments as well: one for the set from which
an element has to be selected and the other for the chosen element. When these
two cognitive operations are combined in a single network (as in the phrase ‚Äúthe
mouse", where ‚Äúmouse" introduces the class identiÔ¨Åer), the new network has
only two external arguments: One for the selected element and another for the
original source set as used by the Ô¨Ålter operation. Internally, the non-external
arguments are linked together in the combined network so that the set derived
by filter-set-class on the basis of the class ‚Äòmouse‚Äô is the set from which the
element is selected by select-unique-element.
3.2 Constructions
A construction is the basic computational unit at the operational level in FCG. It
contains a semantic pole that captures aspects of pragmatics, meaning, seman-
tic structure and semantic categorization, and a syntactic pole that captures
aspects of syntactic structure, syntactic categorization, as well as phonetic and
morphological marking. Constructions typically have a set of units for the diÔ¨Äer-
ent constituents. Information is represented in terms of features associated with
each of the units.
The data structure built during the parsing and production of a particular
sentence is called a transient structure. It has the same division into units and
features as a construction, as well as a semantic and a syntactic pole. Initially
the transient structure contains only one unit (usually called the top-unit), which
contains everything that is known when processing starts. In parsing, it contains
a feature form that contains a description of all the form characteristics of the
utterance. In production, the top-unit contains a feature meaning that contains
the complete meaning which the speaker wants to express.
A construction is viewed as a bi-directional association between meaning (the
semantic pole) and form (the syntactic pole). In production the semantic pole of
the construction is matched against the semantic pole of the transient structure
in order to check whether the construction is applicable, and then the informa-
tion contained in the syntactic pole of the construction is added by merging it
with the syntactic pole of the transient structure. In parsing, the syntactic pole
of the construction is matched against the transient structure to see whether
the construction is applicable, and if this is the case then information from the
semantic pole is merged with the transient structure so as to progressively re-
construct the semantic structure and meaning of the sentence. One construction
thus prepares the ground for the application of the next construction, so that
we get a chain of construction applications (see Figure 7). Usually there is more
than one construction that can apply at any point in time, and we therefore get
Design Methods for Fluid Construction Grammar 19
UNIT
A
CXN
1
CXN
2
CXN
3
...
CXN
72
CXN
73
UNIT
A
UNIT
B
UNIT
C
initial
transient
structure
constructions
CXN
1
CXN
2
CXN
3
...
CXN
72
CXN
73
transient structure
modified by
cxn 3 and 72
MATCH
MERGE
MERGE
MATCH
MATCH
UNIT
A
UNIT
B
UNIT
D
UNIT
C
...
constructions
transient structure
modified by
cxn 2
MERGE
Fig. 7. Constructions are applied in a chain starting from an initial transient structure.
Application either fails in mid-stream or continues until a complete sentence can be
produced (in language production) or the meaning could be completely reconstructed.
a search space in which diÔ¨Äerent search paths have to be tried out to Ô¨Ånd the
best possible solution.
Constructions are complicated because of their bi-directional nature. It is not
enough to say, for example, that a determiner-nominal phrase consists of a de-
terminer and a nominal, we also need to say when such a determiner-nominal
phrase should be used (in production) and how the meaning of the determiner
and nominal is to be combined (in parsing). We also need to specify the agree-
ment relations, percolations, and linkings of subnetworks. An additional factor
that makes constructions complicated is that both syntactic and semantic issues
need to be considered at the same time. This leads to much greater eÔ¨Éciency
compared to a separation of the grammar into diÔ¨Äerent layers or a decomposition
of linguistic decisions into small steps. A construction should take as many con-
straints as possible into account before building more structure, so that search
gets maximally avoided. On the other hand, it makes it much harder to write
grammars.
To make the analysis and implementation of grammars nevertheless doable,
FCG divides constructions up into diÔ¨Äerent construction sets. This helps also to
streamline the processing of constructions because all constructions in one set
can be considered before the next set in the sequence is tried. Here are some
example construction sets that are typically found for most applications:
1. Lexical constructions introduce lexical items, i.e. word stems. They specify
the meaning, external arguments, phonetic, syntactic and semantic cate-
gories, and form of a word.
20 L. Steels
2. Morphological constructions introduce morphemes, i.e. preÔ¨Åxes and suÔ¨Éxes
that are attached to word stems. They specify with what word the morpheme
can be combined, the form the combintion takes, syntactic and semantic cat-
egorizations, the form of the morpheme, and possibly its phonetic features.
3. Functional constructions are concerned with deÔ¨Åning associations between
lexical categories, syntactic functions, and semantic functions. They deÔ¨Åne
potential values. The actual values are decided based on the syntactic and
semantic context.
4. Phrasal constructions are concerned with capturing constraints on phrases:
What constituents there are, what the semantic constraints on constituents
are, which semantic and syntactic function they should have, what kind of
agreement, ordering, and percolation phenomena must be taken into account.
There are usually additional construction sets that deal with the expression of
grammatical meaning. For example, it could be that a language expresses argu-
ment structure using semantic roles and cases, and this would then lead to the
inclusion of argument-structure constructions [47]. Or it could be that a language
has an elaborate system of aspect which would require constructions that han-
dle the semantic and syntactic features related to aspect so that morphological
constructions can mark them with external forms [13].
3.3 Templates
A design pattern does not directly translate into a particular construction be-
cause one construction will integrate aspects of many diÔ¨Äerent design patterns,
and a single design pattern has an impact on many diÔ¨Äerent constructions. For
example, to implement agreement requires that lexical constructions, morpholog-
ical constructions, and phrasal constructions introduce syntactic and semantic
features and that agreement relations are deÔ¨Åned within the context of the rel-
evant phrasal constructions. It is nevertheless possible to capture some of the
basic aspects of design patterns into abstractions that hide a lot of the imple-
mentation details. FCG does this using templates.
A template determines some of the aspects of a construction. It has a number
of slots which act as parameters for how exactly the template should be instan-
tiated. When a template is applied to a construction it extends the construction
as a side eÔ¨Äect (Figure 8). Each construction has a unique name so that tem-
plates can retrieve the construction they want to have an impact on. Moreover,
the units in a construction are associated with variable-names so that they can
be used by diÔ¨Äerent templates to add more information.
The general syntax for using a template takes the following form:
( template-name construction-name optional-parameters
:slot-name-1 value-name-1
...
:slot-name-n value-name-n)
The set of possible templates is open, and a grammar designer implements
the speciÔ¨Åc templates required for the language phenomena that he or she is
Design Methods for Fluid Construction Grammar 21


	
	

	

	



	


Fig. 8. DiÔ¨Äerent templates progressively add more structure to a construction. Each
template adds information relevant to a particular design pattern. For example, the
def-phrasal-agreement template adds mechanisms to implement the relevant agree-
ment relations to the postposed-genitive-cxn.
interested in and from then on uses these templates. There are libraries of tem-
plates made available with each FCG release. The more speciÔ¨Åc templates are,
the easier it is to focus on the speciÔ¨Åc linguistic aspects of the language being
studied because computational issues are hidden as much as possible. But the
less they will be relevant for other languages.
The values of slots can either be symbols, lists of symbols, or expressions
using the same special operators as used at the operational level. FCG uses logic
variables as commonly used in logic programming languages. They are denoted
by putting a question mark in front of the name of the variable. Variables get
bound as a side eÔ¨Äect of the matching and merging process, either to constants
or to other variables. (Details of FCG-variables, special operators, and the basic
uniÔ¨Åcation operations that use them are discussed in a follow up chapter [10].)
Here are a few examples of templates. There are Ô¨Årst of all some ‚Äòshell tem-
plates‚Äô that create a shell for a construction with a given name. The template
also puts the construction in a particular construction set. Shell templates are
of the form
(def -construction-type construction-name
... invocation of other templates ... )
Typical names for shell templates are def-lex-cxn, def-morph-cxn,
def-fun-cxn, def-phrasal-cxn, etc., to build lexical, morphological, functional
or phrasal constructions respectively.
For example, let us initialize the deÔ¨Ånition of a lexical construction called
mine-cxn for deÔ¨Åning the word ‚Äúmine", as it may appear in possessive construc-
tions, such as ‚Äúthis house of mine". The process of building this construction
starts with the creation of a shell using the def-lex-cxn template. Only the
name of the construction has to be supplied:
(def-lex-cxn mine-cxn)
22 L. Steels
Next, there are typically templates that deÔ¨Åne the basic skeletal structure
of each construction. For example, lexical constructions primarily associate
meaning with a string. Thus there is a template called def-lex-skeleton with
slots for :meaning and :string.
(def-lex-skeleton mine-cxn
:meaning (== (context ?context)
(dialog-participant ?indiv speaker ?context))
:string "mine"))
The linking design pattern requires deÔ¨Åning the external arguments of the sub-
network introduced by this lexical item, which is usually done with an extra slot
called :args in the def-lex-skeleton template:
(def-lex-skeleton mine-cxn
:meaning (== (context ?context)
(dialog-participant ?indiv speaker ?context))
:args (?indiv)
:string "mine"))
Syntactic and semantic categorizations are associated with lexical items by an-
other template, called def-lex-cat. It has a slot :sem-cat for the semantic
categorizations and a slot :syn-cat for the syntactic categorizations:
(def-lex-cat mine-cxn
:sem-cat (==1 (sem-function possessive))
:syn-cat (==1 (lex-cat pronoun)
(person 1st)
(number singular)
(case genitive)))
The semantic function of ‚Äúmine" is that of possessive. From a syntactic side, it
is a 1st person, singular pronoun in the genitive case. All of this is of course
meant to be an example. FCG allows the grammar designer to use any kind of
feature deemed necessary. Templates can also incorporate more information or
less, depending on preferred implementation style. For example the syntactic and
semantic categorizations could also be put in a single lexical template together
with the meaning and string.
Here is another more elaborate example to illustrate the use of templates
for building constructions (discussed at length in [40]). It deÔ¨Ånes a possessive
phrasal construction, underlying a phrase such as ‚Äúthis house of mine". The
possessive phrasal construction involves two constituents: a nominal phrase (‚Äúthis
house") and a possessive pronominal ‚Äúmine". The construction itself is called
postposed-genitive-cxn. It starts with the creation of a shell that makes this
construction a member of the set of phrasal constructions:
Design Methods for Fluid Construction Grammar 23
(def-phrasal-cxn postposed-genitive-cxn)
Next, the def-phrasal-skeleton template is used to introduce units both for
the phrase as a whole, with a slot called :phrase, and for the diÔ¨Äerent con-
stituents, with a slot called :constituents. The constituents are deÔ¨Åned in
terms of their semantic functions, syntactic functions, lexical categories, phrase
types, or syntactic and semantic categorizations. Information is provided on the
phrase-type of the parent and its possible syntactic and semantic
functions:
(def-phrasal-skeleton postposed-genitive-cxn
:phrase
(?possessive-nominal-phrase
:sem-function referring
:phrase-type nominal-phrase)
:constituents
((?nominal-unit
:sem-function referring
:phrase-type nominal-phrase)
(?pronominal-unit
:sem-function possessive
:lex-cat pronoun
:syn-cat (==1 (case genitive)))))
The variables that are used for the constituents (i.e. ?nominal-unit,
?pronominal-unit) and for the parent phrase (i.e. ?possessive-nominal
-phrase) can be used by other templates to address these units and add more in-
formation. Other variables used in feature values can also be used acrosstemplates.
Other templates implement other design patterns. For example, the postposed
genitive construction requires that the number of the nominal unit percolates
to the possessive nominal phrase as a whole. This is speciÔ¨Åed with a template
called def-phrasal-agreement. For all constituents that share features and for
the parent phrase in which features percolate up from the constituents, the def-
phrasal-agreement lists the following:
(def-phrasal-agreement postposed-genitive-cxn
(?possessive-nominal-phrase
:syn-cat (==1 (number ?number)
(is-definite ?definiteness)))
(?nominal-unit
:syn-cat (==1 (is-definite ?definiteness)
(number ?number))))
The variables ?possessive-nominal-phrase and ?nominal-unit are used to
retrieve which units are involved, and the slot-values specify which syntactic
and/or semantic categories have to agree. Use of the same variable name indi-
cates that this indicates that an agreement relation is established. For exam-
ple, ?number of the possessive nominal phrase is shared with ?number of the
24 L. Steels
?nominal-unit. Thanks to the uniÔ¨Åcation operation, bindings can Ô¨Çow in both
directions: It is not only possible that the number value propagates up from the
nominal-unit to the phrase but also that it propagates down from the nominal
phrase to the nominal unit.
Phrasal constructions may add some meaning of their own, and they may
add form constraints over and above the form constraints supplied by indi-
vidual constituents, which is usually speciÔ¨Åed with another template called
def-phrasal-require. It has a slot for constructional meaning, called :cxn
-meaning, and a slot for constructional form, called :cxn-form. The postposed
-genitive-cxn illustrates how the construction adds a possessive relation as
part of the meaning, a grammatical function word, namely ‚Äúof", and ordering
relations between these components:
(def-phrasal-require postposed-genitive-cxn
(?possessive-nominal-phrase
:cxn-meaning (== (possessive ?referent-nominal
?referent-pronominal))
:cxn-form (== (meets ?nominal-unit ?word-of)
(string ?word-of "of")
(meets ?word-of ?pronominal-unit))))
As a Ô¨Ånal example, we use a template called def-phrasal-linking, to establish
the linking between the external arguments of the constituents and the parent
phrase [36]. The template simply lists for each constituent which external ar-
guments are involved and if the same variable-name is used they are assumed
to be linked. The uniÔ¨Åcation operation takes care of the binding of the relevant
variables.
(def-phrasal-linking postposed-genitive-cxn
(?possessive-nominal-phrase
:args (?referent-nominal))
(?nominal-unit
:args (?referent-nominal))
(?pronominal-unit
:args (?referent-pronominal)))
4 The Operational Level
This paper advocates that the design of a lexicon and grammar for a partic-
ular language fragment should proceed in a top-down manner, starting from
an analysis at the linguistic level, identifying the semantic domains and func-
tions, and the representations and communications functions that need to be
expressed in the language and how they are expressed. It then moves to the
design level with the identiÔ¨Åcation of design patterns and the templates that
Design Methods for Fluid Construction Grammar 25
actualize them. For example, to implement agreement requires templates that
add syntactic and semantic categorizations to units and templates that specify
what agreement and percolation relations need to be established for a particular
phrase.
We now arrive at the operational level, which is the level at which constructions
with all their details have to be deÔ¨Åned. Although constructions can be deÔ¨Åned
by hand, it is much easier to do so using templates. Nevertheless it is import
to understand the operational level also, partly to be able to follow in detail
what changes a construction has made and why it does (or does not) trigger,
and partly to be able to extend or adapt the set of available templates. The
remainder of this section provides a brief introduction to the main structures
and operations at the operational level. The reader is referred to a later chapter
[10] for more details, and to the examples further discussed in this book or in
other publications [41].
4.1 Representing Transient Structures
FCG uses feature structures for representing the information that is built up
during parsing and production, thus following generally accepted practices in
contemporary computational linguistics, The so called transient structure starts
in parsing with all the information that can be extracted from the utterance
(strings, ordering, possibly phonetic information) and progressively reconstructs
semantic and syntactic structures and meanings. In production, the transient
structure contains initially only the meaning that needs to be expressed. DiÔ¨Äer-
ent constructions cover parts of this meaning, progressively building up phrasal
structures and constraining the form of the sentence until a concrete sentence
can be derived.
The feature structures used in FCG compose the linguistic structure in terms
of units with features and values. Units have names, and these names can be
bound to variables for reference inside constructions. Consequently, hierarchical
structure is represented explicitly by a feature called subunits Ô¨Ålled by names of
all subunits.
The transient structure is decomposed into a semantic pole and a syntactic
pole to improve readability and eÔ¨Éciency. The graphical representation in Fig-
ure 9 provides an example of a simple determiner-nominal phrase in (taken from
[42], which explains this example in detail). There is a list notation which re-
Ô¨Çects the internal LISP-based implementation of feature structures. Graphical
representations are constructed automatically by the FCG-system and there is
a browser for interactive and selective display (see [23]).
The same feature structure is shown in list notation in Figure 9. The unit
names are in bold and the unit features in italics. In the semantic pole, there
is a unit for top, which has one semantic subunit called nominal-phrase-12.
nominal-phrase-12 has two semantic subunits: mouse-12 and the-11. The
same unit-names are found on the syntactic pole with pending syntactic features.
Indices like 12 or 11 are there to distinguish between instances of a symbol but
do not carry meaning.
26 L. Steels
sem-subunits
top
(nominal-phrase-12)
syn-subunits
top
(nominal-phrase-12)
meaning
sem-subunits
footprints
args
sem-cat
nominal-phrase-12
((context
?context-67))
(mouse-12
the-11)
(determiner-nominal-phrase-cxn)
(?indiv-37
?context-67)
((sem-function
referring))
footprints
meaning
sem-cat
args
the-11
(the-cxn
article-determiner-cxn)
((unique-definite
?indiv-37
?base-set-81))
((determination
definite)
(sem-function
reference)
(is-countable
+))
(?indiv-37
?base-set-81)
footprints
meaning
sem-cat
args
mouse-12
(mouse-cxn
noun-nominal-cxn)
((mouse
?base-set-81
?context-67))
((is-animate
+)
(class
object)
(sem-function
identifier)
(is-countable
+))
(?base-set-81
?context-67)
sem
syn
form
syn-subunits
syn-cat
footprints
nominal-phrase-12
((meets
the-11
mouse-12))
(mouse-12
the-11)
((is-definite
+)
(number
singular)
(phrase-type
nominal-phrase))
(determiner-nominal-phrase-cxn)
form
syn-cat
footprints
the-11
((string
the-11
"the"))
((is-definite
+)
(number
singular)
(lex-cat
article)
(syn-function
determiner))
(the-cxn
article-determiner-cxn)
form
syn-cat
footprints
mouse-12
((string
mouse-12
"mouse"))
((number
singular)
(lex-cat
noun)
(syn-function
nominal))
(mouse-cxn
noun-nominal-cxn)
Fig.
9.
Graphical
display
of
a
transient
structure
when
parsing
or
producing
‚Äúthe
mouse‚Äù.
Each
box
represents
a
unit
with
its
name
and
feature
values.
All
features
of
the
semantic
poles
are
displayed
on
the
left
side
and
all
features
of
the
syntactic
poles
on
the
right
side.
Both
poles
are
shown
in
more
detail
in
Figure
10.
Design Methods for Fluid Construction Grammar 27
sem-subunits
top
(nominal-phrase-12)
meaning
sem-subunits
footprints
args
sem-cat
nominal-phrase-12
((context ?context-67))
(mouse-12 the-11)
(determiner-nominal-phrase-cxn)
(?indiv-37 ?context-67)
((sem-function referring))
footprints
meaning
sem-cat
args
the-11
(the-cxn
article-determiner-cxn)
((unique-definite
?indiv-37
?base-set-81))
((determination
definite)
(sem-function
reference)
(is-countable +))
(?indiv-37 ?base-set-81)
footprints
meaning
sem-cat
args
mouse-12
(mouse-cxn
noun-nominal-cxn)
((mouse
?base-set-81
?context-67))
((is-animate +)
(class object)
(sem-function
identifier)
(is-countable +))
(?base-set-81
?context-67)
sem
syn-subunits
top
(nominal-phrase-12)
syn
form
syn-subunits
syn-cat
footprints
nominal-phrase-12
((meets the-11 mouse-12))
(mouse-12 the-11)
((is-definite +)
(number singular)
(phrase-type nominal-phrase))
(determiner-nominal-phrase-cxn)
form
syn-cat
footprints
the-11
((string the-11 "the"))
((is-definite +)
(number singular)
(lex-cat article)
(syn-function
determiner))
(the-cxn
article-determiner-cxn)
form
syn-cat
footprints
mouse-12
((string mouse-12
"mouse"))
((number singular)
(lex-cat noun)
(syn-function nominal))
(mouse-cxn
noun-nominal-cxn)
Fig. 10. Zooming in on the semantic (top) and syntactic (bottom) poles of the transient
structure shown in Figure 9
28 L. Steels
( (top
(sem-subunits (nominal-phrase-12)))
(nominal-phrase-12
(sem-subunits (mouse-12 the-11))
(meaning ((context ?context-67)))
(args (?indiv-37 ?context-67))
(sem-cat ((sem-function referring)))
(footprints (determiner-nominal-phrase-cxn)))
(the-11
(meaning ((unique-definite ?indiv-37 ?base-set-81)))
(args (?indiv-37 ?base-set-81))
(sem-cat
((determination definite)
(sem-function reference) (is-countable +)))
(footprints (the-cxn article-determiner-cxn)))
(mouse-12
(meaning ((mouse ?base-set-81 ?context-67)))
(args (?base-set-81 ?context-67))
(footprints (mouse-cxn noun-nominal-cxn))
(sem-cat
((is-animate +) (class object)
(sem-function identifier) (is-countable +)))))
<-->
( (top
(syn-subunits (nominal-phrase-12)))
(nominal-phrase-12
(syn-subunits (mouse-12 the-11))
(form ((meets the-11 mouse-12)))
(syn-cat
((is-definite +) (number singular)
(phrase-type nominal-phrase)))
(footprints (determiner-nominal-phrase-cxn)))
(the-11
(form ((string the-11 "the")))
(syn-cat
((is-definite +) (number singular)
(lex-cat article) (syn-function determiner)))
(footprints (the-cxn article-determiner-cxn)))
(mouse-12
(form ((string mouse-12 "mouse")))
(syn-cat
((number singular) (lex-cat noun)
(syn-function nominal)))
(footprints (mouse-cxn noun-nominal-cxn))))
Design Methods for Fluid Construction Grammar 29
Feature structures in FCG do not fundamentally diÔ¨Äer from those used in other
feature-structure based formalisms. For example, part of the syntactic pole of the
transient structure in Figure 10 would be represented in many other uniÔ¨Åcation-
based formalisms as follows:
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
syn-cat
‚é°
‚é¢
‚é£
phrase-type nominal-phrase
is-deÔ¨Ånite +
number singular
‚é§
‚é•
‚é¶
syn-subunits
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
form

string "the"
	
syn-cat
‚é°
‚é¢
‚é¢
‚é¢
‚é£
is-deÔ¨Ånite +
number singular
lex-cat article
syn-function determiner
‚é§
‚é•
‚é•
‚é•
‚é¶
‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
form

string "mouse"
	
syn-cat
‚é°
‚é¢
‚é£
number singular
lex-cat noun
syn-function nominal
‚é§
‚é•
‚é¶
‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
The main diÔ¨Äerence concerns the use of names for units and the use of logic
variables for representing values of features that are unknown.
4.2 Representing Constructions
Constructions use the same representations as transient structures: They consist
of units with features and values, which are matched against transient structures
and then merged so that information present in the construction, but not yet
in the transient structure, gets added. Constructions are more abstract than
transient structures. They leave out information so that the construction matches
with a wide range of transient structures. They contain variables that can be
bound to speciÔ¨Åc values contained in a transient structure. And they may specify
partial values using a set of special operators, such as an includes operator (if
only some of the elements have to be present), a uniquely includes operator (if
a particular element can appear only once), an excludes operator (if an element
should not occur), and so on.
DiÔ¨Äerent templates build up diÔ¨Äerent elements of a construction. For exam-
ple, the lexical construction for ‚Äúmine" was deÔ¨Åned earlier using the following
templates:
30 L. Steels
(def-lex-cxn mine-cxn
(def-lex-skeleton mine-cxn
:meaning (== (context ?context)
(dialog-participant ?indiv speaker ?context))
:args (?indiv)
:string "mine")
(def-lex-cat mine-cxn
:sem-cat (==1 (sem-function possessive))
:syn-cat (==1 (lex-cat pronoun)
(person 1st)
(number singular)
(case genitive))))
The operational construction based on these templates looks as follows, with the
semantic and syntactic pole separated by a double arrow <‚Äì>:
(def-cxn mine-cxn
((?top-unit
(tag ?meaning
(meaning
(== (context ?context)
(dialog-participant ?indiv speaker ?context))))
(footprints (==0 mine-cxn lex)))
((J ?word-mine ?top-unit)
?meaning
(args (?indiv))
(footprints (==1 mine-cxn lex))
(sem-cat (==1 (sem-function possessive)))))
<-->
((?top-unit
(footprints (==0 mine-cxn lex))
(tag ?form
(form (== (string ?word-mine "mine")))))
((J ?word-mine ?top-unit)
?form
(footprints (==1 mine-cxn lex))
(syn-cat
(==1 (lex-cat pronoun)
(person 1st)
(number singular)
(case genitive))))))
In production, the construction is applied from the semantic pole to the syntactic
pole. It looks out whether a particular meaning is present in the ?top-unit
(which is the initial top unit of a transient structure). If that meaning is found,
the construction creates a new sub-unit (bound to the variable ?word-mine) and
hangs it from the top-unit on the semantic side. It also adds information about
Design Methods for Fluid Construction Grammar 31
the external arguments of the word and its semantic categorizations. On the
syntactic side, the construction creates a syntactic subunit and adds information
about the word form (the string ‚Äúmine") as well as syntactic categorizations
concerning lexical-class, person, number and case.
In parsing, the construction is applied from the syntactic pole to the seman-
tic pole. It looks out for the presence of a particular string (namely ‚Äúmine")
in the top-unit. If that is the case, the construction builds a new unit bound
to ?word-mine and hangs it from ?top-unit. The string is moved from the
form feature of the top-unit to the form feature of the new unit, and syntac-
tic categorizations are added. On the semantic side, the construction creates a
new semantic subunit and adds information about its meaning and its semantic
categorization.
Parts of this operational construction are clearly based on the elements sup-
plied by the templates: the :meaning, :string and :args come from the def-lex
-skeleton template, and the :syn-cat and :sem-cat come from the def-lex
-cat template. However, more is needed to make a construction fully operational.
Choices have to be made as to whether information is put into the semantic pole
or the syntactic pole, and if triggering the construction or additive in merging
should be conditional. Other issues concern the question of how new units are
built and how information is moved to them, and how the recursive applica-
tion of constructions is regulated. This section brieÔ¨Çy discusses some procedu-
ral annotations in operational constructions that have been designed for these
purposes.
4.3 Procedural Annotations
Procedural annotations consist of extra information supplied with a construction
to carry out structure building operations or to avoid that constructions keep
applying indeÔ¨Ånitely. Structure building requires two operations: a way to create
new units and hang them somewhere from an existing unit in the hierarchy, and
a way to associate information with the new unit, possibly by moving features
or values that were located elsewhere.
The J-operator. The J-operator is the main FCG primitive for building hi-
erarchical structure [11]. It has three arguments: a daughter-unit, a parent-unit,
and possibly a set of pending-subunits. These are either speciÔ¨Åed with concrete
names or with variables that have been bound elsewhere in the matching or
merging process. When the daughter-unit is an unbound variable at the time of
merging, a new unit will be created for it. For example, in the mine-cxn above,
the following expression evokes the J-operator.
(J ?word-mine ?top-unit)
It introduces a new daughter-unit bound to ?word-mine and hangs it as a subunit
from a parent-unit bound to ?top-unit. There are no further pending units,
otherwise they would be made subunits of the daughter-unit. The J-operator
32 L. Steels
can associate additional information with the daughter-unit. In the example of
the mine-cxn construction, the J-operator adds information about the lexical
category, person, number, and case.
The TAG-operator. The J-operator is made more versatile by introducing a
way to tag parts of a feature structure so that they can be moved elsewhere in
the transient structure. The tag-operator has two arguments: a variable, known
as the tag-variable, and a set of features and values that are bound to the tag-
variable. The normal matching process is still used to check whether the features
and values match. If a tag-variable re-occurs inside a unit governed by a J-
operator, then the structure is moved from its old position to its new position.
Here is an example. In production, the top-unit initially contains all the mean-
ings that need to be covered , and lexical constructions take those parts that
they can cover and encapsulate them in a new unit. This is done with the tag
operator, which binds the meaning of the word ‚Äúmine" and then moves into the
?word-mine unit created by the J-operator, as illustrated in the semantic pole
of the mine-cxn construction.
(tag ?meaning
(meaning
(== (context ?context)
(dialog-participant ?indiv speaker ?context))))
The meaning covered by the word is tagged and then moved from the top-unit
to the newly created unit that covers this meaning in production. The form
introduced by the word is also tagged and then moved from the top-unit to a
newly created unit in parsing.
Footprints. One of the biggest issues in language processing is the management
of the search space. This arises unavoidably in parsing because most word forms
or syntactic constraints have multiple meanings and functions, and it is often not
possible to make a deÔ¨Ånite choice until more of the sentence has been processed.
It also arises in production because there is usually more than one way to express
a particular meaning, and it is not always possible to decide fully which choice is
the most appropriate until other aspects of the sentence are worked out. Many
techniques help to avoid search whenever possible, for example, choices can be
left open as variables until enough information is available to choose their bind-
ings, or the value of a particular syntactic feature (such as the lexical-category)
can be a list of potential values from which one is then actually chosen to be the
actual value.
Adding footprints to a transient structure is another technique for avoid-
ing search and particularly the harmful recursive application of constructions.
Footprints are represented as one of the features of a unit. They are left behind
by constructions, so that other constructions (or the same construction) can see
that this construction was involved in building a particular piece of structure and
hence can refrain from application. By convention, the name of the footprint left
Design Methods for Fluid Construction Grammar 33
behind by a construction is the name of the construction itself. A construction
may also leave behind other footprints. For example, if the construction is a
member of a family of constructions, each construction leaves behind a family
footprint so that more general constructions of the same family will no longer
trigger. Another example concerns the handling of defaults. Constructions that
deal with overt cases leave behind footprints so that default construction dealing
with an unmarked case does not need to trigger anymore (see examples in [3]).
In the example given earlier, the mine-cxn construction Ô¨Årst checks whether
it has not yet already applied on the ?top-unit, so that recursive application is
avoided. Once it has applied, it leaves behind a footprint that it was involved in
building the new unit bound to ?word-mine so that there can be no recursive
application where the unit ?word-mine becomes bound to ?top-unit. Footprints
are not only useful for controlling the application of constructions. They are also
useful for a grammar designer who is inspecting transient structures in order to
Ô¨Ågure out which construction did what.
5 Conclusions
This paper introduced some of the design principles that are currently used in
Fluid Construction Grammar. We distinguished three levels of analysis: a linguis-
tic level, a design level and an operational level. The linguistic level starts from
an analysis of which semantic domains and communicative functions are relevant
for the language fragment being studied. It then investigates Ô¨Årst the functional
structure underlying sentences: which semantic functions are involved, how do
they map to syntactic functions, and how are syntactic functions expressed in
the language. Next it investigates the expression of grammatical meanings, such
as tense and aspect, using the grammar square as guidance.
The design level starts from an analysis of the major design patterns that are
used in the language fragment and then seeks to Ô¨Ånd out which templates could
be used to implement them. A template emphasises linguistic content, hiding
computational details as much as possible. Templates are translated automat-
ically to the operational level by a compilation process so that we obtain the
‚Äòreal‚Äô constructions that drive parsing and production processes. Constructions
can be written by hand, but it is much more eÔ¨Écient to do so with templates,
as later chapters with case studies show.
FCG is an attempt to capture many ideas that have been Ô¨Çoating around
in the construction grammar literature. But there are certainly still many ideas
which are not yet incorporated. For example, inheritance plays an important
role in many construction grammars but it is not a core component of FCG, and
the same phenomena are captured in other ways. FCG uses many of the same
techniques found in other uniÔ¨Åcation-based grammars, but there are also pro-
found diÔ¨Äerences. For example, FCG constructions are split into two poles which
are used diÔ¨Äerently in parsing and production, whereas HPSG would put every-
thing together in a single structure. Deeper comparisons with other attempts for
formalizing construction grammar and the relation to other uniÔ¨Åcation-based
34 L. Steels
grammars are discussed in later chapters of this book (see particularly [6]). FCG
is still a very new formalism and many issues remain to be explored. In some
cases, solutions developed in other uniÔ¨Åcation-based grammars can be nicely
translated into FCG. In other cases, FCG suggests new venues that might be
translatable to other formalisms, but this needs to be examined.
Acknowledgements. FCG has been under development for a decade with
teams at the University of Brussels (VUB AI Lab) and the Sony Computer
Science Laboratory in Paris. The primary source of funding has come from the
Sony Computer Science Laboratory with additional funding provided by the
EU-FP6 ECagents project and the EU-FP7 ALEAR project.
References
[1] Alexander, C.: The Timeless Way of Building. Oxford University Press, Oxford
(1979)
[2] Bergen, B.K., Chang, N.: Embodied Construction Grammar. In: √ñstman, J.O.,
Fried, M. (eds.) Construction Grammars: Cognitive Grounding and Theoretical
Extensions. John Benjamins, Amsterdam (2005)
[3] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[4] Carpenter, B.: The Logic of Typed Feature Structures. Cambridge University
Press, Cambridge (1992)
[5] Carroll, S., Grenier, J., Weatherbee, S.: From DNA to Diversity. Molecular Ge-
netics and the Evolution of Animal Design. Blackwell Science, Oxford (2001)
[6] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraint
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[7] Copestake, A.: Implementing Typed Feature Structure Grammars. CSLI Publica-
tions, Stanford (2002)
[8] Croft, W.: Radical Construction Grammar. Oxford University Press, Oxford
(2001)
[9] Dalrymple, M., Kaplan, R., Maxwell, J., Zaenen, A.: Formal issues in Lexical-
Functional Grammar. CSLI Publications, Stanford (1995)
[10] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[11] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[12] Gamma, E., Helm, R., Johnson, R., Vlissides, J.: Design Patterns: Elements of
Reusable Object-Oriented Software. Addison-Wesley Pub. Co., Reading (1995)
[13] Gerasymova, K.: Expressing Grammatical Meaning with Morphology: A Case
Study for Russian Aspect. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 91‚Äì122. Springer, Heidelberg (2012)
[14] Goldberg, A.E.: A Construction Grammar Approach to Argument Structure.
Chicago UP, Chicago (1995)
Design Methods for Fluid Construction Grammar 35
[15] Goldberg, A.E.: Constructions: a new theoretical approach to language. Trends in
Cognitive Sciences 7(5), 219‚Äì224 (2003)
[16] H√∂fer, S.: Complex Declension Systems and Morphology in Fluid Construction
Grammar: A Case Study of Polish. In: Steels, L. (ed.) Computational Issues in
FCG. LNCS (LNAI), vol. 7249, pp. 143‚Äì177. Springer, Heidelberg (2012)
[17] Kay, M.: Parsing in functional uniÔ¨Åcation grammar. In: Grosz, B., Spark-Jones, K.,
Webber, B. (eds.) Readings in Natural Language Processing. Morgan Kaufmann,
San Francisco (1986)
[18] Kay, P., Fillmore, C.: Grammatical constructions and linguistic generalizations:
the what‚Äôs x doing y? Language 72, 1‚Äì33 (1996)
[19] Laenzlinger, C.: French adjective ordering: Perspectives on dp-internal movement
types. Lingua 115(5), 645‚Äì689 (2000)
[20] Langacker, R.W.: Foundations of Cognitive Grammar, vol. 1. Stanford University
Press, Stanford (1987)
[21] Langacker, R.W.: A dynamic usage-based model. In: Barlow, M., Kemmer, S.
(eds.) Usage-Based Models of Language, pp. 1‚Äì63. Chicago University Press,
Chicago (2002)
[22] Levinson, S.C.: Space in Language and Cognition. In: Language, Culture and
Cognition, vol. 5. Cambridge University Press, Cambridge (2003)
[23] Loetzsch, M.: Tools for Grammar Engineering. In: Steels, L. (ed.) Computational
Issues in FCG. LNCS (LNAI), vol. 7249, pp. 37‚Äì47. Springer, Heidelberg (2012)
[24] Micelli, V.: Field Topology and Information Structure: A Case Study for Ger-
man Constituent Order. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 178‚Äì211. Springer, Heidelberg (2012)
[25] Michaelis, L.: Sign-based construction grammar. In: Heine, B., Narrog, H. (eds.)
The Oxford Handbook of Linguistic Analysis. Oxford University Press, Oxford
(2009)
[26] Michaelis, L., Lambrecht, K.: Toward a construction-based theory of language
function: The case of nominal extraposition. Language 72, 215‚Äì247 (1996)
[27] Newmeyer, F. (ed.): Language Form and Language Function. MIT Press, Cam-
bridge (1998)
[28] Pollard, C., Sag, I.A.: Head-Driven Phrase Structure Grammar. Chicago Univer-
sity Press, Chicago (1994)
[29] Sag, I., Wasow, T., Bender, E.: Syntactic Theory. A Formal Introduction. CSLI
Publications, Stanford (2003)
[30] Spranger, M., Pauw, S., Loetzsch, M., Steels, L.: Open-ended Procedural Seman-
tics. In: Steels, L., Hild, M. (eds.) Language Grounding in Robots. Springer, New
York (2012)
[31] Spranger, M., Loetzsch, M.: Syntactic indeterminacy and semantic ambiguity: A
case study for German spatial phrases. In: Steels, L. (ed.) Design Patterns in Fluid
Construction Grammar. John Benjamins, Amsterdam (2011)
[32] Stadler, K.: Chunking Constructions. In: Steels, L. (ed.) Computational Issues in
FCG. LNCS (LNAI), vol. 7249, pp. 75‚Äì88. Springer, Heidelberg (2012)
[33] Steels, L.: Language as a Complex Adaptive System. In: Schoenauer, M., Deb, K.,
Rudolph, G., Lutton, E., Merelo, J.J., Schwefel, H.-P. (eds.) PPSN 2000. LNCS,
vol. 1917, pp. 17‚Äì26. Springer, Heidelberg (2000)
[34] Steels, L.: Constructivist development of grounded construction grammars. In:
Scott, D., Daelemans, W., Walker, M. (eds.) Proceedings of ACL, pp. 9‚Äì16. ACL,
Barcelona (2004)
[35] Steels, L.: Grounding Language through Evolutionary Language Games. In: Steels,
L., Hild, M. (eds.) Language Grounding in Robots. Springer, New York (2012)
36 L. Steels
[36] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[37] Steels, L., De Beule, J., Neubauer, N.: Bnaic. Transactions of the Belgian Royal
Society for Science and Arts (October 2005)
[38] Steels, L., Kaplan, F.: Spontaneous lexicon change. In: Proceedings of COLING-
ACL 1998, pp. 1243‚Äì1250. Morgan Kaufmann, San Francisco (1998)
[39] Steels, L.: The emergence of grammar in communicating autonomous robotic
agents. In: Horn, W. (ed.) ECAI 2000: Proceedings of the 14th European Confer-
ence on ArtiÔ¨Åcial Life, pp. 764‚Äì769. IOS Publishing, Amsterdam (2000)
[40] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar.John Benjamins, Amsterdam (2011)
[41] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[42] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[43] Steels, L. (ed.): Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[44] Steels, L., van Trijp, R.: How to make construction grammars Ô¨Çuid and robust. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[45] Talmy, L.: Toward a Cognitive Semantics, Typology and Process in Concept Struc-
turing, vol. 2. MIT Press, Cambridge (2000)
[46] Tomasello, M.: Constructing a Language. A Usage Based Theory of Language
Acquisition. Harvard University Press (2003)
[47] van Trijp, R.: A design pattern for argument structure constructions. In: Steels,
L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Ams-
terdam (2011)
[48] van Trijp, R.: Feature matrices and agreement: A case study for German case. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[49] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[50] Winograd, T.: A procedural model of language understanding. In: Computation &
Intelligence, pp. 203‚Äì234. American Association for ArtiÔ¨Åcial Intelligence, Menlo
Park (1995), http://dl.acm.org/citation.cfm?id=216000.216012
[51] Woods, W.: Problems in procedural semantics. In: Pylyshyn, Z., Demopolous, W.
(eds.) Meaning and Cognitive Structure. Ablex Publishing, New York (1986)
Tools for Grammar Engineering
Martin Loetzsch
ArtiÔ¨Åcial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium
Abstract. Developing a FCG grammar can easily become very complex
when larger sets of interdependent constructions are involved and when
consequently tracking down mistakes in single constructions or analyz-
ing the overall behavior of the system becomes diÔ¨Écult. FCG supports
users in this task by providing interfaces for accessing most of its inter-
nal representations together with powerful debugging and visualization
tools. This paper will outline some of these interfaces and explain its
visualization components in detail.
1 Introduction
Fluid Construction Grammar is a formalism for deÔ¨Åning grammars along the
lines advocated by construction grammarians and a theory and implementation
on how sentences are parsed and produced using construction grammar [4]. Un-
like many other implementations of grammar formalisms, FCG does not come
with a standalone program that is started once and then provides a (possibly
graphical) user interface for editing and testing grammars ‚Äì FCG is rather a
software framework that users directly interact with. FCG is written in the
programming language Common Lisp [3], which is commonly used in artiÔ¨Åcial
intelligence and computational linguistics. The choice of Lisp makes it very easy
to adapt FCG to a variety of usage scenarios because Lisp allows for powerful
yet simple abstractions that Ô¨Çexibly wrap core mechanisms for speciÔ¨Åc uses. Lisp
makes it also easy to write macros that allow the deÔ¨Ånition of constructions by
specifying only their relevant features (and thus avoid writing redundant code).
In addition to the increased Ô¨Çexibility of use, the choice of Lisp as a pro-
gramming language means that the traditional time consuming ‚Äúedit - compile
- test cycle‚Äù (i.e. changing code, then compiling the program and then testing
it) does not exist. Instead, users load the FCG framework into a Lisp program-
ming environment and then on top of that develop and test their grammar or
multi-agent experiment. During that, the ‚ÄúLisp image‚Äù (i.e. the ‚Äúprogram‚Äù) is con-
stantly running and changes (e.g. adding constructions or changing functions)
have immediate eÔ¨Äect on the state of the system.
A minimal example of a typical interaction with FCG is shown in Figure 1
(see [5] for a Ô¨Årst introduction to FCG). The GNU Emacs text editor (shown
on the right) serves here as a Lisp environment, but any other Lisp IDE can
be used. The Emacs window contains a Lisp Ô¨Åle with a variety of Lisp expres-
sions that each are manually evaluated by the user to change the state of the
Lisp image (but such a Ô¨Åle can also be loaded and evaluated automatically as
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 37‚Äì47, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
38 M. Loetzsch
Fig. 1. Interacting with FCG. On the right, a Lisp development environment (here
GNU Emacs) containing a minimal example of using FCG is shown. The result of
evaluating some of the expressions in the example (such as adding a construction to a
set and parsing an utterance) is then visualized in real-time through a standard web
browser (here Safari, on the left).
a part of a larger application). The Ô¨Årst two expressions (asdf:operate ..)
and (in-package ..) load the FCG framework into the current Lisp image
so that from then on it can be used by the user. Then an empty construction
set is created (defparameter ..) and a monitor for visualizations is activated.
The Ô¨Åfth expression (add-cxn ...) adds a new construction to the previously
created construction set and the notiÔ¨Åcation ‚ÄúAdded red-cxn to construction-set
(1)‚Äù appears in the web browser window. Finally, the utterance ‚Äúred‚Äù is parsed
and some graphical output of FCGs processing appears in the web browser.
Changing the previously deÔ¨Åned construction or adding new constructions does
not require to repeat all the steps above because the Lisp image is still running
and thus developing a grammar is a continuous process of adding or replacing
constructions and then trying them out.
The learning curve for new users of FCG is quite high because they have to
learn how to work with a Lisp environment. However, there are detailed instruc-
tions for getting FCG running on all major platforms / Lisp implementations
and once this initial hurdle is taken, interacting with FCG becomes an inspiring
experience. Part of this experience is an extensive visualization and debugging
component, which we will introduce in Section 2 and explain in a bit more in
Section 3.
Tools for Grammar Engineering 39
2 Understanding FCG Processing
Producing or parsing utterances in FCG involves complex processes that depend
on the interplay of the involved constructions as well as often unpredictable ex-
ternal systems for discourse, semantics and learning. Consequently, understand-
ing the behavior of such processes may become quite a challenge. For example
it can be very diÔ¨Écult to track down which construction needs to be changed
when a production or parsing process fails, or to analyze which construction is
responsible for an undesired utterance or meaning. Even when the behaviour is
as expected it might be far from trivial to understand or show why this is the
case, or for example how a grammar could be further reÔ¨Åned. Furthermore, when
FCG is applied in multi-agent learning scenarios where constructions are con-
tinuously created, adapted or removed by agents or where systems for embodied
semantics provide open-ended streams of conceptual structures, the behavior of
FCG grammars can not be tested in isolation because it tightly interacts with
all these other subsystems. These sorts of diÔ¨Éculties in understanding the un-
derlying dynamics of complex software systems are a common problem in many
areas of computer science such as robotics, artiÔ¨Åcial intelligence and distributed
systems.
The probably most common approach to tackle this problem is tracing, i.e.
by printing information about what is going on to to the Lisp listener (either by
directly adding print statements to the code or by using built-in trace facilities
or other custom mechanisms). The advantages of this technique are that (1) it is
very easy to do and (2) it allows to monitor program execution at almost any level
of detail (i.e. from only the result of applying a construction set to near-complete
information including all intermediate processing steps). When the level of detail
is high however, the output rapidly becomes unmanageable: complete traces of
FCG search processes can reach hundreds of text pages. Furthermore, plain text
in a Lisp listener is not easy to read and can only be presented linearly which
makes it impractical for getting an overview of, or a ‚Äòfeeling‚Äô for, particular
dynamics of FCG.
A second method is to retrospectively analyse a search process by inspecting
Lisp objects ‚Äì either using inspector tools of Lisp environments or by directly
calling chains of accessor functions on an object. As we will explain further below,
FCG allows users to access detailed data representations of most of its internal
processing steps so that the complete chain of operations can be reconstructed.
Inspection has the advantage that it does not require to change or write any code
but on the other hand does not provide any overview of a process whatsoever.
Furthermore, accessing for example a node deep in a search process requires a
high number of manual steps and often it is unclear which one of the many
objects to inspect, which prevents inspection to be useful in many cases.
Third, many Lisp implementations and development environments provide
mechanisms for manually stepping through code either by using the built in
step facilities or by invoking the stepper directly from the code. This technique
can be very helpful for Ô¨Ånding logical mistakes in small pieces of code, but in
order to make use of stepping one has to know which part of the code to look
40 M. Loetzsch
at. Stepping through a large construction set application just for exploring its
dynamics would take hours and is thus impracticable.
A last technique is to create visualisations: they are great to get an intuition
of an algorithm‚Äôs dynamics because our mind understands graphical representa-
tions much better than text output, which is why in areas such as for example
robotics it is exceptional to even write programs without having graphical means
to verify that the system behaves as expected (ideally even for each intermedi-
ate step). Visualisations are costly, because it takes time to implement them,
but they often pay oÔ¨Ä in the long run when they become an invaluable eye into
the system‚Äôs internals. A clear disadvantage is that visual representations only
allow for a low to medium level of detail: complex data structures have to be
transformed into two-dimensional (or sometimes 3D) representations, involving
constraints such as available window size and a required visual clarity so that
the representation remains readable. Furthermore, despite many recent devel-
opments in cross-platform libraries for graphical user interfaces, there is none
that easily works in all major Common Lisp implementations and there is a lot
of overhead in dealing with windows, menus and other user interface elements,
event handling and the interaction with the actual code to monitor. Finally, FCG
processing relies on many textual (i.e. semantic structures) and hierarchical (e.g.
feature structures, search processes) data structures, which in turn are hard to
visualise. Although virtually every graphic library has means to display text on
the screen, the responsibility for arranging text blocks (estimating widths an
heights of text areas depending on available space, avoiding overlap, re-Ô¨Çowing
multi-line text) is usually in the hand of the programmer.
The implementation of the FCG formalism comes with an extensive user in-
terface (called web interface) that combines many of the advantages of the pre-
viously introduced techniques, while at the same time removing most of their
respective disadvantages. The main idea (we will go into some of the details in
the next section) is to use a normal web browser as a terminal for tracing inter-
nals of FCG. That is, information is ‚Äúprinted‚Äù in real time to the web browser
window instead of to the Lisp listener. This already has the advantage that dif-
ferent colors, text styles, backgrounds and many other graphical means can be
used to make representations more readable than if there were printed as plain
text. Second, recent advances in HTML rendering engines have made it possible
to create tree-like representations (for feature structures, search trees, etc.) that
are automatically laid out by the client browsers so the available screen space is
used as economically as possible. And third, scripting mechanisms of contempo-
rary web browsers allow to create expandable and collapsible elements so that
details of a structure or a process can be initially hidden but then be recursively
revealed if the user clicks on them, thus enabling to display the most important
information of a structure or process in a single browser window, while still pro-
viding access to the smallest details. Forth and Ô¨Ånally, current web technologies
enable to interact with FCG grammars through the browser window (e.g. ap-
plying constructions to previously selected transient feature structures with a
mouse click).
Tools for Grammar Engineering 41
top
top
Parsing "block"
Applying construction set (70) in direction
Found a solution
initial
structure top
application
process
applied
constructions
resulting
structure
top
Meaning:
((apply-class ?ref-2 ?src-2 ?class-1) (bind object-class ?class-1 block))
sem syn
initial
top
top
cxn-applied
application result
status cxn-applied
source
structure top
applied
construction
resulting
structure top
resulting
bindings
((?form-84 form ((string block-83 "block")))
(?block-unit-2 . block-83) (?top-39 . top))
added in
first merge block-83
added in
second
merge
block-83
cxn supplier :ordered-by-label
remaining labels (cat gram)
remaining cxns (right-lex speaker-lex unique-lex hearer-lex)
block-morph (morph t)
sem syn
block-morph (morph t)
sem syn
block-83 block-
lex
(lex t)
noun-
cat
(cat t)
noun-cat (cat t) block-lex (lex t) block-morph (morph t)
noun-unit-
273
footprints
meaning
ref
sem-cat
block-83
(block-lex)
((bind object-class
?class-1 block))
?class-1
((sem-function
((value ?sem-function-value-4)
(valence (identifier))))
(class (object-class)))
sem syn noun-
unit-273
block-
83
expanded search tree node
expanded unit
Fig. 2. Example output produced by the web interface. The search tree node
(block-morph) and unit (block-83) of the resulting structure have been manually
expanded.
42 M. Loetzsch
An example for such interactive visualizations is shown in Figure 2. The utter-
ance ‚Äúblock‚Äù is parsed and as a side eÔ¨Äect, a condensed visualization of the involved
processes and representations is sent to the web browser. This high-level summary
shows the utterance, the applied construction set, the initial coupled feature struc-
ture, a visualization of application search tree, the applied constructions, the Ô¨Ånal
coupled feature structure and Ô¨Ånally the resulting semantic structure are shown.
This information is already enough to get a good overview of what happened, that
is, whether the processing succeeded, which constructions were applied in which
order and what the resulting utterance or semantic structure is. Showing only this
little information has the advantage that even the processing of larger utterances
or meanings can still be visualized in a single browser window.
This information is already enough to verify whether the grammar behaves as
expected. However, when developing a set of constructions for a particular lin-
guistic example, this is usually not the case and Ô¨Ånding out which constructions
need to be changed to yield the desired result is far from trivial. FCG helps with
this by making virtually all of its internal representations and intermediate pro-
cessing results accessible through graphical representations that reveal a more
detailed (and bigger in terms of screen space) version when the user clicks on
them. For example, each node in a application search initially only shows only
the name of the applied construction (which results in a compact representation
of the search tree), but when expanded, near-complete information about the
construction application, goal tests and other internals of the application pro-
cess are shown. Concretely, as shown in the center of Figure 2, the expanded
versions of search tree nodes contain some search status information, the tran-
sient structure to which the construction was applied, the applied construction,
the resulting transient structure, bindings that show what things the variables
in the construction matched with and information about what was added to
which unit in the Ô¨Årst and second merge phase. Many of these representations
such as constructions or transient structures can in turn be further expanded,
as for example shown at the bottom of Figure 2, where the unit block-83 of
the Ô¨Ånal coupled feature structure is expanded to show all of its features. Some-
times, when a goal test requires running another construction set application,
the whole search tree of that process will be also shown within that particular
node, leading to quite deeply nested visual representations. This exploratory as-
pect of the interaction with FCG is best experienced Ô¨Årsthand and readers are
invited to try out the examples at www.fcg-net.org.
In addition to allowing users inspect most processing details of FCG, some
representations can also be manipulated through the web interface. When the
mouse is moved over the graphical representation of a construction, a coupled
feature structure, or a search node, a small menu appears that oÔ¨Äers a set of
operations on the structure:
Tools for Grammar Engineering 43
For search nodes, these operations include rendering the transient structure
of the node into an utterance or extracting its meaning, saving the actual node
or its transient structure to a global variable so that it can be accessed from
within Lisp, and restarting the search process below the node. Furthermore,
the pop-up menu of constructions contains operations for saving and printing
the construction as well as for applying the construction to a previously saved
transient structure in parsing or production. Finally, coupled feature structures
also can be saved, printed, rendered, etc. ‚Äì additionally there are operations for
applying all constructions of the construction inventory to the structure in order
to see which constructions apply and which not.
All these mechanisms help FCG users to quickly Ô¨Ånd and Ô¨Åx problems in their
grammars. For example, in order to Ô¨Ånd out why a construction that should
have been applied did not apply, the expandable graphical representations of
construction application search trees make it easy to Ô¨Ånd the last ‚Äúcorrect‚Äù tran-
sient structure, which can be saved through its menu to a global variable and
then can be compared to the construction in question side by side. The changes
to the construction are made in the Lisp editor, but as soon as the construction
is added to a construction inventory, a graphical representation of the changed
construction will appear in the web browser, where it can be applied to the
saved transient structure through its popup menu. This isolated application test
is continued until the construction behaves as expected and can be tried out
again within a complete production or parsing process.
3 The Web Interface and Monitoring System
FCG shares its visualization and monitoring mechanisms with other systems for
discourse, semantics and learning under the umbrella of the Babel2 framework
[2, 6]. The web interface is described in detail in [1] and the monitoring system
in [2, Chapter 3], but we will nevertheless outline some basic design choices and
components in this section.
The web interface is based on the HUNCHENTOOT web server that runs in
the same Lisp image as FCG/ Babel2 and is loaded automatically with FCG.
Web browsers connect to the web interface by loading an empty client page and
then content can be pushed to that page from within Lisp through an AJAX-
based client-side event loop that frequently polls the web server for new ele-
ments to display. Creating HTML elements in Lisp is a straightforward trans-
formation of s-expressions such as ((p :style "color:red") "hi!") into <p
style="color:red">hi!</p>" and with these basic mechanisms it is already
possible to create program traces that are much more readable and informa-
tive than plain text because diÔ¨Äerent colors, a multitude of font styles, sizes,
backgrounds or borders can be used.
Contemporary HTML rendering engines are extremely good in distributing
the available browser window width among recursively nested child elements,
and in re-Ô¨Çowing the layout when the window size changes or when more data
44 M. Loetzsch
Fig. 3. Example for a resizing HTML representation of a feature structure. The same
semantic pole of a transient structure is automatically rendered by the Safari web
browser to Ô¨Åt into a horizontally constrained space (top) or a more wide browser
window (bottom).
Tools for Grammar Engineering 45
is added to the page). FCGs web interface heavily exploits these abilities by
providing general mechanisms for drawing tree-like structures (such as search
trees, feature structures, constructions) in HTML. Tree nodes and horizontal
and vertical lines connecting them are created as recursively nested tables and
the web browser then takes care of Ô¨Åtting the tree in the available space and
of adjusting the width of the nodes accordingly. Furthermore, as many of FCGs
representations are Lisp s-expressions (e.g. semantic structures, feature values of
coupled feature structures), and experienced Lisp users strongly rely on proper
indentation of parentheses, the web interface can create HTML representations
of s-expressions that automatically adopt their width to the available space,
while remaining properly indented. As shown in Figure 3, this Ô¨Çexible layout of
feature structures (and other tree-like representations) results in a very eÔ¨Écient
use of (precious) browser window space.
A second key feature of the web interface is the way in which complex data
and control structures can be displayed: the level of detail of what is visualised is
not restricted by the size of the web browser window. The trick is to create sim-
pliÔ¨Åed visual representations of data that expand into a detailed version when
the user clicks on them and that collapse to their original state when clicked
a second time. As for example explained above in Section 2, for a production
or parsing process the user initially is presented with the main results of the
application process and the search tree and then can get to almost any inter-
mediate representation by clicking through the HTML elements in the client
page. Technically, the web interface internally stores for each of expandable el-
ements both a collapsed and expanded version (actually anonymous functions
are stored to avoid computing HTML code that never gets requested). The col-
lapsed version is initially sent to the client page, and when the user clicks on
the element the expanded version is requested from the Lisp side using Ajax
communication.
The use of lexical closures makes the web interface very fast and responsive,
but users may not always want the visualizations to be computed (or switch be-
tween alternative visualizations). The monitoring system of FCG/ Babel2 solves
this issue (for details see chapter 3 of [2]). The main idea is to not clutter the
source code of FCGs implementation with code that produces debug traces, but
rather to have a event/ notiÔ¨Åcation/ event handler system that separates actual
code from debugging and visualization mechanisms. For example, after each ap-
plication of a construction set, an event is triggered that notiÔ¨Åes a list of monitors
of the Ô¨Ånished application. Those monitors that are active can then handle this
event, for example by adding visualizations to the web interface. Consequently,
FCG users can switch diÔ¨Äerent visualizations on and oÔ¨Ä by activating/ deacti-
vating monitors.
Finally, advanced users of FCG and Lisp can easily create their own visu-
alizations and monitors for their speciÔ¨Åc experiments. The web interface pro-
vides mechanisms for deÔ¨Åning client side Javascript and CSS code fragments, for
replacing and appending the content of existing HTML elements, and so on.
46 M. Loetzsch
When the basic graphical capabilities of HTML are not suÔ¨Écient for certain
visualisation purposes, SVG graphics or Flash animations can of course be also
sent to the client page.
4 Conclusions
The tools for grammar engineering introduced in this chapter have changed the
way users of FCG interact with the system, not only making the experience
richer, but also more trouble-free. Meaningful processing traces allow FCG de-
velopers to debug and make sense of the formalism itself and they help FCG
users to see the eÔ¨Äects of their linguistic rules by having access to all details
of the parsing process without losing a general overview. Some dynamics that
were previously mystifying and impenetrable have cleared up and as a welcome
side-eÔ¨Äect newcomers to FCG grasp the material at a considerably faster speed
because of the way they can interact with and gradually investigate the dynam-
ics. Furthermore, having detailed visualizations is very helpful explaining the
working of FCG to other audiences ‚Äì in fact most of the graphics in this book
are visualizations created by the web interface.
Using a web server and web browsers as the main technology for designing a
user interface might seem as an unusual choice and indeed only a few years ago
it would not have been feasible to implement a system such as described here.
Although our present-day web standards are much older, they were only poorly
supported making it strenuous for web developers to ensure the interoperabil-
ity of their web sites in diÔ¨Äerent browsers. Fortunately, things have improved.
Today valid XHTML+CSS code is properly interpreted by a variety of browsers
and AJAX has become an ubiquitous technology that just works. Particularly
impressive is the way contemporary HTML rendering engines are able to lay-
out (and re-Ô¨Çow) heavily nested HTML constructs with incredible speed and
perfectly looking in almost all cases. Furthermore, not needing to rely on other
external libraries for user interfaces than (readily available) web browsers makes
the visualization component of FCG/ Babel2 very lightweight and easily em-
ployable on a wide variety of Lisp implementations and platforms.
Acknowledgements. The research in this paper was conducted at the ArtiÔ¨Åcial
Intelligence Laboratory at the Vrije Universiteit Brussel (VUB AI lab) and is
partly funded through the EU FP7 ALEAR project.
References
[1] Loetzsch, M., Bleys, J., Wellens, P.: Understanding the dynamics of complex lisp
programs. In: Proceedings of the 2nd European Lisp Symposium, Milano, Italy,
pp. 59‚Äì69 (May 2009)
[2] Loetzsch, M., Wellens, P., De Beule, J., Bleys, J., van Trijp, R.: The Babel2 manual.
Tech. Rep. AI-Memo 01-08, AI-Lab VUB, Brussels, Belgium (2008)
[3] Steele, G.L.: Common LISP: The Language, 2nd edn. Digital Press, Bedford (1990)
Tools for Grammar Engineering 47
[4] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[5] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[6] Steels, L., Loetzsch, M.: Babel: a tool for running experiments on the evolution of
language. In: NolÔ¨Å, S., Mirolli, M. (eds.) Evolution of Communication and Language
in Embodied Agents, pp. 307‚Äì313. Springer, Heidelberg (2010)
A Reflective Architecture for Robust Language
Processing and Learning
Remi van Trijp
Sony Computer Science Laboratory Paris, France
Abstract. Becoming a proÔ¨Åcient speaker of a language requires more
than just learning a set of words and grammar rules, it also implies mas-
tering the ways in which speakers of that language typically innovate:
stretching the meaning of words, introducing new grammatical construc-
tions, introducing a new category, and so on. This paper demonstrates
that such meta-knowledge can be represented and applied by reusing
similar representations and processing techniques as needed for routine
linguistic processing, which makes it possible that language processing
makes use of computational reÔ¨Çection.
1 Introduction
When looking at natural language, two striking observations immediately jump
to the mind. First, there is an extraordinary amount of diversity among the
world‚Äôs languages [10] and ‚Äòalmost every newly described language presents us
with some ‚Äúcrazy‚Äù new category that hardly Ô¨Åts existing taxonomies‚Äô [9, p. 119].
Secondly, languages are not static homogeneous entities, but rather complex
adaptive systems [24] that dynamically change over time and in which new forms
are forever emerging [11]. These observations pose strong requirements on lin-
guistic formalisms, which need to support an enormous amount of variety while
at the same time coping with the open-ended nature of language [33].
Both requirements may seem overwhelming for anyone who wants to develop
operational explanations for language, but two formalisms within the cognitive
linguistics tradition have nevertheless accepted the challenge: Fluid Construc-
tion Grammar (FCG; for handling parsing and production; see the remainder
of this volume and [26]) and Incremental Recruitment Language (IRL; a con-
straint language that has been proposed for operationalizing embodied cognitive
semantics [20]). Both IRL and FCG have the necessary expressivity for capturing
the myriad of conceptual and grammatical structures of language. FCG is based
on feature structures and matching and merging (i.e. uniÔ¨Åcation) [6, 18, 28, 32],
whereas IRL is based on constraints and constraint propagation.1
1
In order to fully appreciate the technical details of this paper, the reader is expected
to have a Ô¨Årm grasp of the FCG-system and a basic understanding of IRL. Inter-
ested readers are also advised to Ô¨Årst check [33] for learning about how problems
concerning robustness and Ô¨Çuidity are typically handled in FCG, and [4, 15] for how
that approach is implemented.
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 51‚Äì74, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
52 R. van Trijp
Both FCG and IRL are embedded in a double-layered meta-level architecture
for handling unforeseen problems and inventing novel solutions [4, 33]. This
meta-level architecture allows the implementation of computational reÔ¨Çection
[19], which is commonly deÔ¨Åned as ‚Äúthe activity performed by a system when
doing computation about (and by that possibly aÔ¨Äecting) its own computation‚Äù
[16, p. 21]. The architecture is illustrated in Figure 1. On the one hand, there
is a routine layer that handles habitual processing. On top of that, a meta-
layer tries to detect and solve problems that may occur in routine processing
through diagnostics and repairs (also called meta-layer operators). For instance,
a diagnostic may detect that the listener encountered an unknown word, while
a repair can ask the language system to perform a top-down prediction on what
kind of word it is and what its meaning might be (see [4, 33]; and the remainder
of this paper for more concrete examples). Once a repair is made, computation
resumes at the routine-layer.


routine processing
diagnostic
problem
repair
diagnostic diagnostic
diagnostic
problem
repair
meta-layer processing
Fig. 1. FCG and IRL feature a double-layered meta-level architecture. Besides a layer
for routine processing, a meta-layer diagnoses and repairs problems that may occur in
the routine layer [4].
Recent studies on the evolution of language [29, 30] have identiÔ¨Åed numer-
ous meta-layer operators that operationalize open-ended language processing for
speciÔ¨Åc domains such as agreement [3], tense-aspect [7], event structure [34, 36],
space [14, 21], and quantiÔ¨Åers [17]. However, most operationalizations imple-
ment the functions of the diagnostics and repairs in LISP code, so the language
processing system is only reÔ¨Çective in a weak sense. Figure 2 shows a typical
example of this approach in pseudo-code. The diagnostic shown in the Figure
tries to detect unknown words by looking for unprocessed strings in each last
search node (or ‚Äòleaf‚Äô) of linguistic processing. If the set of those strings contains
exactly one word, the diagnostic reports an unknown-word problem.
A ReÔ¨Çective Architecture 53
diagnostic (detect-unknown-word)
when SEARCH-NODE in PARSING is a LEAF
then get the UNPROCESSED-STRINGS from the SEARCH-NODE
when the UNPROCESSED-STRINGS contain a SINGLE-WORD
then report UNKNOWN-WORD problem
Fig. 2. Most diagnostics and repairs for IRL and FCG are implemented directly as
computational functions, whereas full reÔ¨Çection requires that IRL and FCG are their
own meta-language
This paper demonstrates that the same representation and application ma-
chinery now used at the routine language processing layer can also be used for
the meta-layer, which makes the whole system reÔ¨Çective in a strong sense. By
doing so, this paper paves the way towards experiments in which novel language
strategies emerge and become culturally shared. More speciÔ¨Åcally, this paper
proposes the following approach:
1. Diagnostics can be represented as feature structures, which can be processed
by the FCG-interpreter. Problems are detected by matching these feature
structures against other feature structures.
2. Repairs can be represented as constraint networks, which can be conÔ¨Ågured,
executed and chunked by IRL.
3. Diagnostics and repairs that exclusively operate on the linguistic level can
be associated to each other in the form of coupled feature structures and thus
become part of the linguistic inventory in their own right.
I use the term language strategy for a particular set of diagnostics and repairs (see
[31], for a more complete deÔ¨Ånition of a language strategy). Language strategies
are processed in the meta-layer and allow a language user to acquire and expand a
language system, which are the concrete choices made in a language for producing
and comprehending utterances, such as the English word-order system. Language
systems are processed in the routine layer.
2 Diagnostics Based on Matching
This section demonstrates through a series of examples how feature structures,
which are used for representing linguistic knowledge in FCG [22], can represent
diagnostics. When they are able to match with a transient structure they detect
a speciÔ¨Åc problem.
2.1 A First Example: Detecting an Unknown Word
Let‚Äôs start with one of the most common problems in deep language processing:
unknown words [1]. The key to diagnosing this problem through the FCG ma-
chinery (rather than by using a tailored LISP function) is to understand how
54 R. van Trijp
routine processing handles familiar words. As explained in more detail by [27],
FCG processing Ô¨Årst involves a transient structure, which is a temporary data
structure that contains all the information of the utterance that a speaker is
producing, or that a listener is parsing. The transient structure consists of a
semantic and a syntactic pole. Both poles comprise a set of units, which have
feature structures associated with them. The following transient structure repre-
sents the initial structure of the utterance the snark at the beginning of a parsing
task:
Example 1
((top-unit))
<-->
((top-unit
(form ((string the-unit "the")
(string snark-unit "snark")
(meets the-unit snark-unit)))))
As can be seen, both the semantic pole (above the double arrow symbol) and the
syntactic pole have a unit called top-unit. The top-unit on the semantic pole
is still empty because we‚Äôre at the beginning of a parsing task hence the listener
has not analyzed any of the words yet. The top-unit of the right pole has a form
feature, whose value contains two words and an ordering constraint (meets)
between the words. During parsing, the FCG-interpreter then tries to apply
linguistic constructions to the transient structure and, by doing so, modifying
it. For example, the following lexical entry applies for the word the:
Example 2
((?top-unit
(tag ?meaning (meaning (== (unique-entity ?entity))))
(footprints (==0 the-lex)))
((J ?the-unit ?top-unit)
?meaning
(args (?entity))
(footprints (the-lex lex))))
<-->
((?top-unit
(tag ?form (form (== (string ?the-unit "the"))))
(footprints (==0 the-lex)))
((J ?the-unit ?top-unit)
?form
(footprints (the-lex lex))))
The above lexical construction is kept simple for illustration purposes. In parsing,
all it does is look for any unit whose form feature contains the string ‚Äúthe‚Äù in its
value. If such a unit is found, the construction builds a new unit for the article
A ReÔ¨Çective Architecture 55
and moves the form to this new unit. The construction also leaves a footprint that
prevents it from applying a second time. On the semantic pole, the construction
builds a corresponding unit for the article and it adds the article‚Äôs meaning to
this new unit. So when applying the lexical construction of example 2 to the
transient structure in example 1, the transient structure is modiÔ¨Åed into the
following structure:
Example 3
((top-unit
(sem-subunits (the-unit)))
(the-unit
(meaning ((unique-entity ?entity)))
(args (?entity))
(footprints (the-lex lex))))
<-->
((top-unit
(syn-subunits (the-unit))
(form ((string snark-unit "snark")
(meets the-unit snark-unit))))
(the-unit
(form ((string the-unit "the")))
(footprints (the-lex lex))))
It is common design practice in FCG to consider the top-unit as a buÔ¨Äer that
temporarily holds all data concerning meaning (on the semantic pole) or form
(on the syntactic pole) until they are moved into their proper units by lexical
constructions. If all lexical constructions abide by this design rule, all meanings
and strings that are left in the top-unit after all constructions have been tried can
be considered as unprocessed and therefore problematic. For detecting whether
any unknown words are left, we can thus simply deÔ¨Åne a meta-level feature
structure that matches on any string in the top-unit:
Example 4
diagnostic (string)
((?top-unit
(form (== (string ?any-unit ?any-string)))
(footprints (==0 lex))))
This diagnostic looks exactly like the ‚Äòconditional‚Äô features of a lexical construc-
tion (i.e. units that need to be ‚Äòmatched‚Äô before the other features are merged by
the FCG-interpreter), except for the fact that there is a variable ?any-string
instead of an actual string, and that the feature structure cannot trigger if the
footprint lex has been left in the unit by a lexical construction.
Assume now that the FCG-system did not have a lexical construction for the
word snark, which is likely because it is an imaginary word invented by Lewis
56 R. van Trijp
Carroll for his 1876 poem The Hunting of the Snark, so routine processing gets
stuck at the transient structure of example 3. The FCG-interpreter can now
match the meta-level feature structure of example 4 with the syntactic pole of
that transient structure, which yields the following bindings:
((?any-string . "snark") (?any-unit . snark-unit) (?top-unit . top-unit))
In other words, the meta-level feature structure matches with the top-unit
and Ô¨Ånds the unknown string snark. Here, there is only one unknown word,
but if there would be multiple unknown strings, matching would yield multiple
hypotheses. This example, which is kept simple for illustration purposes, achieves
the same result as the diagnostic that was illustrated in Figure 2.
By exploiting the same feature structure representation as FCG uses for tran-
sient structures and linguistic constructions, the FCG-interpreter can be reused
without resorting to tailor-made functions. Moreover, the diagnostic explicitly
uses the design pattern shared by all lexical constructions, namely that strings
and meanings are taken from the buÔ¨Äer-like top-unit and put into their own
unit, whereas the tailored function keeps this information implicit.
2.2 Internal Agreement
A common feature of language is ‚Äòinternal agreement‚Äô, which involves two or
more linguistic units that share semantic or syntactic features such as gender or
number [3]. For example, in the French noun phrase la femme (‚Äòthe woman‚Äô),
the singular-feminine deÔ¨Ånite article la is used in agreement with the gender and
number of femme, as opposed to the singular-masculine article le as in le gar√ßon
(‚Äòthe boy‚Äô).
Assume now a grammar of French that uses phrasal constructions for handling
agreement between an adjacent determiner and noun, using the design pattern
for phrasal constructions as proposed by [25]. The schema in Figure 3 illustrates
how a DetNP-construction modiÔ¨Åes the transient structure on the left to the
resulting transient structure on the right: the construction takes the units for
the determiner and the noun and groups them together as subunits of a new
NP-unit, which has the same number and gender features as its two subunits.
Just like with lexical constructions, we can exploit the design pattern captured
in phrasal constructions for detecting problems. The diagnostic in example 5
detects whether the DetNP-construction applied successfully or not. It looks for
any unit that contains at least two subunits, and which does not contain the
feature-value pair (phrase-type nominal-phrase) (ensuring that the phrasal
construction did not apply on this unit). The two speciÔ¨Åed subunits should ‚Äòmeet‚Äô
each other (i.e. be adjacent), and they should be a determiner and a noun. Both
the determiner and the noun have a number and gender feature, but their values
are unspeciÔ¨Åed through unique variables for each unit, which allows the actual
values to diÔ¨Äer from each other.
A ReÔ¨Çective Architecture 57
top-unit
la-unit
(syn-cat
(syn-function determiner)
(number SG)
(gender F))
femme-unit
(syn-cat
(syn-function nominal)
(number SG)
(gender F))
top-unit
la-unit
(syn-cat
(syn-function determiner)
(number SG)
(gender F))
femme-unit
(syn-cat
(syn-function nominal)
(number SG)
(gender F))
DetNP-unit
(syn-cat
(phrase-type nominal-phrase)
(number SG)
(gender F))
application of
DetNP-construction
Fig. 3. The DetNP-construction groups a determiner- and noun-unit together as sub-
units of a phrasal unit
Example 5
diagnostic (internal-agreement)
((?top-unit
(syn-subunits (== ?determiner-unit ?noun-unit))
(form (== (meets ?determiner-unit ?noun-unit)))
(syn-cat (==0 (phrase-type nominal-phrase))))
(?determiner-unit
(syn-cat
(==1 (gender ?determiner-gender)
(number ?determiner-number)
(syn-function determiner))))
(?noun-unit
(syn-cat
(==1 (gender ?noun-gender)
(number ?noun-number)
(syn-function nominal)))))
Suppose the FCG-interpreter has to parse the ungrammatical utterance *le
femme. Matching the meta-level feature structure would yield the following bind-
ings for those unique variables:
((?determiner-number . SG) (?determiner-gender . M)
(?noun-number . SG) (?noun-gender . F))
From these bindings, we can infer that there is a problem with the gender
feature, because there are two diÔ¨Äerent values for both units: masculine and
feminine. The number feature, on the other hand, is singular for both units
58 R. van Trijp
because the variables ?determiner-number and ?noun-number are both bound
to the same value. Similarly, the diagnostic can detect a problem of number
(but not of gender) if it would be matched against a feature structure for the
utterance *la femmes:
((?determiner-number . SG) (?determiner-gender . F)
(?noun-number . PL) (?noun-gender . F))
Again, the diagnostic in example 5 does not require a special function, but
simply reuses the FCG-interpreter for discovering problems and providing the
FCG-system with details about where the problem is found. The diagnostic is,
however, speciÔ¨Åc to a language such as French that has internal agreement of
gender and number, but it would be almost useless for English, which does not
mark gender agreement between an article and the adjacent noun, and which
also does not mark number agreement between a deÔ¨Ånite article and a noun.
2.3 Word Order
Another widespread language strategy is based on using word order for marking
various kinds of grammatical or pragmatic functions, but there is a wide variety
in which word order constraints are applied by particular languages. For exam-
ple, Dutch is fairly free in its word order constraints but it is a so-called V2
(verb second) language, which means that (with the exception of certain con-
structions), the inÔ¨Çected verbal unit of a Dutch utterance has to be in second
position in the main clause. For example, a Dutch speaker would translate ‚ÄòYes-
terday, I went walking‚Äô as Gisteren ging ik wandelen, literally ‚Äòyesterday went I
walk‚Äô. The following meta-level feature structure is able to diagnose violations
of the Dutch V2-constraint:
Example 6
diagnostic (V2-constraint)
((?top-unit
(syn-subunits
(== ?unit-a ?unit-b ?verbal-unit))
(form (== (meets ?unit-a ?unit-b)
(meets ?unit-b ?verbal-unit))))
(?verbal-unit
(syn-cat (==1 (syn-function verbal)
(inflected? +)))))
The diagnostic uses two adjacency constraints to check whether there is any
‚Äòillegal‚Äô unit that precedes the verbal unit, which itself is identiÔ¨Åed through its
syntactic function and the inÔ¨Çection constraint. Thus if an English speaker who
learns Dutch would say *Gisteren ik ging wandelen, the diagnostic would Ô¨Ånd
matching variables for ?unit-a (the adverbial phrase gisteren ‚Äòyesterday‚Äô) and
?unit-b (the subject ik ‚ÄòI‚Äô), which means that at least one of these two units is
in the wrong position.
A ReÔ¨Çective Architecture 59
2.4 Unexpressed Meanings
Diagnostics can not only be of lexical or morphosyntactic nature, but also target
semantic properties. In dialogues it often happens that a language user cannot
remember a particular word for the meaning he wishes to express, especially
when speaking in a foreign language. This problem is equivalent to detecting
unknown words, hence we can use a similar solution on the meaning side. The
meta-level feature structure of example 7 triggers on all meanings that have been
left unprocessed by lexical constructions.
Example 7
diagnostic (meaning)
((?top-unit
(meaning (== (?predicate . ?args)))
(footprints (==0 lex))))
Suppose that FCG-processing got stuck at a transient structure that includes
the following top-unit, which contains an unprocessed temporal meaning that
states that one event happened before another one:
(top-unit
(meaning ((before ev-1 ev-2))))
Matching the meta-level structure yields the following bindings:
((?predicate . before) (?args ev-1 ev-2) (?top-unit . top-unit))
The diagnostic Ô¨Ånds out that the unexpressed meaning predicate (if one uses a
predicate calculus for handling meaning) is before. The diagnostic also uses a
dot before the variable ?args, which is a Common Lisp notation that corresponds
to ‚Äòthe rest of the list‚Äô, so ?args is bound to the remainder of the meaning
element (ev-1 ev-2). For each unexpressed meaning predicate, the diagnostic
thus returns a binding for the predicate and its arguments.
2.5 Valence
A major challenge for linguistic formalisms is the distribution of verbs (i.e. which
argument structures are compatible with which verbs). Usually, a verbal lexical
entry contains a valence feature that states which semantic (and syntactic) roles
the verb can assign to its arguments. Problems, however, arise when speakers
wish to override those constraints, as when for instance using the intransitive
verb sneeze in a Caused-Motion frame as in Pat sneezed the napkin oÔ¨Ä the table
[8, p. 3]. Assume the following meaning and semantic valence for the verb sneeze:
(meaning
(== (sneeze ?ev)
(sneezer ?ev ?sneezer)))
(sem-cat
(==1 (sem-valence
(==1 (agent ?ev ?sneezer)))))
60 R. van Trijp
Using a predicate calculus for meaning, the verb contains one predicate for the
event itself and one predicate for the participant who‚Äôs sneezing (the sneezer).
The semantic valence of the verb states that the sneezer can be categorized
in terms of the semantic role agent by repeating the variable ?sneezer for its
argument, thereby making the verb compatible with the intransitive construction
(see [35] for a detailed discussion of valence and argument structure constructions
in FCG).
The Caused-Motion construction, however, requires not only an Agent but
also a Patient and a Direction, as found in the valence of verbs that typically
express caused motion such as push and pull. There is thus a mismatch between
the valence of sneeze and the requirements of the Caused-Motion construction,
which means that the argument structure construction will not be triggered
during routine processing.
According to Goldberg [8], this problem can be solved through coercion. Gold-
berg argues that the Caused-Motion construction only speciÔ¨Åes that the Agent
is obligatory and that the other roles can be added by the construction itself on
the condition that there are no conÔ¨Çicts with the semantics of the verb. If we
want to operationalize this hypothesis, an adequate diagnostic thus needs to Ô¨Åg-
ure out the following two things. First, it has to detect that the Caused-Motion
construction failed to apply, and if so, it has to check whether the verb can
be coerced into the Caused-Motion frame if necessary. The meta-level feature
structure shown in example 8 achieves both goals.
Example 8
diagnostic (Caused-Motion)
((?top-unit
(sem-subunits
(== ?agent-unit ?verbal-unit ?patient-unit
?direction-unit))
(meaning
(== (cause-move ?ev) (causer ?ev ?agent)
(moved ?ev ?patient)
(direction ?ev ?direction)))
(footprints (==0 arg-cxn)))
(?verbal-unit
(sem-cat (==1 (sem-valence
(==1 (agent ?ev ?agent)))))
(args (?ev)))
(?agent-unit
(args (?agent)))
(?patient-unit
(args (?patient)))
(?direction-unit
(args (?direction))))
The diagnostic in example 8 matches if there is a unit whose meaning
feature contains a Caused-Motion frame. The footprints ensure that no
A ReÔ¨Çective Architecture 61
argument-structure construction has applied on this unit. The diagnostic also
veriÔ¨Åes whether all necessary units are present, and whether the semantic va-
lence of the verb contains at least the obligatory Agent-role. When matched
against a transient structure that contains the verb sneeze, the diagnostic would
thus immediately be capable of linking the sneezer-role to the causer-role in the
Caused-Motion frame through the variable ?agent.
3 Diagnostics Based on Merging
The examples in the previous sections have all used the matching facility of
the FCG-interpreter. A second way in which meta-level feature structures can
be exploited is to use merging. The merge-operation is more permissive than
matching and hence should only be used as a test for conÔ¨Çicts. In this usage, the
meta-level feature structure does not represent a particular problem, but rather
captures certain ‚Äòfelicity conditions‚Äô of a language. This means that a failure in
merging it with the transient structure reveals a violation of the constraints of
that language. Let‚Äôs take the example of internal agreement in French again. The
following meta-level feature structure checks whether the number and gender
features of a determiner and an adjacent noun agree with each other when it is
merged with a transient structure:
Example 9
diagnostic (internal-agreement-2)
((?top-unit
(syn-subunits (== ?determiner-unit ?noun-unit))
(form (== (meets ?determiner-unit ?noun-unit))))
(?determiner-unit
(syn-cat
(==1 (gender ?gender)
(number ?number)
(syn-function determiner))))
(?noun-unit
(syn-cat
(==1 (gender ?gender)
(number ?number)
(syn-function nominal)))))
The meta-level feature structure uses the same variables ?gender and ?number
for both units, indicating that the determiner and the noun need to have the
same value for both features. Merging the meta-level feature structure with the
transient structure of la femme (‚Äòthe woman‚Äô) would thus succeed because both
forms are feminine-singular. However, merging would fail for utterances such as
*le femme because the two words have diÔ¨Äerent gender values.
However, using FCG‚Äôs merging operation for diagnosing problems is less pow-
erful than using the matcher because there is less feedback: merging simply fails
without providing more information about what caused the failure. So when the
62 R. van Trijp
diagnostic of example 9 reports a problem, it cannot say whether the problem
is caused by mismatches in gender, number or both.
4 Exploiting Constraint Networks for Repairs
As explained in more detail by [4], repairs are powerful operations that try
to solve the problems detected by diagnostics. Repairs are able to modify the
inventory used in routine processing, and to restart or even repurpose a parsing
or production task. As is the case for diagnostics, most currently implemented
repairs for FCG are speciÔ¨Åc functions that look as the repair shown in Figure 4.
repair (add-meta-level-cxn problem parsing-task)
If there is an UNKNOWN-WORD in PROBLEM
then add a META-LEVEL CONSTRUCTION of UNKNOWN-WORD to GRAMMAR
and restart PARSING-TASK
else return FAILURE
Fig. 4. Most current FCG repairs are implemented as speciÔ¨Åc LISP functions
The repair handles unknown words by inserting a meta-level construction in
the linguistic inventory. Interested readers are kindly referred to [33] to learn
more about how the solution works. Roughly speaking, the meta-level construc-
tion creates a new unit for the unknown word and makes it compatible with
any semantic and syntactic speciÔ¨Åcation, which may trigger the application of
other constructions that were previously blocked. Returning to our example of
the snark, for instance, a DeterminerNominal construction can now treat snark
as a noun because it is immediately preceded by a determiner. FCG can thus
overcome the problem and continue parsing until a Ô¨Ånal transient structure is
found that passes all the ‚Äògoal tests‚Äô that decide on the adequacy of a parse result
[5].
Writing a speciÔ¨Åc function for each repair is useful for fast prototyping, but
soon becomes problematic. First, there is no uniform and coherent way of rep-
resenting and processing repairs. As a result, it largely depends on the grammar
engineer‚Äôs appreciation of particular problems whether the repair is adequate or
not. Secondly, there is no ‚Äòsafe‚Äô way of testing the consequences of a repair: re-
pairs have to ‚Äòcommit‚Äô their changes to the linguistic inventory and then restart
a process before any hidden eÔ¨Äects may pop up. Needless to say, when complex
problems need to be solved, writing adequate repairs soon involves a lot of trial
and error, even for experienced grammar engineers.
This paper proposes that the implementation of repairs should be treated as
constraint satisfaction problems, which allows the grammar engineer to deÔ¨Åne
constraints that need to be satisÔ¨Åed before a repair is allowed to commit its
changes to the inventory. For this purpose, repairs can be formulated as con-
straint networks using IRL, a constraint language that has been proposed for
A ReÔ¨Çective Architecture 63
handling conceptualization and interpretation [20], and which can be considered
as FCG‚Äôs sister formalism. The next subsection shows a Ô¨Årst example of an ‚ÄòIRL
repair‚Äô. The subsequent section then goes a step further and shows the full power
of IRL for implementing repairs.
4.1 A First Example: Repairing an Unknown Word
Assume that a diagnostic has detected the unknown word snark in the utterance
the snark. We now need to deÔ¨Åne a network of constraints that performs the same
operations as the repair function in Figure 4 and that Ô¨Årst tests the solution
instead of immediately committing any changes and restarting the parsing task.
Every IRL repair network consists of the following elements:
‚Äì An object store, which contains ‚Äòlinguistic types‚Äô such as transient structures,
constructions, meanings and strings. SpeciÔ¨Åc instantiations of each type are
called ‚Äòlinguistic instances‚Äô.
‚Äì A component store, which contains ‚Äòlinguistic operators‚Äô, which are the build-
ing blocks of each network. These operators perform speciÔ¨Åc operations on
linguistic instances, such as applying a construction, fetching the inventory
of constructions, and so on.
A possible repair network is shown in Figure 5. Every node in a repair network
evokes a speciÔ¨Åc linguistic operation, represented by the name of the opera-
tor and a list of its arguments, for instance (get-construction-inventory
?inventory). The arguments are variables (indicated by a question mark) that
are or will be bound to a linguistic instance. Binding variables to a speciÔ¨Åc
linguistic instance of a certain type is done by the special operator bind. For ex-
ample, the operation (bind string ?word snark) binds the word snark (which
is of type string) to the variable ?word. DiÔ¨Äerent operations in the network are
linked to each other through the variables. For example, the variable ?inventory
is shared by two operations. In its list notation, the network looks as follows:
(bind string ?word snark)
(get-construction-inventory ?inventory)
(apply-construction ?ts-2 ?ts-1 ?cxn ?direction)
(build-meta-level-construction ?cxn ?word)
(FCG-parse ?ts-3 ?ts-2 ?inventory)
(get-latest-transient-structure ?ts-1)
(get-process-direction ?direction)
Fig. 5. A possible IRL repair network for handling unknown words. This Ô¨Årst example
does not yet exploit the full power of IRL and uses a sequential order for the execution
of linguistic operations (with precedence relations indicated by the arrows).
64 R. van Trijp
((bind string ?word snark)
(get-construction-inventory ?inventory)
(get-latest-transient-structure ?ts-1)
(get-process-direction ?direction)
(build-meta-level-construction ?cxn ?word)
(apply-construction ?ts-2 ?ts-1 ?cxn ?direction)
(FCG-parse ?ts-3 ?ts-2 ?inventory))
An explanation of how each operator can be implemented in IRL can be found
in [20]. When described in words, the network performs the following operations:
1. Take the unknown word snark of type string (provided by a diagnostic)
and bind it to the variable ?word.
2. Get the construction inventory from the parsing task in which the problem
was detected and bind it to the variable ?inventory.
3. Get the latest transient structure from the parsing task in which the problem
was detected and bind it to the variable ?ts-1 (transient structure 1).
4. Get the processing direction (parsing or production) from the task in which
the problem was detected and bind it to the variable ?direction.
5. Build a meta-level construction using the linguistic instance bound to the
variable ?word. Bind the meta-level construction to the variable ?cxn (con-
struction).
6. Take the linguistic instances bound to the variables ?cxn (of type ‚Äòcon-
struction‚Äô), ?ts-1 (of type ‚Äòtransient structure‚Äô) and ?direction (of type
‚Äòprocess-direction‚Äô). Apply the construction to the transient structure to ob-
tain a new transient structure. Bind this new transient structure to the
variable ?ts-2.
7. Take the linguistic instances bound to ?inventory (of type ‚Äòconstruction-
inventory‚Äô) and ?ts-2 (of type ‚Äòtransient structure‚Äô). Perform a parsing task
with these linguistic instances in order to obtain a new transient structure.
Bind the Ô¨Ånal transient structure to ?ts-3.
Particular constraints can be deÔ¨Åned for each operation. For example, the oper-
ation FCG-parse only succeeds if the Ô¨Ånal transient structure passes all the goal
tests that the grammar engineer deÔ¨Åned for obtaining adequate results. Likewise,
applying a single construction is only successful if (a) the construction indeed
applies on a particular transient structure, and (b) if the resulting transient
structure passes all the ‚Äònode tests‚Äô deÔ¨Åned in the FCG-system [5].
4.2 Dataflow Repairs
The example of the previous section showed how IRL can provide the grammar
engineer with a safer way of testing the adequacy of repairs. However, the ap-
plied IRL-network still featured a simple sequential control Ô¨Çow in which there
is a Ô¨Åxed order in which the network‚Äôs constraints are executed, which does
not necessarily warrant a constraint propagation approach. This section justiÔ¨Åes
the use of IRL by showing how the formalism allows the operationalization of
A ReÔ¨Çective Architecture 65
Table 1. In a dataÔ¨Çow approach, the operator apply-construction can perform diÔ¨Äerent
computations depending on the availability of linguistic instances
Available instances Computation
- Resulting transient structure The operator can compute which construction
- Source transient structure needs to be applied (and in which direction) in
order to go from the source to the resulting
transient structure.
- Resulting transient structure The operator can compute which construction
- Source transient structure needs to be applied in order to go from the source
- Direction to the resulting transient structure.
- Resulting transient structure The operator can compute the direction of
- Source transient structure application.
- Construction
- Resulting transient structure The operator can perform a ‚Äòsanity check‚Äô to
- Source transient structure see whether application of the construction on
- Construction the source structure indeed leads to the resulting
- Direction structure.
dataÔ¨Çow repairs, in which information can propagate in any direction depending
on instance availability [23]. The main advantage of dataÔ¨Çow repairs is that they
can be used for both parsing and production at the same time.
Apply-construction. Using dataÔ¨Çow instead of control Ô¨Çow makes it possible
to develop more powerful linguistic operators. For instance, in a control Ô¨Çow
approach, the operator apply-construction (which takes four arguments: a
resulting transient structure, a source transient structure, a construction and
a process-direction; see Figure 4) requires three available instances (the source
transient structure, construction and direction) before it can return a new tran-
sient structure. In a dataÔ¨Çow approach, at least the scenarios listed in Table 1
become possible.
In principle, it is also possible to implement a scenario in which the operator
has the output transient structure and the construction as available instances in
order to compute what the source transient structure was. This scenario how-
ever requires the retroactive application of constructions, which is currently not
supported in FCG.
In sum, depending on the particular conÔ¨Åguration of instance availability, the
operators can already perform various computations and pass the results to other
operators instead of waiting for other procedures to Ô¨Ånish their work. IRL keeps
cycling through each operator until no more computation can be achieved.
Build-meta-level-construction. With the power of IRL‚Äôs dataÔ¨Çow approach comes
the possibility of anticipating diÔ¨Äerent scenarios of instance availability depend-
ing on the task that the FCG-interpreter needs to perform. For example, when
building a meta-level construction for an unknown word during parsing, the
FCG-interpreter already has the form of the new construction at its disposal.
66 R. van Trijp
Table 2. DiÔ¨Äerent scenarios of instance availability for the linguistic operator build-
meta-level-construction
Available instances Computation
- String (parsing) The operator assumes a meta-level meaning
and builds a meta-level construction. The
results are bound to the variables ?meaning and ?cxn.
- Meaning (production) The operator assumes a meta-level form
and creates a new construction. The results
are bound to the variables ?word and ?cxn.
- Meaning The operator builds a meta-level construction
- String and binds it to the variable ?cxn.
The same function, however, would also be useful for a problem in production in
which the FCG-interpreter has a novel meaning to express but no corresponding
form yet. A new ‚Äòcall pattern‚Äô for the operator that allows the meaning and form
to be speciÔ¨Åed looks as follows:
(build-meta-level-construction ?cxn ?meaning ?word)
The operator now needs to be implemented in such a way that it can handle
at least the situations listed in Table 2. Now that the principle and power of
dataÔ¨Çow repairs are clear, it is time to change the IRL repair of Figure 5 into
a repair that can be applied in both parsing and production. Such a repair is
shown in Figure 6. The linking lines between operations in the Ô¨Ågure do not have
arrows anymore, which illustrates the dataÔ¨Çow approach. The bind operations
are shown in dark grey and italics to indicate that their availability depends on
whether FCG is producing or parsing an utterance.
Apart from the new call pattern for build-meta-level-construction, the
operator FCG-parse has been replaced by the more general operator FCG-apply.
As opposed to FCG-parse, this operator takes a fourth argument, which is the
direction of processing: from meaning to form, or from form to meaning. The
direction is provided by the operator get-process-direction, which fetches
the direction from the task that the FCG-interpreter is performing. In its list
notation, the network looks as follows (the bind operations are left out; these
have to be provided by the diagnostics):
((get-construction-inventory ?inventory)
(get-latest-transient-structure ?ts-1)
(get-process-direction ?direction)
(build-meta-level-construction ?cxn ?meaning ?word)
(apply-construction ?ts-2 ?ts-1 ?cxn ?direction)
(FCG-apply ?ts-3 ?ts-2 ?inventory ?direction))
A ReÔ¨Çective Architecture 67
(bind string ?word snark)
(get-construction-inventory ?inventory)
(apply-construction ?ts-2 ?ts-1 ?cxn)
(build-meta-layer-construction ?cxn ?meaning ?word)
(FCG-apply ?ts-3 ?ts-2 ?inventory ?direction)
(get-latest-transient-structure ?ts-1)
(bind meaning ?meaning new-prototype)
(get-process-direction ?direction)
Fig. 6. A dataÔ¨Çow repair. This IRL network implements the solution of a meta-level
construction for both parsing and production. The bind operations for meaning and
form are shown in grey italic because their availability depends on the direction of
processing.
5 Diagnostics and Repairs as Coupled Feature Structures
The previous two sections have shown how FCG and IRL can be exploited for
representing and processing meta-level operators. The approach can readily be
applied in the current formalisms without needing any extensions. One limitation
of the current implementation, however, is that the repair of a problem involves
a lot of (computational) red tape: Ô¨Årst, a diagnostic needs to be implemented
that operates on certain predeÔ¨Åned situations. If the diagnostic detects issues
in processing, it needs to instantiate a problem, which subsequently triggers
one or more repairs [4]. Using problems as ‚Äòmediators‚Äô between diagnostics and
repairs allows for a lot of Ô¨Çexibility, but it would often be much more eÔ¨Écient
to implement a ‚Äòquick Ô¨Åx‚Äô by directly coupling a repair to a diagnostic.
This section explores a way in which meta-level operators can be directly
associated to each other in the form of coupled feature structures, thereby repre-
senting them in the same way as transient structures and constructions. In the
remainder of this paper, I will use the term Ô¨Åx for the association of a diagnostic
and an IRL-repair, because they are meant to be eÔ¨Écient solutions that blend in
seamlessly with routine processing. All of the examples presented in this section
have been computationally implemented in a proof-of-concept fashion and are
therefore not (yet) part of the current FCG implementation.
5.1 Coupled Feature Structures
In FCG, both transient structures and constructions use the same feature
structure representation, which is implemented in CLOS (Common Lisp Object
68 R. van Trijp
System; see [13]). A coupled-feature-structure is the base class for both,
which has a left pole and a right pole:
Definition 1.
class coupled-feature-structure
Description An association of two feature structures.
Slots left-pole
right-pole
Transient structures are direct instantiations of coupled feature structures. For
each pole, it can be speciÔ¨Åed which domain it belongs to: semantic or syn-
tactic. By default, the left pole is semantic and the right pole is syntactic. A
construction is a subclass of a coupled-feature-structure that contains
additional slots that are relevant for their application, but which do not mat-
ter for our current purposes. The FCG-interpreter uses the domain of a pole of
a construction to decide whether it should operate on the semantic or on the
syntactic pole of a transient structure.
In order to integrate a meta-level Ô¨Åx into FCG-processing, we need to deÔ¨Åne
another subclass of a coupled-feature-structure, which inherits a left pole
and a right pole. Diagnostics are contained in the right pole (as they can be
considered as the ‚Äòform‚Äô of a problem) and repairs go in the left pole (as they
are the ‚Äòmeaning‚Äô of a problem). In principle, no additional slots are required,
but here we include three slots called name, domain and score:
Definition 2.
class fix subclass of
coupled-feature-structure
Description A coupling of a diagnostic and a repair.
Slots name
domain
score
The name of a Ô¨Åx is a symbol for identifying it. The slot score could potentially
be exploited to orchestrate a competition between diÔ¨Äerent Ô¨Åxes if there are mul-
tiple ways of repairing the same problem, or if there are diÔ¨Äerent problems that
try to exploit the same repair. The domain slot speciÔ¨Åes whether the diagnostic
of the Ô¨Åx should operate on the semantic or the syntactic pole of a transient
structure.
5.2 Extending FCG-Apply
Let‚Äôs return to the problem of Pat sneezed the napkin oÔ¨Ä the table, where the
speaker wishes to express a Caused-Motion frame using the intransitive verb
sneeze, whose valence is incompatible with the requirements of the Caused-
Motion construction. However, coercing verbs into the Caused-Motion frame
is a recurrent and productive pattern in English [8], hence it is worthwhile to
implement a fix that Ô¨Årst decides whether coercion is needed and indeed pos-
sible (i.e. whether the verb can be coerced), and if so, immediately performs
coercion.
A ReÔ¨Çective Architecture 69
irl-repair network
((bind arg-cxn ?cxn caused-motion-cxn)
(get-latest-transient-structure ?ts-1)
(get-match-bindings ?bindings)
(coerce-cxn ?ts-2 ?ts-1 ?cxn ?bindings))
?top-unit
------------------------------------------------
sem-subunits
(== ?agent-unit ?patient-unit
?direction-unit
?event-unit)
------------------------------------------------
meaning
(== (cause-move ?ev)
(causer ?ev ?agent)
(moved ?ev ?patient)
(direction ?ev ?direction))
------------------------------------------------
footprints
(==0 arg-cxn)
?direction-unit
----------------------------------------------
args
(== ?direction)
?agent-unit
----------------------------------------------
args
(== ?agent)
?event-unit
----------------------------------------------
sem-cat
(==1 (sem-valence
(==1
(agent ?ev ?agent))))
?patient-unit
----------------------------------------------
args
(== ?patient)
Fig. 7. This ‚ÄòÔ¨Åx‚Äô associates a diagnostic (right pole) with a repair (left pole). The
diagnostic Ô¨Årst checks the need and opportunity for coercion. The repair then performs
coercion, thereby exploiting the bindings obtained by matching the diagnostic.
We have already deÔ¨Åned a meta-level feature structure in example 8 that is
capable of detecting the need and opportunity for coercion: if no argument struc-
ture construction has been applied, the diagnostic checks whether the speaker
wishes to express the Caused-Motion frame and whether the verb can at least
assign the Agent-role to one of its arguments, which is the only obligatory se-
mantic role. If so, the diagnostic is supposed to report a problem. In a fix,
however, the repair is immediately triggered. Figure 7 shows how the diagnostic
and repair are coupled to each other, with the diagnostic on the right and the
repair on the left (both in a graphical representation). In order for the fix to
be applied, the method fcg-apply (which is used for applying constructions)
needs to specialize on applying a fix to a transient structure. This specialized
method looks as follows:
FCG-apply (fix transient-structure)
if the DOMAIN of FIX is SEMANTIC
then MATCH the DIAGNOSTIC of FIX
with SEMANTIC-POLE of TRANSIENT-STRUCTURE
else MATCH it with SYNTACTIC-POLE of TRANSIENT-STRUCTURE
if MATCH is found
then EXECUTE the IRL REPAIR NETWORK of FIX and RETURN RESULT
else do nothing
70 R. van Trijp
All Ô¨Åxes can be applied using this specialized method. Interested readers can
check a detailed discussion of how FCG achieves coercion in [33]. Summarizing
in words, the repair needs to perform the following linguistic operations:
1. Bind the Caused-Motion construction to the variable ?cxn. This is already
possible because the fix implements a construction-speciÔ¨Åc solution.
2. Get the latest transient structure (against which the diagnostic was matched)
and bind it to ?ts-1.
3. Get the bindings obtained from matching the diagnostic pole, and bind that
information to the variable ?bindings.
4. Coerce the construction bound to ?cxn into the transient structure bound to
?ts-1, using the bindings bound to ?bindings, to obtain a new transient-
structure. Bind that structure to ?ts-2.
5. If the repair is successful, return the result as a new search node so FCG can
continue routine processing.
5.3 Advantages and Issues of Fixes
Besides eÔ¨Éciency and the blending of Ô¨Åxes with routine processing, one of the
main advantages of a fix is that the bindings obtained from matching the diag-
nostic against the transient structure can be passed to other linguistic operators.
For example the operator coerce-cxn performs a powerful operation that skips
FCG‚Äôs matching phase and tries to merge both poles of a construction with a
transient structure [33]. Without the inhibitive constraints of matching, how-
ever, there is always the danger of an explosion of the possible merge-results,
which is exactly the reason why other precision-grammar formalisms that do
not have a matching phase implement additional constraints on the uniÔ¨Åcation
of feature structures [12, p. 437]. By passing the match-bindings to coerce-cxn,
improbable coercions can be ruled out. Moreover, if the IRL-repairs are treated
as feature structures, they can be matched and merged as well, which opens up
the possibility of enriching the repairs with additional information in the form
of feature structures.
The most natural way of applying a meta-level Ô¨Åx is to Ô¨Årst detect prob-
lems by matching the diagnostic against a transient structure and then solving
the problem by executing the IRL repair network. However, just like linguistic
constructions are bidirectional, Ô¨Åxes can in principle be applied in the other di-
rection as well. For instance, if a speaker introduces a novelty in conversation,
the listener might infer why he did so (i.e. detect what the speaker‚Äôs problem
was) by recognizing which repair was performed by the speaker. The prospects
of reasoning over Ô¨Åxes for learning and robust language processing is in itself an
exciting new research avenue that needs closer examination in future work.
In sum, it is technically speaking possible to blend meta-level Ô¨Åxes with routine
processing: all that is required is an additional class fix and an fcg-apply
method that specializes on this new class. However, blending Ô¨Åxes with routine
processing requires more control on when a Ô¨Åx is allowed to Ô¨Åre: the Ô¨Åx in Figure 7
should only be applied after routine processing has tried all argument structure
A ReÔ¨Çective Architecture 71
constructions, and likewise, a Ô¨Åx that would insert a meta-level construction
for handling unknown words should only be executed after the application of
‚Äònormal‚Äô lexical constructions. Fortunately, FCG already provides various ways
in which the application of constructions (and Ô¨Åxes) can be regulated, such
as specializing the search algorithm [5], using dependency networks [37], or by
treating Ô¨Åxes as ‚Äòdefaults‚Äô using construction sets [2].
6 Discussion and Conclusion
This paper has demonstrated how the same representations and processing tech-
niques that support routine language processing can be reused for implementing
diagnostics and repairs, which makes it possible that language processing makes
use of strong computational reÔ¨Çection. All of the discussed examples have been
fully implemented; most of them without needing any extensions to the exist-
ing computational frameworks of FCG and IRL. The approach adopted in this
paper has both practical and scientiÔ¨Åc merits: it oÔ¨Äers new ways for grammar
engineers to operationalize their hypotheses, and it paves the way to research on
how language strategies can be culturally acquired by autonomous agents.
The Ô¨Årst set of examples demonstrated how diagnostics can be represented
as feature structures, which can be matched against transient structures by the
FCG-interpreter. Using feature structures provides a uniform way of representing
linguistic knowledge in transient structures, constructions and diagnostics, which
potentially allows diagnostics to be directly abstracted from recurrent patterns
and structures of a particular language.
Next, I have shown how repairs can be represented as constraint networks us-
ing IRL. Such repairs consist of linguistic operators (such as coercion) that per-
form operations on linguistic instances (such as constructions). There are three
main advantages of using this approach. First, the dataÔ¨Çow of IRL constraints
allows the same repair to work for both production and parsing. Secondly, IRL
provides grammar engineers with a coherent and safer way of implementing and
testing adequate repairs. Finally, the use of IRL allows future research to fo-
cus on the origins of culturally acquired repairs by letting IRL autonomously
compose networks of linguistic operations and chunking successful networks.
The Ô¨Ånal part has shown how diagnostics and repairs can be coupled to each
other and become a meta-level ‚ÄòÔ¨Åx‚Äô for processing problems. Using a small ex-
tension to the FCG-system for handling associations of diagnostics and repairs,
Ô¨Åxes can blend in with routine processing and eÔ¨Éciently handle problems im-
mediately as they occur. Future research needs to focus on how associations of
diagnostics and repairs can marry the strengths of constraint networks (IRL)
and feature structures (FCG) in a more powerful way.
Acknowledgements. This research was conducted at and funded by the Sony
Computer Science Laboratory Paris, with additional funding from the EU FP7
Alear project. I would like to thank Luc Steels, director of the VUB AI-Lab at
the Vrije Universiteit Brussel and Sony CSL Paris, for his invaluable feedback
72 R. van Trijp
and pioneering ideas. I also thank my colleagues for their support, in particular
Katrien Beuls for her courtesy in allowing me to use Figure 1, Kevin Stadler for
his comments, and Joachim De Beule (whose earlier work on FCG included a
system of ‚ÄòÔ¨Åxes‚Äô that inspired this research). All remaining errors are of course
my own.
References
[1] Baldwin, T., Beavers, J., Bender, E.M., Flickinger, D., Kim, A., Oepen, S.: Beauty
and the beast: What running a broad-coverage precision grammar over the BNC
taught us about the grammar ‚Äì and the corpus. In: Kepser, S., Reis, M. (eds.)
Linguistic Evidence: Empirical, Theoretical, and Computational Perspectives,
pp. 49‚Äì69. Mouton de Gruyter, Berlin (2005)
[2] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[3] Beuls, K., Steels, L., H√∂fer, S.: The emergence of internal agreement systems. In:
Steels, L. (ed.) Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[4] Beuls, K., van Trijp, R., Wellens, P.: Diagnostics and Repairs in Fluid Construction
Grammar. In: Steels, L., Hild, M. (eds.) Language Grounding in Robots. Springer,
New York (2012)
[5] Bleys, J., Stadler, K., De Beule, J.: Search in linguistic processing. In: Steels, L.
(ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Amster-
dam (2011)
[6] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[7] Gerasymova, K., Spranger, M.: An Experiment in Temporal Language Learning.
In: Steels, L., Hild, M. (eds.) Language Grounding in Robots. Springer, New York
(2012)
[8] Goldberg, A.E.: A Construction Grammar Approach to Argument Structure.
Chicago UP, Chicago (1995)
[9] Haspelmath, M.: Pre-established categories don‚Äôt exist ‚Äì consequences for lan-
guage description and typology. Linguistic Typology 11(1), 119‚Äì132 (2007)
[10] Haspelmath, M., Dryer, M.S., Gil, D., Comrie, B. (eds.): The World Atlas of
Language Structures. Oxford University Press, Oxford (2005)
[11] Hopper, P.: Emergent grammar. BLC 13, 139‚Äì157 (1987)
[12] Jurafsky, D., Martin, J.H.: Speech and Language Processing. An Introduction to
Natural Language Processing. In: Computational Linguistics, and Speech Recog-
nition. Prentice Hall, New Jersey (2000)
[13] Keene, S.: Object-Oriented Programming in Common Lisp: A Programmar‚Äôs
Guide to CLOS. Addison-Wesley, Boston (1988)
[14] Loetzsch, M., van Trijp, R., Steels, L.: Typological and Computational Investi-
gations of Spatial Perspective. In: Wachsmuth, I., Knoblich, G. (eds.) Modelling
Communication 2008. LNCS (LNAI), vol. 4930, pp. 125‚Äì142. Springer, Heidelberg
(2008)
[15] Loetzsch, M., Wellens, P., De Beule, J., Bleys, J., van Trijp, R.: The babel2 manual.
Tech. Rep. AI-Memo 01-08, AI-Lab VUB, Brussels (2008)
A ReÔ¨Çective Architecture 73
[16] Maes, P.: Issues in computational reÔ¨Çection. In: Maes, P., Nardi, D. (eds.) Meta-
Level Architectures and ReÔ¨Çection, pp. 21‚Äì35. Elsevier, Amsterdam (1988)
[17] Pauw, S., Hilferty, J.: The emergence of quantiÔ¨Åers. In: Steels, L. (ed.) Experiments
in Cultural Language Evolution. John Benjamins, Amsterdam (2012)
[18] Santib√°√±ez, J.S.: A Logic Programming Approach to Parsing and Production in
Fluid Construction Grammar. In: Steels, L. (ed.) Computational Issues in FCG.
LNCS (LNAI), vol. 7249, pp. 239‚Äì255. Springer, Heidelberg (2012)
[19] Smith, B.C.: Procedural ReÔ¨Çection in Programming Languages. Ph.D. thesis, Mas-
sachusetts Institute of Technology, Cambridge MA (1982)
[20] Spranger, M., Pauw, S., Loetzsch, M., Steels, L.: Open-ended Procedural Seman-
tics. In: Steels, L., Hild, M. (eds.) Language Grounding in Robots. Springer, New
York (2012)
[21] Spranger, M., Steels, L.: Emergent functional grammar for space. In: Steels, L.
(ed.) Experiments in Cultural Language Evolution. John Benjamins, Amsterdam
(2012)
[22] Steels, L., De Beule, J., Wellens, P.: Fluid Construction Grammar on Real Robots.
In: Steels, L., Hild, M. (eds.) Language Grounding in Robots. Springer, New York
(2012)
[23] Steels, L.: The emergence of grammar in communicating autonomous robotic
agents. In: Horn, W. (ed.) Proceedings of the 14th European Conference on Arti-
Ô¨Åcial Intelligence (ECAI), pp. 764‚Äì769. IOS Press, Berlin (2000)
[24] Steels, L.: Language as a Complex Adaptive System. In: Schoenauer, M., Deb, K.,
Rudolph, G., Lutton, E., Merelo, J.J., Schwefel, H.-P. (eds.) PPSN 2000. LNCS,
vol. 1917, pp. 17‚Äì28. Springer, Heidelberg (2000)
[25] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[26] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[27] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[28] Steels, L.: Design Methods for Fluid Construction Grammar. In: Steels, L. (ed.)
Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 3‚Äì36. Springer, Hei-
delberg (2012)
[29] Steels, L. (ed.): Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[30] Steels, L.: Modeling the cultural evolution of language. Physics of Life Reviews
(2011)
[31] Steels, L.: Self-organization and selection in cultural language evolution. In: Steels,
L. (ed.) Experiments in Cultural Language Evolution. John Benjamins, Amster-
dam (2012)
[32] Steels, L., De Beule, J.: Unify and Merge in Fluid Construction Grammar. In:
Vogt, P., Sugita, Y., Tuci, E., Nehaniv, C.L. (eds.) EELC 2006. LNCS (LNAI),
vol. 4211, pp. 197‚Äì223. Springer, Heidelberg (2006)
[33] Steels, L., van Trijp, R.: How to make construction grammars Ô¨Çuid and robust. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[34] van Trijp, R.: Grammaticalization and semantic maps: Evidence from artiÔ¨Åcial
language evolution. Linguistic Discovery 8(1), 310‚Äì326 (2010)
74 R. van Trijp
[35] van Trijp, R.: A design pattern for argument structure constructions. In: Steels,
L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Ams-
terdam (2011)
[36] van Trijp, R.: The Emergence of Case Systems for Marking Event Structure. In:
Steels, L. (ed.) Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[37] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
Chunking Constructions
Kevin Stadler
ArtiÔ¨Åcial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium
Abstract. Compositionality is a core property of human languages that
sets them apart from other communication systems found in the animal
world. But psycholinguistic evidence indicates that humans do not al-
ways decompose complex expressions in language processing. Redundant
representations of compositional structure appear to be necessary to ac-
count for human linguistic capacities, a fact that should be reÔ¨Çected in
any realistic language processing framework. This chapter presents an
algorithm for dynamically combining multiple constructions into a sin-
gle chunk in Fluid Construction Grammar. We further investigate where
cases of spontaneous combinations of productive constructions occur in
natural language, and discuss the relevance of redundant representations
for experiments on artiÔ¨Åcial language evolution.
1 Introduction
Compositionality is one of the deÔ¨Åning properties of human languages. Being
able to use productive rules to combine words into complex expressions gives rise
to the uniquely human capacity to easily communicate previously unexpressed
meanings. Consequently, it is these compositional rules which have been at the
center of investigations in mainstream linguistic theory for the last few decades,
with idiosyncratic properties of particular expressions or lexical items pushed to
the periphery of linguistic theory.
But psycholinguistic evidence indicates that humans make use of a signiÔ¨Åcant
amount of direct access to compositional structures, even for perfectly productive
and transparent combinations which would be analysed as compositional by
a linguist [9]. This intriguing Ô¨Ånding, which is at odds with the very formal
and fully generalising dogma of generative grammar [8], has sparked interest
in the question of what the productive units of language really are, and why.
Computational models have helped address this question, with grammar learning
reframed as a problem of Ô¨Ånding the optimal encoding balance between storage
and computation (i.e. a tradeoÔ¨Ä between machine-level resources [23]), or the
ability to predict future novelty versus future reuse in order to best account for
the linguistic data observed [11].
What these models still share with the generative paradigm is their reductive
stance in linguistic description, also coined the ‚Äúrule/list fallacy‚Äù [7] ‚Äì the as-
sumption that any kind of linguistic knowledge would have to be either stored
in an autonomous lexical entry or be derived productively via rule, but not
both. In a usage-based account on the other hand, knowledge about particular
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 75‚Äì88, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
76 K. Stadler
instances is never generalised away, speciÔ¨Åc experiences are stored while at the
same time giving rise to more general, productive patterns [1]. Formal and com-
putational models of language should therefore not only require the possibility
of having multiple representations to account for the same compositional struc-
tures [10], but consequently also a theory and mechanisms which can eÔ¨Éciently
handle and make use of these ‚Äôredundancies‚Äô.
In cognitive linguistics, this need for multiple representations has been coun-
tered by approaches such as Construction Grammar [5]. Their uniform represen-
tation of linguistic knowledge signiÔ¨Åes not only that the boundary between pure
lexical entries and compositional rules (such as grammatical constructions) is
gradual rather than abrupt. The fact that all linguistic items ‚Äì lexical, idiomatic
and syntactic ‚Äì are stored and retrieved from the same linguistic inventory, the
constructicon, also lends itself to the idea of co-maintaining representations of
the same structure at many diÔ¨Äerent levels of abstraction.
What characterises these multiple representations is that they are not a static
immutable representation of our language capacity but that they can be derived
and updated dynamically. During interactive dialogue, for example, humans ex-
hibit a strong tendency for routinisation [12]: when a compositional phrase is
used with a speciÔ¨Åc meaning in discourse, it is likely to be adopted by the con-
versation partner and become a routine, a strong convention for the duration of
a conversation. But such routines are more than just a temporary phenomenon
of dialogue. Depending on factors such as frequency or saliency they might also
persist beyond the scope of a conversation and leave a permanent trace in a
human‚Äôs linguistic inventory [1].
While such mechanisms have already been proposed in the theoretical litera-
ture, we want to bring these models to a next level by describing a computational
algorithm of how to dynamically derive holistic routines in Fluid Construction
Grammar [17]. The following section presents a formal deÔ¨Ånition of the algorithm
which can be used to chunk constructions, with reference to the computational
concepts employed by FCG. Section 3 discusses consequences of using multiple
representations and handling and exploiting redundant information in the lin-
guistic inventory. Section 4 addresses not only the repercussions of the approach
for artiÔ¨Åcial language evolution experiments but also potential applications in
natural language processing tasks, followed by the conclusion.
2 Chunking in Fluid Construction Grammar
For the remainder of this article we will use the simple example phrase ‚Äúthe
pretty dog‚Äù to illustrate the workings of the algorithm. The example is highly
simpliÔ¨Åed and we make no claim about the best or most realistic linguistic repre-
sentation of the example phrase. For our purposes, we only require a very simple
grammar with the three lexical constructions (the-cxn, pretty-cxn and dog-cxn)
as well as two grammatical constructions to link the adjective to the noun
(adjective-noun-cxn) as well as the article to the noun phrase (article-np-cxn).
While we assume familiarity with the basic concepts of Fluid Construction
Grammar, we brieÔ¨Çy recapitulate the core concepts employed by FCG before
Chunking Constructions 77
presenting the chunking algorithm. For a more detailed account of the construc-
tion application process in FCG we kindly refer the interested reader to [17] as
well as the individual articles referenced throughout this section.
Figure 1 shows the adjective-noun-cxn from the example phrase which repre-
sents the coupling of a speciÔ¨Åc semantic structure on the left with its syntactic
representation on the right. The construction expresses the association of two sib-
ling units (an adjective and a noun) under one overarching unit. On the semantic
pole, the construction establishes variable equality between the respective refer-
ents of the units‚Äô semantic predicates by using the same ?ref variable. On the
syntactic pole on the right, this operation is expressed by a form feature which
speciÔ¨Åes that the form content of the adjective-unit has to directly precede the
form content of the noun-unit.
Of the units visible in the example construction, we will refer to the Ô¨Årst
three (above the dashed line) as the match units of the construction, since they
have to unify with the transient feature structure during the matching phase
of FCG construction application [18]. The transient feature structure, which
captures FCG‚Äôs intermediate processing structure, has to fulÔ¨Åll the constraints
expressed within the match units in order for the construction to apply. In the
case of the example construction they assert that the lexical categories (lex-cat)
of the two units which are combined are adjective and noun, respectively. They
stand in contrast to the J-units (below the dashed line) which are the core
component of FCG responsible for building hierarchy [3]. Their contents are
ignored during the initial matching phase but are merged in during the second
phase of construction application, which allows the creation of new units on both
poles.
2.1 Terminology
The chunking algorithm presented here can be used to combine a collection of
co-occurring constructions into one holistic chunked construction which has as
its main property that its application results in exactly the same changes to
the FCG feature structure as if all of its constituent constructions had applied
consecutively. To determine which constructions are candidates for such a chunk-
ing operation, the algorithm builds on the networks of application dependencies
which can be tracked by FCG [22]. An example of such a dependency network
for the example phrase ‚Äúthe pretty dog‚Äù can be seen in Figure 2. The network
captures the dependencies between the constructions, i.e. it shows which con-
structions could only apply because of material that was merged in by earlier
constructions. Note that the conditions are not explicitly expressed in the net-
works, and usually much more general than visible in the speciÔ¨Åc examples. The
adjective-noun-cxn for example can take as its constituents any units with the
lexical categories adjective and noun, respectively.
The relationships captured by the dependency networks provide the basis for
the chunking algorithm, since it only makes sense to chunk together construc-
tions which actually interact in construction application, i.e. they merge in or
78 K. Stadler
sem-subunits
?top-unit
(?adjective-unit
?noun-unit)
syn-subunits
tag ?form
?top-unit
adjective-noun-cxn
?top-unit
(?adjective-unit
?noun-unit)
(form
(==
(meets
?adjective-unit
?noun-unit)))
?top-unit
referent
?adjective-unit
?ref
referent
?noun-unit
?ref
sem syn
syn-cat
?adjective-unit
(==1
(lex-cat
adjective))
syn-cat
?noun-unit
(==1
(lex-cat noun))
referent
?adjective-
noun-unit
?ref
?adjective-unit
?noun-unit
syn-cat
?adjective-noun-unit
 ?form
(==1
(lex-cat
noun-phrase))
?adjective-unit
?noun-unit
tag ?meaning
?top-unit
(meaning (== (pretty ?ref)))
tag ?form
?top-unit
pretty-cxn
?top-unit
(form (== (string ?pretty-unit "pretty")))
?top-unit
sem syn
referent
?pretty-unit
 ?meaning
?ref syn-cat
?pretty-unit
 ?form
(==1 (lex-cat adjective))
Fig. 1. Two of the original constructions required to parse or produce the example
phrase. Above: the phrasal adjective-noun-cxn which consists of three match units
(above the dotted line) and one J-unit (below) on each pole. The match units match
onto the adjective and noun units as well as their parent unit, while the J-unit is used
to introduce hierarchy into the transient feature structure. Below: the simple lexical
pretty-cxn with just one match unit matching on the simple semantic predicate pretty
and its corresponding string representation, and one J-unit to manipulate the feature
structure accordingly.
article-np-cxn
the-cxn adjective-noun-cxn
pretty-cxn dog-cxn
Fig. 2. The construction dependency network [22] for parsing the example phrase
‚Äúthe pretty dog‚Äù, using three lexical constructions as well as two grammatical ones
(adjective-noun-cxn and article-np-cxn). Note that the ordering of constructions
is only for clariÔ¨Åcation, the exact ordering of constituents is not dependent on the or-
dering of construction applications. The direction of processing is bottom-up (i.e. the
adjective-noun-cxn could only apply because both pretty-cxn and dog-cxn applied
before and supplied material for the adjective-noun-cxn to match on, although in
no particular order). The exact matching conditions are also not shown, but since the
model is general they can be arbitrarily complex (or simple).
Chunking Constructions 79
match on the same material of the transient feature structure. Consequently, it
is only possible to chunk together connected subsets of a dependency network.
Example chunks from the given network could be the-cxn together with dog-cxn,
adjective-noun-cxn and article-np-cxn, which would leave an open slot for any
adjective and thus represent a general the-<adjective>-dog-cxn. The maximal
case is when the entirety of the network is chunked together, which would signify
a direct representation of the entire phrase ‚Äúthe pretty dog‚Äù including linking
operations [13]. We call the (sub-)hierarchy of a dependency network that a
chunked construction is based on its underlying construction hierarchy or also
the chunked hierarchy, and the constructions which contribute to a chunked
construction its constituent constructions.
2.2 The Algorithm
In order for a chunked construction to have exactly the same impact on the
transient feature structure as if all of its constituent constructions had applied
consecutively, this construction has to meet the following requirements:
‚Äì it combines all the match conditions expressed by its constituent construc-
tions (it is consequently applicable in exactly the same contexts as its un-
derlying construction hierarchy)
‚Äì it merges in all the same units and unit-content as all the constructions of
the original hierarchy
Starting from an initially empty construction with no units on either pole, the
chunked construction is created through the following steps which are applied
to both the semantic and the syntactic poles separately:
‚Äì Given a hierarchy of dependent constructions, represented by a subtree of a
construction dependency network, go through the constructions bottom-up1
and, for every construction:
1. match units which are matched on parts of the feature structure which
were already there before the Ô¨Årst construction of the chunked hierarchy
applied are copied over to the chunked construction as they are or, if the
unit is already part of the chunked hierarchy, the match constraints are
merged into the already existing unit.
2. match units which are matched on structure which was only merged in by
one of the previous constructions which are part of the chunked hierarchy
are added to the chunked construction as J-units. The reasoning behind
this is as follows: if the chunked construction applies then all the match
conditions for the leaves of the dependency network are met (since the
relevant match conditions were taken over as they are). Consequently,
1
The exact ordering doesn‚Äôt matter as long as a construction‚Äôs priming constructions
(i.e. its children in the dependency network, which means that they provided some
content for the construction to match on) are processed Ô¨Årst. This can easily be
achieved by processing the constructions in the order of their original application.
80 K. Stadler
the applicability of all inner constructions is met since all conditions of
its dependent constructions are met. While the match conditions of all
inner constructions of the dependency hierarchy are thus not relevant,
the information is still required for merging, making the transformation
to J-units an ideal solution.
3. J-units are copied over as they are, or merged with the current unit
content if the J-unit is already part of the chunked construction.
‚Äì Return the chunked construction
Additional issues have to be taken into account every time a unit is added to
the chunked construction:
‚Äì Merging units: when the same unit is referred to from more than one con-
struction of the hierarchy, the contents of the respective match units have
to be merged together into one unit. This operation is not to be confused
with the merge applied during construction application, where content from
a match pattern is merged into the transient feature structure [2]. Rather, we
are talking about merging multiple match patterns into one all-encompassing
match pattern. What this means becomes clear when looking at the example
of a chunked construction in Figure 3. All Ô¨Åve constructions underlying this
chunk matched on diÔ¨Äerent subparts of the top unit‚Äôs meaning and form fea-
tures ‚Äì in the chunked construction all these constraints are brought together
in one unit, with all special operators (in this case only ==) being preserved.
The example case is trivial since the constraints are non-overlapping, but
more complex handling is required when diÔ¨Äerent special operators applying
on the same feature have to be combined.
‚Äì Tracking of transitive variable equalities: during step-wise construction ap-
plication, variable linking (such as equating the referents of two previously
unrelated units) is carried out incrementally [19]. Individual variables are
added one by one and get linked during the uniÔ¨Åcation step of construction
application. In a chunked construction however there are no intermediate uni-
Ô¨Åcation steps, therefore all variable equalities have to be expressed explicitly.
This can also be seen in Figure 4, where only one variable is introduced on
the semantic pole, in contrast to three in the original construction applica-
tion process which only get equated later on by the two grammatical linking
constructions. To take care of this, the variable bindings established during
construction application have to be inspected every time a new construc-
tion is processed during the build-up of a chunked construction. Whenever a
binding between two variables is detected, the algorithm selects one of them
to become the new unique representation of that variable, and greedily re-
places all occurrences of the other variable. This approach makes the linking
of variables explicit and guarantees that all variable equalities are expressed
in only one step whenever the chunked construction is applied.
Chunking Constructions 81
tag ?meaning-1
?meaning-2
?meaning-3
?top-unit
(meaning (== (det ?ref)))
(meaning (== (dog ?ref)))
(meaning (== (pretty ?ref)))
tag ?form-1
?form-2
?form-3
?form-4
?form-5
?top-unit
?top-unit
?top-unit
?top-unit
?top-unit
chunked-cxn ((article-noun-cxn adjective-noun-cxn the-cxn dog-cxn pretty-cxn))
?top-unit
(form (== (string ?the-unit "the")))
(form (== (string ?dog-unit "dog")))
(form (== (string ?pretty-unit "pretty")))
(form
(==
(meets ?pretty-unit
?dog-unit)))
(form
(==
(meets ?the-unit
?pretty-unit)))
?top-unit
?top-unit
?top-unit
?top-unit
?top-unit
sem syn
referent
?the-unit
 ?meaning-1
?ref
referent
?dog-unit
 ?meaning-2
?ref
referent
?pretty-unit
 ?meaning-3
?ref
referent
?adjective-
noun-unit
?ref
?pretty-unit
?dog-unit
referent
?article-
noun-unit
?ref
?the-unit
?adjective-
noun-unit
syn-cat
?the-unit
 ?form-1
(==1 (lex-cat article))
syn-cat
?dog-unit
 ?form-2
(==1 (lex-cat noun))
syn-cat
?pretty-unit
 ?form-3
(==1 (lex-cat adjective))
syn-cat
?adjective-noun-unit
 ?form-4
(==1 (lex-cat noun))
?pretty-unit
?dog-unit
syn-cat
?article-noun-unit
 ?form-5
(==1
(lex-cat
article-noun-phrase))
?the-unit
?adjective-
noun-unit
Fig. 3. FCG representation of the chunked construction derived from the full original
construction hierarchy for processing ‚Äúthe pretty dog‚Äù. The construction encompasses
the match conditions and operations of all three lexical constructions as well as the
two linking constructions.
82 K. Stadler
sem-subunits
tag ?meaning-1
?meaning-2
?top-unit
(?noun-unit)
(meaning
(== (det ?ref)))
(meaning
(== (pretty ?ref)))
syn-subunits
tag ?form-1
?form-2
?form-3
?form-4
?top-unit
?top-unit
?top-unit
?top-unit
chunked-cxn ((article-noun-cxn adjective-noun-cxn the-cxn pretty-cxn))
?top-unit
(?noun-unit)
(form
(==
(string ?the-unit "the")))
(form
(==
(string ?pretty-unit
"pretty")))
(form
(==
(meets ?pretty-unit
?noun-unit)))
(form
(==
(meets ?the-unit
?pretty-unit)))
?top-unit
?top-unit
?top-unit
?top-unit
referent
?noun-unit
?ref
sem syn
syn-cat
?noun-unit
(==1
(lex-cat noun))
referent
?the-unit
 ?meaning-1
?ref
referent
?pretty-unit
 ?meaning-2
?ref
referent
?adjective-
noun-unit
?ref
?pretty-unit
?noun-unit
referent
?article-
noun-unit
?ref
?the-unit
?adjective-
noun-unit
syn-cat
?the-unit
 ?form-1
(==1 (lex-cat article))
syn-cat
?pretty-unit
 ?form-2
(==1 (lex-cat adjective))
syn-cat
?adjective-noun-unit
 ?form-3
(==1
(lex-cat noun-phrase))
?pretty-unit
?noun-unit
syn-cat
?article-noun-unit
 ?form-4
(==1
(lex-cat
article-noun-phrase))
?the-unit
?adjective-
noun-unit
Fig. 4. FCG representation of a chunked construction based on four out of the Ô¨Åve
constructions required for processing ‚Äúthe pretty dog‚Äù. This example, which could be re-
phrased as a the-pretty-<noun>-cxn shows how chunking can be used to create chunks
with slots, and potentially even chunks comprising multiple grammatical constructions
without any lexical material.
3 Computational and Conceptual Considerations
The immediate use of chunked constructions is evident: since they apply in the
same contexts as their underlying construction hierarchy and aÔ¨Äect the feature
structure in exactly the same way, they can be used in place of these composi-
tional construction applications. It is useful to look into some of the consequences
and challenges of the approach.
‚Äì From a processing point of view, chunking introduces the possibility of trade-
oÔ¨Ä between grammar size and complexity of search. The Ô¨Çexibility of full
compositionality is sacriÔ¨Åced for a reduction in combinatorial complexity of
the search space in combination with a decrease of processing cost for the
application of individual constructions. The sacriÔ¨Åce for this is, however,
Chunking Constructions 83
potentially huge: adding all potential subhierarchies of all utterances that
are encountered by a speaker in parsing or production to the constructicon
would lead to the holistic storage of all compositional (sub-)structures ever
encountered, as exempliÔ¨Åed in Figure 5. This explosion in grammar size
would have to be dampened, retaining only those constructions which are
actually relevant and useful to the language user.
‚Äì In some ways the optimisations that chunked constructions reproduce func-
tionality of construction dependency networks, particularly the priming net-
works already implemented in FCG [22]. But unlike in dependency networks,
chunked constructions are autonomous from their original constituent parts.
While entrenchment through frequent co-occurrence can lead to a strong
preference for co-activation in dependency networks as well, the underlying
representations of the constituent constructions do not change, and are in-
dividually activated and processed every time the compositional structure
is encountered. In the chunking approach, the content of the constructions
is copied and the new constructicon entries are not explicitly coupled to
their constituent parts. The only connection betweem them is in fact indi-
rect, through direct competition in search. This corresponds nicely to the
duality observed in human language processing: while a human might use
a chunked version of a construction in active parsing and production, the
compositional route is still present and very much accessible to the language
user when required. He can potentially be aware of the compositionality of
his or her utterance since it is still represented in the linguistic inventory,
but in most cases of processing this representation is not regarded due to a
preference for the holistic analysis.
‚Äì Another important feature which sets the chunking approach apart from
optimisations using construction networks is that it is possible to chunk
together structures in which a single construction is used more than once.
This is relevant for any compositional idiomatic expression in which the same
construction occurs at least twice, and particularly when a construction can
be used recursively, as is the case in natural language. The easiest example
for this is a noun phrase which is embedded in another (more complex) noun
phrase, such as ‚Äúthe cat on the mat‚Äù. In a priming network, trying to capture
the entrenched and thus preferred parsing of such a phrase will result in a
(potentially indirect) circle. Instead of representing a particular instance of
chunking, construction networks constitute a separate layer which generalises
eagerly to all (co-)occurrences of constructions. The interesting fact that
chunked constructions do not introduce an additional layer of representation
into the formalism will be discussed in more detail in the next section.
No matter to what extent chunked constructions are used in practice, the ap-
proach brings additional challenges for search. Creating redundant representa-
tions is only half the job, more importantly this redundancy has to be handled
and exploited eÔ¨Éciently during actual parsing and production. The decision of
which chunked constructions to retain or even reinforce and which ones to re-
move from the linguistic inventory are closely coupled to their utility for the
84 K. Stadler
art-np-cxn
adj-noun-cxn
art-np-cxn
adj-noun-cxn
dog-cxn pretty-cxn
art-np-cxn
adj-noun-cxn
dog-cxn
the-cxn
art-np-cxn
adj-noun-cxn
dog-cxn
art-np-cxn
the-cxn
art-np-cxn
adj-noun-cxn
pretty-cxn
the-cxn
art-np-cxn
adj-noun-cxn
pretty-cxn
art-np-cxn
adj-noun-cxn the-cxn
adj-noun-cxn
dog-cxn
adj-noun-cxn
pretty-cxn
adj-noun-cxn
dog-cxn pretty-cxn
art-np-cxn
adj-noun-cxn
dog-cxn pretty-cxn
the-cxn
Fig. 5. The twelve diÔ¨Äerent chunkable sub-hierarchies for the dependency network of
the example phrase. The minimal case with just two grammatical constructions can
be found at the top left, the full hierarchy which also corresponds to the complete
dependency network of the parse at the bottom right. The number of possible com-
binations for a dependency hierarchy is a function of the tree structure of the depen-
dencies. Note that with the exception of the last two, none of these hierarchies can
be represented by their surface forms alone, since the resulting collapsed constructions
contain both semantic as well as syntactic slots (such as the chunked construction
in Figure 4). The hierarchy in the middle of the second line for example could be
coined a general the-<noun-phrase>-cxn, the one above it a somewhat more spe-
cialised <article>-pretty-dog-cxn.
Chunking Constructions 85
language user, which is highly correlated to their frequency of activation dur-
ing search. Intelligent models of construction inventory self-organisation should
not only capture the autonomy of frequently accessed chunked constructions,
but also dampen the productivity of its constituent constructions when they are
only infrequently activated on their own.
4 Applications
The study of the emergence and self-organisation of linguistic inventories has
been at the core of experiments carried out in Fluid Construction Grammar.
While the distributed development of a shared lexicon [14] and shared ontolo-
gies of perceptually grounded categories [15] have been investigated and suc-
cessfully characterised early, the extension of these principles to compositional
structures is not that straightforward. The additional problem arising with com-
positional structures is that of multi-level selection [21]. For competition on
one level (i.e. holistic names) consolidation strategies based on lateral inhibition
constitute an adequate model for selecting linguistic conventions. But once such
entries are themselves re-used as parts of larger compositional structures it is
not clear on which units the lateral inhibition dynamics should apply. So far
only the explicit linking of constructions in a separate network layer has been
proposed as a solution [20], but a model building on chunked constructions of-
fers an alternative approach to the same problem. Instead of explicitly coupling
individual co-occurring constructions together, chunked constructions added to
the constructicon could implicitly compete with their compositional constituents
during search. One of the central tenets of the multiple representation model is
that there is more than just one productive unit at play in producing or un-
derstanding any compositional structure, as exempliÔ¨Åed by dual-route models of
lexical access in which direct and compositional access explicitly compete with
each other [6]. Given the similarity of the phenomena in these two domains, it is
likely that a cognitively plausible computational model of capturing redundancy
and productivity in human language will also provide answers to open research
questions in the Ô¨Åeld of self-organising communication systems.
Conversely, a better understanding of language coordination dynamics based
on computational models would also lead to improvements in Natural Language
Processing systems. The phenomenon of routinisation in humans happens auto-
matically and leads to strong lexical and syntactic alignment processes between
interlocutors [12]. Such alignment processes and their importance for the emer-
gence of shared communication systems is well-known [16], but they are hardly
exploited in natural language applications. For example, the rigid nature of most
current dialogue systems keeps them far from human-like performance, but the
importance and potential beneÔ¨Åts of reciprocal learning in language coordination
between humans and interactive agents is receiving more and more attention [4].
The chunking mechanism presented here provides a cognitively plausible basis
for the computational modelling of routinisation eÔ¨Äects. But interactive align-
ment does not just lead to more natural discourse, it can also aid in optimis-
ing and guiding computational processing through a uniÔ¨Åed theory of dialogue.
86 K. Stadler
Tracking of discourse referents and anaphora resolution are often treated as
modular problems which are not handled by core parsing components but using
extra-linguistic systems. Since routines are derived from more speciÔ¨Åc cases of
use than their individual constituents, humans use them naturally to express as-
sociation to speciÔ¨Åc discourse referents, a fact easily exploited by systems making
use of dynamically-derived redundant representations.
5 Conclusion
In this article we argued for the relevance of redundant representations in the
linguistic inventory and presented an algorithm for dynamically deriving holis-
tic constructions from sets of dependent constructions which are used to build
compositional structure. The model crucially relies on some of the properties
of Construction Grammar in general and some features of Fluid Construction
Grammar in particular. Construction Grammar makes use of only a single rep-
resentation for all kinds of linguistic structure which is also capable of handling
the additional complexity that characterises chunked constructions. Lexical and
grammatical constructions can be combined just as easily, and parts of a chun-
ked phrase can also be left unexpressed. Constructions derived by chunking can
themselves become part of even larger chunks using exactly the same algorithm.
The fact that FCG is uniÔ¨Åcation-based enables the combination and composition
of chunked constructions to be carried out relatively straightforward.
Another important feature is the bidirectional applicability of constructions
in both parsing and production. Routinisation has been shown to cover both
language understanding as well as generation, and a homogeneous linguistic
representation for both tasks allows to support this aspect and enable positive
feedback loops for alignment processes between interlocutors. Most natural lan-
guage processing frameworks on the other hand are optimised for one task (most
prominently parsing), and this one-sidedness is often reÔ¨Çected in the representa-
tions and data structures they employ. Consequently, these approaches can not
easily capture and take advantage of cognitive mechanisms such as routinisation.
Although we pointed out some potential applications in language modelling
and processing, the mechanism is by far not limited to these cases. Chunking is a
theory-neutral operation and can also be used for other purposes. Since chunked
constructions form autonomous units, their content is immediately amenable to
modiÔ¨Åcations, be it capturing semantic idiosyncracies or simplifying syntactic
structure. The algorithm presented is thus not only useful for questions of opti-
mising linguistic processing, but also extensible to any area of linguistics research
in which entrenchment processes play a role.
Acknowledgements. This research was carried out at the ArtiÔ¨Åcial Intelligence
Laboratory at Vrije Universiteit Brussel with funding from the Vrije Universiteit
Brussel. I would like to thank Luc Steels, Pieter Wellens and Joachim De Beule
for their help with the work and Remi van Trijp for useful comments on an
earlier draft.
Chunking Constructions 87
References
[1] Bybee, J.: From usage to grammar: The mind‚Äôs response to repetition. Lan-
guage 82(4) (2006)
[2] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[3] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[4] Fern√°ndez, R., Larsson, S., Cooper, R., Ginzburg, J., Schlangen, D.: Reciprocal
learning via dialogue interaction: Challenges and prospects. In: Proceedings of
the IJCAI 2011 Workshop on Agents Learning Interactively from Human Teach-
ers (ALIHT), Barcelona, Catalonia, Spain (2011)
[5] Goldberg, A.E.: Constructions. A Construction Grammar Approach to Argument
Structure. The University of Chicago Press (1995)
[6] Hay, J.: Causes and Consequences of Word Structure. Routledge (2003)
[7] Langacker, R.W.: Foundations of Cognitive Grammar, vol. I: Theoretical Prereq-
uisites. Stanford University Press (1987)
[8] Langacker, R.W.: A usage-based model. In: Rudzka-Ostyn, B. (ed.) Topics in
Cognitive Linguistics, Current Issues in Linguistic Theory, vol. 50, pp. 127‚Äì161.
John Benjamins Publishing Company (1988)
[9] McQueen, J.M., Cutler, A.: Morphology in word recognition. In: Spencer, A.,
Zwicky, A.M. (eds.) The Handbook of Morphology, pp. 406‚Äì427. Blackwell Hand-
books in Linguistics, Blackwell (1998)
[10] Mos, M.B.J.: Complex Lexical Items. Netherlands Graduate School of Linguistics
(2010)
[11] O‚ÄôDonnell, T.J., Snedeker, J., Tenenbaum, J.B., Goodman, N.D.: Productivity
and reuse in language. In: Proceedings of the Thirty-Third Annual Conference of
the Cognitive Science Society (2011)
[12] Pickering, M.J., Garrod, S.C.: Toward a mechanistic psychology of dialogue. Be-
havioral and Brain Sciences 27(2), 169‚Äì190 (2004)
[13] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[14] Steels, L.: Emergent adaptive lexicons. In: Proceedings of the Simulation of Adap-
tive Behavior Conference. The MIT Press, Cambridge (1996)
[15] Steels, L.: The origins of ontologies and communication conventions in multi-agent
systems. Journal of Agents and Multi-Agent Systems 1(2), 169‚Äì194 (1998)
[16] Steels, L.: Language as a Complex Adaptive System. In: Schoenauer, M., Deb, K.,
Rudolph, G., Lutton, E., Merelo, J.J., Schwefel, H.-P. (eds.) PPSN 2000. LNCS,
vol. 1917, pp. 17‚Äì26. Springer, Heidelberg (2000)
[17] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[18] Steels, L., De Beule, J.: Unify and Merge in Fluid Construction Grammar. In:
Vogt, P., Sugita, Y., Tuci, E., Nehaniv, C.L. (eds.) EELC 2006. LNCS (LNAI),
vol. 4211, pp. 197‚Äì223. Springer, Heidelberg (2006)
[19] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammar.
In: Proceedings of BNAIC. Transactions of the Belgian Royal Society of Arts and
Sciences (2005)
88 K. Stadler
[20] Steels, L., van Trijp, R., Wellens, P.: Multi-level Selection in the Emergence of
Language Systematicity. In: Almeida e Costa, F., Rocha, L.M., Costa, E., Har-
vey, I., Coutinho, A. (eds.) ECAL 2007. LNCS (LNAI), vol. 4648, pp. 425‚Äì434.
Springer, Heidelberg (2007)
[21] van Trijp, R.: Analogy and Multi-level Selection in the Formation of a Case Gram-
mar. A Case Study in Fluid Construction Grammar. Ph.D. thesis, University of
Antwerp, Antwerp (2008)
[22] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[23] Zuidema, W.: What are the Productive Units of Natural Language Grammar? A
DOP Approach to the Automatic IdentiÔ¨Åcation of Constructions.. In: Proceedings
of the Tenth Conference on Computational Natural Language Learning, pp. 29‚Äì36.
Association for Computational Linguistics, New York City (2006)
Expressing Grammatical Meaning
with Morphology: A Case Study
for Russian Aspect
Kateryna Gerasymova
Sony Computer Science Laboratory Paris, France
Abstract. Phrasal structures form the backbone of any sentence, and
they provide key information about, respectively, the constituent struc-
ture of a sentence and how its meanings are to be used in achieving a
communicative purpose. In addition, languages typically feature several
other systems that express meaning through grammatical rather than
lexical means. Examples are a tense-aspect system, which expresses in-
formation about the timing and temporal structure of events, a mood-
modality system, which concerns the epistemic status and opinion of the
facts reported in a sentence and a determination system, which pro-
vides information about the access status of the referent of nominal
phrases. This chapter shows how such grammatical meanings are ap-
proached within the framework of Fluid Construction Grammar through
a concrete example of the Russian aspect system.
1 Introduction
Certainly a large part of the meaning of a sentence is expressed through lexical
items, but languages also package a lot more information into the sentence by
expressing additional meanings through grammatical devices like morphology
and syntax, resulting in the need for a discussion of grammatical meaning instead
of simply lexical meaning. Languages of the world diÔ¨Äer widely in terms of which
meanings they express grammatically. One language may grammatically express
a very speciÔ¨Åc nuance in meaning that may be completely ignored in the grammar
of another language. Here are some examples:
1. To describe events in time, some languages employ tenses to locate situations
in the past, present or future from a particular moment in time. In French,
a speaker can say ‚Äúil pleut" (it rains), ‚Äúil pleuvait" (it rained) and ‚Äúil pleu-
vera" (it will rain) so as to relate the event of rain to the moment of speech.
In Bamileke-Dschang (spoken in Cameroon), a Ô¨Åner-grained distinction holds
that includes past and future tenses of Ô¨Åve diÔ¨Äerent degrees of remoteness,
such as immediate past and the past within one day from today, whereas in
English only the distinction of past/non-past is expressed morphologically [4].
2. Other languages focus more upon how events unfold in time using the gram-
matical category of aspect. Aspect does not annotate the passage of time in a
situation according to an external clock, but reveals the internal timing of an
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 91‚Äì122, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
92 K. Gerasymova
event by describing its temporal structure, such as, ‚Äúit rained" versus ‚Äúit was
raining" [3].
3. By means of modality, the status of the proposition that describes the sit-
uation can be indicated, as in the German utterance ‚ÄúIch glaubte, er w√§re
krank" where the subjunctive mood of ‚Äúw√§re" marks the belief of the speaker.
4. In Japanese, a sophisticated system of honoriÔ¨Åcs may be used to convey
information about the social distance or disparity in rank between speaker
and hearer, or to emphasize social intimacy or similarity in rank.
5. In Romance languages such as French, the ubiquitous articles serve as an
expression of deÔ¨Åniteness, as in ‚ÄúLes fruits que j‚Äôai achet√©s" (The fruit that I
bought), which, in contrast, are completely absent from Japanese or Slavic
languages.
This chapter presents a case study that demonstrates how grammatical meanings
can be expressed through grammar and how this expression can be represented
in constructions for Fluid Construction Grammar [15, 17]. Examples are drawn
from Russian aspect. Although the Russian aspectual system is notorious for its
complexity, it is possible to crystallize a regular subsystem out of it and to ad-
dress the issues of grammatical expression of this subsystem, serving the didactic
purposes of this chapter. Thus, no attempt is made here to give a comprehensive
description of the total verbal system of Russian with its numerous exceptions
and grammaticalization processes. Rather, we only address the principle or idea
of Russian aspect as a grammatical category.
The ultimate goal of this study is to be able to process dialogues in FCG that
appeared in the comprehension experiment of [19], who investigated how Rus-
sian children develop their understanding of aspectual forms. Preschool children
were interviewed after watching pairs of short movies, each illustrating what
would be described by a diÔ¨Äerent aspectual form of the same verb stem. The
comprehension of those dialogues was the test condition for the ability to man-
age aspect. For example, the question Kto narisoval lico? (Kto narisoval
lico?, ‚ÄòWho has drawn the face?‚Äô) tested whether a child understood the concept
of completion of the event of drawing expressed by the perfective aspect. The
grammar presented in this chapter constitutes part of a larger study on aspect
acquisition [8], which consequently motivated the choice of the test examples.
This chapter assumes that the reader has had a Ô¨Årst encounter with FCG,
for example by reading [16, 18] and is also acquainted with the templates for
implementing phrasal constructions [5, 14]. Section 2 begins with a sketch of the
linguistic background in order to build a foundation for the grammar developed
later. Section 3 introduces some general design principles on how to organize
complex grammars and how to divide labor between constructions. In the next
stage, the full grammar is implemented with the help of templates (Section 4),
raising new questions in the process, such as how to deal with an unmarked case
of imperfective (Section 5). Section 6 brieÔ¨Çy outlines the language processing,
and, Ô¨Ånally, the Appendix provides an insight into what actually happens behind
the scenes by oÔ¨Äering a tutorial on how to write fully-Ô¨Çedged constructions and
how to develop templates for them.
Expressing Grammatical Meaning with Morphology 93
2 Linguistic Insights into Russian Aspect
When modeling a nontrivial linguistic phenomenon, it is crucial to Ô¨Ånd a linguis-
tic theory capable of providing the necessary grip for its in-depth computational
treatment. The analysis in this chapter is based on the view that aspect is a gram-
matical category, manifested in Russian through the contrast between perfective
and imperfective.1
As formulated by [6], perfective aspect expresses the action
as a total event summed up with reference to a single juncture, and imperfective
is characterized by the absence of that notion. In Russian, in contrast to many
other languages such as Turkish, English or the broader family of Romance lan-
guages, it is the perfective rather than the imperfective that is morphologically
marked in verbs.
2.1 Dimensions of Aspect
However, the story does not simply end with this basic opposition of perfective
versus imperfective. In order to comprehensively describe the Russian aspectual
system, another distinction needs to be introduced ‚Äì the semantic category of
Aktionsart. Aktionsart expresses additional, often temporal, properties of the
event introduced by a verb. For instance, telic Aktionsart conveys that the event
has an inherent goal or result; ingressive Aktionsart proÔ¨Åles the beginning of the
event; delimitative Aktionsart conveys that the event has a limited time span
and so on. The categories of aspect and Aktionsart are linked by the fact that
perfective aspect is deÔ¨Åned as a means to highlight the boundaries of the event.
It is not important which boundaries are proÔ¨Åled (initial, Ô¨Ånal or both), as long
as at least one of them is actually proÔ¨Åled. While the notion of perfectivity does
not discriminate between the diÔ¨Äerent possible positions of the boundary, the
boundary‚Äôs position is fundamental for the Aktionsart of the verb [2, 19]. For
example, in the verb narisovat (narisovat‚Äô, ‚Äòdraw.PFV‚Äô) perfective highlights
the inherent notion of completeness of the event by focusing on the Ô¨Ånal bound-
ary, and in the verb zaplakat (zaplakat‚Äô, ‚Äòstart-crying.PFV‚Äô), perfective signals
the notion of beginning (the initial boundary), viewing the beginning of crying
as a single indivisible whole. Imperfective is often connected with the durative
Aktionsart, but due to its unmarked nature it is also compatible with a wide
range of contexts, even those where most languages would use perfective [20].
Overall, aspect is omnipresent in Russian grammar, and every verb in all
forms and tenses is either perfective or imperfective. For instance:
(1) Neqego
nothing
byloi
be.PT.IPFV
delati
,
do.INF.IPFV
my
we
pritilisp
harbor.PT.PFV.REFL
u
near
ogn,
Ô¨Åre
zakurilip
smoke.PT.PFV
trubki,
pipe
i
and
skoro
soon
qanik
tea kettle
zaxipelp
hiss.PT.PFV
privetlivo.
friendly
Neƒçego byloi
delat‚Äôi
, my prijutilis‚Äôp
u
1
Perfective is hereafter indicated as PFV and imperfective as IPFV.
94 K. Gerasymova
ognja, zakurilip
trubki, i skoro ƒçajnik za≈°ipelp
privetlivo.
‚ÄòThere was nothing to do but to make ourselves comfortable by the Ô¨Åre, we
lighted up our pipes, and soon the teakettle began to hiss happily.‚Äô
[M. Y. Lermontov. Gero naxego vremeni (‚ÄòA hero of our time‚Äô)]
The above sentence exhibits examples of verbs in diÔ¨Äerent aspects and
Aktionsarten. The two verbs at the beginning of the sentence are imperfective (in-
dicated by the superscript i
). All the rest are perfectives (indicated by the super-
script p
) of various Aktionsarten. For instance, both perfectives zakurilip
(za-
kurili, ‚Äòbegan to smoke.PFV.PT.1PS.PL‚Äô)2
and zaxipelp
(za≈°ipel, ‚Äòbegan to
hiss.PFV.PT.3PS.SG‚Äô) portray the beginning of events of smoking and hissing, re-
spectively, and are of the ingressive Aktionsart.
2.2 Morphology
The morphology of the Russian aspect mirrors the complexity of its semantics.
Again, in contrast to other languages like English, there is no single morpho-
logical marker that marks either of the two aspects. In English, the progressive
aspect is marked with the conjugated ‚Äòto be‚Äô + inÔ¨Ånitive of the verb + ‚Äò-ing‚Äô,
as in ‚Äúit is raining" in contrast to ‚Äúit rains", and thus the progressive is marked
unambiguously. In contract to this, Russian verbs can be roughly divided into
‚Äòsimple‚Äô verbs, consisting of a stem and a conjugated ending, such as qitat (ƒçi-
tat‚Äô, ‚Äòread.IPFV‚Äô), wipat (≈°ƒçipat‚Äô, ‚Äòpinch.IPFV‚Äô), and ‚Äòcomplex‚Äô verbs, which
are derived from the ‚Äòsimple‚Äô verbs by the addition of aspectual markers, such as
by preÔ¨Åxation pereqitat (pereƒçitat‚Äô, ‚Äòre-read.PFV‚Äô) and vywipat (vy≈°ƒçipat‚Äô,
‚Äòpinch-out.PFV‚Äô). Simple verbs typically describe activities and are imperfective,
such as rezat (rezat‚Äô, ‚Äòcut.IPFV‚Äô). The addition of a preÔ¨Åx changes the aspect
of simple verbs into perfective, such asnarezat (narezat‚Äô, ‚Äòcut.PFV‚Äô),porezat
(porezat‚Äô, ‚Äòcut-for-a-while.PFV‚Äô), dorezat (dorezat‚Äô, ‚Äòcut-to-the-end.PFV‚Äô) and
so on, indicated schematically in Figure 1. Russian has nineteen verbal preÔ¨Åxes
that productively form perfective [12]. There is also a perfectivizing suÔ¨Éx -nu-
leading to such forms as rezanut (rezanut‚Äô, ‚Äòcut-once.PFV‚Äô).
Moreover, Russian verbs can undergo more than one aspectual derivation. Af-
ter the preÔ¨Åx is added to the simple verb (e.g., dumat, dumat‚Äô, ‚Äòthink.IPFV‚Äô)
making it perfective ( pridumat, pridumat‚Äô, ‚Äòinvent.PFV‚Äô), the so-called im-
perfectivizing suÔ¨Éxes can Ô¨Çip the verb‚Äôs aspect to imperfective again, as in
pridumyvat (pridumyvat‚Äô, ‚Äòinvent.IPFV‚Äô). However, another preÔ¨Åx can be at-
tached to this form, changing the aspect to perfective again ‚Äì popridumyvat
(popridumyvat‚Äô, ‚Äòinvent-for-a-while.PFV‚Äô). This chapter focuses on the Ô¨Årst as-
pectual derivation: the addition of preÔ¨Åxes to simple verbs, which changes them
from imperfective to perfective. These forms account for roughly 80 percent of
2
The following abbreviations are used throughout the chapter: PFV ‚Äì perfective,
IPFV ‚Äì imperfective, PR ‚Äì present tense, PT ‚Äì past tense, FT ‚Äìfuture tense, REF
‚Äì reÔ¨Çexive, PS ‚Äì person, PL ‚Äì plural, SG ‚Äì singular.
Expressing Grammatical Meaning with Morphology 95
 	

 


	

	

	



perfective
imperfective
Fig. 1. Schema of the simple verb rezat (rezat‚Äô, ‚Äòcut.IPFV‚Äô) and its perfective
derivatives narezat (narezat‚Äô, ‚Äòcut.PFV‚Äô), porezat (porezat‚Äô, ‚Äòcut-for-a-while.PFV‚Äô)
and dorezat (dorezat‚Äô, ‚Äòcut-to-the-end.PFV‚Äô), which are formed by preÔ¨Åxation
the total verb occurrences in written corpora, and, as stated by [7], awareness of
the aspectual opposition is therefore likely to be focused precisely on the contrast
between simple imperfective and preÔ¨Åxed perfective forms (and not on that of
perfective and secondary imperfective).
3 Designing a Grammar
3.1 What Is a Suitable Grammar Architecture?
Rather than immediately start writing FCG constructions, it is important Ô¨Årst
to develop a general strategy as to how the grammar should be organized. The
production procedure starts with a meaning that has to be communicated and
tries to construct an utterance that would convey this meaning in a given con-
text. In the following example, the speaker wishes to communicate the event of
Michael completing the drawing of a face, which in English might be expressed
as ‚ÄúMichael has drawn a face" and in Russian ‚ÄúMixa narisoval lico" (Mi≈°a
narisoval lico). The meaning underlying the target utterance can be represented
in the following way in the notation of the Ô¨Årst-order predicate calculus:
(2) (michael michael-indiv context-1)
(draw draw-ev context-1)
(drawer draw-ev michael-indiv)
(drawee draw-ev face-obj)
(event-type draw-ev complete)
(face face-obj context-1)
(context context-1)
The above notation essentially indicates four main components in the context:
1) there is an individual Michael and 2) a draw event (draw-ev) which has a
drawer and a drawee, 3) that event is complete, and 4) the object of that event,
the drawing, is a face.
When dealing with a nontrivial language subsystem and trying to write con-
structions to handle it, it is easier to split up the whole constructicon in sets
96 K. Gerasymova
of constructions with similar functions, arriving thereby at a clearer design
and division of labor between constructions. It is Ô¨Årst of all useful to distin-
guish between the lexical and grammatical pathways. There are a lot of ad-
vantages to such an organization, which will become apparent in the course
of the chapter. Let us momentarily shift the focus away from the grammar
and toward the information that can already be expressed by purely lexical
items. The two predicates (michael michael-indiv context-1) and (face
face-obj context-1) could fall into the responsibility of the lexical construc-
tions that have the corresponding meaning of michael and face on their seman-
tic poles. (See the introductory chapter in this volume [18].) Similarly, the three
predicates
(draw draw-ev context-1)
(drawer draw-ev michael-indiv)
(drawee draw-ev face-obj)
can be expressed by the lexical entry for the verb ‚Äúto draw." The meaning left un-
processed is (event-type draw-ev complete), which, in Russian, is grammat-
icalized and morphologically expressed in the verb. Thus, this predicate should
be captured by grammatical constructions diÔ¨Äerent from the lexical ones for the
case of Russian, although, in some languages, this meaning can very well be
expressed lexically. Now we turn to the question as to which grammatical con-
structions are needed in order to capture this meaning in a way consistent with
the Russian grammar.
As shown in the previous section, the notion of completeness is an integral
part of the semantics of some Russian verbs, which are said to belong to the
telic Aktionsart. There are other Aktionsarten characterized by the notions of
ingressivity, durativity, deliminativity, and so forth. In other words, Aktionsart
describes the lexical temporal semantics of a verb and is therefore a semantic
category. This principle can be formalized with the help of a special construction,
which puts the semantic feature of completeness ‚Äì the predicate (event-type
draw-ev complete) ‚Äì in relation to the semantic category of Aktionsart of the
corresponding verb. Additionally, the semantic dimension of Aktionsart has to
be translated into its grammatical counterpart of aspect by another grammat-
ical construction. For example, for the telic Aktionsart this mapping construc-
tion should state that the notion of telicity is grammatically expressed by the
perfective aspect. It is then the duty of another kind of construction ‚Äì the mor-
phological construction ‚Äì to express the perfective aspect by the attachment of
a preÔ¨Åx to a verb stem, with the particular string of a preÔ¨Åx depending on the
semantic category of Aktionsart.
The notion of totality characteristic of all perfective verbs does not constitute
a part of meaning (which is supposed to come from the world model), it is rather a
semantic constraint captured in the semantic category of the corresponding verb.
This design decision is motivated by the theory of genesis of aspect proposed by
[7], underlining that the ‚Äúperfectivity" (i.e. the notion of totality) of a preÔ¨Åxed
verb is basically nothing more than a by-product of the word-building process
out of which the forms with new semantic nuances are derived.
Expressing Grammatical Meaning with Morphology 97
meaning form
semantic
categories
syntactic
categories
semantic categorization constructions
lexical entries
morphological constructions
mapping constructions
Fig. 2. The grammar square for aspect shows the diÔ¨Äerent relations that grammars
need to establish. They are done here by diÔ¨Äerent construction types: lexical, semantic
categorization, mapping and morphological. Lexical constructions map lexical stems
to their meanings (top, horizontal arrow), semantic categorization constructions re-
categorize meaning in terms of semantic categorizations (left arrow), mapping con-
structions map abstract semantic structures to abstract syntactic structures (bottom
arrow), and morphological constructions express syntactic categories using morphology
(right arrow).
3.2 Division of Labor between Constructions
Writing eÔ¨Äective operational constructions is complicated. One has to consider
many aspects, such as uniÔ¨Åcation and merging procedures, hierarchical organi-
zation, bidirectional applicability and so on. Tackling all of the issues simulta-
neously is possible only in simple cases. In more complicated ones, it is useful
to Ô¨Årst look at a construction as a ‚Äúblack box" and attempt to determine its
exact behavior resulting from a speciÔ¨Åc body of input, especially in light of its
interaction with other constructions.
Grammatical meaning works through the intermediary of semantic and syn-
tactic categorizations as illustrated in the grammar square (see Figure 2), and for
clarity of design, constructions are used that correspond to each of these steps,
even though all of them can involve criteria from any level of the grammar.
For example, morphological constructions (further called morph-constructions)
focus on mapping syntactic categorizations to surface forms, but they may take
semantic as well as phonological criteria into account.
Lexical entries provide the base material for further grammatical processing;
therefore, they are applied Ô¨Årst both in production and parsing. Given a partic-
ular stretch of meaning to be expressed, these lexical entries should grab that
meaning in production, encapsulate it in a new unit, and associate a word string
with that unit. In so doing, the lexical entry for the noun ‚Äòface‚Äô should trigger in
98 K. Gerasymova
the presence of the meaning (face ?obj ?ctx) and associate it with the string
‚Äúlico", as schematically shown in the Example 3. A similar association applies
for the verb ‚Äòto draw‚Äô with the diÔ¨Äerence that the meaning consists of the three
predicates instead of one (Example 4).
(3) meaning: (face ?obj ?ctx) ‚Üê‚Üí form: (string "lico")
(4) meaning: form:
(draw ?ev ?ctx) ‚Üê‚Üí (string "risova")
(drawer ?ev ?drawer)
(drawee ?ev ?drawee)
In order to prepare the resulting linguistic structure for the application of gram-
matical constructions, lexical entries should also introduce additional semantic
and/or syntactic categorizations of the unit, thereby providing constraints for
the latter to trigger on. For example, if a morphological marker should only be
used with verbs, the lexical entry of the verb should supply the information that
it is a verb.
We now look at the constructions that establish the relations in the grammar
square, focusing Ô¨Årst on production to make the construction types easier to
understand.
1. After applying lexical constructions, the additional meaning of the event-
type should be re-categorized in terms of the language-internal semantic
category of Aktionsart and encapsulated in the unit of the verb introduced by
the lexicon. This task is undertaken by semantic categorization constructions
(called sem-cat constructions). A sem-cat construction is needed here, stating
that if the event type of the event expressed in a unit is complete, then the
semantic category ‚Äòtelic Aktionsart‚Äô is added to this unit. We need these sem-
cat constructions because this categorization is not always so straightforward
and diÔ¨Äerent meanings could map into the same Aktionsart depending on
the context. The relation that the sem-cat construction has to put in eÔ¨Äect
is schematically captured in the following way:
(5) meaning: (event-type ?ev complete) ‚Üê‚Üí
sem-cat: (aktionsart telic)
Sem-cat constructions could in principle take into account many other as-
pects of the linguistic context, such as syntactic criteria, but the examples
treated here are suÔ¨Éciently simple so that this is not necessary.
2. The next step in production is the translation of Aktionsarten into their
grammatical counterparts of aspect. This is necessary because the same Ak-
tionsart can be mapped to both perfective or imperfective aspect depending
on the context. For instance, a distinction between pererisovat (pereriso-
vat‚Äô, ‚Äòredraw.PFV‚Äô) and pererisovyvat (pererisovyvat‚Äô, ‚Äòredraw.IPFV‚Äô),
which are both of the totalizing Aktionsart, is in aspect (the perfective in
the former and imperfective in the latter). Moreover, the notion of totality
Expressing Grammatical Meaning with Morphology 99
characteristic of all perfective verbs is not yet captured in the transient struc-
ture. We achieve this eÔ¨Äect through mapping constructions, which implement
the bottom bi-directional relation of the grammar square. Our example must
then have a construction triggering on the semantic category of telic Aktion-
sart. It should not only link this category to perfective aspect, but also add
the feature totality characteristic of all perfective verbs. Here is the mapping:
(6) sem-cat: (aktionsart telic)
sem-cat: (view ?ev totality)
‚Üê‚Üí syn-cat: (aspect perfective)
Such mapping constructions implement the core of aspectual grammar by
establishing the subtle interplay between Aktionsarten and aspect, thereby
achieving a distinguished role for each category: Aktionsart is responsible
for the semantics of telicity, whereas perfective aspect is responsible for the
notion of totality.
3. As the last step in production, a construction is needed that implements
the expression of perfective aspect by means of preÔ¨Åxation. Which one of
nineteen preÔ¨Åxes is attached to the verb depends on the semantics of the
perfective form, that is, on the Aktionsart. These kinds of constructions
are called morphological constructions because they settle morphology, even
if it may involve taking additional pragmatic, semantic or other linguistic
contexts into account. Morph-constructions establish the following relation:
(7) sem-cat: (aktionsart telic)
‚Üê‚Üí
syn-cat: (aspect perfective)
prefix: (string "na-")
Morph-constructions thus provide the missing strings of grammatical mark-
ers (similar to the lexical constructions that supply strings for lexical entries)
and thereby Ô¨Ånalize the production process.
This organization, already proposed in [9], is schematically illustrated in Figure
2. Let us see how these diÔ¨Äerent construction types now operate in parsing:
1. The lexical entries again provide the base material for further grammatical
processing, so they apply Ô¨Årst. Given a particular word in the utterance,
the lexical entry encapsulates it in a new unit and associates the relevant
meaning with that unit. Lexical entries also add semantic and syntactic
categories to the unit that will be relevant in further grammatical processing.
2. Next, the morph-constructions are applied, because they detect additional
form elements in the utterance and translate them into syntactic categories.
For example, they detect that a verb is preÔ¨Åxed and add the relevant syn-
tactic categorizations to the unit that covers the base verb.
3. All syntactic and semantic categorizations are now available to apply the
mapping constructions, which map some of the syntactic categories (e.g., per-
fective aspect) into a semantic categorization (telic Aktionsart), constrained
by the syntactic and semantic context.
100 K. Gerasymova
4. Finally, sem-cat constructions are applied that map the language-internal
semantic categories into meaning, in our case Aktionsart, to the event type
of the verb.
Hence, parsing uses the same construction sets, but they are ordered in the op-
posite direction from that in production: clockwise when looking at the grammar
square for parsing and counter-clockwise for production (Figure 2).
4 Implementing a Grammar
This section uses templates to introduce an implementation of the grammar
design outlined in the previous section. Templates allow the grammar engineers
to abstract away from the technical details of the FCG formalism and instead
concentrate on linguistic aspects. The Appendix at the end of the paper oÔ¨Äers
an explanation of how to develop such templates.
Our starting point in production is on the meaning that has to be expressed
(as presented in Example 2):
(8) (michael michael-indiv context-1)
(draw draw-ev context-1)
(drawer draw-ev michael-indiv)
(drawee draw-ev face-obj)
(event-type draw-ev complete)
(face face-obj context-1)
(context context-1)
4.1 Lexical Constructions
Face-Construction. As discussed previously, the lexical construction for the
noun ‚Äòface‚Äô produces the following bidirectional mapping:
(9) meaning: (face ?obj ?ctx) ‚Üê‚Üí form: (string "lico")
However, a lexical construction usually has to do more in order to prepare the
resulting linguistic structure for the application of grammatical constructions.
It should also introduce some additional semantic and/or syntactic categories
of the unit, thereby providing constraints for the grammatical constructions to
trigger on. Instead of using only one template def-lex-cxn specifying everything
that is needed to build a construction, the entire task can be split into diÔ¨Äerent
templates for handling diÔ¨Äerent issues, as discussed by [14]. Thus, the template
for deÔ¨Åning a lexical entry for the noun ‚Äúface" is shown below, where, in addition
to the simple meaning-to-form mapping with def-lex-skeleton, there is also
a speciÔ¨Åcation of semantic and syntactic categories of the construction with the
help of the def-lex-cat template.3
3
All templates (def-lex-cxn, def-lex-skeleton and def-lex-cat) are discussed
in detail in [14].
Expressing Grammatical Meaning with Morphology 101
(10) (def-lex-cxn face-cxn
(def-lex-skeleton face-cxn
:meaning (== (face ?obj ?ctx))
:args (?obj ?ctx)
:string "lico")
(def-lex-cat face-cxn
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(gender neuter)
(case ?case))))
Draw-Construction. The lexical entry construction for the verb risovat
(risovat‚Äô, ‚Äòdraw‚Äô) (more precisely, for the stem risova- because endings of verbs
in Russian are subject to conjugation) has to establish the following mapping:
(11)meaning: form:
(draw ?ev ?ctx) ‚Üê‚Üí (string "risova")
(drawer ?ev ?drawer)
(drawee ?ev ?drawee)
The corresponding template for deÔ¨Åning a draw-construction with additional
semantic and syntactic categories appears as the following:
(12) (def-lex-cxn draw-cxn
(def-lex-skeleton draw-cxn
:meaning (== (draw ?ev ?ctx)
(drawer ?ev ?drawer)
(drawee ?ev ?drawee))
:args (? ev ?ctx)
:string "risova")
(def-lex-cat draw-cxn
:sem-cat
(==1 (class event)
(sem-val
(==1 (agent ?ev ?drawer)
(patient ?ev ?drawee))))
:syn-cat (==1 (lex-cat verb)
(gender ? gender))))
Of particular interest is the verb-speciÔ¨Åc semantic category of semantic va-
lency (sem-val), which contains information regarding who the agent and pa-
tient of the event described by the verb are. This valency is used later to establish
a grammatical agreement between the subject and the verb in a sentence.4
Scaling Up the Lexicon. Once the language-speciÔ¨Åc slots for a def-lex-cxn
template have been worked out, it is very simple to scale up the lexicon. New
nouns can be deÔ¨Åned as in Examples 13 and 14 and other verbs as in Example 15.
4
More about the verb agreement can be found in [21].
102 K. Gerasymova
(13) (def-lex-cxn masha-cxn
(def-lex-skeleton masha-cxn
:meaning (== (masha ?obj ?ctx))
:args (?obj ?ctx)
:string "Masha")
(def-lex-cat masha-cxn
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(gender feminine)
(case ?case))))
(14) (def-lex-cxn letter-cxn
(def-lex-skeleton letter-cxn
:meaning (== (letter ?obj ?ctx))
:args (?obj ?ctx)
:string "pis‚Äômo")
(def-lex-cat letter-cxn
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(gender neuter)
(case ?case))))
(15) (def-lex-cxn read-cxn
(def-lex-skeleton read-cxn
:meaning (== (read ?ev ?ctx)
(reader ?ev ?reader)
(readee ?ev ?readee))
:args (?ev ?ctx)
:string "cita")
(def-lex-cat read-cxn
:sem-cat
(==1 (class event)
(sem-val
(==1 (agent ?ev ?reader)
(patient ?ev ?readee))))
:syn-cat (==1 (lex-cat verb)
(gender ?gender))))
4.2 Sem-cat Constructions
The next step in production is the application of the sem-cat constructions,
which translate those parts of the meaning not directly expressed by lexical
items into semantic categories that are later mapped onto syntactic features of
the utterance, such as morphological markers and word order.
Telic-construction. In the case at hand, the sem-cat construction has to trig-
ger on the meaning (event-type ?ev complete) and re-categorize it into the
Expressing Grammatical Meaning with Morphology 103
meaning form
semantic
categories
syntactic
categories
semantic categorization constructions
lexical entries
morphological constructions
mapping constructions
(event-type
complete)
(aktionsart
telic)
Fig. 3. The semantic construction translates the meaning of the complete event type
into the telic Aktionsart and back
semantic category of telic Aktionsart, as depicted on the grammar square in
Figure 3. (If we look at the meaning in Example 8, this predicate is precisely
what remained unprocessed after the lexical constructions applied.)
(16)meaning: (event-type ?ev complete) ‚Üê‚Üí
sem-cat: (aktionsart telic)
It is very important to note that the meaning of the event type is allocated to
the already existing unit of the verb. The sem-cat construction does not create
any new units to host this meaning; it rather enhances the verb with the event
type and Aktionsart information that is expressed later by means of morphology.
The template def-sem-cat-cxn is used to deÔ¨Åne such constructions. It has
a subtemplate called def-sem-cat-skeleton which deÔ¨Ånes the basic relation
between meaning and semantic categorization. It also needs the args feature to
provide a link between the event variable ?ev of the construction and the one
used with the unit in the transient structure by the lexicon based on the meaning
of the verb. Thus, the completed form of a template looks as follows:
(17) (def-sem-cat-cxn telicity-sem-cxn
(def-sem-cat-skeleton telicity-sem-cxn
:meaning (== (event-type ?ev complete))
:args (?ev ?ctx)
:sem-cat (==1 (aktionsart telic))))
Scaling Up. The sem-cat constructions for other Aktionsarten can be deÔ¨Åned in
a way similar to the telicity-sem-cxn. The corresponding event-types are rep-
resented with analogous predicates, such as (event-type ?ev begin) standing
for ingressive, (event-type ?ev finish) for terminative, (event-type ?ev
for-a-while) represents delimitative, (event-type ?ev ongoing) durative
Aktionsarten and so on.
104 K. Gerasymova
(18) (def-sem-cat-cxn terminative-sem-cxn
(def-sem-cat-skeleton terminative-sem-cxn
:meaning (== (event-type ?ev finish))
:args (?ev ?ctx)
:sem-cat (==1 (aktionsart terminative))))
(19) (def-sem-cat-cxn durative-sem-cxn
(def-sem-cat-skeleton durative-sem-cxn
:meaning (== (event-type ?ev ongoing))
:args (?ev ?ctx)
:sem-cat (==1 (aktionsart durative))))
4.3 Mapping Constructions
The next step in production is the transformation of the abstract semantic cat-
egories, which re-conceptualize meaning, into the abstract syntactic categories
that are expressed through morphology. For Russian aspect, this transformation
is the place where the interplay between semantic and grammatical categories
of aspect is captured.
Telic-perfective-Construction. For the case of telic Aktionsart, the seman-
tic dimension of telicity has to be translated into its grammatical counterpart
of perfective aspect with all the consequences involved. Here is the mapping
discussed earlier:
(20)sem-cat: (aktionsart telic)
sem-cat: (view ?ev totality)
‚Üê‚Üí syn-cat: (aspect perfective)
As it was the case with the previous construction types, a template called
def-map-cxn is used to create a mapping construction, which realizes this
schematic translation. Instead of deÔ¨Åning everything within the body of a single
template, the diÔ¨Äerent facets of the mapping construction are captured in several
other templates grouped together with def-map-cxn. The def-map-skeleton is
used to realize the basic transformations of categories; the addition of any supple-
mentary categories is delegated to another template. In this case, the basic map-
ping is the translation of telic Aktionsart into perfective aspect (as long as the unit
is a verb) and vice versa. Basic here means that one of the categories is triggered
during the uniÔ¨Åcation phase and is translated into the other during merging.
In production, the construction is triggered by the presence of the telic verb in
the transient structure (assigned by the semantic categorization construction).
Whereas in parsing, the construction is triggered by the syntactic category of
the perfective aspect (assigned by a morphological construction due to the pres-
ence of a preÔ¨Åx). In contrast, the supplementary category of the event view is
never present in the transient structure and is added by the construction both in
Expressing Grammatical Meaning with Morphology 105
meaning form
semantic
categories
syntactic
categories
semantic categorization constructions
lexical entries
morphological constructions
mapping constructions
(aktionsart telic)
(view totality)
(aspect
perfective)
Fig. 4. The mapping telic-perfective-construction couples the semantic category of telic
Aktionsart to its syntactic counterpart of perfective aspect, thereby capturing the se-
mantic Ô¨Çavor of totality that is characteristic of all perfective verbs in an additional
semantic category ‚Äì totality view of event
parsing and production. The special template def-map-cxn is used for this pur-
pose. Summing up thus far, the schematic mapping from Example 20 is equiva-
lent to the following template:
(21) (def-map-cxn telicity-map-cxn
(def-map-skeleton telicity-map-cxn
:sem-cat (==1 (aktionsart telic))
:syn-cat (==1 (lex-cat verb)
(aspect perfective)))
(def-map-impose telicity-map-cxn
:cxn-sem-cat (==1 (view totality))))
Figure 4 summarizes the semantic and syntactic dimensions of aspect, upon
which the construction operates, with the help of the grammar square.
Scaling Up. Other Aktionsarten correspond to analogous constructions, for
example, the delimitative, ingressive and terminative Aktionsarten are also sig-
naled through the perfective aspect. Thus, their mapping constructions diÔ¨Äer
only in the name of aktionsart, as in Example 22. However, the construction
for the durative links durative Aktionsart to the imperfective aspect, which lacks
any notion of totality and is an unmarked case, so the structure of the construc-
tion will diÔ¨Äer as well. Section 5 is dedicated to the discussion of dealing with
the unmarked case of imperfective.
(22) (def-map-cxn terminative-map-cxn
(def-map-skeleton terminative-map-cxn
:sem-cat (==1 (aktionsart terminative))
:syn-cat (==1 (lex-cat verb)
(aspect perfective)))
(def-map-impose terminative-map-cxn
:cxn-sem-cat (==1 (view totality))))
106 K. Gerasymova
Argument Structure Construction. Because we are considering a complete
transitive sentence, there is also a need for a construction that actualizes the
argument structure, that is, a construction that 1) equates the referent of the
subject with that of the verb‚Äôs agent, 2) equates the referent of the direct object
with the verb‚Äôs object, as well as 3) settles case assignments of subject and direct
object, and, Ô¨Ånally, 4) makes the predicate agree with the subject.
Since the implementation of the argument structure is not the focus of this
chapter, we only show the phrasal construction used in this example and refer the
reader to the earlier work on phrasal constructions [13, 14]. More sophisticated
argument structures are discussed in [1, 21].
(def-phrasal-cxn transitive-phrase-cxn
(def-phrasal-skeleton transitive-phrase-cxn
:phrase
(?phrase-unit)
:constituents
((?subject-unit)
(?predicate-unit)
(?object-unit)))
(def-phrasal-agreement transitive-phrase-cxn
(?subject-unit
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(gender ?agent-gender)
(case nominative)))
(?predicate-unit
:sem-cat
(==1 (class event)
(sem-val ((agent ?ev ?agent)
(patient ?ev ?patient))))
:syn-cat (==1 (lex-cat verb)
(gender ?agent-gender)))
(?object-unit
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(case accusative))))
(def-phrasal-linking transitive-phrase-cxn
(?subject-unit
:args (?agent ?ctx))
(?predicate-unit
:args (?ev ?ctx))
(?object-unit
:args (?patient ?ctx))))
Expressing Grammatical Meaning with Morphology 107
4.4 Morphological Constructions
The last processing step in production is the application of morphological con-
structions. Such constructions operate mostly only on the syntactic pole of lin-
guistic structures and specify the surface form of abstract syntactic categories.
Prefix-Construction. The morphological constructions expressing the perfec-
tive aspect have to determine which preÔ¨Åx out of the possible nineteen preÔ¨Åxes
should apply. This decision has also to take semantics into account, illustrating
the non-modular nature of grammar. Here is the proposed schematic mapping:
(23)sem-cat: (aktionsart telic)
‚Üê‚Üí
syn-cat: (aspect perfective)
prefix: (string "na-")
The template for deÔ¨Åning syntactic constructions is called def-morph-cxn and
is able to take constituents such as preÔ¨Åx, stem and suÔ¨Éx, some of which
are optional. It starts by deÔ¨Åning a basic skeleton using the template
def-morph-skeleton. The mapping (23) corresponds to the following template,
which speciÔ¨Åes the preÔ¨Åx na- (na-) and a stem as constituents of a
telic-prefix-cxn construction, with some constraints put on the latter:
(24) (def-morph-cxn telic-prefix-cxn
(def-morph-skeleton telic-prefix-cxn
:prefix "na-"
:stem
(?stem-unit
:sem-cat (==1 (aktionsart telic))
:syn-cat (==1 (aspect perfective)))))
The preÔ¨Åx-construction states that the preÔ¨Åx na- (na-) can serve as an expression
of the telic Aktionsart, such as in napisat (napisat‚Äô, ‚Äòwrite‚Äô), narvat
(narvat‚Äô, ‚Äòcut/pluck/pick‚Äô), nalgat (nalgat‚Äô, ‚Äòlie‚Äô) and so on. Other preÔ¨Åxes
have similar morphological constructions. What the preÔ¨Åx-construction does in
terms of aspectual dimensions is summarized in the grammar square in Figure 5.
Scaling Up. Other preÔ¨Åxes can be deÔ¨Åned in a similar way, as shown:
(25) (def-morph-cxn terminative-prefix-cxn
(def-morph-skeleton terminative-prefix-cxn
:prefix "do-"
:stem
(?stem-unit
:sem-cat (==1 (aktionsart terminative))
:syn-cat (==1 (aspect perfective)))))
108 K. Gerasymova
meaning form
semantic
categories
syntactic
categories
semantic constructions
lexical entries
syntactic constructions
mapping constructions
Aktionsart telic aspect perfective
prefix "-"
Fig. 5. The preÔ¨Åx-construction speciÔ¨Åes the surface expression of telic Aktionsart and
perfective aspect through the preÔ¨Åx na- (na-)
Ending-Construction. Additionally, all Russian verbs require a conjugated
ending to complete their form. The ending is implemented here with the help of
a similar template, specifying the ending -l (-l), which has to be attached to
all masculine verbs in the past tense:5
(def-morph-cxn masculine-ending-morph-cxn
(def-morph-skeleton masculine-ending-morph-cxn
:suffix "-l"
:stem
(?stem-unit
:syn-cat (==1 (lex-cat verb)
(gender masculine)))))
The feminine ending -la (-la) is deÔ¨Åned analogously.
5 Dealing with the Unmarked Case
Imperfective aspect is the unmarked case in Russian grammar. This raises
the question of how to treat the unmarked forms in FCG, as pointed out in
the previous section. The diÔ¨Éculty, namely, lies in parsing: if in the course
of the application of the morphological constructions there is no marker in-
dicating perfectivity, the syntactic category of aspect remains unassigned in the
transient structure. The question arises, then, as to how to Ô¨Åll something in
based on the absence of information.
One can imagine several possible ways of dealing with unmarked cases. A
rather unfortunate solution is to have an explicit representation of an absent
marker, such as the empty preÔ¨Åx (NIL-preÔ¨Åx), and then to have a morpho-
logical construction that triggers on it, assigning the imperfectivity to a verb.
5
Expression of tense falls out of the scope of the present chapter.
Expressing Grammatical Meaning with Morphology 109
Although it is widely used, this solution creates unnecessary search because such
null-forms would have to be assumed all the time. The second possible way is
to assume the default (unmarked) feature value from the very beginning, so, in
the case at hand, the default imperfective aspect would already appear in the
deÔ¨Ånition of the verb stem. To be realizable, this solution requires that linguistic
processing is able to override these defaults when a speciÔ¨Åc grammatical marking
is encountered. At this point, FCG does not allow overriding values of features
and with good reason, one of which is that although overriding signiÔ¨Åcantly
extends the representational power, it also increases the risk in grammar design.
More importantly, all the decisions that were made based on the default (such
as all constructions applying under the assumption of imperfective) have to be
reverted, which creates the need for complex backtracking mechanisms. Such
mechanisms are not currently part of the FCG-interpretation process due to the
great costs connected to them. What is the alternative solution for handling
unmarked cases?
It is important to postpone the decision on a feature value until it is deÔ¨Ånitely
sure that no counter evidence of marking can be expected anymore; and only
then is the default case assumed. One way to actualize this approach is by or-
ganizing constructions into sets and ordering their application (as discussed in
[22], and used in a case study on Hungarian by [1]). SpeciÔ¨Åcally, after the appli-
cation of the morphological constructions, the system runs special constructions
for unmarked cases. The drawback of this solution is that this special construc-
tion set is only needed in parsing. Thus, one ends up with the application of
diÔ¨Äerent constructions in diÔ¨Äerent processing directions, which is counter to the
general design philosophy of FCG. Another solution explored here requires the
constructions that need to know about the possibly unmarked feature values to
add this information, which is explained in detail below.
Durative-Imperfective Construction. The mapping construction needed
here has to relate the durative Aktionsart to the imperfective aspect. This con-
struction is the Ô¨Årst one to notice the lack of grammatical marking in parsing.
After all morphological constructions have been tried out and none of them have
detected an expression of perfective, the aspect feature on the syntactic pole of
the transient structure remains empty due to the unmarked nature of imper-
fective. At this point the decision concerning the unmarked case can be made
with certainty, and the language processing requires the mapping of the newly
assumed imperfective into the durative Aktionsart. Being the Ô¨Årst one to apply
at this point, our construction, besides the mapping realization, has to also Ô¨Åll
in the default case of the imperfective aspect. Since imperfective is never present
in uniÔ¨Åcation, it cannot be speciÔ¨Åed in the skeleton of the construction and has
to be added afterwards by using the def-map-impose template which adds the
information about the imperfective aspect as illustrated in Example 26:
110 K. Gerasymova
(26) (def-map-cxn durativity-map-cxn
(def-map-skeleton durativity-map-cxn
:sem-cat (==1 (aktionsart durative))
:syn-cat (==1 (lex-cat verb)))
(def-map-impose durativity-map-cxn
:cxn-syn-cat
(==1 (aspect imperfective))))
In case there are many constructions that require the information supplied by
such an unmarked case, this solution implies that all of them make the decision
separately upon application. This redundancy is not problematic here, since in
the case at hand, only the durative has to be translated to imperfective. In other
cases, however, this way of solving the default case may become less elegant.
6 Language Processing
The goal of this section is to examine, in more detail, how all the constructions
introduced in earlier sections apply in production and in parsing.
6.1 Production
At the beginning of production, the FCG engine creates an initial linguistic struc-
ture, which is a meaning-form mapping similar to constructions, as shown in Fig-
ure 6: the semantic pole contains the meaning that has to be expressed, and the
syntactic pole is empty so far. In the process of production this linguistic structure
gradually becomes enhanced with other linguistic information, especially on the
syntactic side, Ô¨Ånally creating an utterance as an outcome of production.
The Ô¨Årst construction set to apply in production is the lexical entries set.
Upon its application, each lexical construction creates a new unit in both poles
meaning
top
((michael michael-indiv
context-1)
(face face-obj context-1)
(draw draw-ev context-1)
(drawer draw-ev
michael-indiv)
(drawee draw-ev face-obj)
(event-type draw-ev
complete)
(context context-1))
top
sem syn
Fig. 6. Initial transient structure in production. Its semantic pole contains the meaning
that has to be expressed; the syntactic pole is empty.
Expressing Grammatical Meaning with Morphology 111
sem-subunits
meaning
top
(word-draw-2
word-michael-2
word-face-2)
((context context-1)
(event-type draw-ev
complete))
syn-subunits
top
(word-draw-2
word-michael-2
word-face-2)
meaning
sem-cat
args
footprints
word-draw-2
((draw draw-ev
context-1)
(drawer draw-ev
michael-indiv)
(drawee draw-ev
face-obj))
((class event)
(sem-val
((agent draw-ev
michael-indiv)
(patient draw-ev
face-obj))))
(draw-ev context-1)
(draw-cxn)
meaning
sem-cat
args
footprints
word-michael-2
((michael
michael-indiv
context-1))
((class indiv))
(michael-indiv
context-1)
(michael-cxn)
meaning
sem-cat
args
footprints
word-face-2
((face face-obj
context-1))
((class indiv))
(face-obj context-1)
(face-cxn)
sem syn
form
footprints
syn-cat
word-draw-2
((string word-draw-2
"risova"))
(draw-cxn)
((lex-cat verb)
(gender ?gender-38))
form
footprints
syn-cat
word-face-2
((string word-face-2
"lico"))
(face-cxn)
((lex-cat noun)
(gender neuter)
(case ?case-59))
form
footprints
syn-cat
word-michael-2
((string word-michael-2
"Misha"))
(michael-cxn)
((lex-cat noun)
(gender masculine)
(case ?case-58))
Fig. 7. Current transient structure after the application of all lexical entries. Each
lexical entry creates a new unit in both poles of the linguistic structure and relocates
all the relevant information to it.
of the transient structure and relocates there all the relevant information of the
found word.6
After all the lexical entries that could be applied ‚Äì in our example,
these are the face-, michael- and draw-constructions ‚Äì have been applied, the
current transient structure contains three units hanging from the top-unit, each
corresponding to one lexical stem, as shown in Figure 7.
This way, starting from the initial structure in Figure 6 with an empty syn-
tactic pole, the FCG engine gradually enhances the transient structure by trying
out diÔ¨Äerent lexical, semantic, mapping and Ô¨Ånally morphological constructions
until no more constructions can be applied. Figure 8 shows the syntactic pole of
the resulting structure. The head of the hierarchy builds the top-unit, followed
by the phrase-unit that was created by the argument structure construction to
capture all the constituents of the transitive sentence under one parent. The units
for each of the constituents were established by the lexical constructions; in the
course of production other grammatical constructions have gradually Ô¨Ålled them
with linguistic information. In later stages, the morphological constructions have
attached two units to the verb with information about the preÔ¨Åx and ending. The
Ô¨Ånal linguistic structure is rendered into the utterance Misha na- risova -l lico
(‚ÄòMisha has drawn a face‚Äô), which was the target of the production process.
6.2 Parsing
The great advantage of FCG is that in parsing the exact same events occur as in
production except for the direction of the construction application. The parsing
6
The detailed application of lexical constructions is covered in [14, 16].
112 K. Gerasymova
syn-subunits
top
(phrase-unit-15)
sem syn
footprints
syn-subunits
phrase-unit-15
(transitive-phrase-cxn)
(word-draw-9
word-face-9
word-michael-9)
footprints
form
syn-cat
word-face-9
(face-cxn)
((string word-face-9
"lico"))
((gender neuter)
(case accusative)
(lex-cat noun))
footprints
form
syn-cat
word-michael-9
(michael-cxn)
((string word-michael-9
"Misha"))
((gender masculine)
(case nominative)
(lex-cat noun))
footprints
syn-subunits
form
syn-cat
word-draw-9
(map draw-cxn
masculine-ending-morph-cxn)
(morph--l-1 morph-na-6)
((string word-draw-9
"risova"))
((lex-cat verb)
(gender masculine)
(aspect perfective))
form
footprints
morph-na-6
((meets morph-na-6
word-draw-9)
(string morph-na-6 "na-"))
(telic-prefix-syn-cxn)
form
footprints
morph--l-1
((meets word-draw-9
morph--l-1)
(string morph--l-1 "-l"))
(masculine-ending-morph-cxn)
Fig. 8. The syntactic pole of the transient structure at the end of production. It is
rendered into the utterance Misha na- risova -l lico (‚ÄòMisha has drawn a face‚Äô).
top
form
top
((string lico-6 "lico")
(string -l-1 "-l")
(string risova-6 "risova")
(string na--4 "na-")
(string misha-6 "Misha")
(meets misha-6 na--4)
(meets na--4 risova-6)
(meets risova-6 -l-1)
(meets -l-1 lico-6))
sem syn
Fig. 9. Initial feature structure by parsing of Misha na- risova -l lico
process is initiated by an agent‚Äôs perceiving an utterance: Misha na- risova -l lico.
This information is captured by the FCG system in the initialcoupledfeature struc-
ture (Figure 9): on the syntactic side the top unit consists of parsed strings and or-
dering constraints explicating which string meets which, while the semantic pole
remains empty. Note the mirroring of poles when compared to initial structure in
production in Figure 6. From this stage, the system constructs the meaning of the
observed utterance by simply reversing the order of the construction application:
the uniÔ¨Åcation takes place on the syntactic pole followed by the merging of the se-
mantic pole (and the syntactic pole). This diÔ¨Äerence leads also to the reversed order
of application of the various types of constructions: lexical constructions still come
Ô¨Årst but are immediately followed by the morphological constructions. This order
is necessary because these two construction types provide the syntactic informa-
tion that is required by mapping constructions for determining a verb‚Äôs Aktion-
sart and aspect. Finally, once the mapping constructions have been applied, the
Expressing Grammatical Meaning with Morphology 113
sem-subunits
top
(phrase-unit-16)
sem-subunits
footprints
phrase-unit-16
(lico-7 misha-7
risova-7)
(transitive-phrase-cxn
telicity-sem-cxn)
footprints
meaning
sem-cat
args
misha-7
(michael-cxn)
((michael ?drawer-38
?ctx-127))
((class indiv))
(?drawer-38 ?ctx-127)
footprints
meaning
sem-cat
args
lico-7
(face-cxn)
((face ?drawee-38
?ctx-127))
((class indiv))
(?drawee-38 ?ctx-127)
meaning
args
sem-cat
footprints
risova-7
((drawee ?ev-76
?drawee-38)
(drawer ?ev-76
?drawer-38)
(draw ?ev-76
?ctx-127)
(event-type ?ev-76
complete))
(?ev-76 ?ctx-127)
((view totality)
(sem-val
((agent ?ev-76
?drawer-38)
(patient ?ev-76
?drawee-38)))
(aktionsart telic)
(class event))
(map draw-cxn
telic-prefix-syn-cxn
telicity-sem-cxn)
sem syn
Fig. 10. The semantic pole of the Ô¨Ånal structure built in parsing of Misha na- risova
-l lico. The underlying meaning is in Example (27).
semantic constructions are able to reveal the meaning encoded in the semantic cat-
egories.Thus, in production, the movement along the grammar square (Figure 2) is
clockwise.
Analogous to production, the application of available constructions enhances
the initial transient structure with an empty semantic pole to the Ô¨Ånal tran-
sient structure in Figure 10, which contains elaborate semantics. This transient
structure codes for the underlying meaning of the perceived utterance Misha na-
risova -l lico (Mixa narisoval lico), which is the combination of all meaning
features of its units:
114 K. Gerasymova
(27) (michael ?drawer ?ctx)
(draw ?ev ?ctx)
(drawer ?ev ?drawer)
(drawee ?ev ?drawee)
(event-type ?ev complete)
(face ?drawee ?ctx)
(context ?ctx)
It is important to note that the notion of totality is not directly represented in
the meaning, but is instead captured as a semantic constraint of an event view
(sem-cat (==1 (view totality))).
The Ô¨Ånal transient structure of parsing is structurally identical to the Ô¨Ånal tran-
sient structure of production with the only diÔ¨Äerence being that it contains some
variables. The reason for this diÔ¨Äerence is that in production the meaning comes
out of the world model, and everything is already instantiated with concrete en-
tities from the context, whereas in parsing the resulting meaning is anchored to
the world only during the interpretation process which starts after parsing.
7 Discussion
The presented organization of the grammar into diÔ¨Äerent sets of constructions
provides not only a mechanism for setting decision points, necessary, for example,
for dealing with the unmarked case, but it also has important implications on
Ô¨Çexibility. In case of uncertainty and communicative problems, the inability to
process parts of the utterance does not inhibit the processing of the utterance
as a whole. For instance, when encountering unfamiliar or missing grammatical
markers, the ability to process the lexicon already gives the possibility to be
partially understood.
The division into diÔ¨Äerent types of constructions is also helpful for organizing
the learning process that is the target of the current research. SigniÔ¨Åcant is that
the presented construction sets exhibit diÔ¨Äerent levels of abstraction. That is,
they can be subsumed in diÔ¨Äerent sets not only in terms of their functionality but
also in terms of abstractness, with the lexical entries being much less abstract
than the most abstract mapping constructions. During the acquisition process,
lexical constructions can be learned independently of the complex aspect system;
aspect markers can be learned Ô¨Årst in an ad hoc way, and then the more abstract
and more diÔ¨Écult to learn categories can be acquired [8].
Another approach for grammar organization is discussed in [22]. It shows how
families of related constructions can be organized in a network-based relation-
ship, how this organization is useful during linguistic processing and how it can
be learned by the FCG-engine during the linguistic processing. The latter point,
that the constructicon organization can stem from the linguistic processing it-
self, demonstrates that the division of labor between constructions as shown in
this chapter is not a pure artifact imposed by the grammar architect.
Overall, the presented chapter is relevant to some current questions in linguis-
tics. One interesting issue of speculation for linguists is what in a language is
Expressing Grammatical Meaning with Morphology 115
learned in an individual instance and what is represented in a rule-based fashion.
The grammar presented in this chapter comprised preÔ¨Åxes that are likely to be
learned as a rule, or in our terminology as semantic item-based constructions.
However, there are many inconsistent cases in Russian, which is also the reason
for the diÔ¨Éculties that aspect causes to language learners. There is essentially no
one-to-one mapping between preÔ¨Åxes and Aktionsarten: one can say that each
verb basically decides itself how to interpret a particular preÔ¨Åx, which in con-
junction with 19 existing preÔ¨Åxes generates a terrifying number of cases that
have to be memorized. To account for this complexity, the presented didactic
example could be extended with respect to the intertwinement between preÔ¨Åxes
and verbs. One possible way to enact this conjoining is to enhance construc-
tions for verbs with the information about the preÔ¨Åxes they employ in order to
build diÔ¨Äerent Aktionsarten. Another alternative would be to create separate
holophrastic constructions for each of the idiosyncratic perfective forms.
A further issue concerning Russian aspect that intrigues linguists is that not
all verbs behave the same way with respect to aspectual derivation. Recent
studies in cognitive linguistics suggested that it is the lexical meaning of a verb
that constrains its possibilities for deriving diÔ¨Äerent Aktionsarten [10, 11]. For
instance, the verb pahnuti
(pachnut‚Äô, ‚Äòsmell‚Äô) is inherently atelic and can-
not derive the telic Aktionsart. To account for these constraints, the presented
grammar could be extended to incorporate a new category ‚Äì potential to derive
a particular aspectual form ‚Äì into the knowledge about a verb.
8 Conclusion
This chapter presented a case study of the Russian aspect as a didactic example
demonstrating how to deal with grammatical meaning in FCG. The reader was
introduced to a general methodology for designing complex grammars and di-
viding labor between constructions. The success of the approach was highlighted
by demonstrating the grammar in operation using example dialogues that were
produced and parsed. During the development of aspect grammar, the case of
imperfective raised the issue of unmarked forms, which was plausibly solved on
the basis of the current grammar organization. The key to the solution was the
division of the constructicon into diÔ¨Äerent construction sets providing potential
decision points for inÔ¨Çuencing the language processing. When developing gram-
mars for other grammatical categories, the design described in this study can
aid grammarians in their decision process, especially for those domains that are
expressed morphologically or feature unmarked forms.
Acknowledgements. Research reported in this chapter was partly funded by
the EU project ALEAR and carried out at the Sony Computer Science Labo-
ratory in Paris. I thank the whole team working on FCG at the University of
Brussels (VUB AI lab) and at Sony CSL for their contributions in making FCG
such a superb environment for doing sophisticated experiments in construction
grammar.
116 K. Gerasymova
References
[1] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[2] Bickel, B.: Aspectual scope and the diÔ¨Äerence between logical and semantic rep-
resentation. Lingua 102, 115‚Äì131 (1997)
[3] Comrie, B.: Aspect: An Introduction to the Study of Verbal Aspect and Related
Problems. Cambridge University Press, Cambridge (1976)
[4] Comrie, B.: Tense. Cambridge University Press, Cambridge (1985)
[5] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[6] Forsyth, J.: A Grammar of Aspect: Usage and Meaning in the Russian Verb.
Cambridge University Press, Cambridge (1970)
[7] Forsyth, J.: The nature and development of the aspectual opposition in the Russian
verb. The Slavonic and East European Review 50(121), 493‚Äì506 (1972)
[8] Gerasymova, K., Spranger, M.: Acquisition of Grammar in Autonomous ArtiÔ¨Åcial
Systems. In: Proceedings of the 19th European Conference on ArtiÔ¨Åcial Intelli-
gence, ECAI 2010 (2010)
[9] Gerasymova, K., Steels, L., van Trijp, R.: Aspectual morphology of Russian verbs
in Fluid Construction Grammar. In: Proceedings of the 31th Annual Conference
of the Cognitive Science Society (2009)
[10] Janda, L.A.: Aspectual clusters of Russian verbs. Studies in Language 31(3),
607‚Äì648 (2007)
[11] Janda, L.A.: Semantic motivations for aspectual clusters of Russian verbs. In:
American Contributions to the XIV International Congress of Slavists, p. 22 (2008)
[12] Krongauz, M.A.: Pristavki i glagoly v russkom jazyke: semantiƒçeskaja grammatika.
Jazyki russkoj kul‚Äôtury, Moscow (1998)
[13] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[14] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[15] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[16] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[17] Steels, L. (ed.): Computational Issues in Fluid Construction Grammar. Springer,
Berlin (2012)
[18] Steels, L.: Design Methods for Fluid Construction Grammar. In: Steels, L. (ed.)
Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 3‚Äì36. Springer, Hei-
delberg (2012)
[19] Stoll, S.: The role of aktionsart in the acquisition of Russian aspect. First Lan-
guage 18(54), 351‚Äì376 (1998)
[20] Stoll, S.: Beginning and end in the acquisition of the perfective aspect in Russian.
Journal of Child Language 32(4), 805‚Äì825 (2005)
Expressing Grammatical Meaning with Morphology 117
[21] van Trijp, R.: A design pattern for argument structure constructions. In: Steels,
L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Ams-
terdam (2011)
[22] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
Appendix: Defining a Grammar or How to Write
Templates
Templates are useful abstractions; however, they hide what happens behind the
scenes. This section is targeted to those readers who are interested in the tech-
nical details of the implementation. For an example of a semantic categorization
construction, a general methodology of how to develop templates is illustrated in
detail. The reader can get acquainted with how to write real FCG-constructions
that serve a particular function and, thereafter, how to turn them into self-
deÔ¨Åned templates.
Methodology for Writing Templates. Templates can be very large or quite
small, complicated or basic, highly specialized or multi-purpose, but the devel-
opment of almost all of them goes through the following four steps:
1. The linguistic dimensions that play a key role are identiÔ¨Åed.
2. An example of a complete construction is developed into which a future
template expands.
3. When scaling up, the changeable elements of a construction are identiÔ¨Åed.
4. A template emerges as a parametrized version of a construction.
Taking an example of a semantic categorization construction for a case of the telic
Aktionsart, let us develop the template def-sem-cat-cxn used in the previous
section to deÔ¨Åne all semantic categorization constructions.
1. Key Linguistic Dimensions. Semantic categorization constructions have to
re-categorize parts of the meaning into the language-internal semantic categories.
Hence, they operate on the dimensions of meaning and sem-cats. For the case
of the telic Aktionsart, the schematic mapping was already identiÔ¨Åed in Section
3.2 as the following:
(28)meaning: (event-type ?ev complete) ‚Üê‚Üí
sem-cat: (aktionsart telic)
2. Writing a Complete Construction. By this time the reader is familiar
with several FCG-constructions. Our telic-construction diÔ¨Äers from all the pre-
vious ones in that it operates only on one pole of the linguistic structure to
which it applies, namely, only on the semantic pole. This is the case because the
transformation it realizes ‚Äì translation of meaning into semantic categories and
back ‚Äì aÔ¨Äects only semantics.
118 K. Gerasymova
It is important to note that our telic-construction still contains two coupled
poles; yet, both its left and its right poles refer to the semantic pole of a linguistic
structure.
In building a construction, let us start by creating a skeleton and pinning
down the meaning it should trigger on. After the application of the lexical con-
structions, the information about the event type is still located in the top of
the linguistic structure (Figure 7), so the construction has to search for it there.
Additionally, we tag this meaning to make it movable in order to allocate it later
to an appropriate unit.
((?top-unit
(tag ?meaning (meaning (== (event-type ?ev complete))))))
<-->
((?top-unit))
There are some things to take into account before we relate this meaning to
the telic Aktionsart. First, the preliminary construction shown above has to be
constrained in a way so that it uniÔ¨Åes with only speciÔ¨Åc kinds of structures.
Namely, we want it to apply only in the presence of a verb because this is where
the aspectual information about the internal structure of events is expressed in
Russian. Thus, we extend the construction by the desired hierarchical structure,
i.e., the top unit should contain a subunit (?ev-unit), which is responsible for
an event. To assure that it is an event, we constrain the sem-category of this
unit to the (class event), under the assumption that the lexical entry for this
verb has already applied creating this separate unit. The extended version looks
as follows:
((?top-unit
(tag ?meaning
(meaning (== (event-type ?ev complete))))
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (class event)))))
<-->
((?top-unit
(sem-subunits (== ?ev-unit))))
Now the time has come to translate the completeness of the event into the
category of the telic Aktionsart of the corresponding verb. For this we have to
add the sem-cat of Aktionsart to the event unit and move the corresponding
meaning of event-type from the top-unit into it.
Important to note is that this construction actualizes merging of the new
information into an existing structure. It accesses the substructure and alters
it, augmenting the existing unit with some parts of meaning and a semantic
category. To specify the semantic category of Aktionsart, we simply add it to
the event unit on the right pole of the construction, because this is where the
merging phase takes place in production:
Expressing Grammatical Meaning with Morphology 119
((?top-unit
(tag ?meaning
(meaning (== (event-type ?ev complete))))
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (class event)))))
<-->
((?top-unit
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (aktionsart telic)))))
On the other hand, the addition of the tagged meaning on the left pole has to
be done with the help of the J-operator. This addition cannot be done here by
merging as well due to the nature of parsing. When writing FCG-constructions,
one has to consider the Ô¨Çow of information in both application directions in order
to ensure bi-directionality. With regard to production in the previous case, the
information about the telic Aktionsart would already be present in the event
unit after the application of the morphological construction: the construction
for the preÔ¨Åx will already have translated the preÔ¨Åx into the telic Aktionsart of
the preÔ¨Åxed verb. Thus, when the right pole of our semantic construction uniÔ¨Åes
with the linguistic structure, the presence of the sem-cat of the telic Aktionsart
has to serve as a constraint in order to ensure that the translation only occurs
by those verbs that are telic. Therefore, this condition is speciÔ¨Åed in the sem-cat
of the event unit on the right pole. However, with respect to the current case
of parsing, at this point in parsing there is no information about the meaning
‚Äì it is speciÔ¨Åcally the job of the semantic construction to add meaning to the
transient structure. The meaning cannot simply be put on the right pole of the
event unit as a condition; it has to be added with the J-operator:
((?top-unit
(tag ?meaning
(meaning (== (event-type ?ev complete))))
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (class event))))
((J ?ev-unit)
?meaning))
<-->
((?top-unit
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (aktionsart telic)))))
120 K. Gerasymova
The next step in building our telic-construction is the addition of footprints. Nor-
mally, the footprints are put in the same unit once with an excludes (==0) and
once with an includes operator (==1) on each pole of the construction, respec-
tively. The excludes Ô¨Årst ensures that the construction applies for the very Ô¨Årst
time, and the includes leaves a mark (usually, the name) after the construction‚Äôs
application. In our case, however, the footprints have to be attached to separate
units on the left and right poles because both refer to the semantic pole, and
hence the added mark on one pole would cause conÔ¨Çicts by the merging of the
other pole with an excludes operator and vice versa. The footprints are attached
on the left pole to the event-unit and on the right pole to the top-unit:
((?top-unit
(tag ?meaning
(meaning (== (event-type ?ev complete))))
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (class event)))
(footprints (==0 telicity-sem-cxn)))
((J ?ev-unit)
?meaning
(footprints (==1 telicity-sem-cxn))))
<-->
((?top-unit
(sem-subunits (== ?ev-unit))
(footprints (==0 telicity-sem-cxn)))
(?ev-unit
(sem-cat (==1 (aktionsart telic))))
((J ?top-unit)
(footprints (==1 telicity-sem-cxn))))
Our construction is already fully operational and behaves in the desired manner
during production. However, in parsing a small detail is still missing. What the
present construction lacks is that the variable ?ev in the event-type predicate
refers to the same event as the one in the event-unit ?ev-unit. Up until now
there was nothing linking the two, which means that nothing stated that this
particular event is of the type complete, although the event-type predicate was
moved into the event-unit, and the variable names happened to be the same
locally in both feature structures. The gap can be closed with the help of the
args feature. Recall that the lexical entry for event has speciÔ¨Åed its arguments
in the list (?ev ?ctx), the purpose of which has hitherto remained mysterious.
It can now be made use of, in order to specify the variables‚Äô equality by means
of referring to both the event argument of the event unit and the event of the
event-type predicate with the same name within the same construction. In this
way, we arrive at the following telic-construction:
Expressing Grammatical Meaning with Morphology 121
((?top-unit
(tag ?meaning
(meaning (== (event-type ?ev complete))))
(sem-subunits (== ?ev-unit)))
(?ev-unit
(sem-cat (==1 (class event)))
(args (?ev ?ctx))
(footprints (==0 telicity-sem-cxn)))
((J ?ev-unit)
?meaning
(footprints (==1 telicity-sem-cxn))))
<-->
((?top-unit
(sem-subunits (== ?ev-unit))
(footprints (==0 telicity-sem-cxn)))
(?ev-unit
(sem-cat (==1 (aktionsart telic))))
((J ?top-unit)
(footprints (==1 telicity-sem-cxn))))
Now the construction is complete. Note that it is concerned neither with perfec-
tive aspect nor the notion of totality characteristic to all perfective verbs. This
design decision underlines that Aktionsarten alone are not responsible for the
emergence of the grammatical aspect. Another point to note is that this telic-
construction is item-based; item being a speciÔ¨Åc kind of temporal semantics Ô¨Åxed
for a construction, whereas the event that this temporal semantics refers to is
unspeciÔ¨Åed and represented as a slot to Ô¨Åll in by a verb.
3. Identifying the Pattern. To discover a pattern, one has to consider what
the semantic categorization constructions for other Aktionsarten look like. As al-
ready mentioned, other semantic nuances are also represented with the predicate
of event type, such as (event-type begin). Respectively, they get mapped onto
diÔ¨Äerent Aktionsarten, such as the notion of beginning onto the (aktionsart
ingressive). Thus, these elements of a construction diÔ¨Äer for other Aktion-
sarten. The rest of the construction‚Äôs structure remains the same except for its
name and the event variable present in the :args feature.
4. Template def-sem-cxn. As soon as the changeable elements of a construc-
tion deÔ¨Ånition are known, a construction can be easily converted into a template,
where concrete values are substituted by parameters that are supplied later by
a template. In the case at hand, the feature value components for meaning,
sem-cat, args as well as the name of the construction will be diÔ¨Äerent for
diÔ¨Äerent constructions, thus they are turned into parameters in a template deÔ¨Å-
nition (i.e., the underlined list).7
When the template is called, these parameters
7
&key means that parameters are named.
122 K. Gerasymova
are substituted inside the construction by the actual values supplied in the call.
Shown below is the template deÔ¨Ånition with substituted parameters indicated in
bold:
(defmacro def-sem-cat-cxn (name &key meaning args sem-cat)
‚Äò(((?top-unit
(tag ?meaning (meaning ,meaning))
(sem-subunits (== ?unit-name)))
(?unit-name
(sem-cat (==1 (class event)))
(args ,args)
(footprints (==0 ,name)))
((J ?unit-name)
?meaning
(footprints (==1 ,name))))
<-->
((?top-unit
(sem-subunits (== ?unit-name))
(footprints (==0 ,name)))
(?unit-name
(sem-cat ,sem-cat))
((J ?top-unit)
(footprints (==1 ,name))))))
With the def-sem-cat-cxn template, the deÔ¨Ånition of the entire telic-
construction can be folded into the following call:
(29) (def-sem-cat-cxn telicity-sem-cxn
:meaning (== (event-type ?ev complete))
:args (?ev ?ctx)
:sem-cat (==1 (aktionsart telic)))
Handling Scope in Fluid Construction Grammar:
A Case Study for Spanish Modals
Katrien Beuls
ArtiÔ¨Åcial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium
Abstract. This paper demonstrates one way how the Spanish epistemic
modal system can be implemented in Fluid Construction Grammar.
Spanish is a Romance language with a rich morpho-phonological sys-
tem that is characterized by paradigmatic stem changes, a considerable
degree of syncretism in verbal suÔ¨Éxes and a sophisticated usage of modal
markers. Because the choice of mood does not only depend on the lin-
guistic expression that is used (e.g. "probablemente", "creo que ..."), but
also on the position of such expression in the utterance and its scope, the
processing engine needs to be Ô¨Çexible enough to capture these conditions.
The formal implementation of the Spanish conjugational paradigm with
special focus on syncretic markers forms a prerequisite for the processing
of verbal mood and modal expressions.
1 Introduction
Language is a product of its users. Conversation partners usually do not hesitate
to package their utterances in such a way that the interlocutor understands their
attitude toward the proposition that is expressed. This strategy is operational
in many language systems around the world and is mostly realized by means of
mood and modal expressions that create diÔ¨Äerent shades of meaning. Since these
forms are inextricably tied to the Ô¨Åeld of (inter)subjective communication, the
main question of this paper is concerned with the way in which such expressions
can be captured by a formal representation of grammar. This paper shows one
way in which a modal language system for (peninsular) Spanish1
can be modeled
in Fluid Construction Grammar (hereafter: FCG) [3, 8, 12]. Linguists tradition-
ally make the distinction between propositional modality and event modality [7].
Since this paper reports on a Ô¨Årst case study of the implementation of a modal
system in FCG, only propositional modality has been considered, with special
focus on epistemic modality.
The following requirements are speciÔ¨Åc to this FCG grammar and make this
case study an interesting workbench for grammar formalizations:
1. Since the Spanish language is characterized by frequent stem changes in
the verbal conjugational paradigm and syncretic suÔ¨Éxes (single form for
1
Modal expressions are often dependent on the geographical and social situation of
the language community.
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 123‚Äì142, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
124 K. Beuls
multiple functions), the formalization needs to be robust enough to handle
such morpho-phonological incongruencies.
2. Multiple modal constructions are needed to actualize diÔ¨Äerences in meaning
and form (e.g. mood suÔ¨Éxes). The organization of such a series of construc-
tions poses an interesting challenge: The moment in the processing pipeline
when the modal constructions apply is crucial for their success.
3. A modal grammar requires the use of subclauses and therefore launches the
handling of scoping and the start of possible long distance dependencies
between clauses.
4. Flexible processing allows the grammar to come up with multiple solutions
for one meaning, inÔ¨Çuenced by the discourse context. The constructions
themselves are thus not the only decision makers in the production process.
After the introduction of some basic linguistic facts about the language system
that forms the subject of this case study in Section 2, the paper addresses the four
requirements listed above in their order of appearance. Section 3 demonstrates
the processing of syncretic forms in FCG and introduces a template that handles
verbal stem changes. Modal constructions form the subject of Section 4: their
functionality as well as their role in the processing pipeline are discussed. Section
5 launches the use of modal subclauses and the presence of a scoping relation
between the main clause and the subordinated clause. Section 6 discusses de-
viant uses of modal expressions and their implications for the processing engine.
Finally, Section 7 concludes the paper and gives directions for further research
on the topic.
2 Linguistic Facts
Since this paper is concerned with a case study on the implementation of epis-
temic modality in Spanish, some basic linguistic background information is re-
quired in order to fully grasp its computational complexity and relevance for
theories of grammar formalization. Section 2.1 addresses the meaning of the
term epistemic modality; Section 2.2 concentrates on the building blocks of the
verbal conjugational paradigm in Spanish. Section 2.3 brieÔ¨Çy discusses the use
of the subjunctive mood in Spanish.
2.1 Epistemic Modality
Modality typically encodes the speaker‚Äôs attitude towards the proposition that is
expressed. In the case of epistemic modality, the speaker forms his or her modal
"judgement" based on the kind of knowledge (< Gr. epist√®m√®) he or she has
acquired about the proposition (truth, probability, certainty, belief, evidence).
The use of the term epistemic is relatively straightforward, with possibility and
probability as two major epistemic meaning predicates. Another epistemic cat-
egory is certainty, which is used when the speaker has good reason to believe
that the statement is true (e.g. ‚ÄòThere must be some way to get from New York to
Handling Scope in Fluid Construction Grammar 125
San Francisco for less than $600.‚Äô). Consider the clear contrast in the notional
features involved in the following pairs of examples (adopted from [7]):
(1) Kate may be at home now.
Kate must be at home now.
(2) Kate may come in now.
Kate must come in now.
The distinction between (1) and (2) is usually made in terms of propositional
modality and event modality. This is illustrated by the use of paraphrases using
‚Äòpossible‚Äô and ‚Äònecessary‚Äô:
(3) It is possibly the case that Kate is at home now.
It is necessarily the case that Kate is at home now.
(4) It is possible for Kate to come in now.
It is necessary for Kate to come in now.
In Example (4), the speaker expresses his personal attitude toward a potential
future event, that of Kate coming in. Example (3) is concerned with the speaker‚Äôs
judgement of the proposition that Kate is at home.
2.2 Spanish Verbal Paradigm
Spanish is a member of the Indo-European language family and belongs to the
branch of Romance languages. This branch comprises all languages that descend
from vulgar Latin, the language of Ancient Rome. Today, Spanish is the third
most spoken language in the world with about 500 million native speakers.
A deÔ¨Åning feature of Spanish phonology is its diphthongization of the Latin
short vowels e and o into ie and ue, respectively, in stressed contexts (e.g. Lat.
petram > Sp. piedra). This diÔ¨Äerence in stress pattern has been preserved in
the current stem morphology, which has lead to four main cases that a language
user has to account for when conjugating a verb in Spanish:
1. Regular stem, regular endings: ‚Äòcortar‚Äô, ‚Äòdeber‚Äô, ‚Äòvivir‚Äô, etc. (see Table 1)
2. Irregular stem, regular endings: e.g. ‚Äòempezar‚Äô > ‚Äòempiezo‚Äô (begin.inf > be-
gin.1sg.present), ‚Äòvolver‚Äô > ‚Äòvuelvo‚Äô (return.inf > return.1sg.present)
3. Regular stem, irregular endings: e.g. ‚Äòandar‚Äô > ‚Äòand-uve‚Äô (walk.inf >walk.1sg.
past.pf )
4. Irregular stem, irregular endings: ‚Äòhacer‚Äô > ‚Äòhic-e‚Äô (do.inf > do.1sg.past.pf )
Irregular uses do not always show a deviant conjugation over the full paradigm2
.
Depending on the class a verb belongs to and the verb tense and mood that is
required, verbs may or may not be conjugated in an irregular manner. There
2
The term paradigm is used here to refer to one column in the conjugational table;
e.g. 1st verb class indicative present.
126 K. Beuls
are three verb classes in Spanish: verbs ending on -ar, -er and -ir. Without
taking into account the compound tenses (auxiliary haber + past participle),
there are Ô¨Åve diÔ¨Äerent tenses in the indicative mood: present, past imperfect,
past perfect, future and conditional. The subjunctive mood only occurs with
three tenses: present, past imperfect and future. Table 1 presents parts of the
(regular) Spanish conjugational paradigm that have been implemented for the
current case study: indicative present, indicative past perfect and subjunctive
present. All forms for the three regular verb classes have been included.
Table 1. Indicative present, past perfect and subjunctive present conjugation
paradigms for regular verbs of the three main verb classes: ‚Äòcortar‚Äô (‚Äòto cut‚Äô), ‚Äòdeber‚Äô
(‚Äòhave to‚Äô), ‚Äòvivir‚Äô (‚Äòto live‚Äô)
-ar -er -ir
ind. subj. ind. subj. ind. subj.
pres. past pf. pres. pres. past pf. pres. pres. past pf. pres.
cort-o cort-√© cort-e deb-o deb-√≠ deb-a viv-o viv-√≠ viv-a
cort-as cort-aste cort-es deb-es deb-iste deb-as viv-es viv-iste viv-as
cort-a cort-√≥ cort-e deb-e deb-i√≥ deb-a viv-e vivi√≥ viv-a
cort-amos cort-amos cort-emos deb-emos deb-imos deb-amos viv-imos viv-imos viv-amos
cort-√°is cort-asteis cort-√©is deb-√©is deb-isteis deb-√°is viv-√≠s viv-isteis viv-√°is
cort-an cort-aron cort-en deb-en deb-ieron deb-an viv-en viv-ieron viv-an
There is a considerable number of syncretic forms present in Table 1. Syn-
cretism occurs where two or more distinct morphosyntactic values are collapsed
in a single inÔ¨Çected word form [1]. Table 1 contains three main instances of
syncretic forms:
1. indicative present and past suÔ¨Éxes for 1st person plural are equal in form,
e.g. ‚Äòcort-amos‚Äô (present/past);
2. 1st person indicative present and past forms are the same in writing but
receive a diÔ¨Äerent emphasis (o vs. √≥), e.g. ‚Äòcort-o‚Äô (1sg) vs. ‚Äòcort-√≥‚Äô (3sg);
3. subjunctive present suÔ¨Éxes of the Ô¨Årst verb class and indicative present
suÔ¨Éxes of the second and third verb classes are shared across all persons
except 1st person singular: e.g. ‚Äòcort-es‚Äô (subjunctive) vs. ‚Äòviv-es‚Äô/‚Äòdeb-es‚Äô
(indicative).
2.3 Subjunctive
The diÔ¨Äerence between the indicative and the subjunctive mood is linked to the
degree of aÔ¨Érmation of an utterance. When the speaker is conÔ¨Årming that what
he or she is saying is valid at the moment of speaking, the indicative is used. In
the contrary case, the subjunctive shows up to mark the non-aÔ¨Érmative stance
of the speaker towards his or her proposition. The following sentences illustrate
the use of the two moods in a conditional subordinated clause:
Handling Scope in Fluid Construction Grammar 127
(5) Aunque
although
llueve,
rain-(3sg.ind.pres),
vamos
go-(1sg.ind.pres)
a
to
la
the
playa.
beach.
Although it is raining, we are going to the beach.
(6) Aunque
although
llueva,
rain-(3sg.subj.pres),
vamos
go-(1sg.ind.pres)
a
to
la
the
playa.
beach.
Even if it rains, we are going to the beach.
The indicative ending in (5) expresses the fact that it is raining right now, impos-
ing an ‚Äòalthough‚Äô meaning onto the conditional adverb aunque. The subjunctive
verb form in (6) signals a rather hypothetical statement: ‚Äòeven if‚Äô it is raining
now, we will go to the beach. The speaker indicates that the condition of the
weather cannot be conÔ¨Årmed at the moment of the utterance.
3 Capturing Syncretism
The previous section has already pointed at the presence of syncretic forms in
the conjugational paradigm of verbs in Spanish. There are two main elements
of processing complexity when multiple values are conÔ¨Çated into one morpho-
phonological form: First, all values of the single form need to be learned to lead
to successful parsing. When the suÔ¨Éx ‚Äò-amos‚Äô is encountered, three alternative
values will usually be activated: 1st person plural indicative present, indicative
past perfect or subjunctive present. According to the morphological verb form
and the semantics of the verbal clause, one of these gets selected. Second, in
production, a language user needs to know which forms go together with which
meaning. This second element is thus an additional (syntactic) operation one
needs to perform in order to Ô¨Ånd the right form. In order to express the indicative
present Ô¨Årst person plural form of the verb ‚Äòcantar‚Äô (‚Äòto sing‚Äô), a speaker of
Spanish needs to have access to the fact that there are three suÔ¨Éxes that can
Ô¨Åll this slot (‚Äò-amos‚Äô, ‚Äò-emos‚Äô and ‚Äò-imos‚Äô) so he can select the appropriate form
matching the verb class of the verb (‚Äò-amos‚Äô).
Section 3.1 illustrates how such syncretic forms can be implemented in FCG to
assure optimal processing in parsing as well as production. Section 3.2 discusses
one way for dealing with morpho-phonological elements that share the same
function but are used with diÔ¨Äerent forms. Stem changes form the main focus of
the discussion.
3.1 Morpho-phonological Constructions
The standard way of dealing with morphological variation in FCG is through
morphological constructions. There have been many case studies on this is-
sue ranging from Russian aspectual aÔ¨Éxes [4], over German case markers [11],
to Hungarian verbal agreement markers [2]. The general FCG template that
128 K. Beuls
instantiates a morphological construction has two main slots (apart form the
obligatory construction name): suffix and stem. The suÔ¨Éx slot contains the
marker string; its grammatical function is speciÔ¨Åed in the stem slot. The function
of a marker is usually implemented as a list of syntactic categories that a verb
stem must have in order to license the presence of the marker string.
By deÔ¨Ånition, syncretic markers share the same marker string. The following
lines of code show how such markers can be instantiated by means of the mor-
phological template def-morph-cxn. The suÔ¨Éx "-e" is syncretic since it is used
for the 3rd person singular present indicative (2nd and 3rd conjugation) and the
3rd person singular present subjunctive (1st conjugation). The only diÔ¨Äerence
in functional use is the verbal mood.
(def-morph-cxn present-ind-3sg-2/3-morph-cxn
:suffix "e"
:stem (?stem-unit
:syn-cat (==1! (verb-class (==1 (1 -) (2 ?vc2) (3 ?vc3)))
(agreement (==1 (singular + - - +)
(plural - - - -)))
(tam (==1 (indicative + - + -)
(subjunctive - - - -))))))
(def-morph-cxn present-subj-1sg/3sg-1-morph-cxn
:suffix "e"
:stem (?stem-unit
:syn-cat (==1! (verb-class (==1 (1 +) (2 -) (3 -)))
(agreement (==1 (singular ?sg ?1sg - ?3sg)
(plural - - - -)))
(tam (==1 (indicative - - - -)
(subjunctive + - + -))))))
The syntactic categories3
that constitute the grammatical function of these
markers contain three elements: the verb class (verb-class), subject-verb agree-
ment information (agreement) and values for tense, aspect and mood categories
(tam). Each of these is implemented as a so-called feature matrix, which contains
the actual and potential functional values (see also [13]). The actual values are in-
dicated by a ‚Äò+‚Äô or a ‚Äò‚àí‚Äô sign, the potential values by variables: e.g. the verb class
value of the Ô¨Årst construction ((==1 (1 ‚àí) (2 ?vc2) (3 ?vc3))) is 2 or 3 but
never 1. Agreement values are read as follows: (singular ?sg ?1sg ?2sg ?3sg)
and (plural ?pl ?1pl ?2pl ?3pl). Third person singular is thus formalized as
(==1 (singular + - - +) (plural - - - -)). Tense and mood are speciÔ¨Åed as
3
The special operator ==1! needs to be interpreted as follows: The elements that
follow it should occur only once in the list in any order (regular ==1) and they should
always be matched to the transient structure, even in merging (!). This operator
avoids merging the wrong feature values into a unit in parsing.
Handling Scope in Fluid Construction Grammar 129
(indicative ?ind ?ind-past ?ind-present ?ind-future) and (subjunctive
?subj ?subj-past ?subj-present ?subj-future), resulting in (==1 (indicative
+ - + -) (subjunctive - - - -) for present indicative. A more detailed exam-
ple that discusses the functioning of feature matrices can be found elsewhere in
this Volume [5].
Syncretism can also occur across lexical class boundaries. Remember the Span-
ish "-o" and "-a" suÔ¨Éxes to mark agreement in gender (masculine, feminine)
between nouns and adjectives: ‚Äòuna torta delicios-a‚Äô, ‚Äòa delicious cake‚Äô. These
cases are captured through the grammatical function that is expressed by these
markers. A verbal marker "-a" will never conÔ¨Çate with an adjectival marker "-a"
since they diÔ¨Äer on substantial syntactic categories such as agreement (person,
number vs. gender, number) and lexical category (verb vs. adjective).
Even though underspeciÔ¨Åcation costs something in terms of ambiguity, it also
facilitates processing. Having a construction inventory with less markers can re-
duce the storage cost considerably. Within the same verb class, the "-e" marker
can be used for 1st and 3rd person singular subjunctive present. The Ô¨Ånal de-
cision on whether the person value is 1 or 3 does not have to be stored in the
inventory but can be delayed toward the moment of processing. It is then the
grammar that Ô¨Ålls in the person slot as soon as it is needed. However, such a
reduction only works within one verb class.
3.2 Stem Changes
The previous section has shown that, in production, the decision of which form
goes with which meaning can be guided by morpho-syntactic categories such
as the verb class of the stem. There is one more aspect that plays a role in
choosing the right form: phonology. Examples (7) and (8) illustrate a diÔ¨Äerence
in stem vowel between the 1st person singular and plural of the indicative present
paradigm.
(7) Vuelv-o
return-(1sg.ind.pres)
ma√±ana.
tomorrow.
I will return tomorrow.
(8) Volv-emos
return-(1pl.ind.pres)
ma√±ana.
tomorrow.
We will return tomorrow.
How does one represent such stem changes in a formal grammar? Generally,
there are two possible approaches:
‚Äì A series of lexical entries can be created for to cover all diÔ¨Äerent forms that
might be encountered (e.g. ‚Äòvuelv-‚Äô, ‚Äòvolv-‚Äô, etc.). However, this approach
would lead to a processing overload in the lexical construction set (subset
in the construction inventory containing all lexical constructions), since not
only lexical but also morpho-phonological decisions would have to be made
within this single processing step.
130 K. Beuls
‚Äì By separating multiple concerns, the alternative option divides the work
over three types of constructions: lexical, stem and morpho-phonetic. The
lexical constructions contain the verb inÔ¨Ånitive (e.g. ‚Äòvolver‚Äô), the stem con-
structions instantiate the inÔ¨Ånitive so it becomes a morphological stem (e.g
‚Äòvuelv-‚Äô, ‚Äòvolv-‚Äô) and the morpho-phonetic constructions match a stem with
a suÔ¨Éx.
This case study follows the second approach. Separation of concerns implies
that processing is separated into distinct modules that overlap in functionality
as little as possible. Organizing constructions into construction sets fulÔ¨Ålls this
requirement (see also [2]). Figure 1 shows how two diÔ¨Äerent verb forms of the
verb ‚Äòvolver‚Äô (‚Äòreturn‚Äô), see (7) and (8) can be rendered in a production process.
The constructional application order is set to: lexical, (functional, grammatical,)
stem, morpho-syntactic. The role of the functional and grammatical construction
sets can currently be ignored. Section 4 addresses their functional use.
initial
return-
cxn
(lex)
regular-
verb-
verbal-cxn
(fun)
present-
tense-
phrase-cxn
(gram)
subjectless-
1sg-
agreement-
cxn (gram)
volver-
vuelv-cxn
(stem)
present-
ind-1sg-
cxn
(morph)
(a) ‚Äòvuelvo‚Äô (‚ÄòI return‚Äô)
initial
return-
cxn
(lex)
regular-
verb-
verbal-cxn
(fun)
present-
tense-
phrase-cxn
(gram)
subjectless-
1pl-
agreement-
cxn (gram)
volver-
volv-cxn
(stem)
present-
ind-1pl-
2-cxn
(morph)
(b) ‚Äòvolvemos‚Äô (‚Äòwe return‚Äô)
Fig. 1. Resulting application processes in production for ‚Äòvuelvo‚Äô (a) and ‚Äòvolvemos‚Äô
(b). The lexical construction for the verb (return-cxn) is shared, the stem and morpho-
syntactic constructions diÔ¨Äer
The only diÔ¨Äerence that is visible in the processing pipelines of both verb forms
is the application of the stem and morpho-syntactic constructions: volver-
vuelv-cxn vs. volver-volv-cxn and present-ind-1sg-cxn vs. present-ind-1pl-2-
cxn. In order to better understand how the production of a single verb form
proceeds, we run step by step through the application of ‚Äòvuelvo‚Äô, ignoring func-
tional and grammatical constructions (responsible for subject-verb agreement
and time).
‚Äì The initial transient structure contains the following semantic
representation:
((1sg-agent indiv-1 context) (return event-1 context)
(return-returner event-1 indiv-1) (event-overlaps event-1 now)
(current-time-point now))
Handling Scope in Fluid Construction Grammar 131
‚Äì First, the lexical construction return-cxn triggers on the presence of (return
event-1 context) (return-returner event-1 indiv-1) in the initial struc-
ture. The lexical template that creates this construction consists of a skeleton
covering its meaning and form (inÔ¨Ånitive) and a lexical categorization which
speciÔ¨Åes its semantic class, lexical category and syntactic verb class.
(def-lex-cxn return-cxn
(def-verb-skeleton return-cxn
:meaning (== (return ?event ?base-set)
(return-returner ?event ?agent))
:args (?event ?base-set)
:string "volver")
(def-lex-cat return-cxn
:syn-cat (==1 (lex-cat (regular verb))
(verb-class (==1 (1 -) (2 +) (3 -))))
:sem-cat (==1 (class event))))
‚Äì Second, after grammatical constructions have done their work and added the
necessary syntactic information for agreement (covering meaning predicate
(1sg-agent indiv-1 context)) and tense and mood (covering meaning pred-
icates (event-overlaps event-1 now) (current-time-point now)), the stem
construction volver-vuelv-cxn translates the inÔ¨Ånitive "volver" into "vuelv-
". This happens only when the verb form is speciÔ¨Åed as indicated by the
syntactic slots agreement and tam, that is in the present tense indicative or
subjunctive with all a singular person or the third person plural.
(def-stem-cxn volver-vuelv-cxn
:infinitive "volver"
:string "vuelv-"
:syn-cat (==1 (agreement
(==1 (singular ?sg ?1sg ?2sg ?3sg)
(plural ?3pl - - ?3pl)))
(tam
(==1 (indicative ?ind-pres - ?ind-pres -)
(subjunctive ?subj-pres - ?subj-pres -)))))
‚Äì Finally, the morpho-syntactic construction that adds the matching suÔ¨Éx
to the stem form "vuelv-" can apply. According to the morpho-syntactic
template included below, the "o" suÔ¨Éx triggers when the subject is Ô¨Årst
person singular and the tense is present indicative. All three verb classes
take this suÔ¨Éx.
132 K. Beuls
(def-morph-cxn present-ind-1sg-cxn
:suffix "o"
:stem
(?stem-unit
:syn-cat (==1 (agreement
(==1 (singular + + - -)
(plural - - - -)))
(tam
(==1 (indicative + - + -)
(subjunctive - - - -)))
(verb-class (==1 (1 ?vc1) (2 ?vc2) (3 ?vc3))))))
In parsing, the processing pipeline is traversed in almost the opposite direc-
tion: morpho-syntactic constructions trigger before grammatical constructions
and stem constructions before lexical ones.
4 Formalizing Modal Constructions
Now that all morpho-phonological machinery for dealing with the Spanish con-
jugational paradigm has been introduced, it is time to move on to the real topic
of this paper: modals in FCG. Modal expressions typically belong to one of the
following three classes of modal assessment:
1. Mental expressions including cognition verbs such as believe and doubt
and complex expressions such as have the impression, etc.
2. Modal adjuncts such as adverbs like perhaps, prepositional phrases like in
all likelihood and clauses such as there is a good chance that, etc.
3. Modal auxiliaries such as may, can and must.
Each of these classes is related to a diÔ¨Äerent subjective position a speaker can
take according to a proposition. Take the proposition "Anna is pregnant". There
are many possible sentences a speaker could utter when he or she forms a modal
assessment of this proposition: e.g. ‚ÄòI believe that Anna is pregnant‚Äô, ‚ÄòAnna is
probably pregnant‚Äô, ‚ÄòAnna may be pregnant‚Äô, etc. Each of these utterances is
characterized by a certain degree of belief the speaker has about the proposition
that Anna is pregnant.
This section only concentrates on the FCG processing of modal adjuncts (ad-
verbs) and modal auxiliaries. Apart from introducing a new range of construc-
tions needed to operationalize main clauses that contain these modal expressions
(Section 4.1), the remainder of the current section zooms in on the organization
of the application process of these modal clauses (Section 4.2). Section 5 deals
with cognition verbs, and consequently with subclauses and modal scoping.
4.1 Expanding the Construction Inventory
Lexical Constructions. Lexical constructions map meaning to form and re-
versely. While the form part of modal adjuncts and auxiliaries is straightforward
Handling Scope in Fluid Construction Grammar 133
to implement, more questions arise when the meaning is considered. Is it pos-
sible to attribute a particular semantic representation to them? And moreover,
how does one capture the semantic diÔ¨Äerence between modal adjuncts and aux-
iliaries in predicate logic terms? According to Nuyts [6], modal auxiliaries show
the same functional position as the modal adverbs. Both adverbs and auxiliaries
are neutral with respect to all functional factors in his model. He argues that
an illustration of this is that they only very rarely occur in a focus position (as
opposed to modal adjectives (‚Äòit is possible that‚Äô) and mental state predicates
(‚ÄòI think that‚Äô)).
The current case study follows this Ô¨Ånding and does not distinguish between
modal auxiliaries and adverbs in terms of their semantic representation. Spanish
has three main modal auxiliaries that diÔ¨Äer in the epistemic strength they ex-
press: ‚Äòpuede‚Äô, ‚Äòdebe‚Äô and ‚Äòtiene que‚Äô. Three "corresponding" modal adverbs are,
respectively: ‚Äòposiblemente‚Äô, ‚Äòprobablemente‚Äô and ‚Äòseguramente‚Äô. The meaning
predicates that have been implemented for these modals look as follows:
(speaker ?speaker ?base-set)
(judgement ?evaluation ?speaker ?proposition)
(proposition ?proposition ?event)
(qual-strength ?evaluation [possibility|probability|certainty])
By using a modal expression, a speaker makes a judgement about a proposition
concerning a particular event. Such an evaluation is characterized by a certain
qualitative strength, which ranges from possibility over probability to certainty,
depending on the modal expression that is used. Note that only the speaker
predicate is linked to the physical context (?base-set). This implementation il-
lustrates the fact that modal meaning is not directly observable from the context
but that it needs to be constructed by a speaker.
Modal Constructions. Apart from its presence in the lexicon of a construc-
tion inventory, the modal meaning also needs to be propagated to the rest of
the utterance that a modal expression occurs in. This is the task of the modal
constructions. For the modal auxiliaries, this means that a verbal complex (aux-
iliary + main verb) is created, and it is marked as a modal verb. Embedded
modal adverbs are processed similarly.
The template for creating a modal auxiliary-verb construction is included
here for the purpose of illustration. It comprises three main modules: a tem-
plate skeleton, percolation of agreement features and percolation of variables
for semantic linking. The template used here is the standard FCG template for
creating phrasal constructions [9].
‚Äì The skeleton contains three main slots: :cxn-set, :phrase and :constituents.
The phrasal unit that this template creates is a modal verb phrase that has
a modal auxiliary and a verb as its constituents. The modal features of the
auxiliary unit (provided by the lexicon) are percolated upwards so that the
complete verbal complex gets marked for modality. The :cxn-form slot within
the ?modal-verb-complex sets the word order of the constituents.
134 K. Beuls
(def-phrasal-skeleton modal-auxiliary-verb-cxn
:cxn-set modal
:phrase
(?modal-verb-complex
:sem-function predicator
:cxn-form (== (meets ?modal-aux ?verb))
:phrase-type (modal verbal-phrase))
:constituents
((?verb
:sem-function predicator
:syn-cat (==1 (lex-cat (?type verb))))
(?modal-aux
:sem-cat (==1 (class (epistemic evaluation)))
:phrase-type (modal verbal-phrase))))
‚Äì The phrasal agreement template percolates some values from the constituents
to the newly created phrasal unit. Valency information is provided by the
verb unit, while the auxiliary unit contributes the agreement information.
The mood value is here merged into the syntactic category of the modal
auxiliary. The indicative is the default mood but can be overridden by addi-
tional constructions that have scope over the modal-auxiliary-verb-cxn. An
example of this is included in Section 5.
(def-phrasal-agreement modal-auxiliary-verb-cxn
(?modal-verb-complex
:sem-cat (==1 (sem-val ?sem-val))
:syn-cat (==1 (syn-val ?syn-val)
(agreement ?agreement)))
(?verb
:sem-cat (==1 (sem-val ?sem-val))
:syn-cat (==1 (syn-val ?syn-val)))
(?modal-aux
:syn-cat
(==1 (agreement ?agreement)
(tam
(==1 (indicative ?ind ?ind-past ?ind-present ?ind-future)
(subjunctive - - - -))))))
‚Äì Finally, the phrasal linking template percolates the values from the verb unit
to the new modal verb unit so they can be accessed in later grammatical pro-
cessing (agreement constructions, argument structure constructions). Note
also that it is secured that the ?event variable is shared across all units.
Handling Scope in Fluid Construction Grammar 135
(def-phrasal-linking modal-auxiliary-verb-cxn
(?modal-verb-complex
:args (?event ?context))
(?verb
:args (?event ?context))
(?modal-aux
:args (?speaker ?event ?context)))
The template for the adverbial modal construction functions analogously. The
slot of the modal auxiliary is Ô¨Ålled in by a modal adverb and the agreement and
mood information is provided by the main verb unit this time. Also here, the
default mood is the indicative. Examples of a change in mood that is guided by
the adverbial‚Äôs position in the clause are included in Section 5.
4.2 Processing Modals
This section demonstrates the bi-directional processing of the previously intro-
duced modal constructions. The following example sentences accompany this
demonstration.
(9) Ana
Anna
puede
could-(3sg.ind.pres)
estar
be.temp(inf)
embarazada.
pregnant.
Anna could be pregnant.
(10) Ana
Anna
est√°
be.temp(3sg.ind.pres)
posiblemente
possibly
embarazada.
pregnant.
Anna is possibly pregnant.
Let us Ô¨Årst concentrate on Sentence (9). The sentence contains one modal aux-
iliary (‚Äòpuede‚Äô), which expresses a weak epistemic assessment of the proposi-
tion ‚ÄòAnn is pregnant‚Äô. Figure 2 contains its production process (a) and the
resulting linguistic structure (b). The application order is guided by construc-
tion sets that group constructions that share a certain functionality. Figure 2a
illustrates this processing chain of construction sets, which starts oÔ¨Ä with the
lexical construction set and reaches its goal (cf. the bold search node) when the
last morpho-syntactic construction could apply. In order for the modal meaning
to propagate, it is important that the modal construction set precedes other
grammatical constructions (argument structure, agreement, word order) in both
processing directions. Since the modal construction Ô¨Årst groups modal auxiliary
and main verb, argument structure and agreement constructions can then use
use the values of the modal verb phrase as its input and propagate them further
in the clause.
Note that the order of application of the argument structure and agreement
constructions is reversed in parsing. This is a consequence of the fact that in
136 K. Beuls
initial
* be-transient-cxn (lex), anna-cxn (lex), pregnant-
cxn (lex), poder-modal-cxn (lex)
* proper-noun-cxn (fun), modal-verb-verbal-cxn
(fun), copular-verb-verbal-cxn (fun)
* present-tense-phrase-cxn (phrasal), proper-
nominal-phrase-cxn (phrasal)
modal-auxiliary-
verb-cxn (modal)
copular-cxn
(argument-structure)
* verb-object-agreement-cxn (agreement),
subject-verb-agreement-cxn (agreement)
declarative-cxn
(word-order)
poder-
pued-cxn
(stem)
fem-
adjective-cxn
(morph)
present-ind-3sg-
2/3-morph-cxn
(morph)
+
...
...
...
(a) production process
top top
sentence-
8
verbal-
phrase-
18
modal-
verb-
complex-
9
verbal-
phrase-
17
word-
poder-
5
word-estar-5
word-embarazad-5
nominal-phrase-9
word-ana-5
sem syn
sentence-
8
verbal-
phrase-
18
word-embarazad-5 morph-a-7
modal-
verb-
complex-
9
word-estar-5
verbal-
phrase-
17
word-
poder-
5
morph-
e-7
nominal-phrase-9 word-ana-5
(b) resulting linguistic structure
Fig. 2. Search process and resulting linguistic structure for the production of Sentence
(9). 18 diÔ¨Äerent constructions applied to build the resulting linguistic structure that
contains the utterance: "Ana puede estar embarazada".
production, the argument structure relations are provided by the semantic rep-
resentation and need to be translated into agreement feature matrices in order to
express the appropriate form. In parsing, the process starts from the form side,
so that the available agreement information needs to be converted into argument
structure relations.
Figure 2b shows the Ô¨Ånal linguistic structure that has been built during the
production process. The semantic and syntactic pole are symmetric with each
a sentence unit directly under the top unit, which has a nominal phrase (sub-
ject: ‚ÄòAna‚Äô) and a verbal phrase as its constituents (predicate: ‚Äòpuede estar em-
barazada‚Äô). The verbal phrase unit then comprises the main verbal complex
(‚Äòpuede estar‚Äô) and its complement (‚Äòembarazada‚Äô). It is through feature per-
colation that the agreement values (number and gender) of the adjectival com-
plement are synchronized with the subject‚Äôs. The same goes for the agreement
information needed for conjugation of the verb (person and number).
The processing of Sentence (10) proceeds in a similar fashion. Since the modal
is an adverb and not an auxiliary anymore, it is the main verb ‚Äòestar‚Äô that receives
the conjugational ending this time. The following slight diÔ¨Äerence in the meaning
representations of Sentences (9) and (10) is responsible for this processing ef-
fect: (event-overlaps speaker-1 time-1) vs. (event-overlaps event-1 time-1).
In the sentence with the modal auxiliary, it is the speaker constant that is linked
to the present time span. Since the modal auxiliary construction poder-modal-cxn
also guarantees such a speaker link (see above) while the be-transient-cxn
does not, it is assured that the present tense construction inserts conjugational
Handling Scope in Fluid Construction Grammar 137
information to the appropriate unit. Since the semantic diÔ¨Äerence between the
use of a modal auxiliary and a modal adverb only becomes visible in the phrasal
constructions, that is, after the lexical constructions have been processed, there
are always two main branches in the search tree. One branch will Ô¨Ånally fail in
re-entrance, because the event-overlaps variables do not correspond.
5 Modal Scope
Section 4 has shown that the indicative is the default mood that modal construc-
tions assign to the Ô¨Ånite verb form of a clause. The current section shows how
this default can be overridden through the application of an additional modal
construction that has scope over the indicative verb form. The sentence that
illustrates this scoping process builds further on Example Sentence (9):
(11) Dudo
doubt-(1sg.ind.pres)
que
that
Ana
anna
pueda
could-(3sg.subj.pres)
estar
be.temp(inf)
embarazada.
pregnant.
I doubt that Anna could be pregnant.
This sentence demonstrates the use of the third most common linguistic expres-
sion of modality (see Section 4): mental state predicates. A mental state predicate
(‚Äòdudo‚Äô in (11)) is a cognition verb in the Ô¨Årst person singular present that ex-
presses the speaker‚Äôs degree of certainty toward the realization of the proposition
(following or preceding this predicate). In the Ô¨Årst position of a sentence, men-
tal state predicates are always followed by a complementizer such as "that" in
English or "que" in Spanish.
First, we update the construction inventory with two new constructions: a
lexical construction for the cognition verb ‚Äòdudar‚Äô and a grammatical construc-
tion that takes care of the scoping relation. The lexical construction takes the
verbal inÔ¨Ånitive (without ‚Äòque‚Äô) as its form. Its meaning representation includes
two additional predicates compared to the previous modal meanings:
(speaker ?speaker ?base-set)
(judgement ?evaluation ?speaker ?proposition)
(proposition ?proposition ?event))
(qual-strength ?evaluation unlikelihood)
(evidence ?proposition personal-knowledge)
(responsibility ?speaker ?evaluation)
The evidence predicate indicates the evidential source the speaker used to make
his evaluation of the proposition ‚ÄòAnn is pregnant‚Äô. In the case of ‚Äòdudar‚Äô (‚Äòto
doubt‚Äô), this evidence stems from personal knowledge of the speaker. The last
predicate relates the responsibility of the evaluation and its impact to the realm
of the speaker.
138 K. Beuls
The grammatical construction that regulates the use of a subjunctive mood in
the subordinated clause that depends on a mental state predicate is characterized
by three main tasks:
‚Äì guaranteeing a scoping relation between the evaluation of the mental state
predicate ‚Äòdudo‚Äô and the modal subordinated clause ‚Äòana pueda estar em-
barazada‚Äô
‚Äì adding agreement and valency features for a 1st person singular agent
(speaker)
‚Äì providing the complementizer ‚Äòque‚Äô.
Scoping has an eÔ¨Äect on both structural poles of the transient structure. On the
semantic side, this construction is responsible for the variable linking of speaker,
event, proposition, context and time variables in the subordinated clause and
the mental state predicate. The evaluation variables are kept diÔ¨Äerent, since we
are dealing with a second evaluation (‚Äòdudo que‚Äô) of an earlier evaluation (‚Äòpuede
estar‚Äô). On the syntactic side, the clausal mood feature (tam) is set to subjunctive
mood. Since the mood feature already had a speciÔ¨Åed value, this value needs to
be "overridden". This is done with help of the -> operator:
(tam (==1 (-> (subjunctive - - - -)
(subjunctive + ?subj-past ?subj-present ?subj-fut))
(-> (indicative + ?ind-past ?ind-present ?ind-fut)
(indicative - - - -)))
The semantics of the overrides operator are speciÔ¨Åed as follows: (-> original-
value new-value). The subjunctive value was already set to ‚àí by the modal
construction that operated in the subordinated clause, but it is now replaced by
the subjunctive mood (any tense). The indicative feature receives the previous
value of the subjunctive feature.
The syntactic pole of the resulting linguistic structure of parsing sentence
(11) is visualized by Figure 3. Processing the mental state predicate has lead to
a considerable increase in structural complexity. A sentence unit now unites the
subordinated clause (clause-489) and the mental state predicate (verbal-phrase-
2927). The complementizer ‚Äòque‚Äô is present in the structure as a subunit of the
verbal-phrase-2927 unit. The scoping construction only changes the mood fea-
ture values in the clause-489, since they are automatically percolated among all
children that carry such a feature. Eventually, this results in the presence of the
subjunctive ‚Äò-a‚Äô marker that the stem ‚Äòpued‚Äô receives, as opposed to a default
indicative ‚Äò-e‚Äô marker.
Another frequent example of overriding the default mood feature is the
fronting of a modal auxiliary such as in:
(12) Posiblemente
possibly
Ana
anna
est√©
be.temp(3sg.subj.pres)
embarazada.
pregnant.
Possibly Anna is pregnant.
Handling Scope in Fluid Construction Grammar 139
top
syn
sentence-479
clause-489
verbal-phrase-2928
word-embarazad-657 morph-a-2883
modal-verb-complex-687
word-estar-685
verbal-phrase-2925 word-poder-477 morph-a-2884
nominal-phrase-1030 word-ana-680
verbal-phrase-2927
word-dudar-102 morph-o-613
que-33
Fig. 3. The syntactic pole of the Ô¨Ånal transient structure after parsing "Dudo que Ana
est√° embarazada"
Also here, the modal is not part of the clause that expresses the proposition
but precedes it and can thereby inÔ¨Çuence the use of the subjunctive mood. Note
that in this case, the modal has a direct inÔ¨Çuence on the presentation of the
proposition itself, whereas the example of the mental state predicate ‚Äòdudo que‚Äô
showed that there can also be an inÔ¨Çuence on another modal expression.
6 Robustness
Modality is generally a domain that has not been explored very much in im-
plementations of grammar formalizations. This is probably due to the fact that
it is an extreme example of an open-ended system, which has a negative ef-
fect on the robustness of the formalization. There are two main issues to con-
sider when making a modal grammar more solid toward internal and external
incongruencies:
1. The exact semantic representation of a modal expression can vary across
speakers and between linguistic communities, since modality concerns per-
sonal judgements of individual language users. Moreover, depending on the
situation, the choice of verbal mood for a particular proposition might diÔ¨Äer.
2. Due to deviating meanings, the modal forms that are parsed by a hearer dot
not always conform to his or her constructional knowledge. This happens
when the speaker is being innovative, when he belongs to a diÔ¨Äerent linguistic
community or when he speaks carelessly.
In terms of semantic robustness, a single user grammar does not really encounter
the issue of variable semantic representations across speakers. There is only
one speaker, which is the system itself. It is only in multi-agent experiments
that make use of FCG, where semantic representations are built by every agent
individually. Nevertheless, once semantic representations are constructed from
grounded scenes, discrete modal categories such as qualitative strength, have to
be replaced by continuous values.
Syntactic robustness is a diÔ¨Äerent issue. Previous FCG research on robust
parsing has focused on unknown words and coercion (for an overview see [10]).
140 K. Beuls
form
syn-subunits
footprints
syn-cat
clause-680
((meets
nominal-phrase-1064
verbal-phrase-2807))
(verbal-phrase-2807
nominal-phrase-1064)
(declarative-cxn
marked-phrasal)
((tam
((indicative + - + -)
(subjunctive - - - -)))
(phrase-type
(copular clause)))
syn-cat
?clause-3530
(==1
(phrase-type
(?type-4504 clause))
(tam
(==1
(subjunctive ?subj-29
?subj-past-17
?subj-pres-2324
?subj-future-17)
(indicative - - - -))))
>
(indicative + - + -
bj ti
?subj-future-17)
)
indicative
j
j
- - - -)
)
source pattern
Fig. 4. In parsing the marked sentence "Dudo que Ana est√° embarazada", the
source unit of the transient structure (left) is matched with the pattern unit of the
mental-state-predicate-cxn (right). The match fails since the values of the indica-
tive feature do not correspond: the source unit contains a present indicative mood,
while the pattern expects a subjunctive mood.
The most straightforward deviating use of a modal expression, is an unexpected
mood marker: the subjunctive instead of the indicative or reversed. Take the
following mood alternation:
(13) Dudo
doubt-(1sg.ind.pres)
que
that
Ana
anna
est√©
be.temp-(3sg.subj.pres)
embarazada.
pregnant.
I doubt that Anna is pregnant. (default reading)
(14) Dudo
doubt-(1sg.ind.pres)
que
that
Ana
anna
est√°
be.temp-(3sg.ind.pres)
embarazada.
pregnant.
I doubt that Anna is pregnant. (marked reading)
Sentence (13) illustrates the default use of the mood marker that follows a men-
tal state predicate which expresses a high degree of uncertainty: the subjunc-
tive ("-e" in "est√©"). Parsing this sentence with the construction inventory that
supports this case study, leads to a successful parsing process with 20 search
nodes and a single search branch, the goal node being the scope construction
mental-state-predicate-cxn. Now, parsing the marked mood marker in the sub-
ordinate clause, that is the indicative "-a", results in an explosion of the search
space: 18 search branches with each 19 nodes and no correct solution found. The
reason for this is the lacking of the twentieth node, namely that of the scope
construction.
The FCG inspector tells us that there was no match between the transient
structure after the 19th construction has applied and the scope construction.
Figure 4 shows that the match failed exactly because of the presence of the
indicative mood feature in the transient structure (source), whereas the scope
construction (pattern) requires a subjunctive feature (of any tense).
The traditional FCG solution to such a problem in processing, is to create a
diagnostic that notiÔ¨Åes the mismatch in mood and then instantiate a repair pro-
cess that adjusts the mood in the clausal unit. The diagnostics and repairs form
part of the so-called ‚Äòmeta-layer‚Äô in processing. On top of the routine processing
Handling Scope in Fluid Construction Grammar 141
layer, diagnostics check whether there has been some unexpected processing re-
sult, and if so, they call on a series of repair methods to solve the problem and
continue regular processing.
7 Conclusion and Outlook
This paper has presented basic insights into the operationalization of modal
constructions and their organization in terms of processing eÔ¨Éciency. Modal
constructions are best processed before other grammatical constructions can
apply so that the latter take over the modal values left in the verb unit by the
former. Scope constructions (mental state predicates) are processed at the end of
the grammatical construction batch. In production, this is right before morpho-
syntactic constructions start to Ô¨Åll in the appropriate marker forms. A scope
construction can thus modify a mood value left by the modal constructions and
processed by the grammatical ones at the very last moment.
Since all the modal constructions that have been introduced in this paper work
on verbal units, also the Spanish conjugational paradigm had to be captured
in FCG constructions. A considerable degree of syncretism (same form shared
across multiple functions) and variation in verbal stem morphology has been
reported and covered by the current implementation. The use of the ==1 operator
in the morpho-syntactic templates and the introduction of stem templates that
translate inÔ¨Ånitives into stems and reversely have been essential in this process.
The importance of building robust grammars has been pointed at through the
incorporation of the parsing process of a sentence with an indicative subordinate
clause where a subjunctive was expected. The FCG meta-layer has proved to be
a valuable processing extension to capture unusual language use. By means of a
repair strategy that modiÔ¨Åed the matching pattern of the modal construction,
processing can be continued from the point where an earlier problem had been
reported.
The goal of this paper has been to present a feasibility study on the implemen-
tation of modal expressions in FCG. The potential of such an implementation
has become clear throughout the diÔ¨Äerent sections. Nevertheless, an expansion
of the current test grammar within the domain of epistemic modality (more
modals, more sentences) as well as toward a wider application of modality (evi-
dentials, event modality) is in order. The implementation of more modal systems
that cover a number of diÔ¨Äerent languages can oÔ¨Äer a better understanding of
the current Spanish test grammar.
Acknowledgements. This research was conducted at the Vrije Universiteit
Brussel, Ô¨Ånanced by a strategic basic research grant (IWT-489) from the agency
for Innovation by Science and Technology (IWT). Additional funding came from
the European research project ALEAR (FP7, ICT-214856). Apart from the
members of our team in Brussels and at the Sony CSL lab in Paris, I espe-
cially want to thank Johan van der Auwera (University of Antwerp) for his help
in my quest for the right modal terminology.
142 K. Beuls
References
[1] Baerman, M.: Syncretism. Language and Linguistics Compass 1(5), 539‚Äì551
(2007)
[2] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[3] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[4] Gerasymova, K., Steels, L., van Trijp, R.: Aspectual morphology of Russian verbs
in Fluid Construction Grammar. In: Taatgen, N., van Rijn, H. (eds.) Proceedings
of the 31th Annual Conference of the Cognitive Science Society, pp. 1370‚Äì1375.
Cognitive Science Society (2009)
[5] H√∂fer, S.: Complex Declension Systems and Morphology in Fluid Construction
Grammar: A Case Study of Polish. In: Steels, L. (ed.) Computational Issues in
FCG. LNCS (LNAI), vol. 7249, pp. 143‚Äì177. Springer, Heidelberg (2012)
[6] Nuyts, J.: Epistemic Modality, Language and Conceptualization. John Benjamins,
Amsterdam (2001)
[7] Palmer, F.: Mood and Modality. Cambridge University Press, Cambridge (2001)
[8] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[9] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[10] Steels, L., van Trijp, R.: How to make construction grammars Ô¨Çuid and robust. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[11] van Trijp, R.: Argumentsstruktur in der Fluid Construction Grammar. In: Fischer,
K., Stefanowitsch, A. (eds.) Konstruktionsgrammatik II: Von der Konstruktion
zur Grammatik, StauÔ¨Äenburg Linguistik, vol. 47. StauÔ¨Äenburg Verlag, T√ºbingen
(2008)
[12] van Trijp, R., Steels, L., Beuls, K., Wellens, P.: Fluid construction grammar: The
new kid on the block. In: Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Linguistics. ACL, Avignon (2012)
[13] van Trijp, R.: Feature matrices and agreement: A case study for German case. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
Complex Declension Systems and Morphology
in Fluid Construction Grammar:
A Case Study of Polish
Sebastian H√∂fer
Robotics and Biology Laboratory, Technische Universit√§t Berlin, Germany
Abstract. DiÔ¨Äerent languages employ diÔ¨Äerent strategies for grammati-
cal agreement. Slavic languages such as Polish realize agreement with rich
declension systems. The Polish declension system features seven cases,
two number categories and is subdivided further with respect to gender
and animacy. In order to diÔ¨Äerentiate among these diÔ¨Äerent grammati-
cal categories Polish exhibits a complex, syncretistic and highly irregular
morphology. But not only the morphology is complex, the grammatical
rules that govern agreement are, too. For example, the appropriate case
of a noun in a verbal phrase does not only depend on the verb itself but
also on whether the verb is in the scope of a negation or not.
In this paper we give an implementation of the Polish declension sys-
tem in Fluid Construction Grammar. In order to account for the com-
plexity of the Polish declension system we develop a uniÔ¨Åcation-based
formalism, called nested feature matrices. To demonstrate the power of
the proposed formalism we investigate its appropriateness for solving
the following linguistic problems: a) selecting appropriate morphological
markers with respect to the noun‚Äôs gender and stem for expressing case
and number, b) establishing phrasal agreement between nouns and other
parts of speech such as verbs, and Ô¨Ånally c) dealing with long-distance
dependencies in phrasal agreement. We show that our formalism succeeds
in solving these problems and that the presented implementation is fully
operational for correctly parsing and producing simple Polish transitive
sentences.
1 Introduction
Developing computational models for Slavic languages is very beneÔ¨Åcial for
understanding language in general, as Slavic languages exhibit many complex
grammatical and morphological structures that English and other Western Eu-
ropean languages lack. A particularly intriguing part of Slavic languages is their
declension system. The Polish declension system, for instance, features seven
cases, two number categories and is subdivided further with respect to gender
and animacy. In order to diÔ¨Äerentiate among these diÔ¨Äerent grammatical cate-
gories Polish exhibits a complex, syncretistic and highly irregular morphology.
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 143‚Äì177, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
144 S. H√∂fer
But not only the morphology is complex, the grammatical rules that govern
agreement are, too. For example, the appropriate case of a noun in a verbal
phrase does not only depend on the verb itself but also on whether the verb is
in the scope of a negation or not.
Due to their inherent linguistic complexity, there has been growing interest
in formalizing Slavic languages in computational grammar theories in recent
years [3, 19]. One of the currently most prominent grammar formalisms is Head-
Driven Phrase Structure grammar (HPSG) [17] and therefore most of the Slavic
community focussed on the implementation of Slavic languages theories in this
formalism.
In this paper, the implementation of diÔ¨Äerent aspects of the Polish noun de-
clension system in Fluid Construction Grammar (FCG) is presented. The main
purpose is to show that the FCG formalism provides a uniform way of deal-
ing with the Polish declension system at the morphological, syntactical and se-
mantical level. In order to account for the complexity of the Polish declension
system we develop a uniÔ¨Åcation-based formalism, called nested feature matri-
ces. To demonstrate the power of the proposed formalism we investigate its
appropriateness for solving the following linguistic problems: a) selecting appro-
priate morphological markers with respect to the noun‚Äôs gender and stem for
expressing case and number, b) establishing phrasal agreement between nouns
and other parts of speech such as verbs, and Ô¨Ånally c) dealing with long-distance
dependencies in phrasal agreement in terms of a weak form of the so-called long
distance genitive of negation. We show that our formalism succeeds in solving
these problems and that the presented implementation is fully operational for
correctly parsing and producing simple Polish transitive sentences.
The work presented in this paper builds upon many studies concerning the
operationalization of lexical, phrasal and morphological constructions in FCG.
It follows the FCG design pattern approach presented in this volume [25], and
shares the implementation of morphological constructions with operationaliza-
tions of Hungarian verbs [1], Spanish modals [2] and Russian verbal aspect [12].
Furthermore, we develop an extension of the feature matrix formalism which has
been originally introduced in [27] for dealing with syncretisms in the German
declension system.
As the Slavic community has conducted a lot of work on the implementation
of Slavic linguistic phenomena in HPSG, the reader might also refer to another
chapter in this volume presenting FCGLight [7]. This formalism makes a link
between HPSG and FCG by implementing a core subset of the latter in LIGHT,
a system previously used for the implementation of large-scale HPSG grammars
[5]. Another related study on a Slavic language example in FCG which deals
with verbal aspect in Romanian can be found in [6].
The remainder of this paper is structured as follows: Ô¨Årst, the linguistic prob-
lems addressed in this paper are explained. Next, feature matrices and nested
feature matrices are introduced, which constitute the core formalism used to
Complex Declension Systems and Morphology 145
model the declension system and establish agreement on the morphological and
syntactic level. Finally, the operationalization of the Polish case study in FCG
is presented, and the results are summarized and evaluated.
2 Linguistic Insights
This case study presents a formalization of the Polish noun declension system,
the so-called genitive of negation and the long distance genitive of negation.
The main part of the implementation deals with morphological aspects of the
Polish noun declension system, and, in particular, how this complex system
can be represented in FCG in a uniform manner. The long distance genitive of
negation phenomenon is considered in order to illustrate that FCG is also suit-
able for the operationalization of long distance dependencies. In order to grasp
the implementational details of the formalism presented later, some linguistic
background on these phenomena is required which is provided in the following
section.
2.1 Polish Noun Declension System
Nominal inÔ¨Çections in Polish conÔ¨Çate two grammatical categories: case and num-
ber. There are seven cases (nominate, genitive, dative, accusative, instrumental,
locative and vocative) and two numbers (singular and plural). Additionally, Pol-
ish nouns are traditionally divided into three inÔ¨Çectional paradigms or declension
schemes in terms of the three genders (masculine, feminine, neuter). However,
the paradigms are not entirely consistent; for almost every case and number
there exist several endings, and the appropriate ending depends mainly on the
morphological and syntactic properties of the noun. Therefore the number of
distinct paradigms is very large [16]. Things get even more complicated, since
some nouns can have two diÔ¨Äerent endings in the genitive case, depending on
the meaning that a speaker wants to express.
Let us look at an example in order to illustrate the complexity of the Polish
declension system. Consider the following examples, which deal with the two
masculine nouns przypadek (case) and cz≈Çowiek (man):
(1) W
In
≈ºadnym
no.LOC
przypadku
case.LOC
nie
not
znajdziemy
(we) Ô¨Ånd
ca≈Çej
whole.GEN
prawdy
truth.GEN
o
about
cz≈Çowieku.
man.LOC
‚ÄòIn no case do we Ô¨Ånd out the whole truth about mankind.‚Äô
This example shows that -u is a marker for the locative case for masculine nouns,
and indeed it is so quite consistently. The next examples consider the -a ending:
146 S. H√∂fer
(2) Nie
Not
ma
is
ani
even
jednego
one.GEN
cz≈Çowieka.
man.GEN
‚ÄòThere is not even one man.‚Äô
(3) Widzƒô
(I) see
jednego
one.ACC
cz≈Çowieka.
man.ACC.
‚ÄòI see one man.‚Äô
(4) Przyimek
Preposition.NOM
‚Äôzamiast‚Äô
‚Äôzamiast‚Äô
wymaga
requires
u≈ºycia
usage.GEN
drugiego
second.GEN
przypadka.
case.GEN
‚ÄòThe preposition ‚Äòzamiast‚Äô requires usage of the second case.‚Äô
(5) Pierwszy
Ô¨Årst
raz
time
widzƒô
(I) see
taki
such.ACC
przypadek.
case.ACC
‚ÄòIt is the Ô¨Årst time that I see such a case.‚Äô
The Ô¨Årst thing to be noticed is that the ending -a occurs with both nouns, but
not always in the same cases. The examples 2 and 4 suggest that -a serves as a
marker for genitive. However, things are more complicated: as seen in example
3, the accusative of cz≈Çowiek corresponds to its genitive, that is, it takes the -a
too. On the other hand, the accusative of przypadek corresponds to its nomi-
native and is therefore unmarked. Why is this so? As a rule of thumb, nouns
that denote virile (masculine-human) individuals agree in the genitive and the
accusative case, while nouns denoting non-animate objects agree in nominative
and accusative. Therefore, in many Polish textbooks the masculine gender is
subdivided into three: virile (animate and personal), animate (and not personal)
and impersonal. In current Polish language the amount of nouns following the
virile scheme is steadily expanding [16]; particularly neologisms like email follow
the virile declension scheme and therefore exhibit the -a marker in accusative,
although they denote inanimate objects.
Yet, the whole issue of the declension scheme becomes even more puzzling, as
the following example shows:
(6) Nie
Not
by≈Ço
was
takiego
such.GEN
przypadku
case.GEN
choroby.
illness.GEN.
‚ÄòThere was no such case of illness.‚Äô
The noun przypadek is an example from a small group of nouns which can take
either -a or -u in the genitive case. Whether one or the other ending is preferred
sometimes depends on idiomatic use. In this case it depends on the intended
meaning of the word: if the grammatical case is meant, as in example 4, the
noun takes the -a marking. If a certain circumstance or fact is to be expressed,
the -u marking is used. See, for example, [10] for an extensive discussion of the
distribution of the two endings in genitive masculine.
Complex Declension Systems and Morphology 147
Table 1 exempliÔ¨Åes in which cases the ending -a can actually occur. It shows
that the marker is completely independent from the grammatical categories case,
number and gender.
Table 1. The ending -a occurs across diÔ¨Äerent cases, genders and numbers. An example
of a noun form is given for each of the possible entries occurrences of the ending. The
nominative singular forms of the inÔ¨Çected nouns are ksiƒÖ≈ºe (duke), pole (Ô¨Åeld), cz≈Çowiek
(man) and cud (miracle).
-a SG PL
Case SG-M SG-F SG-N PL-M PL-F PL-N
NOM sƒôdzia dziewczyna ‚Äì ksiƒô≈ºa ‚Äì pola
(judge) (girl) (dukes) (Ô¨Åelds)
GEN cz≈Çowieka ‚Äì pola ‚Äì ‚Äì ‚Äì
(man) (Ô¨Åeld)
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC cz≈Çowieka ‚Äì ‚Äì cuda ‚Äì pola
(miracles)
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì pola
Stem Palatalization. As in many other Slavic languages, during the evolution
of Polish several sound changes subsumed under the term palatalization occurred.
In this process mid, close front vowels (e.g. /i/, /e/) and the semi-vowel /j/ shift
nearby phonemes, usually preceding consonants, towards the palatal articulatory
position. There exist several types of palatalization, such as the so-called iotation,
as in the occurrence of the i in nie (no / not) results in changing the sound of
/n/ to /√±/. In Polish, the /√±/ phoneme is represented by ni in the beginning
and by ≈Ñ in the end of a syllable. Consider, for example, dzie≈Ñ (day) and nie,
which both contain this very same phoneme.
The Polish declension system includes two palatalizing endings denoted by -‚Äôe
and -‚Äôi. The way the stem of a noun is changed depends on the stem or the stem
consonant of a noun, respectively. Hence, consider for example the changes that
occur in feminine nouns that exhibit the -‚Äôe in the dative singular case: ryba
becomes rybie (Ô¨Åsh), ≈ÇƒÖka becomes ≈ÇƒÖce (meadow), sk√≥ra becomes sk√≥rze, etc.
There do exist reliable rules as to how palatalization aÔ¨Äects nearby phonemes.
For a more complete analysis see, for example, [13].
Note that the non-palatalizing counterparts -e and -i also appear in the de-
clension scheme, for example, the dative singular of the noun szansa (chance)
takes the palatalized ending and becomes szansie, but the noun‚Äôs nominative
plural is szanse.
In any case, this brief analysis shows that beside the support for parsing
and production of nouns and their endings, an operationalization of the Polish
declension scheme must also account for changes which aÔ¨Äect the stem of a noun.
148 S. H√∂fer
2.2 Genitive of Negation
Another interesting grammatical phenomenon in Slavic languages, including
Polish, is the so-called genitive of negation (GoN). The phenomenon can be
explained as follows: in the presence of verbal negation, the genitive case is as-
signed to the argument of the verb if the verb requires the argument to take the
accusative in the absence of negation. The following example demonstrates that
the case of the accusative object needs to be changed due to the appearance of
the negative marker nie:
(7) Micha≈Ç
Michael.NOM
widzi
sees
Mariƒô.
Maria.ACC
‚ÄòMichael sees Maria.‚Äô
(8) Micha≈Ç
Michael.NOM
nie
not
widzi
sees
Marii.
Maria.GEN
‚ÄòMichael does not see Maria.‚Äô
Note that the GoN only applies to accusative objects:
(9) Micha≈Ç
Michael.NOM
macha
waves
patykiem.
stick.INS.
‚ÄòMichael waves the stick.‚Äô
(10) Micha≈Ç
Michael.NOM
nie
not
macha
sees
patykiem.
stick.INS
‚ÄòMichael does not wave the stick.‚Äô
Moreover, the GoN does not only aÔ¨Äect Ô¨Ånite verb forms but also non-Ô¨Ånite verb
forms such as inÔ¨Ånitivals and participles.
Whereas in languages such as Russian, the application of GoN is not obliga-
tory but often depends on pragmatic, semantic or idiosyncratic factors, GoN in
Polish is fully grammaticalized, that is, it is triggered by the morphosyntactic
structure of the negative marker nie.1
2.3 Long Distance GoN
An interesting property of the GoN in Polish is that it appears even in cases
where the nie does not negate the verb directly, but only a verb higher in the
hierarchical structure of the sentence [18]. This is illustrated in the following
example, where the negation applies to the auxiliary verb but still causes the
object of the inÔ¨Ånitival to take genitive case:
1
However, as already noted in [4], there exist some exceptional cases in Polish where
the GoN is indeed optional, for example [18]:
(11)
Mariƒô / Marii nie boli g≈Çowa.
Maria.ACC / Maria.GEN not aches head.NOM
‚ÄòMaria does not have a headache.‚Äô
Complex Declension Systems and Morphology 149
(12) Micha≈Ç
Michael.NOM
nie
not
chce
want
widzieƒá
see
Marii.
Maria.GEN
‚ÄòMichael does not want to see Maria.‚Äô
This phenomenon is discussed in more detail in [18] and additional cases are
presented where the long distance GoN is not obligatory or is singled out by
Polish native speakers. In the following analysis, a simple example consisting
of an auxiliary and an inÔ¨Ånitival as shown above is considered. In spite of its
simplicity, it reÔ¨Çects well how long distance relationships can be handled in FCG.
3 Feature Matrices
The previous section demonstrated the need for an eÔ¨Écient formalism that is
able to account for the complexity of the presented declension system. The ap-
proach in this paper is based on feature matrices which constitute a solely uni-
Ô¨Åcation based method for handling syncretisms in terms of case, gender and
number distinctions [27]. Common accounts for the issue of case syncretism in-
volve disjunctive feature representations which represent the multifunctionality
by disjunctions, i.e. alternatives. Let us contrast the two approaches with an
example and consider the representations for the proper name Maria and the
-a ending. To be more precise, not the feature matrix of Maria, but only of its
stem Mari- is considered, since the former already is a combination of a noun
stem with an ending. The noun stem can be represented by the following concise
disjunctive feature representation:
Mari-:
‚é°
‚é¢
‚é£
GENDER f
NUM sg
CASE nom ‚à® gen ‚à® dat ‚à® acc ‚à® ins ‚à® loc ‚à® voc
‚é§
‚é•
‚é¶
Since Mari- is considered a noun stem, all cases are allowed and have to be
speciÔ¨Åed either by being left unmarked or by acquiring a suÔ¨Éx. Because Maria
is a female proper name, this example assumes that it only occurs in the singular
case. The representation for the ending -a looks as follows:
-a:
‚é°
‚é¢
‚é£
GENDER m
NUM sg
CASE nom ‚à® gen ‚à® acc
‚é§
‚é•
‚é¶ ‚à®
‚é°
‚é¢
‚é£
GENDER m
NUM pl
CASE nom ‚à® acc
‚é§
‚é•
‚é¶ ‚à®
‚é°
‚é¢
‚é£
GENDER f
NUM pl
CASE nom
‚é§
‚é•
‚é¶ ‚à®
‚é°
‚é¢
‚é£
GENDER n
NUM sg
CASE gen
‚é§
‚é•
‚é¶ ‚à®
‚é°
‚é¢
‚é£
GENDER n
NUM pl
CASE nom ‚à® acc
‚é§
‚é•
‚é¶
The respective feature matrix representation for Mari- is shown in Table 2.
150 S. H√∂fer
Table 2.
Mari- SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ?n ?n-sg-m ?n-sg-f ‚Äì ?n-pl-m ‚Äì ?n-pl-n
GEN ?g ?g-sg-m ‚Äì ?g-s-n ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ?a ?a-sg-m ‚Äì ‚Äì ?a-pl-m ‚Äì ?a-pl-n
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ?v ?v-sg-m ‚Äì ‚Äì ‚Äì ‚Äì ?v-pl-n
Table 3 shows the feature matrix for the ending -a which can directly be read
from Table 1 on page 147.
Table 3.
-a SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ?n ?n-sg-m ?n-sg-f ‚Äì ?n-pl-m ‚Äì ?n-pl-n
GEN ?g ?g-sg-m ‚Äì ?g-s-n ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ?a ?a-sg-m ‚Äì ‚Äì ?a-pl-m ‚Äì ?a-pl-n
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ?v ?v-sg-m ‚Äì ‚Äì ‚Äì ‚Äì ?v-pl-n
In the given feature matrix representations, strings preceded by a quotation
mark denote variables which can be bound during the uniÔ¨Åcation process to
either ‚Äô‚Äì‚Äô, ‚Äô+‚Äô, or other variables. As opposed to variables, strings without quo-
tation marks are called symbols, such as ‚ÄôNOM‚Äô, ‚Äô‚Äì‚Äô and ‚Äô+‚Äô. Additionally, the
matrix cells contained in the columns beginning with the SG-M column are
called feature cells. The symbol ‚Äô‚Äì‚Äô occurring in a feature cell means that the par-
ticular case-gender-number combination is not possible for the linguistic item. A
variable displays the possibility of this combination, and the ‚Äô+‚Äô symbol makes
a Ô¨Ånal commitment, determining the grammatical categories of the item. The
upcoming example shows how a well-formed feature matrix should look and how
feature matrix uniÔ¨Åcation works.
Whereas disjunctive features prove elegant in easily separable cases without
intermingling categories like for the form Mari-, they obviously do not form a
very compact representation for irregular systems as the Polish case system, as
can be seen for the -a ending. Feature matrices, on the other hand, may be fairly
sparse for very speciÔ¨Åc linguistic items. However, disjunctions were proven to be
computationally expensive [11]. Moreover, uniÔ¨Åcation of disjunctive features is,
in general, NP-complete [20]. In contrast, feature matrix uniÔ¨Åcation is a rather
simple task in terms of computational eÔ¨Äort. UniÔ¨Åcation based processing of
Complex Declension Systems and Morphology 151
disjunctive features cannot be covered in detail at this point, since this paper
concentrates solely on feature matrices. For a more detailed comparison, see [27].
Let us take a look at the uniÔ¨Åcation result of the feature matrices for Mari- and
-a. What exactly happens during uniÔ¨Åcation? The formal details of uniÔ¨Åcation
and merging in FCG are given in [9], however, an intuitive notion of uniÔ¨Åcation
of feature matrices is given in the following.
Table 4.
Mari-a SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ?n-sg-f ‚Äì ?n-sg-f ‚Äì ‚Äì ‚Äì ‚Äì
GEN ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
All cells of both matrices are compared pairwise, that is, the cell in row i,
column j from the Ô¨Årst matrix is compared to the cell in row i, column j from
the second matrix. If both cells contain symbols (in this case a string like ‚ÄôNOM‚Äô,
‚Äô‚Äì‚Äô or ‚Äô+‚Äô), they must be identical; if one cell contains a variable and the other
a symbol, the variable is bound to this symbol ‚Äì if the variable is not bound
to another symbol yet. Similarly, if both cells contain variables, the Ô¨Årst vari-
able is bound to the second one. Thus, for example, the variable ?n-sg-m from
the -a-matrix is bound to ‚Äô‚Äì‚Äô, since this is the value of the corresponding cell
in the Mari- matrix. Obviously, as shown in Table 4 the right solution is
obtained, because all possibilities except nominative singular feminine get sorted
out this way.
At this point, the role of the matrix‚Äôs second column, C, has not yet been
explained. The C actually stands for case and will be called the case column.
In order to understand what that case column does, let us take a look at the
resulting Mari-a matrix in Table 4 again. The feature cell corresponding to
nominative singular feminine contains the same variable ?n-sg-f as the cell in
the C column in the nominative row. That means that if ?n-sg-f is bound to ‚Äô+‚Äô
or ‚Äô‚Äì‚Äô, both cells are aÔ¨Äected. It was mentioned before that a ‚Äô+‚Äô would signal
full commitment; obviously, the result is unique, but why does no ‚Äô+‚Äô occur in
the resulting matrix then? The reason is that neither of the two linguistic items,
neither the noun stem nor the suÔ¨Éx, can make a deÔ¨Ånite commitment for a case
on its own. Assuming that the -a ending would only occur in nominative, there
would be a ‚Äô+‚Äô in the nominative case column of the -a feature matrix, and this
‚Äô+‚Äô would also make its way into the result matrix through uniÔ¨Åcation.
Whether to put a ‚Äô+‚Äô in a feature cell, too, depends on the number of al-
ternatives in this row: if the item can mark singular and plural or diÔ¨Äerent
genders, there would be variables like before. Otherwise, if a speciÔ¨Åc case-gender
152 S. H√∂fer
commitment could be made, there would be a ‚Äô+‚Äô in the corresponding column
as well.
Although in the Mari-a example no Ô¨Ånal commitment in terms of ‚Äô+‚Äôs could
be made, it is not harmful in practice when constructions that commit to case
are involved. This is illustrated by the following sentence:
(13) Maria
Maria.NOM
≈õpi.
sleeps.
‚ÄòMaria sleeps / is sleeping.‚Äô
In parsing or producing this sentence the construction for the verb ≈õpi would
contain a feature matrix for phrasal agreement, which would specify the case
of the subject (also usually including feature matrices for the cases of potential
objects, shown later). The verb‚Äôs feature matrix related to the subject or agent
in this phrase is shown in Table 5.
Table 5.
≈õpi Subject SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM + ?n-sg-m ?n-sg-f ?n-sg-n ?n-pl-m ?n-pl-f ?n-pl-n
GEN ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
Clearly evident, when the ≈õpi Subject feature matrix and the Mari-a feature
matrix are uniÔ¨Åed, the resulting matrix contains a ‚Äô+‚Äô in the nominative case
column and another ‚Äô+‚Äô in the feature cell corresponding to nominative singular
feminine. This example illustrates the purpose of the case column: the hypothesis
is that information about the case comes from the wider context, such as a verb
requiring its arguments to taking speciÔ¨Åc cases, while information about number
and gender can be inferred from the noun or at least from a nominal phrase. The
latter is the case for languages which mainly mark case by articles like German.
3.1 Limitations of Feature Matrices
The last section explained the basic idea and application mechanism of feature
matrices. This section will show that the previously introduced feature matrix
formalism is not Ô¨Çawless. However, the issues can be remedied by a canonical
extension called nested feature matrices in the forthcoming section.
Revisiting the previous example, the -a is combined with a masculine noun,
choosing cz≈Çowiek (man), which is also a noun stem since the nominative case
Complex Declension Systems and Morphology 153
is unmarked here. For the sake of completeness, provided are both the feature
matrix (Table 6) and the disjunctive feature representation for this noun:
cz≈Çowiek:
‚é°
‚é¢
‚é£
GENDER m
NUM sg ‚à® pl
CASE nom ‚à® gen ‚à® dat ‚à® acc ‚à® ins ‚à® loc
‚é§
‚é•
‚é¶
Table 6.
cz≈Çowiek SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ?n ?n-sg-m ‚Äì ‚Äì ?n-pl-m ‚Äì ‚Äì
GEN ?g ?g-sg-m ‚Äì ‚Äì ?g-pl-m ‚Äì ‚Äì
DAT ?d ?d-sg-m ‚Äì ‚Äì ?d-pl-m ‚Äì ‚Äì
ACC ?a ?a-sg-m ‚Äì ‚Äì ?a-pl-m ‚Äì ‚Äì
INS ?i ?i-sg-m ‚Äì ‚Äì ?i-pl-m ‚Äì ‚Äì
LOC ?l ?l-sg-m ‚Äì ‚Äì ?l-pl-m ‚Äì ‚Äì
VOC ?v ?v-sg-m ‚Äì ‚Äì ?v-pl-m ‚Äì ‚Äì
As before, the feature matrices for the noun stem and the ending -a whose
feature matrix was shown in Table 3 are uniÔ¨Åed. The result is shown in Table 7.
Table 7.
cz≈Çowiek-a SG PL
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ?n ?n-sg-m ‚Äì ‚Äì ?n-pl-m ‚Äì ‚Äì
GEN ?g ?g-sg-m ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ?a ?a-sg-m ‚Äì ‚Äì ‚Äì ?a-pl-m ‚Äì
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ?v ?v-sg-m ‚Äì ‚Äì ?v-pl-m ‚Äì ‚Äì
Notice that there are many variables, thus many possibilities are still open.
Next, cz≈Çowiek-a is embedded into a full sentence:
(14) Nie
Not
widzƒô
(I) see
cz≈Çowieka.
man.GEN
‚ÄòI do not see the man.‚Äô
As known from Section 2.2, a negated verb calls for the genitive of negation,
therefore cz≈Çowiek-a deÔ¨Ånitely takes the genitive case. Suppose that nie widzƒô
154 S. H√∂fer
has a feature matrix for its direct object as in Table 5 (the subject matrix
for ≈õpi), but it contains a ‚Äô+‚Äô and variables in the genitive row instead of the
nominative row. If now the matrix for cz≈Çowiek-a from Table 7 and the object
feature matrix of nie widzƒô are uniÔ¨Åed, the resulting feature matrix looks as
shown in Table 8.
Table 8.
(nie widzƒô) SG PL
cz≈Çowiek-a
Case C SG-M SG-F SG-N PL-M PL-F PL-N
NOM ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
GEN + ?g-sg-m ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
DAT ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
ACC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
INS ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
LOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
VOC ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
Something strange has occurred, namely that the case column and the feature
cell for the genitive singular masculine do not match. Why did this happen? By
checking all the feature matrices involved so far, it can be seen that none of these
matrices contain the same variable in the genitive case column and the regarded
feature cell. Therefore, these two cells cannot be related to each other in the
Ô¨Ånal result. In fact, it is not possible for any matrices to make the genitive case
column cell equal to a genitive feature cell since each matrix allows more than
one possibility in the genitive case ‚Äì although after the application of all the
constructions, only one possibility remains.
The reader may wonder if this behavior poses an actual problem, which, un-
fortunately, indeed it does for production. In production processing goes the
other way around, that is, Ô¨Årst the phrase structure with its agreement and de-
pendencies is processed, and the selection of the appropriate ending is made in
the very end. Thus, before any ending is added to cz≈Çowiek, the feature matrix
looks like in Table 8. Now imagine that there are not one possible ending for the
genitive but many diÔ¨Äerent ones. To take a concrete example, let us look only at
the genitive row of the feature matrix of the ending -√≥w which marks genitive
and accusative plural masculine and neuter:
Now comes the problem: Although the ending -√≥w is not allowed for the
masculine singular, its feature matrix uniÔ¨Åes with the one from Table 8. More
precisely, the variable ?g will be bound to ‚Äô+‚Äô and all others will be bound to
‚Äô‚Äì‚Äô. The meaning of the resulting feature matrix can be read as "the linguistic
Case C SG-M SG-F SG-N PL-M PL-F PL-N
GEN ?g ‚Äì ‚Äì ‚Äì ?g-pl-m ‚Äì ?g-pl-n
Complex Declension Systems and Morphology 155
Table 9. A nested feature matrix for Polish
SG PL
Case S S-M S-F S-N PL PL-M PL-F PL-N
?n ?n-s ?n-s-m ?n-s-f ?n-s-n ?n-pl ?n-pl-m ?n-pl-f ?n-pl-n
?g ?g-s ?g-s-m ?g-s-f ?g-s-n ?g-pl ?g-pl-m ?g-pl-f ?g-pl-n
?d ?a-s ?a-s-m ?a-s-f ?a-s-n ?a-pl ?a-pl-m ?a-pl-f ?a-pl-n
?a ?d-s ?d-s-m ?d-s-f ?d-s-n ?d-pl ?d-pl-m ?d-pl-f ?d-pl-n
?i ?i-s ?i-s-m ?i-s-f ?i-s-n ?i-pl ?i-pl-m ?i-pl-f ?i-pl-n
?l ?l-s ?l-s-m ?l-s-f ?l-s-n ?l-pl ?l-pl-m ?l-pl-f ?l-pl-n
?v ?v-s ?v-s-m ?v-s-f ?v-s-n ?v-pl ?v-pl-m ?v-pl-f ?v-pl-n
item takes the genitive case but has no gender and number" ‚Äì which obviously
does not make any sense for nouns in Polish2
.
3.2 Nested Feature Matrices
Before a way to solve the issue raised in the previous paragraphs is presented,
the reason for the problem should be formulated in a more abstract way. As
mentioned before, Polish knows three grammatical categories for nouns, case,
gender and number. Thus, it can be stated that the grammatical category of
a Polish noun is threefold or three-dimensional. A feature matrix, on the other
hand, is in this sense only two-dimensional: the rows encode diÔ¨Äerent cases, but
the columns have to encode gender and number. Let us look at the feature matrix
for cz≈Çowiek in Table 6 again: the noun cz≈Çowiek fully determines the gender,
but this fact cannot be explicitly expressed in this formalism. The intuition is
that a gender column or a number column are needed, which can be related to
the feature cells.
In fact, this is the basic idea of nested feature matrices. Table 9 introduces two
extra columns for number ‚Äì of course gender could also be used, but then one
more column would have to be added, since there are three genders but only two
numbers. Now the trick is the following: if a construction containing a feature
matrix can make a commitment to gender, it makes the gender column and the
feature cell equal. Therefore, the nested version for cz≈Çowiek appears as shown
in Table 10. Of course, all of the other feature matrices have to be transformed
to their nested versions as well.
Notice that also commitment to number can easily be modeled without the
need for nesting number separately. The only requirement is to make the case
and number columns equal.
In summary, in order for the resulting nested feature matrix to be well-formed
and to uniquely determine case, feature and number of a syntactic form, for each
of the syntactic categories, there must be at least one nested feature matrix that
determines its value.
2
In Polish, even indeÔ¨Ånite pronouns like nic (nothing) have to be declined.
156 S. H√∂fer
Table 10.
cz≈Çowiek SG PL
C S S-M S-F S-N PL PL-M PL-F PL-N
?n ?n-s-m ?n-s-m ‚Äì ‚Äì ?n-pl-m ?n-pl-m ‚Äì ‚Äì
?g ?g-s-m ?g-s-m ‚Äì ‚Äì ?g-pl-m ?g-pl-m ‚Äì ‚Äì
?d ?a-s-m ?a-s-m ‚Äì ‚Äì ?a-pl-m ?a-pl-m ‚Äì ‚Äì
?a ?d-s-m ?d-s-m ‚Äì ‚Äì ?d-pl-m ?d-pl-m ‚Äì ‚Äì
?i ?i-s-m ?i-s-m ‚Äì ‚Äì ?i-pl-m ?i-pl-m ‚Äì ‚Äì
?l ?l-s-m ?l-s-m ‚Äì ‚Äì ?l-pl-m ?l-pl-m ‚Äì ‚Äì
?v ?v-s-m ?v-s-m ‚Äì ‚Äì ?v-pl-m ?v-pl-m ‚Äì ‚Äì
To illustrate the whole application chain, let us look at the genitive row of
the nested version of the -a ending (Table 11).
Table 11.
SG PL
C S S-M S-F S-N PL PL-M PL-F PL-N
?g-sg ?g-sg ?g-sg-m ‚Äì ?g-sg-n ‚Äì ‚Äì ‚Äì ‚Äì
The commitment to number is expressed by using the same variable ?g-sg in
the case and the singular column. Finally, the genitive row of the result looks as
follows (all the cells in the other rows are ‚Äô-‚Äô):
Table 12.
SG PL
C S S-M S-F S-N PL PL-M PL-F PL-N
+ + + ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì
The Ô¨Årst ‚Äô+‚Äô means that the case is genitive and is introduced by the nie
widzƒô object feature matrix. The ‚Äô+‚Äô in the second column appears due to the
fact that the case column is made equal to the singular number column by
the -a ending matrix (Table 11). Eventually, the last ‚Äô+‚Äô is in place because the
cz≈Çowiek matrix (Table 10) links the number columns to the masculine feature
cells.
3.3 Modeling the Case System
The previous demonstrated how nested feature matrices can be used for deal-
ing with commitment and making it explicit. Before the presentation of the
actual FCG implementation for Polish, there is one last issue to solve which is
related to ambiguity. Consider the following case which is the positive version of
example 14:
Complex Declension Systems and Morphology 157
(15) Widzƒô
(I) see
cz≈Çowieka.
man.ACC
‚ÄòI see the man.‚Äô
It was previously mentioned that virile nouns take the same form in the genitive
and accusative. Let us take a look at the accusative row of the feature matrix
for the ending -a, shown in Table 13, this time in nested form. Notice that no
number commitment can be made, since both the singular and plural are allowed.
However, the noun cz≈Çowiek cannot take the -a ending in plural: In fact, the
accusative plural entry refers to another class of masculine nouns such as cud
(miracle). So the question is, how can this suÔ¨Éx be prevented from applying to
the wrong noun?
Table 13.
-a SG PL
C S S-M S-F S-N PL PL-M PL-F PL-N
?a ?a-sg-m ?a-sg-m ‚Äì ‚Äì ?a-pl-m ?a-pl-m ‚Äì ‚Äì
There are several possible solutions. The Ô¨Årst thing to do in any case is to
subdivide the declension schemes further. Following [16], there are more than
26 basic declension schemes. One possibility would be to put them into a huge
feature matrix, which would yield more than 26 columns. Obviously, this is not
a very elegant solution, for most of the matrices will be extremely sparse. Ad-
ditionally, the fact that the speciÔ¨Åc declension schemes can be grouped together
and share most of the endings is not taken into account by this solution either.
The possibility chosen here is to add supplementary features which denote the
declension scheme to the lexical constructions and to the suÔ¨Éx constructions.
It is important to note that no disjunctive features are needed here; rather the
feature matrix is used together with a conjunction of new features. Additionally,
the masculine declension scheme is subdivided into three schemes for virile, an-
imate and inanimate and this distinction is introduced into the feature matrix
paradigm. However, as mentioned before, this categorization is not always valid,
since there are inanimate objects following the animate scheme; therefore, the
three schemes are denoted by M1, M2 and M3. In total, this results in nested
feature matrices consisting of ten feature columns, one case column and two
number columns (overall 13 columns).
Another special case is the ending pair -i and -y, for they mostly mark the
same cases. Which one is to be applied depends on the stem: In some declension
schemes -y is the default ending, and it is substituted by -i after k and g. In
other schemes, -i is the default ending and has to be exchanged by i.
In the remainder of this paper the focus is not to implement all the diÔ¨Äerent
schemes, but rather to show how the pursued approach can be used to repre-
sent the whole complexity of this intricate declension system. The next section
deals with the actual implementation of the system in FCG and explains it step
by step.
158 S. H√∂fer
4 Operationalization in FCG
The forthcoming section aims to show how a subset of the Polish grammar can
be implemented in FCG and how nested features matrices (further called fea-
ture matrices) can be used to facilitate morphological and phrasal agreement. As
mentioned in an earlier chapter of this Volume [25], the key idea of construction
grammars is to treat every linguistic item as a form-meaning pair, a construction.
However, not all constructions in FCG have to be form-meaning pairs. Morpho-
logical processing can be modeled by exploiting the fact that FCG also allows
form-form pairs, that is, pure syntactic constructions. The need for syntactic
constructions will become obvious when the implementation of morphological
processing in the Polish example is explained.
Moreover, the generation of constructions is facilitated by templates which
also have been introduced in earlier chapters [2, 12, 25]. In particular the mor-
phological templates from [12] and [2] were adapted to deal with inÔ¨Çection and
stem aÔ¨Éxes. Additional templates for feature matrix creation were already devel-
oped for [27] and were extended for this study to cover nested feature matrices.
The actual application order of the constructions is guided by two factors.
On one hand, only appropriate constructions are considered during the applica-
tion process, since they have to match the current transient structure. In this
sense, constructions are looking for and triggered by certain unit features of
the current transient structure. One the other hand, the grammar designer can
also group constructions into construction sets and induce an explicit ordering
on the families. In the presented grammar constructions are grouped into the
following sets:
Lexical constructions provide the basic lexical items.
Functional constructions map lexical items to their syntactic function in a
phrase or sentence.
Negative and positive verb constructions determine if the phrase has a neg-
ative sense, expressed by the word nie.
Marked inflection constructions handle the proper case, number and gender
related endings for nouns.
Unmarked inflection constructions treat noun forms which do not exhibit an
ending.
Stem constructions provide the appropriate changes to stems of nouns, accord-
ing to their stem class and the attached ending.
Number constructions determine the right number of a noun.
Phrasal constructions take care of phrasal agreement.
Sentential constructions add context on the meaning side and punctuation on
the form side.
In the following the most important constructions are explained in detail. In
order to give the reader an overview of the machinery necessary for the im-
plementation of the formalized linguistic problems, the constructions will be
presented both from the design as well as the operational level; that is, template
deÔ¨Ånitions as well as graphical representations of constructions (using the tools
presented earlier in [14]) are given.
Complex Declension Systems and Morphology 159
4.1 Feature Matrices
So far, feature matrices were only considered in an abstract way, now their im-
plementation in FCG is presented. In fact, the implementation is rather straight-
forward, since a matrix can be modeled as a list of lists. Thus, the following code
shows the nested feature matrix for the noun cz≈Çowiek (man) (see Table 10) in
FCG notation:
((nom ?nom (nom-sg ?nom-sg-m1 ?nom-sg-m1 - - - -)
(nom-pl ?nom-pl-m1 ?nom-pl-m1 - - - -))
(gen ?gen (gen-sg ?gen-sg-m1 ?gen-sg-m1 - - - -)
(gen-pl ?gen-pl-m1 ?gen-pl-m1 - - - -))
(dat ?dat (dat-sg ?dat-sg-m1 ?dat-sg-m1 - - - -)
(dat-pl ?dat-pl-m1 ?dat-pl-m1 - - - -))
(acc ?acc (acc-sg ?acc-sg-m1 ?acc-sg-m1 - - - -)
(acc-pl ?acc-pl-m1 ?acc-pl-m1 - - - -))
(ins ?ins (ins-sg ?ins-sg-m1 ?ins-sg-m1 - - - -)
(ins-pl ?ins-pl-m1 ?ins-pl-m1 - - - -))
(loc ?loc (loc-sg ?loc-sg-m1 ?loc-sg-m1 - - - -)
(loc-pl ?loc-pl-m1 ?loc-pl-m1 - - - -)))
(voc ?voc (voc-sg ?voc-sg-m1 ?voc-sg-m1 - - - -)
(voc-pl ?voc-pl-m1 ?voc-pl-m1 - - - -)))
The overall structure is a list which contains one sublist per case. Each case
list consists of a symbol denoting the case name (e.g. nom), the case (column)
variable (?nom) and two sublists, one for each number. Again, the number lists
contain a symbol for the case-number combination (nom-sg), a number (column)
variable (in this example the Ô¨Årst ?nom-sg-m1) and Ô¨Ånally the actual feature
cells. In the example, all entries except the one at the M1 positions are marked
by a ‚Äô-‚Äô, since cz≈Çowiek follows the masculine virile declension scheme.
4.2 Lexical and Morphological Constructions
One one hand, there are lexical constructions which are simple form-meaning
mappings that translate a semantic entity denoting an individual, an object or
an event into an appropriate lexical representation. On the other hand morpho-
logical constructions deal with the attachment of the right stem and endings to
these representations. The focus of this study is on the morphology of nouns.
Therefore, Ô¨Årst the lexical construction for the noun dziewczyna (girl) is given,
and it is explained how production and parsing on the lexical level works in
FCG. The following example parses the utterance ("dziewczy" "-n" "-a")
and yields its semantic representation (girl girl-set context). It is impor-
tant to note that the very same constructions can also be used to produce the
utterance from the latter semantic representation.
Semantics. In FCG, semantic representations roughly correspond to second
order predicates. However, FCG does not use a formal inference system, so the
160 S. H√∂fer
way of using the predicates is not as strict as in formal predicate calculus. On the
semantic side, a girl is presented by the predicate (girl ?girl-set ?context).
The Ô¨Årst position of the predicate denotes the predicate name, followed by an
arbitrary number of arguments. In this case, a helpful interpretation is to con-
sider predicates as functions which calculate output sets or entities from input
sets. Hence, the girl predicate calculates the set of girl individuals from a given
context set (consisting of diÔ¨Äerent objects and individuals). In a more com-
mon predicate calculus representation, the girl predicate might be written as
Girl(X, Y ), where the predicate calculus set variables X and Y correspond
to the FCG variables ?girl-set and ?context, respectively. In the full FCG
grammar solution presented in this paper, each noun is accompanied by another
predicate denoting whether only one individual or a set of individuals is refer-
enced, namely (single-entity ?entity-set) or (set ?entity-set). A good
way to interpret the single-entity and set predicates is to regard them as
additional constraints rather than functions. For example, the following predi-
cate set denotes one speciÔ¨Åc girl individual in the base set, at least if such an
individual exists in the context:
(girl ?girl-set ?context) (single-entity ?girl-set)
Note how the variable ?girl-set appears in both predicates ensuring the correct
variable binding. The single-entity and set predicates are introduced by the
constructions from the number construction set.
Lexicon. The following code uses lexical templates as presented in [25] to create
the girl construction, at Ô¨Årst without feature matrices:
(def-lex-cxn girl-cxn
(def-lex-skeleton girl-cxn
:meaning (== (girl ?girl-set ?context))
:args (?girl-set ?context)
:string "dziewczy")
(def-lex-cat girl-cxn
:sem-cat (==1 (class indiv))
:syn-cat (==1 (lex-cat noun)
(gender feminine))
:phon-cat (==1 (stem "-n")
(stem-class hard)
(palatal-plural-endings -)))
The resulting construction is depicted in Figure 1. The construction is ac-
tualized by a coupled feature structure, consisting of a semantic (left) and a
syntactic (right) pole. The upper boxes above the dashed line basically state
how the transient feature structure should look in order to be manipulated by
this construction. The lower part contains information that should be added to
the transient feature structure by this construction in terms of J-Units.
Complex Declension Systems and Morphology 161
Fig. 1. Lexical construction for the (stem of the) noun dziewczyna (girl). Due to space
constraints, the full feature matrix is omitted.
As visible in the string argument of the def-lex-skeleton, the lexical item
for girl only contains the form dziewczy, lacking the stem and a concrete case
marking. These must be added by other constructions, considering the intended
case and number of the expression. Therefore, the def-lex-cat template is
used to add more information, particularly about the syntactic and phonetic
properties of the word. It assigns the lexical category to be a noun with feminine
gender (lines 8 and 9), additionally, it adds phonetic categories (lines 10 to 12):
by specifying the default stem and the stem class, only the right endings (in terms
of the right constructions) for this noun are considered during further processing.
Finally, the feature palatal-plural-endings speciÔ¨Åes whether this noun can
take palatal plural endings which aÔ¨Äect the noun stem. This noun obviously does
not, for its nominative plural is dziewczyn-y and not *dziewczyn-i.
After deÔ¨Åning the syntactic, semantic and phonetic features, a feature matrix
is added to the girl construction. In the Ô¨Årst instance, the declension paradigm
has to be created which speciÔ¨Åes which genders, cases and numbers are available:
(defparameter *polish-paradigm*
(make-matrix-paradigm
:dimensions ((nom gen dat acc ins loc)
(sg pl)
(m1 m2 m3 f n))))
Note that the vocative case is left out as it is not be used in this example. The
paradigm is an object which is bound to the variable *polish-paradigm* and
is used throughout the following construction deÔ¨Ånitions.
Next, the feature matrix is created and added to the girl construction by using
the following command:
162 S. H√∂fer
(def-feature-matrix girl-cxn
:paradigm *polish-paradigm*
:dimensions (sg-f pl-f)
:feature (:syn-cat :agr))
The crucial parameter is :dimensions which speciÔ¨Åes which case, number
and gender combinations are allowed for this item. Since the noun is feminine,
only the feminine singular and the feminine plural columns are set to variables,
the other cells are automatically set to ‚Äô-‚Äô. The template takes care of convert-
ing the necessary case and number columns into variables or pluses, and looks
for the possibility of unifying variables. The feature parameter speciÔ¨Åes at
which exact location in the coupled feature structure the matrix is inserted. In
this example, a new feature agr (for agreement) containing the feature matrix
is created, which is appended to the syn-cat feature of the syntactic pole.
Noun Inflection. At this point, only the constructions for the core of the noun
girl is available, now the constructions which deal with the endings are shown.
The following template creates a construction for the -a ending:
(def-inflection-affix-cxn inflection-suffix-a
(def-inflection-affix-skeleton inflection-suffix-a
:suffix "-a"
:syn-cat (==1 (lex-cat noun)
(gender ?gender))
:phon-cat (==1 (stem-class ?stem-class))
:impose-phon-cat (==1 (stem-palatalized -)))
(def-inflection-affix-feature-matrix
inflection-suffix-a
:paradigm *polish-paradigm*
:feature (:syn-cat :agr)
:dimensions
(nom-sg-f
gen-sg-m1 gen-sg-m2 gen-sg-m3 gen-sg-n
acc-sg-m1 acc-sg-m2)
:feature (:syn-cat :agr)))
Several new templates arise here, which are adapted to the creation of inÔ¨Çec-
tion aÔ¨Éxes. Again, there is an overarching template as well as a skeleton and
feature matrix template. An important diÔ¨Äerence is that the resulting construc-
tion will not consist of a semantic and a syntactic, but of two syntactic poles.
The reason for this is that the ending suÔ¨Éx does not add any new information
on the semantic side, but only actualizes the case and number marking. Role
assignment and all other semantically relevant tasks are taken care of by phrasal
constructions which will be shown later.
The application mechanism for pure syntactic constructions is the same as for
normal constructions, that is, it is divided into a matching and a merging phase.
Complex Declension Systems and Morphology 163
Fig. 2. Morphological construction for the -a ending. Due to space constraints, the full
feature matrices are omitted.
However, both matching and merging apply to the syntactic pole of the current
transient feature structure.
The most important diÔ¨Äerence is the suffix parameter by which a string
denoting the actual ending is passed. Alternatively, the parameter infix may
be used which also takes a string as its value. This is necessary since there exist
cases which are in principle unmarked, but which introduce a gap vowel before
the stem. For example, the genitive plural of the feminine noun deska (board) is
desek, that is, an e is introduced before the stem consonant k. This phenomenon
can be handled if the e is treated like a normal inÔ¨Çection ending, but which
occurs in the inÔ¨Åx instead of suÔ¨Éx position.
Fig. 3. Transient structure resulting after the application of girl-cxn and inÔ¨Çection-
suÔ¨Éx-a-cxn
164 S. H√∂fer
Another important new parameter is impose-phon-cat. Intuitively speaking,
the diÔ¨Äerence between this parameter and phon-cat is that the latter formulates
constraints concerning the transient structure before application of the construc-
tion. That means that any feature present in the phon-cat of the construction
must also be present in the phon-cat of the transient structure ‚Äì otherwise the
construction will not apply. On the other hand, the impose-phon-cat in the ex-
ample adds the feature (stem-palatalized -) to the transient structure after
application, and therefore aÔ¨Äects constructions applying afterwards. In partic-
ular, this feature declares that with this ending no palatalization of the stem
occurs, and therefore the default stem has to be attached.
The -a ending construction depicted in Figure 2 and the resulting transient
structure after the application of girl-cxn and inÔ¨Çection-suÔ¨Éx-a-cxn shown in
Figure 3 illustrate the parsing and production process. For a syntactic ending
construction only the right pole of the transient structure has to be considered.
The inÔ¨Çection-suÔ¨Éx-a-cxn attaches a new subunit to the noun unit. In the con-
struction, the noun unit is called ?stem-unit-73, that is, its name is a variable.
Therefore, it can be bound to the dziewczy-6 unit in the transient structure.
Similarly, ?inflection-unit-33 transforms to -a-6. The -a-6 unit contains the
feature (morph-type suffix) in its syn-cat which determines that the stem
added in the next step must be an inÔ¨Åx. Note that the feature matrix in the
syn-cat of dziewczy-6 has already determined the nominative singular case
to be the right solution after application of the inÔ¨Çection-suÔ¨Éx-a-cxn. Further-
more, the inÔ¨Çection-suÔ¨Éx-a-cxn adds another empty unit named -n-6, which
functions as a placeholder for the stem added by the construction presented in
the next section.
Before turning to stem constructions, it should be mentioned how unmarked
cases are handled. Unmarked forms can by actualized by the same inÔ¨Çection
templates as for marked forms, but no suffix or infix arguments are passed.
However, also in the case of unmarked forms an inÔ¨Çection-unit is added to the
transient structure. This unit is necessary since stem constructions need informa-
tion whether or not they are aÔ¨Äected by palatalization. The stem constructions
expect this information to be located in an inÔ¨Çection unit. Therefore, the dif-
ference to marked forms is that the inÔ¨Çection unit for null endings does not
contain any string feature. Furthermore, unmarked inÔ¨Çection constructions are
grouped into another construction set, since they have to be applied after the
constructions that deal with marked endings. Otherwise, unmarked inÔ¨Çection
constructions would apply even if there actually is an ending.
Stems. As explained before, palatalization has an eÔ¨Äect on the stem of a noun.
Stem constructions are very similar to inÔ¨Çection constructions and also use struc-
turally related templates. The following template creates the stem inÔ¨Åx -n:
Complex Declension Systems and Morphology 165
(def-stem-affix-cxn stem-infix-n
(def-stem-affix-skeleton stem-infix-n
:infix "-n"
:syn-cat (==1 (lex-cat noun)
(gender ?gender))
:phon-cat (==1 (stem "-n") (stem-class hard))
:inflection-phon-cat (==1 (stem-palatalized -))))
Most of the parameters contain the same function as the ones in the inÔ¨Çection
template. An important new parameter is inflection-phon-cat which is the
counterpart of the impose-phon-cat from the inÔ¨Çection construction. In this
example, it states that the inÔ¨Çection attached to the noun must not palatalize
the stem; otherwise this construction would not be applied and a diÔ¨Äerent one
would have to be chosen. If needed, a feature matrix can be added to the stem as
well, which is not necessary in this case because the -n stem occurs in all cases.
Figure 4 shows the resulting construction.
Fig. 4. Morphological construction for the -n stem
After parsing ("dziewczy" "-n" "-a") or producing (girl girl-set
context) the -n-6 unit on the syntactic pole now contains the actual string
representation for the stem. The syntactic pole of the obtained coupled feature
structure are depicted in Figure 5.
Number. Now that all work on the syntactic side is done, a predicate denot-
ing the right number of individuals must be introduced on the semantic side.
There are two speciÔ¨Åc constructions, singular-cxn and plural-cxn. For the sake
of brevity, the constructions are not depicted here, also because they do a fairly
simple job: in the semantic pole, they introduce the single-entity or set pred-
icate, respectively. In order to do so, each of them includes a feature matrix in
the syntactic pole which either contains variables in all the singular or in the
166 S. H√∂fer
Fig. 5. Syntactic pole of the coupled feature structure after the application of lexical
and morphological constructions
plural cells. In terms of the previous example, the singular-cxn should apply
because the feature matrix in the dziewczy-unit in Figure 5 determines the
case to be nominative singular.
4.3 Phrases
In the following paragraphs a more complex example in terms of a simple sen-
tence will be developed. Only the SVO pattern considered, therefore, the rel-
atively free word order of Polish is not accounted for. However, this can be
actualized by using a Ô¨Åeld topology approach which was implemented in FCG
for German as presented in a later chapter of this volume [15]. Moreover, only
transitive verbs are considered and no verb morphology is modeled. Therefore,
all verbs are in the third person singular or inÔ¨Ånitives. However, morphology for
verbs can be added in a similar way as the noun morphology presented in the
preceding sections. The grammar can be also easily extended with more complex
phrases by adding constructions for more complex patterns similar to the ones
presented in the forthcoming explanation.
Verbs. First, constructions for verb forms are added. The following lexical con-
struction deÔ¨Ånes the verb form widzi (he/she/it sees):
Complex Declension Systems and Morphology 167
(def-lex-cxn see-cxn
(def-lex-skeleton see-cxn
:meaning (== (see ?see-set ?base-set)
(seer ?see-set ?seer)
(seee ?see-set ?seee))
:args (?see-set ?seer ?seee ?base-set)
:string "widzi")
(def-lex-cat see-cxn
:sem-cat (==1 (class event)
(sem-val
(==1 (agent ?see-set ?seer)
(patient ?see-set ?seee))))
:syn-cat (==1 (lex-cat verb)
(verb-form inflected)))
(def-feature-matrix see-cxn
:paradigm *polish-paradigm*
:dimensions (nom)
:feature (:syn-cat :subject-agr))
(def-feature-matrix see-cxn
:paradigm *polish-paradigm*
:dimensions (acc gen)
:feature (:syn-cat :direct-object-agr)))
This construction is very similar to the lexical noun constructions presented
before, only the semantic features are diÔ¨Äerent because the verbs considered here
describe events rather than individuals. Notice that the construction contains
two feature matrices, one for agreement with the subject, another for agreement
with its direct object. The subject is forced to take the nominative case, while
the direct object can take either the accusative or genitive case ‚Äì owed to the
genitive of negation. In order to distinguish the two feature matrices, the feature
matrix corresponding to the subject is located in the subject-agr feature, while
the other one is located in the direct-object-agr feature.
The constructions for verbs which do not take the accusative look almost the
same, such as macha (he/she/it waves), which takes the instrumental case. The
main diÔ¨Äerence is that they only allow the instrumental case in the direct object
agreement feature matrix, since they are not aÔ¨Äected by the genitive of negation.
Since verb morphology is not covered in this paper a new construction for
every verb form has to be deÔ¨Åned. However, this is not too much work since
only inÔ¨Ånitives and verbs in the third person singular are considered. The see
-infinitive-cxn looks almost the same as the see-cxn construction, except
for having the verb-form feature, which is set to infinitive. Note that this
means that there is no diÔ¨Äerence on the meaning side between an inÔ¨Çected and
an uninÔ¨Çected verb construction. As shown later, this can become a problem in
production which is overcome by the introduction of sentential constructions.
168 S. H√∂fer
Beside the full verbs also inÔ¨Çected forms of auxiliaries like chce (he/she/it
wants) are deÔ¨Åned. In order to distinguish these verbs, the auxiliaries take the
additional (verb-type auxiliary) feature in their syn-cat.
Negation. In order to handle the genitive of negation, in the Ô¨Årst instance,
another lexical construction for the negation marker nie (not) is needed. It is
fairly trivial, for it translates this nie string into the predicate (not ?event).
The argument of the not predicate is an event which is introduced in the meaning
of the verbal construction above.
(def-lex-cxn not-cxn
(def-lex-skeleton not-cxn
:meaning (== (not ?event))
:args (?event)
:string "nie")
(def-lex-cat not-cxn
:syn-cat (==1 (lex-cat particle))
:sem-cat (==1 (class modifier))))
In terms of FCG hierarchy [8], it also adds a new unit to the transient structure
which represents this negation marker or predicate, respectively. Note that only
sentential negation is considered in this example, that is, no constituent negation.
This type of negation also exists in Polish and is marked by the same word nie.
In the next step, a construction is needed which propagates the appearance
of the negation marker to the verbal unit. It must bind the ?event variable in
the not-cxn to the verbal unit, and must also aÔ¨Äect the direct object agreement
feature matrix of a verbal unit. More precisely, it sets the accusative row of this
feature matrix to ‚Äô-‚Äô. The nominative row is also set to ‚Äô-‚Äô, since direct objects
of transitive verbs do not take this case either. The sentential-negation-cxn is
depicted in Figure 6.
However, a construction which discovers negation is not suÔ¨Écient, but also a
construction for the positive case is necessary. The reason for this is that there
must be a way to sort out the possibility that the direct object of a verb like
widzieƒá (see) can take the genitive case, if the phrase is not negated. This positive-
verb-cxn is much simpler than its negative counterpart, for it does not introduce
any new units, but just sets the genitive row of the direct object feature matrix
of the aÔ¨Äected verb unit to ‚Äô-‚Äô.
Note that these constructions are also able to deal with verbs which always
require their direct object to be in the genitive case, that is, also if no negation
is present. An example of such a verb is szukaƒá (search). In this case neither the
sentential-negation-cxn nor the positive-verb-cxn apply, for the feature matrix
for the direct object of szukaƒá contains a ‚Äô+‚Äô in the genitive row. The sentential-
negation-cxn does not apply because no negation marker is present, the positive-
verb-cxn cannot apply, for its feature matrix contains a ‚Äô-‚Äô in the genitive row.
Hence, their feature matrices cannot be uniÔ¨Åed and no change is made to the
verbal unit.
Complex Declension Systems and Morphology 169
Fig.
6.
The
sentential-negation-cxn
prevents
the
direct
object
of
the
verb
construction
from
taking
the
accusative
case
if
the
negation
marker
not
is
present
170 S. H√∂fer
Functional Constructions. Before the units created by the lexical construc-
tions can be processed by phrasal constructions, the functional role of the parts
of speech has to be determined. This is the task of the functional constructions
which are created by the def-fun-cxn template. They are fairly simple, therefore
only one exemplary construction which assigns the predicate role to an inÔ¨Çected
verb is given here:
(def-fun-cxn predicate-cxn
:sem-function action
:sem-cat (==1 (class event))
:syn-cat (==1 (lex-cat verb)
(verb-form inflected))
:syn-function predicate)
Verbal Phrases. In order to model the long distance genitive of negation a
construction is created that allows auxiliary verbs and inÔ¨Ånitives to be grouped
into a verbal phrase. The construction is depicted in Figure 7. In order to apply,
it requires an auxiliary-unit and an infinitive-unit.
It is important to see how long distance dependencies get propagated. During
the application of the construction the feature matrices of the infinitive-unit
are moved into a new auxiliary-infinitive-verbal-phrase-unit which then
heads the verbal units. This new unit behaves as if it were a verb, and the
sentential-negation-cxn can apply to it.
In a similar way also the processing of a chain of inÔ¨Ånitives could be im-
plemented: Pairs of inÔ¨Ånitives are headed by a new phrasal unit, and the last
inÔ¨Ånitive‚Äôs feature matrices are moved to this phrasal unit.
Sentential Phrases. In the last step, phrasal constructions are used to ar-
range all the parts of speech with transitive phrase constructions. Since they
are quite complex constructions, only the templates for creating feature matri-
ces and feature matrix agreement are presented. For more information on how
phrasal agreement is realized in FCG by this templates, see also [22].
Figure 8 shows the general structure of a transitive-phrase-cxn. The construc-
tion requires three units, namely a subject-unit, an object-unit and a verb-unit.
During application, it introduces a new unit called transitive-phrase-unit, which
subsumes the aforementioned units. The construction‚Äôs main task is to assign
the right cases to its constituents. In fact, several constructions are needed, more
precisely, one for each possible case that a direct object can take. This is neces-
sary because the construction should assign a ‚Äô+‚Äô in one of the case rows and set
all other rows to ‚Äô-‚Äô. This is especially needed in production, where the phrasal
constructions precede the morphological constructions, which must be able to
select the right ending without ambiguity3
.
3
Another possibility would be to use a phrasal construction containing a feature
matrix, forcing one row to be ‚Äô+‚Äô and all others to be ‚Äô-‚Äô but changing the case name
(e.g. nom) of all the rows to variables. This solution is not pursued here, since it is
computationally very expensive.
Complex Declension Systems and Morphology 171
Fig.
7.
The
auxiliary-inÔ¨Ånitive-verbal-phrase-cxn
groups
an
inÔ¨Çected
auxiliary
verb
and
an
inÔ¨Ånitive
172 S. H√∂fer
Fig. 8. General structure of the transitive-phrase-cxn
The following template adds the right feature matrices to the accusative-
transitive-phrase-cxn:
(def-phrasal-feature-matrix
accusative-transitive-phrase-cxn
:paradigm *polish-paradigm*
(?subject-unit
(:feature (:syn-cat :agr)
:dimensions (nom)))
(?object-unit
(:feature (:syn-cat :agr)
:dimensions (acc)))
(?verb-unit
(:feature (:syn-cat :subject-agr)
:dimensions (nom))
(:feature (:syn-cat :direct-object-agr)
:dimensions (acc))
In total, this template creates four feature matrices in this construction: one
that will match with the subject-unit‚Äôs feature matrix, one for the object-unit
and two for the agreement matrices of the verb-unit. However, this is still in-
suÔ¨Écient, since the verb has to agree with both the subject and the object.
Therefore, the verb‚Äôs subject feature matrix must unify with the subject‚Äôs fea-
ture matrix and the verb‚Äôs object feature matrix must unify with the object‚Äôs
feature matrix. For this purpose, the def-phrasal-feature-matrix-agreement
template is needed. The following code uniÔ¨Åes the direct object feature matrix
of the verb-unit with the feature matrix of the object-unit:
Complex Declension Systems and Morphology 173
(def-phrasal-feature-matrix-agreement
accusative-transitive-phrase-cxn
:paradigm *polish-paradigm*
:agreement
((?verb-unit
:feature (:syn-cat :direct-object-agr))
(?object-unit
:feature (:syn-cat :agr))))
Similarly, the subject-verb agreement can also be established.
When the construction applies, the units feature matrices unify with the ma-
trices of the phrasal construction. Because of the pairing of the subject-verb and
object-verb feature matrices, the right cases are propagated to the units.
4.4 Sentence Parsing and Production
Fig. 9. Transient structure resulting after parsing the sentence Michael does not want
to see the girl
Figure 9 shows the transient structure after parsing the following sentence:
"Micha" "-≈Ç" "nie" "chce" "widzieƒá" "dziewczy" "-n" "-y" ".".
(Michael does not want to see the girl.)
The following semantical representation is parsed from this sentence:
(michal michal-indiv-1 context-1)
(single-entity michal-indiv-1)
(girl girl-indiv-1 context-1)
(single-entity michal-indiv-1)
(not want-ev-1)
(want want-ev-1 context-1)
(wanter want-ev-1 michal-indiv-1)
(wantee want-ev-1 see-ev-1)
(see see-ev-1 context-1)
(seer see-ev-1 michal-indiv-1)
(seee see-ev-1 girl-indiv-1)
(context context-1))
174 S. H√∂fer
In order to see the result of the feature matrix agreement, the syntactic
dziewczy-unit is shown in more detail in Figure 10. As can be clearly seen,
the feature matrix determines that the noun takes the genitive singular case.
Fig. 10. The syntactic dziewczy-unit resulting after parsing the sentence Michael
does not want to see the girl
The sentence-cxn, not yet explicitly mentioned so far, adds the (context
context-1) predicate on the semantic and the full stop on the syntactic side. It
applies if all units have been subsumed under a phrasal unit and ensures that no
units are uncovered. This might happen in production since the semantic poles
of the inÔ¨Çected and the inÔ¨Ånitive constructions look exactly the same ‚Äì their
meanings are identical, but their form realizations are diÔ¨Äerent. Therefore, FCG
considers the possibility of using the inÔ¨Çected verb form construction for both
want and see. Of course, two inÔ¨Çected verbs forms cannot be grouped together
by the auxiliary-inÔ¨Ånitival-verbal-phrase-cxn, and therefore the following defec-
tive sentence is produced:
*"Micha≈Ç" "nie" "widzi" "dziewczyny" "chce".
(*Michael does not see the girl, wants.)
However, the sentence construction will not apply in this case and leave the
(context context-1) predicate uncovered. This will signal FCG that it should look
for a better solution that processes all the meaning predicates.
Note that multiple subclauses do not pose a problem in principle. In order
to actualize them, several slightly diÔ¨Äering sentence constructions that require a
Ô¨Ånite amount of subphrases could be used in order to group the subphrases in
an appropriate way.
Complex Declension Systems and Morphology 175
5 Conclusion
This paper has explained how a complex declension system can be operational-
ized in FCG. Polish was chosen as a representative from the group of Slavic
languages in order to verify if FCG can cope with highly irregular natural lan-
guage examples. Feature matrices have proven to be an elegant representation
for this system. They can be used to model agreement from the morphological to
the phrasal level. The key idea is to include the feature matrices in constructions
for nouns, morphological suÔ¨Éxes and phrases. Each of the constructions contains
a feature matrix encoding in which the possible cases, numbers and genders of
the item are encoded. Indeed, diÔ¨Äerent constructions for the same ending might
be necessary, if they are required for the disambiguation of declension variations
within the same gender. Which variation a noun must exhibit in order to be
combined with an ending is stored in supplementary features which are added
to the constructions of the noun and the ending. Moreover, the endings contain
more features which encode their eÔ¨Äect on the stem. This allows palatalization
to be modeled. The presented approach can also deal with unmarked cases. In
some of these unmarked cases, a gap vowel has to be introduced before the stem
consonant. This special case can be solved by treating the gap vowel as an inÔ¨Åx
marking. In the same way as palatalizing endings, a gap vowel is indicated by
adding supplementary features to the construction that represents the gap vowel.
This way, the right constructions are triggered in order to parse and produce a
noun form in a grammatically and syntactically correct manner.
Furthermore, a simple example of the long distance genitive of negation has
been implemented. A special focus has been on the case where the genitive of
negation has an eÔ¨Äect on the direct object of a nested inÔ¨Ånitive when the pred-
icate is negated. Phrasal constructions subsume the predicate and the inÔ¨Ånitive
in a new unit and propagate information about verbal agreement up to this
unit. This allows for the right constructions to apply and to change the feature
matrices representing the verbal agreement correctly.
The presented grammar can be extended in several ways. For instance, the
grammar can be scaled up by adding adjectives and pronouns. Morphologically,
these grammatical items can be treated in an analogue way to the nouns, that
is, every item will exhibit its own feature matrix and speciÔ¨Åc endings. From a
syntactic point of view, more Ô¨Çexible phrasal constructions will be necessary.
However, it has already been extensively shown how these diÔ¨Äerent grammatical
items can be handled in FCG (see this volume and also [23]).
More work on how to handle long distance dependencies in FCG in general
could be done. Polish exhibits a strong negative concord, that is, a negative
particle such as nikt (nobody), which always requires the negation marker nie,
despite not expressing double negation [21]. This phenomenon calls for a general
way to represent long distances, and future work should concentrate on how
these dependencies can be modeled in FCG.
Acknowledgements. This research was conducted at the Sony Computer
Science Laboratory in Paris and at the University of Brussels (VUB AI Lab).
176 S. H√∂fer
Funding has come from the Sony Computer Science Laboratory as well as from
the European research project ALEAR (FP7, ICT-214856). I would like to thank
all members of the language groups at Sony CSL and at the VUB AI Lab for
insightful discussions and helpful comments, and Liviu Ciortuz for pointing out
relationships of my work to other work in the Slavic linguist community.
References
[1] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[2] Beuls, K.: Handling Scope in Fluid Construction Grammar: A Case Study for
Spanish Modals. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI),
vol. 7249, pp. 123‚Äì142. Springer, Heidelberg (2012)
[3] Borsley, R.D., Przepi√≥rkowski, A.: Slavic in Head-Driven Phrase Structure Gram-
mar. CSLI Publications, Stanford (1999)
[4] Buttler, D., Kurkowska, H., Satkiewicz, H.: Kultura jƒôzyka polskiego. Zagadnienia
poprawno≈õci gramatycznej [Culture of Polish language: Issues on grammatical
correctness]. Pa≈Ñstwowe Wydawnictwo Naukowe, Warszawa (1973)
[5] Ciortuz, L.: LIGHT - A Constraint Language and Compiler System for Typed-
UniÔ¨Åcation Grammars. In: Jarke, M., Koehler, J., Lakemeyer, G. (eds.) KI 2002.
LNCS (LNAI), vol. 2479, pp. 3‚Äì17. Springer, Heidelberg (2002)
[6] Ciortuz, L., Saveluc, V.: Learning to unlearn in lattices of concepts: A case study
in Fluid Construction Grammars. In: Proceedings of SYNASC 2011, pp. 160‚Äì167.
IEEE Computer Society, Timi≈üoara (2011)
[7] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraint
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[8] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[9] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[10] DƒÖbrowska, E.: Learning a morphological system without a default: the Polish
genitive. Journal of Child Language (28), 545‚Äì574 (2001)
[11] Flickinger, D.P.: On building a more eÔ¨Écient grammar by exploiting types. Natural
Language Engineering 6(1), 15‚Äì28 (2000)
[12] Gerasymova, K.: Expressing Grammatical Meaning with Morphology: A Case
Study for Russian Aspect. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 91‚Äì122. Springer, Heidelberg (2012)
[13] Kowalik, K.: Morfonologia. In: Grzegorczykowa, R., Laskowski, R., Wr√≥bel, H. (eds.)
Gramatyka wsp√≥≈Çczesnego jƒôzyka polskiego: Morfologia [A Grammar of Contem-
porary Polish: Morphology], vol. 1. Pa≈Ñstwowe Wydawnictwo Naukowe, Warszawa
(1998)
[14] Loetzsch, M.: Tools for Grammar Engineering. In: Steels, L. (ed.) Computational
Issues in FCG. LNCS (LNAI), vol. 7249, pp. 37‚Äì47. Springer, Heidelberg (2012)
[15] Micelli, V.: Field Topology and Information Structure: A Case Study for Ger-
man Constituent Order. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 178‚Äì211. Springer, Heidelberg (2012)
Complex Declension Systems and Morphology 177
[16] Orzechowska, A.: Rzeczownik. In: Grzegorczykowa, R., Laskowski, R., Wr√≥bel,
H. (eds.) Gramatyka wsp√≥≈Çczesnego jƒôzyka polskiego: Morfologia [A Grammar of
Contemporary Polish: Morphology], vol. 1. Pa≈Ñstwowe Wydawnictwo Naukowe,
Warszawa (1998)
[17] Pollard, C., Sag, I.A.: Information-based syntax and semantics: vol. 1: funda-
mentals. Center for the Study of Language and Information, Stanford, CA, USA
(1988)
[18] Przepi√≥rkowski, A.: Long distance genitive of negation in Polish (2000)
[19] Przepi√≥rkowski, A., Kup≈õƒá, A.: Why formal grammar? (1999)
[20] Ramsay, A.: Disjunction without tears. Computational Linguistics 16(3), 171‚Äì174
(1990)
[21] Richter, F., Sailer, M.: Negative Concord in Polish. CSLI Publications, Stanford
(1999)
[22] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[23] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[24] Steels, L. (ed.): Computational Issues in Fluid Construction Grammar. Springer,
Berlin (2012)
[25] Steels, L.: Design Methods for Fluid Construction Grammar. In: Steels, L. (ed.)
Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 3‚Äì36. Springer,
Heidelberg (2012)
[26] Steels, L. (ed.): Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[27] van Trijp, R.: Feature matrices and agreement: A case study for German case. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
Field Topology and Information Structure:
A Case Study for German Constituent Order
Vanessa Micelli
Sony Computer Science Laboratory Paris, France
Abstract. A widely used approach for handling German constituent
ordering is based on the so called Ô¨Åeld topology surface model. This
model proposes Ô¨Åve Ô¨Åelds of varying complexity in linear order whereby
each Ô¨Åeld imposes more or less Ô¨Çexible constraints on the number and
the types of sentence constituents it can capture. Both the placement of
constituents into Ô¨Åelds and the order of the constituents within a Ô¨Åeld
can vary widely subject to an intricate interplay of diverse constraints
including information structure. This chapter works out a complete op-
erational solution illustrating this Ô¨Åeld topology approach within the
context of Fluid Construction Grammar. It focuses in particular on the
double object construction in ditransitive sentences.
1 Introduction
An average sentence, in a German newspaper, is a sublime and impressive
curiosity; it occupies a quarter of a column; it contains all the ten parts
of speech ‚Äì not in regular order, but mixed;" ([40], Appendix D).
German language learners in particular will agree with Mark Twain that German
constituent order presents a diÔ¨Écult but also intriguing subject of study. Despite
several strict rules, it is often the case that German constituent order is quite free.
For instance, the Ô¨Ånite verb must appear in the second position in declarative
sentences but subject or objects can shift around without restriction.1
One way of formally describing the seemingly free constituent order in Ger-
man sentences is through a topological surface model. This model tradition-
ally proposes a maximum of Ô¨Åve Ô¨Åelds of varying complexity in linear order as
discussed for example in [29].2
Each Ô¨Åeld then imposes constraints on which
and also on how many parts of the sentence it can capture. There are ongoing
debates on the acceptability of constituent orders in German utterances. Ex-
amples of potential factors determining constituent order are focus, deÔ¨Åniteness,
1
This claim only holds as long as the noun phrases are either case marked or identi-
Ô¨Åable by the context they appear in or by selectional restrictions. Else reordering is
not freely permitted (see [46, 45]).
2
[19] gives a review of the topological Ô¨Åelds. He proposes one additional Ô¨Åeld preceding
the Vorfeld to accommodate left-dislocated-elements. This approach is, however, not
accounted for in this case study.
L. Steels (Ed.) Computational Issues in FCG, LNAI 7249, pp. 178‚Äì211, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
Field Topology and Information Structure 179
case and animacy. (See for instance [16, 21, 24, 41].) In the present study, we
focus on the constraints identiÔ¨Åed by [24]. He found that German constituent
order, especially within the proposed Ô¨Åelds, is subject to an intricate interplay of
a number of diverse semantic, pragmatic or syntactic constraints. SigniÔ¨Åcantly,
these constraints must interact with aspects of information structure that are
often ignored or treated as peripheral to grammar rather than as integral to it.
The information structure of a sentence refers to how that sentence is struc-
tured regarding its focus, ground, topic, comment and so forth. IdentiÔ¨Åcation
of those issues within a sentence is still discussed in the literature, and so far
no common consensus has been reached. Although it is often described in terms
of general discourse principles or pragmatic parameters, empirical studies show
that almost every language has developed concrete strategies for marking infor-
mation structure. Within those languages, those strategies are conventionalized
and are more systematic than often assumed.
This chapter tries to answer the question as to how a speaker‚Äôs knowledge of
the information structure of his or her language can be operationalized so that
it can inÔ¨Çuence constituent order, focusing as a Ô¨Årst step on the double object
construction in declarative sentences in German. The chapter describes a Fluid
Construction Grammar (fcg) implementation that follows a Ô¨Åeld topological
approach and that tightly incorporates information structure into the grammar,
making it an integral part of it. We refer to other papers in this volume [38] as
well as [36] for introductions to fcg. The grammar is fully operational and can
be used for both parsing and production of German interrogative and declarative
sentences with intransitive, transitive or ditransitive verbs. This achievement is
noteworthy as many other approaches to grammar are often purely descriptive.
The main points of the grammar implementation described in detail in this
chapter are the following:
1. As previously suggested by [11], information structure has to be tightly in-
tegrated into the grammar, as it interacts both with phonology and syntax.
Fcg‚Äôs openness with respect to features and constraints oÔ¨Äers an elegant
way for achieving this. To capture German‚Äôs complex constituent order it is
important to deal with various constraints on various levels of the language,
which necessarily interact with aspects of information structure. Therefore,
the syntactic, semantic and pragmatic constraints identiÔ¨Åed by [24] will be
explicitly represented, evaluated and determined during language process-
ing. Their states are accessible to other constructions from any other part
of the grammar at all times. Pragmatic information is incorporated into the
grammar without assuming a separate discourse layer so that all ‚Äòlevels‚Äô of
language are tightly coupled in a non-modular way.
2. The grammar engineer can either put all constructions in one big ‚Äòconstruc-
ticon‚Äô, (one construction set), or group them into several construction sets,
whose order of application can then be controlled. The second option is
180 V. Micelli
chosen in this study, although it may seem to conÔ¨Çict at Ô¨Årst glance with a
non-modular approach to grammar. However, one must keep in mind that
constructions can reach across layers and they only apply when all their
constraints are met. So most of the time it is not at all relevant at which
point in processing they operate. On the other hand, sometimes constraints
in constructions are left as variables (i.e. they are underspeciÔ¨Åed). Therefore
constructions might apply too early, thereby imposing an incorrect value on
an underspeciÔ¨Åed constraint. One way of preventing this strongly undesirable
behavior is to put the constructions that determine those values correctly
into one construction set. It then has to be speciÔ¨Åed that this set is applied
before other constructions which rely on these constraints.
In order to determine the focus of a proposition, it is common practice to assume
that the proposition provides the answer to a lead-in information question. This
question sets the context and ensures that the answer incorporates the most
appropriate information structure, i.e. focus-marks the sentence constituent cor-
responding to the WH-constituent of the question [7, 23]. The presented gram-
mar serves as the language representation in such a question-answering dialogue
and can be used both for producing and interpreting questions and respective
answers.
The remainder of this chapter is structured as follows: Section 2 presents
the linguistic background of the present case study, introducing the notions of
Ô¨Åeld topology and information structure. Section 3 takes a step back from the
actual implementation and describes the diÔ¨Äerent steps necessary for engineer-
ing a grammar, including the previously discussed linguistic Ô¨Åndings. Section 4
highlights the main design patterns of the implementation, with Section 5 diving
into several implementation details and presenting the constructions needed to
produce an utterance. Section 6 brieÔ¨Çy summarizes the handling of information
structure in several other grammar formalisms and concludes the chapter.
2 Constituent Order of German Declaratives
The ordering of constituents in German declarative sentences is an intriguing
subject, because, although several strict rules non-ambiguously determine some
sentence constituents‚Äô position, it is often the case that German exhibits quite
a free constituent order. The approach in this chapter assumes that German
constituent order can be accounted for by following rules forming a topologi-
cal model. This model divides sentences into topological domains or Ô¨Åelds. All
sentence constituents are captured by a Ô¨Åeld and then those Ô¨Åelds are linearly
ordered. Information structure plays a role in partially determining the con-
stituent order within sentences and determining the ordering inside those topo-
logical Ô¨Åelds that capture more than one constituent. This section introduces the
notions of field topology and information structure.
Field Topology and Information Structure 181
2.1 Field Topology
The topological surface model traditionally proposes a maximum of Ô¨Åve Ô¨Åelds
of varying complexity in linear order as discussed for example in [18] and
displayed in Figure 1.3
The two sentence brackets (called linke Klammer (LK;
‚Äôleft bracket‚Äô) and rechte Klammer (RK; ‚Äôright bracket‚Äô)) form the sentence
frame, embracing the Mittelfeld (MF; ‚Äômiddle Ô¨Åeld‚Äô), preceded by the Vorfeld
(VF; ‚Äôfore Ô¨Åeld‚Äô), followed by a Nachfeld (NF; ‚Äôend Ô¨Åeld‚Äô). All of those Ô¨Åelds are
optional, however, some of them more than others. For example, the linke Klam-
mer is typically occupied by a Ô¨Ånite verb, however, never in relative clauses.4
linke
Klammer
sentence frame
Vorfeld Mittelfeld
rechte
Klammer
Nachfeld
Fig. 1. Model of the Ô¨Åve topological Ô¨Åelds
Each of these Ô¨Åelds imposes constraints about the type and number of sentence
constituents it can capture. The Ô¨Ånite verb, for instance, is always positioned
in the LK, whereas non-Ô¨Ånite verb forms as for example the past participle, in
case the verb is in perfect tense are considered to be always included in the RK.
This study does not account for cases where the participle occurs in another
position as this goes beyond the scope of this study. Here we only consider
possible declarative sentences which can answer a WH-question about one of the
event participants. The Vorfeld is generally composed of exactly one sentence
constituent (every constituent is permitted except the Ô¨Ånite verb).5
Figure 2
shows an example of how a sentence can be divided into Ô¨Åve Ô¨Åelds.
Despite the previously mentioned constraints determining which constituent
can go into which Ô¨Åeld, this sentence has more than a dozen possible constituent
orders. The ordering of constituents in the Mittelfeld seems to be relatively
free, but there are factors of varying nature that interact with one another and
aÔ¨Äect the sentence constituents‚Äô order in that Ô¨Åeld, particularly factors related
to information structure.
3
There is, however, controversial literature highlighting possible problems when as-
suming this approach. (See for instance [28].)
4
For more detailed information on topological Ô¨Åelds or a historical overview see for
instance [18], [19] or [10] who Ô¨Årst used the Ô¨Åeld-based terminology. For a discussion
of sentences with an empty left bracket see [28].
5
In this chapter, the investigations are constrained to declarative sentences and WH-
questions. There are, of course, exceptions to the mentioned rules, but these are
beyond the scope of this case study. See [26, 27] for an HPSG approach to account
for multiple frontings in German.
182 V. Micelli
hat
has
Der Junge
The boy.nom
einem Mann das Buch
a man.dat the book.acc
versprochen
promised
zu lesen.
to read.
VF LB MF RB NF
sentence frame
hat
has
Der Junge
The boy.nom
das Buch einem Mann
the book.acc a man.dat
versprochen
promised
zu lesen.
to read.
VF LB MF RB NF
sentence frame
hat
has
Einem Mann
A man.dat
der Junge das Buch
the boy.nom the book.acc
versprochen
promised
zu lesen.
to read.
VF LB MF RB NF
sentence frame
Fig. 2. Example sentences demonstrating three possibilities of placing sentence con-
stituents into the Ô¨Åelds. English translation: "The boy has promised a man to read the
book". The glosses show the literal English translation.
2.2 Information Structure
The term information structure has been Ô¨Årst introduced by Halliday [14]. It refers
to information that is provided to the listener about what aspect is assumed to be
in focus, what is given and new, what perspective is emphasized. Within a shared
communicative context, a speaker aims at avoiding misunderstandings in com-
munication. Therefore, he follows certain conventions with regard to information
structure so that the listener can understand it with minimal processing eÔ¨Äort [45].
Strategies of Information Structure. DiÔ¨Äerent languages use diÔ¨Äerent
strategies to express information structure in their utterances depending on
diÔ¨Äerent communicative circumstances. It can be expressed prosodically, by
grammatical markers or by a speciÔ¨Åc order of syntactic constituents in the form
of complex grammatical constructions. English, for instance, uses constituent
order as in (1) and (2), with possibly additional intonational stress or lexical
means as in (3), to emphasize particular parts of sentences (underlined in the
example sentences):
(1) He likes flowers.
vs.
(2) Flowers he likes.
(3) As for flowers, he likes them.
Field Topology and Information Structure 183
A language can have competing language strategies for expressing similar phe-
nomena. German, like English, is an intonation language. Therefore, one of the
strategies used for expressing information structure is the use of pitch accents on
new or prominent parts of the sentence [32]. Those parts are here called the focus
of the sentence. A diÔ¨Äerent, frequently used strategy is for instance fronting of
the most salient sentence constituents as exempliÔ¨Åed in (3) for English.
Focus-Marking in Question-Answering. One of the main assumptions of
traditional analyses of information structure is that the utterance answers a
previously asked question which presents the relevant context [17, 42]. DiÔ¨Äer-
ent questions (see (4) and (6)) force diÔ¨Äerent prosodic focus-marking (by us-
ing a pitch accent) on the truth-conditionally similar answers as exempliÔ¨Åed in
the following example sentences (The focus-marked constituent is put in square
brackets; the index FOC stands for focus.):
(4) Wer gibt dem Mann das Buch?
Who gives the man the book?
transl.: ‚ÄôWho gives the book to the man?‚Äô
(5) [DerJungeF OC] gibt dem Mann das Buch.
The boy gives the man the book.
transl.: ‚ÄôThe boy gives the book to the man‚Äô
(6) Was gibt der Junge dem Mann?
What gives the boy the man?
transl.: ‚ÄôWhat does the boy give the man?‚Äô
(7) Der Junge gibt dem Mann [einBuchF OC].
The boy gives the man a book.
transl.: ‚ÄôThe boy gives the book to the man‚Äô
In these cases, the use of pitch accent focus-marks that part of the utterance
asked for by the indicated question.
In this chapter, we focus exclusively on focus-marking for the following reasons:
1. Information about focus-marking is helping to account for an acceptable
order of two objects in the Mittelfeld. (See the end of this section.)
2. Through the use of pitch accent the cognitive eÔ¨Äort for the hearer is reduced,
because the part of the response that answers directly the question is made
more salient.
3. In some cases, intonation is necessary for disambiguation.
184 V. Micelli
Example sentences (8) ‚Äì (11) present a case where intonation helps disam-
biguate which sentence constituent plays which role in the situation. Sentence
(9) presents an ambiguous answer to the question in (8): It is not clear who is
seeing whom in that answer.
(8) Wen sieht sie?
transl.: ‚ÄôWhom does she see?‚Äô
(9) Die Professorin sieht die Studentin.
transl.: ‚ÄôThe professor sees the student.‚Äô or
‚ÄôThe student sees the professor.‚Äô6
Sentences (10) and (11) are, however, unambiguous: in (10) the student sees
the professor, in (11) the professor sees the student. However, the constituent
order of both sentences is identical, and only intonation disambiguates the two
diÔ¨Äerent readings.
(10) [DieProfessorinF OC] sieht die Studentin.
transl.: ‚ÄôThe student sees the professor‚Äô.
(11) Die Professorin sieht [dieStudentinF OC].
transl.: ‚ÄôThe professor sees the student‚Äô.
The assumption that focused noun phrases are emphasized through prosodic
means (through pitch accent) is based on Selkirk‚Äôs Ô¨Åndings [31]. She argues that
questions allow control over which syntactic constituent in the answer has to be
emphasized.
The present case study will not make a Ô¨Åne-grained diÔ¨Äerence of nuclear or
prenuclear accents of declarative sentences. It additionally does not distinguish
between rising or falling accents (adapted for German e.g. in [13]) as we are
only interested in general focus-marking of newly introduced noun phrases to
help determine constituent order. In this chapter we follow [30, 32] and use the
term focus in the sense of particularly prominent or new. We concentrate on
how information structure, and to be more precise, how focus-marking helps
determine the ordering of noun phrases (NPs) in the Mittelfeld. To determine
unmistakably which element should be focus-marked in an utterance, a preceding
question is assumed.
DiÔ¨Äerent Criteria InÔ¨Çuencing Constituent Order. Certainly there are
several properties of very diÔ¨Äerent kinds that have an impact on constituent
order. Some studies concentrate on deÔ¨Åniteness [22], animacy [16, 21] or length
of the argument NP in question. (see [1, 139], [2, 86], or [15]). In his seminal work
on constituent order in German, Lenerz identiÔ¨Åed three diÔ¨Äerent constraints on
deÔ¨Åniteness, case and focus-marking that co-determine the ordering of noun
phrases in the double object construction in the Mittelfeld [24]:
6
The Ô¨Årst reading is preferred slightly more, as ‚Äôthe professor‚Äô is in front position of
the sentence.
Field Topology and Information Structure 185
1. deÔ¨Ånite NP precedes indeÔ¨Ånite NP (Definiteness constraint)
2. non-focused NP precedes focused NP (Focus constraint)
3. dative NP precedes accusative NP (Case constraint);7
unmarked constituent
order
These three constraints are taken into account in this study.8
Speakers of Ger-
man have to establish knowledge of these constraints to successfully produce
and understand utterances. There are Ô¨Åve valid ordering scenarios regarding the
interplay of the identiÔ¨Åed constraints. Most interesting about those constraints
is their complex interaction with each other. Table 1 displays the valid scenarios
with the respective truth values of the constraints.
Table 1. Constraints and their interaction between each other (+ means that a con-
straint is met, ‚Äì means that it is not)
Scenarios DeÔ¨Åniteness Focus Case
1 + + +
2 + + ‚Äì
3 ‚Äì ‚Äì +
4 ‚Äì + +
5 + ‚Äì +
Assuming the question in (6), the example sentence in (7) displays Scenario
1. The sentence in (12), however, presents an example of an invalid ordering of
NPs in the Mittelfeld, assuming the same preceding question.
(12) Der Junge gibt ein Buch FOC dem Mann.
The boy gives a book FOC the man.
transl.: ‚ÄôThe boy gives the man a book‚Äô.
The answers in (14) and (15) to the question in (13) present the Scenarios 2 and
3 respectively.
7
Especially the case constraint is currently under debate: As described for instance
in [25] or [8], the order of sentence constituents in the MF is dependent on the kinds
of verbs and the type of its arguments. Cook suggests, for example, to not assume a
case constraint as suggested by Lenerz but to divide dative objects into low and high
datives regarding their grammatical function. Noun phrases are then ordered in the
MF depending on their grammatical function and not on their case. This approach
has the advantage that the grammar then captures all kinds of ditransitive verbs
not only those that are captured by following Lenerz‚Äô approach. However, in this
chapter we follow solely Lenerz seminal study and consider the further division of
dative objects as future work.
8
To ensure that two objects occur both in the MF, it is assumed in this case study
that the subject of the sentence is Ô¨Åxed in Ô¨Årst position. This decision, however, is
not linguistically motivated but chosen to ensure the occurrence of the double object
construction in the MF.
186 V. Micelli
(13) Wem gibt der Mann das Buch?
Whom gives the man the book?
transl.: ‚ÄôTo whom does the man give the book?‚Äô
(14) Der Mann gibt das Buch einem Jungen FOC.
The man gives the book a boy FOC.
transl.: ‚ÄôThe man gives the book to a boy.‚Äô
(15) Der Mann gibt einem Jungen FOC das Buch.
The man gives a boy FOC the book.
transl.: ‚ÄôThe man gives the book to a boy.‚Äô
Lenerz‚Äô Ô¨Åndings can be summed up as follows: As soon as the case constraint
holds, i.e. as soon as the dative NP precedes the accusative NP, it is irrelevant
which of the remaining two constraints is positive. For this reason, this con-
stituent order is called unmarked [24].9
However, in case it does not hold, both
of the other two constraints have to be met (marked constituent order). All
these special constraints and their interaction between each other are explicitly
integrated into the present FCG case study.
3 Progressive Plan Refinement
Before diving into the actual grammar implementation, it is important to con-
sider which diÔ¨Äerent steps have to be taken when composing an utterance using
a grammar that integrates the previously discussed linguistic Ô¨Åndings. This plan-
ning process collects diÔ¨Äerent constraints, tests their validity, makes reÔ¨Ånements
and in the end, composes the utterance, satisfying all constraints, hopefully lead-
ing to communicative success. After the Ô¨Årst and foremost goal has been reached
in the process of producing an utterance, i.e. what will be said has been decided,
the planning of the actual how to say it starts: what are the utterance‚Äôs smallest
constituents?
3.1 Which Words to Use?
Let us focus on the sentence "The man gives the book to a boy". A question
can be asked about each event participant. Here it is assumed that the question
in (13) (repeated here for convenience in (16)) precedes the production of the
utterance and sets the context necessary to determine which event participant
has to be focus-marked.
(16) Wem gibt der Mann das Buch?
Whom gives the man the book?
transl.: ‚ÄôWhom does the man give the book to?‚Äô
9
See additional remarks on unmarked constituent order in Section 6.
Field Topology and Information Structure 187
Producing an utterance is a sequential process in which the planning is constantly
reÔ¨Åned. It generally starts with selecting the required lexical items depending on
the speaker‚Äôs lexicon. There are several possible answers to the question in (16),
two of which take into account the constraints mentioned in the last section.
(17) Der Mann gibt das Buch einem Jungen FOC.
The man gives the book a boy FOC.
transl.: ‚ÄôThe man gives the book to a boy.‚Äô
Another appropriate answer, investigated more closely here, is the following:
(18) Der Mann gibt einem Jungen FOC das Buch.
The man gives a boy FOC the book.
transl.: ‚ÄôThe man gives the book to a boy.‚Äô
When composing the utterance that answers the context question, the previously
mentioned constraints are considered: the event participant being asked for is
made more salient by being marked with a pitch accent and the noun phrase
newly introduced to the context is preceded by an indeÔ¨Ånite article, according
to convention.10
Figure 3 shows which lexical constructions are used to compose the utterance.
Each lexical item is a bi-directional mapping of a form which traditionally is
constituted by the actual string and a meaning. A Ô¨Årst order predicate logic-
based representation of the meaning is used, which, for the lexical item Buch
(engl.: ‚Äôbook‚Äô), looks like this: (book ?x). The predicate book stands for the
ontological class describing books, and the variable ?x can be bound to the actual
book in the real world, which is referenced in this speciÔ¨Åc context. Determiners
do not yet have a form, depending on the semantic and syntactic role that the
item they are combined with plays. The appropriate string is added in a later
step. For simpliÔ¨Åcation, Figure 3 does not list all predicate-logic meanings but
only the placeholder meaning. (See Figure 11 for a meaning representation of
the complete sentence.)
The foundational material for building the utterance has been collected. The
next step is to decide which low-level constituents can be determined thus far.
Mann
meaning "Mann"
Junge
meaning "Junge"
determiner
meaning form
Buch
meaning "Buch"
gibt
meaning "gibt"
determiner
meaning form
determiner
meaning form
Fig. 3. All lexical items needed to produce the utterance
10
This means that we assume that the NP has not been aforementioned to ensure
the possibility to determine constituent order in the MF by accounting for Lenerz‚Äô
Ô¨Åndings (here the determination constraint respectively).
188 V. Micelli
3.2 What Are Possible Sentence Constituents?
Each noun is preceded by a determiner, therefore, in this step nouns and de-
terminers are combined into determined noun phrases. Syntactic and semantic
information from each of the two components of a determined noun phrase are
percolated up to the newly created noun phrase. In addition, the construction
creating the noun phrases adds additional information both to its form part (i.e.
constituent order constraints that the determiner has to precede the noun) and
to its meaning part. The speaker wishes to emphasize the noun phrase asked
for (‚Äôeinem Jungen‚Äô), in order to minimize the cognitive eÔ¨Äort of the hearer.
Focus-marked sentence constituents are more salient than others, which is why
the hearer immediately draws his or her attention to that constituent. Formally,
this is represented by adding the marker "FOC" following the noun phrase in
question. Figure 4 shows the constituents identiÔ¨Åed so far.
determined NP
determiner
meaning form
determiner
meaning form
Junge
meaning "Junge"
Buch
meaning "Buch"
gibt
meaning "gibt"
determined NP
- focus-marked -
determiner
meaning form
Mann
meaning "Mann"
determined NP
meaning form
FOC
meaning form
meaning form
meaning form
Fig. 4. The sentence constituents which so far have been identiÔ¨Åed
3.3 Which Role Do the Sentence Constituents Play?
Knowing which sentence constituents are at disposal, their syntactic and se-
mantic roles in the sentence can be assigned. Traditionally, argument structure
constructions link semantic roles of event participants to their grammatical roles,
and additionally they often impose constituent order on their constituents. (See
for instance [43]). However, here constituent order is only accounted for in the
very last step of building the utterance, when the topological Ô¨Åelds have been de-
termined and can be sorted. One of the reasons for this approach is that the same
argument structure constructions can apply for both declaratives and questions.
After each sentence constituent‚Äôs semantic and syntactic role in the sentence
has been identiÔ¨Åed, the determiners can be assigned their Ô¨Ånal forms. Figure 5
Field Topology and Information Structure 189
gibt
meaning "gibt"
argument structure
verb
noun phrase
noun phrase noun phrase
desired subunits
gibt
meaning "das Buch"
patient direct object
agent subject patient direct object recipient indirect
object
ditransitive
action
predicate
meaning "der Mann"
agent subject
determined NP
determined NP
determined NP
"einem Jungen FOC"
-focus-marked -
meaning
recipient indirect object
meaning "gibt"
ditransitive
action
predicate
assign syntactic and semantic roles to all sentence constituents
Fig. 5. Event participants are assigned their semantic and syntactic roles
shows the constituents identiÔ¨Åed so far, their semantic and syntactic roles and
the forms of the appropriate determiners. It shows that an argument structure
construction asks for four subunits which are assigned semantic and syntactic
roles, assuming that they meet the constraints the construction imposes on them
beforehand.
3.4 What Will Be the Order of the Two Objects in the Mittelfeld?
Before putting sentence constituents that have been determined so far into the
appropriate topological Ô¨Åelds, another decision has to be veriÔ¨Åed: Will the order
of the two objects in the Mittelfeld be marked or unmarked? (See Figure 6.)
This study accounts for three diÔ¨Äerent constraints determining the constituent
order of the two objects in the double object construction. Those constraints
are all initially underspeciÔ¨Åed as presented in Figure 6 by a question mark (?)
following the three keywords designating the three mentioned constraints: case,
focus and deÔ¨Åniteness.
In the case of the chosen constituent order being unmarked (as in sentence
(16)), the case constraint is satisÔ¨Åed, i.e. it is positive. This decision is made
when exactly what to say is decided, i.e. the predicate (unmarked) is listed in
the meaning of the complete utterance to be produced. (See Figure 11.) Figure
6 shows that the question mark following the term case has been substituted by
a +, because the constituent order is going to be unmarked. This step does not
happen magically, but there are mechanisms in the grammar whose job it is to
check if a constraint is met and determine the explicitly presented values of the
constraints. As soon as the case constraint is determined to be positive, however,
it is irrelevant if the other two constraints are fulÔ¨Ålled. The next step in the plan
can be executed, i.e. which constituent is captured by which Ô¨Åeld and ‚Äì in the
case of the Mittelfeld ‚Äì in which order are the constituents put into the Ô¨Åeld?
(See Section 3.5.)
190 V. Micelli
make that NP
indefinite &
focus-mark it
values of other
constraints
irrelevant
unmarked:
case
focus
definiteness
+
?
?
what was
asked for?
case
focus
definiteness
?
?
?
determine the
other
constraints'
values
marked:
case
focus
definiteness
-
?
?
Fig. 6. Which order in the Mittelfeld is preferred (marked or unmarked) and what are
the subsequent steps after the decision has been made?
Before that step is executed, the case should also be considered in which
marked constituent order has been chosen (i.e. the accusative object NP precedes
the dative object NP) (see (17)). In that case, the two other constraints regarding
focus-marking and deÔ¨Åniteness have to be determined (and in fact have to be
check
focus constraint
check
definiteness
constraint
marked:
case
focus
definiteness
-
?
?
check
definiteness
constraint
check
focus constraint
case
focus
definiteness
-
+
?
value of other
constraint
irrelevant
case
focus
definiteness
-
?
+
case
focus
definiteness
-
?
-
value of other
constraint
irrelevant
case
focus
definiteness
-
-
?
valid object
ordering
case
focus
definiteness
-
+
+
case
focus
definiteness
-
+
-
invalid object
ordering
valid object
ordering
case
focus
definiteness
-
+
+
case
focus
definiteness
-
-
+
invalid object
ordering
determine case of
the missing constraint
determine case of
either focus or definiteness constraint
Mittelfeld can be
created when object
ordering is valid
Fig. 7. When marked constituent order is preferred, all other constraints have to be
checked successively. Both the deÔ¨Åniteness and the focus constraint have to be positive
to yield appropriate object ordering.
Field Topology and Information Structure 191
met) in order to yield an appropriate utterance. Figure 7 shows the decision tree
which is traversed in that case. Having decided on producing marked constituent
order in the Mittelfeld, the case constraint can be assigned a negative value,
which means that there is a split in the tree: either the focus constraint or the
deÔ¨Åniteness constraint has to be checked as a subsequent step. If the Ô¨Årst one
picked tests negative, the value of the remaining last constraint is irrelevant,
since no appropriate ordering of the noun phrases is possible. Remember, that
if the case constraint does not hold, both other constraints must be positive.
Therefore, ideally at the end of this planning phase all three constraints will
have been determined, and will describe Scenario 2 of Table 1.
3.5 Which Sentence Constituent Goes into which Field?
As already mentioned, each Ô¨Åeld poses speciÔ¨Åc constraints on the constituent it
can capture. If the constraints are met, the sentence constituent in question is
put into the respective Ô¨Åeld. In this example study, the subject is always pre-
ferred to be in the Vorfeld, to make sure that the two objects are deÔ¨Ånitely in
the Mittelfeld. Their order has already been determined in the last step where
the three constraints and their validity were checked. The linke Klammer is in
declarative sentences typically occupied by a Ô¨Ånite verb. In the example sen-
tence three topological Ô¨Åelds result, which capture all of the present sentence
constituents but which still have to be ordered linearly. Figure 8 illustrates the
state in processing identiÔ¨Åed so far.
3.6 How Are the Topological Fields Ordered?
The last step of the plan still has to be executed: The topological Ô¨Åelds have to
be put into linear order. The Vorfeld is always in Ô¨Årst position, followed by the
linke Klammer, which is in turn followed by the Mittelfeld in which the order
of constituents has previously been determined (see Figure 9). The construction
that creates the linear order of the Ô¨Åelds is a declarative construction, which
is not aÔ¨Äected by the type of constituents in the Ô¨Åelds but simply puts those
Ô¨Åelds that are at its disposal into the appropriate order. In this example this
means that after the declarative construction has applied, the Vorfeld precedes
the linke Klammer, which in turn precedes the Mittelfeld.
der Mann
Vorfeld
gibt
linke Klammer
einem Jungen das Buch
Mittelfeld
Fig. 8. IdentiÔ¨Åed topological Ô¨Åelds capturing their respective constituent(s) in arbitrary
order. The order of the two objects in the Mittelfeld has already been determined.
192 V. Micelli
declarative construction
Field 5
Nachfeld
Field 2
Linke Klammer
Field 1
Vorfeld
...
desired subunits
meets meets meets
Fig. 9. A declarative construction puts the Ô¨Åelds into linear order. The Ô¨Åeld containing
the dots stands for any Ô¨Åeld that is put within the Linke Klammer and the Nachfeld.
3.7 Analyzing an Utterance
To parse the previously discussed utterance, exactly the same mechanisms are
used. All steps are taken similar to the production process described above but
starting from the surface form. The goal in this process is to pick the utterance
apart and collect the sentence‚Äôs expressed meaning. The order of the application
of the mechanisms has, however, been slightly altered. First all lexical items
(including the determiners) are picked out, and their meanings are collected.
Determined noun phrases are then detected, semantic and syntactic roles of
all event participants are assigned, the validity of the constraints are checked,
Ô¨Åelds and their constituents are assigned and the application of the declarative
construction shows that the utterance is in fact a declarative.
After having discussed on a more general level how an utterance is built by
assuming the approach of creating topological Ô¨Åelds, sorting them and incorpo-
rating information structure to determine the Ô¨Åelds‚Äô constituents‚Äô order, the next
section presents some actual design patterns used in the applied fcg grammar
to operationalize all of what has been mentioned before.
4 Design Patterns
This section highlights the main design patterns that have been used to imple-
ment the linguistic decision-making process discussed in the previous section.
4.1 Feature Matrices
The language user is faced with a complex search problem and needs to manage
this problem in an eÔ¨Écient way. In the same way, a computational system has to
Ô¨Ånd an eÔ¨Écient way to deal with it. One possible way to deal with the complex
German case system is the use of feature matrices [44]. It is more eÔ¨Écient to
represent a set of constraints (as case, gender and number) as attributes that take
an array of values. Postponing the decision of a noun‚Äôs case, gender and number
to a point in the analysis where there is no longer ambiguity avoids unnecessary
search or backtracking, in case a wrong hypothesis has been followed. As a result
processing cost is highly reduced.
Field Topology and Information Structure 193
However, not only are feature matrices used to determine the case, gender
and number of noun phrases or deÔ¨Åniteness in determiners, attribute-value pairs
are also put into the top-unit by the argument structure construction. Those at-
tributes and their values are used to help determine the Ô¨Ånal constituent order of
the double object construction in the Mittelfeld. That means that the Ô¨Ånal sur-
face form of the utterance depends on a complex interaction of constraints. Only
when the validity of the constraints has been identiÔ¨Åed, can the Ô¨Ånal constituent
order be determined.
4.2 Construction Sets
Despite the fact that the linguistic inventory is a continuum from lexicon to
grammar, various sets of constructions can be identiÔ¨Åed based on their func-
tion in the grammar. Particularly complex sentences, such as the one examined
in this chapter, involve a considerable number of constructions of a diÔ¨Äerent
nature. Although fcg can also autonomously organize the search [47], the pro-
cess of identifying the various types of constructions involved in the sentences‚Äô
analysis is a Ô¨Årst and necessary step into understanding and operationalizing
a grammar. Hence, constructions are grouped into several construction sets re-
garding their function in interpretation and production.11
(See Figure 10.) All
constructions are bi-directional form‚Äìmeaning pairings, however, they diÔ¨Äer in
their complexity.
lexical
cxns
meaning
phrasal
cxns
intonational
cxns
production
sentential
cxns
meaning field cxns
constraint
checking
cxns
parsing
argument
structure
cxns
morpho-
syntactic
cxns
constraint
checking
cxns
field cxns
sentential
cxns
surface
form
argument
structure
cxns
intonational
cxns
phrasal
cxns
lexical
cxns
morpho-
syntactic
cxns
surface
form
Fig. 10. The order in which fcg constructions are applied in production (upper part)
and in interpretation (lower part)
Another major reason for arranging constructions in diÔ¨Äerent sets is that the
order of processing can thereby be controlled. Normally, the order of application
does not matter, as constructions only apply when their conditions are fulÔ¨Ålled.
However, aside from the fact that they can be grouped in functionally simi-
lar sets, making the application process more readable and easier to follow, it
is important that some constructions only apply after other sets have already
applied. Argument structure constructions add attribute value pairs to the top-
unit, where the value is initially a logic variable. (See paragraph on explicit
11
For more details on construction sets see [3].
194 V. Micelli
constraint representation below.) Later in processing, there are constructions
that check the value of those constraints, whose application requires for instance
either an explicit negative value (i.e. a ‚Äì) or a positive one (+). However, con-
struction application can also successfully happen if the value of the constraint
is still a variable for which the technical reason is that (unify ‚Äô(a b c) ‚Äô(a b
c)) clearly uniÔ¨Åes, however, (unify ‚Äô(a ?x c) ‚Äô(a b c)) uniÔ¨Åes as well and
binds the variable ?x to b. Certainly, this binding is not desired in this case
where all variables should Ô¨Årst clearly be determined.
4.3 Ontological Categories
Constructions usually have a syn-cat and a sem-cat unit-feature that list the
syntactic or semantic categories, respectively. Examples are for instance the part
of speech of a word, its function like nominal or a plain semantic category
like entity. These categories are further used by higher-level constructions:
For instance a determiner-noun-construction asks for two subunits: one whose
function is nominal and whose semantic category is an entity and one whose
part of speech is determiner and whose semantic category contains a deÔ¨Åniteness
value. When having found units that conform to those constraints, these units are
combined into a determined noun phrase. In this grammar, whenever necessary,
instead of single category values, a list of semantic or syntactic categories is
given, describing the same item, but with diÔ¨Äering granularity or speciÔ¨Åcity.
Let‚Äôs have a closer look at one example construction: The sem-cat feature
of the construction describing the lexical item house, for instance, lists the se-
mantic categories (entity container). For a determiner-noun-construction it
is enough to know the actual house belongs to the semantic category entity,
which, therefore, can be combined with a determiner. However, some construc-
tions, for instance the one for the lexical item enter, should solely be combined
with nouns of a speciÔ¨Åc semantic category as, for instance, container. This
approach ensures that house can be the object of verbs like to enter.
An equivalent method is adopted for syntactic categories: Ditransitive sen-
tences have two objects: a direct and an indirect object. Both belong to the
more general category object, therefore their syn-cat feature includes both
(direct-object object) and (indirect-object object) respectively. A
higher level construction like the one building the Mittelfeld for questions con-
siders only that the constituents it captures are objects and not them being
direct or indirect. Other constructions, however, need to make that distinction
and therefore need more Ô¨Åne-grained information.
This method is chosen to account for simple ontological ‚Äòhierarchies‚Äô, which
theoretically can be as Ô¨Åne-grained as desired. Hierarchy here does not imply
the integration of a real ontological hierarchy but refers to a list of ontologi-
cal categories which are not linked in the construction at all. However, those
categories can be mapped to ontological classes in a separate ontological model
where properties and links have been established. The downside of this method
is that so far many categories have to be copied and manually integrated into
constructions again and again.
Field Topology and Information Structure 195
4.4 Explicit Representation of Constraints‚Äô Status
Constituent order in German is inÔ¨Çuenced by various kinds of constraints. Three
of them and their interaction among each other have been discussed in 2.2.
Those are all treated in the same way in the grammar implementation: The
argument structure construction adds one attribute-value pair for each con-
straint to the top-unit of the transient structure representing the status of
each of those constraints. This also shows that information structure as it is rep-
resented here is strongly interwoven with the rest of the grammar. The following
pairs are explicitly added to the top-unit in a newly created unit-feature called
constraint-status:
(constraint-status (==1 (focus-constraint ?fc)
(definiteness-constraint ?dc)
(case-constraint ?cc))
Each attribute is followed by its value, which initially is a variable, indicated by
the ? preceding it. Only when it can be decided unambiguously which constraint
is met, will the respective variable be changed either into a + (indicating that
this constraint is met) or a ‚Äì (indicating that it is not met). Similar category
value pairs, where the value can either be a +, a ‚Äì or a variable, will be used
throughout the grammar on both the semantic and syntactic poles.
All mentioned high-level design patterns of the grammar will recur in the
following section, where parts of the actual implementation are described.
5 Operationalization
Now that the linguistic background and more abstract ideas behind the presented
grammar have been examined, technical issues that arise during operationaliza-
tion can be addressed. Basic knowledge about fcg is assumed [37]. In the course
of this section, several constructions are highlighted that contribute to the pro-
duction of the answer to the respective question in (18). The answer is repeated
in (19) for the reader‚Äôs convenience.
(19) Der Mann gibt einem Jungen FOC das Buch.
The man gives a boy FOC the book.
transl.: ‚ÄôThe man gives the book to a boy.‚Äô
Extensive detail of the application of all of these constructions is not provided,
rather mostly how they are created and what they look like is highlighted.12
The
interested reader is referred to www.fcg-net.org to inspect a complete dialogue
where a question as well as a respective answer is produced and also parsed using
the presented constructions. In the web demonstration, single constructions, as
well as transient structures and their modiÔ¨Åcations after construction applica-
tion, can be inspected. In the following sections, the constructions are described
in their order of application in production as depicted in Figure 10.
12
See [5] for a detailed explanation how constructions are applied.
196 V. Micelli
5.1 Initial Linguistic Structure
Each production process starts with the creation of an initial transient structure
that couples a syntactic and a semantic structure or pole. The semantic struc-
ture speciÔ¨Åes the meaning of a sentence, while the syntactic structure speciÔ¨Åes
its form. Linguistic processing essentially involves the mapping of a semantic
structure to a syntactic structure (i.e. meaning to form) during production, and
the inverse during parsing. In terms of fcg, this is accomplished through the
application of constructions to a transient structure. The consecutive application
of constructions adds additional units and constituent structure to both poles of
the structure as well as additional parts of meaning and form. All meaning to
be rendered into an utterance is stored in the so-called top-unit (cf. Figure 11).
The meaning is represented in Ô¨Årst order predicate logic expressions.
Constructional meanings are stored in a frame-based ontology. A construc-
tion‚Äôs meaning is represented by one of the frames present in the ontology, i.e.
the value of its meaning feature is equivalent to a frame in the ontology. For ex-
ample, the frame representing the meaning of the verb to give looks as follows:
meaning
top
((f-marking indiv-boy)
(reified-entity indiv-boy)
(boy indiv-boy)
(give-frame give-frame-4)
(give-giver give-frame-4 indiv-man)
(give-what give-frame-4 indiv-book)
(give-to-whom give-frame-4
indiv-boy)
(book indiv-book) (man indiv-man)
(determined-entity indiv-book)
(determined-entity indiv-man)
(unmarked))
top
sem syn
save
Fig. 11. Initial transient structure. The semantic pole (to the left of the arrow) contains
the meaning which will be rendered into an utterance, the syntactic pole (to the arrow‚Äôs
right) is still empty.
((give-frame ?give-frame)
(give-giver ?give-frame ?a-giver)
(give-what ?give-frame ?the-given-thing)
(give-to-whom ?give-frame ?the-recipient))
Again, names starting with a question mark are variables. The use of the same
variable name ensures that every instance of its use refers to the same referent.
You can see in Figure 11 that those variables which designate the actual ob-
jects and events the speaker wishes to talk about have been replaced by unique
symbol names. For instance, instead of the variable ?give-frame, an indexed
give-frame-4 is used, referring to the give-action in the context.
Field Topology and Information Structure 197
5.2 Lexical Constructions
To deÔ¨Åne a lexical construction, the same templates as described in [37] are used.
The following template creates a lexical construction called Mann-cxn by Ô¨Årst
creating a skeleton, then incrementally adding syntactic and semantic catego-
rizations and Ô¨Ånally a feature matrix to account for case:
(def-lex-cxn Mann-cxn
(def-lex-skeleton Mann-cxn
:meaning (== (man ?man))
:args (?man)
:string "Mann")
(def-lex-cat Mann-cxn
:sem-cat (==1 mann person entity
(sem-function identifier)))
:syn-cat (==1 (pos noun)
(syn-function nominal))
(def-feature-matrix Mann-cxn
:feature (:syn-cat :case-number-gender)
:paradigm *german-case*
:dimensions (nom-s-m acc-s-m dat-s-m)))
In this state of processing it is not yet possible to unambiguously determine
the lexical item‚Äôs case. It can potentially be nominative, dative or accusative
masculine singular. Feature matrices are used to express that there is still ambi-
guity. (See [44].) To include the respective feature matrix into the Mann-cxn the
template def-feature-matrix is called within def-lex-cxn. Within that tem-
plate, the feature to which the matrix is added to is speciÔ¨Åed (here: case-number
-gender). Also the unit-feature to which case-number-gender is added to is
listed (here: syn-cat). Then the kind of paradigm to be used ‚Äì here *german
-case* ‚Äì is indicated. The possible values (nom-s-m acc-s-m dat-s-m) are
listed as the Mann-cxn can be of all three cases, however always being mas-
culine and singular.13
The German case paradigm has to be created before with
a template called define-paradigm:
(define-paradigm :dimensions ((nom acc dat gen)
(s-m s-f s-n)))
The resulting paradigm deÔ¨Åned by that template is the following:
(syn-cat (==1 (case-number-gender
((nom ?nom ?nom-s-m ?nom-s-f ?nom-s-n)
(acc ?acc ?acc-s-m ?acc-s-f ?acc-s-n)
(dat ?dat ?dat-s-m ?dat-s-f ?dat-s-n)
(gen ?gen ?gen-s-m ?gen-s-f ?gen-s-n)))))
13
Please see [44] for more information on the feature matrices, including a detailed
description of the design choices and the respective templates.
198 V. Micelli
For illustration purposes, plural is ignored in this example. Please refer to [44]
for a complete treatment of German determiners. The paradigm that is included
in the Mann-cxn, then, looks as follows. Some possibilities are already ruled out
(i.e. marked with a ‚Äì), as the gender and number of the lexical item is already
known:
(syn-cat (==1 (case-number-gender ((nom ?nom-s-m ?nom-s-m - -)
(acc ?acc-s-m ?acc-s-m - -)
(dat ?dat-s-m ?dat-s-m - -)
(gen - - - -)))))
In production, the application of the construction is triggered by the meaning
(man indiv-man) in the ?top-unit. A new unit is then created, which contains
both a semantic and a syntactic pole. On the semantic side, an args feature,
whose value is the same referent as the one in the meaning predicate, and a
sem-cat feature, whose value is a simple hierarchy listing the unit‚Äôs semantic
categories (mann person entity), are added. (See Section 4.3.) The syntactic
pole contains the part of speech and the syntactic function of the unit (nominal).
Each construction has a speciÔ¨Åc syntactic function. The function of more com-
plex noun phrases is also nominal. Those functions enable the usage of the
output unit in higher level constructions. For instance, the determiner-noun-
phrase construction does not care if the determiner is combined with a common
noun or an adjective-noun phrase. It only imposes one constraint on the unit the
determiner is combined with: The function of that unit has to be nominal. All
lexical constructions are created in the same way as described for the Mann-cxn.
5.3 Grammatical Constructions
Grammatical constructions are needed to determine semantic or syntactic roles
of the sentence, its phrase structure and the topological sentence structure. The
following sections describe the types of constructions needed to produce the
utterance.
Phrasal and Intonational Constructions. The only phrasal construction
to apply three times is the determiner-nominal-phrase-cxn. To create this
construction the def-phrasal-cxn template is used, which heavily resembles the
one described in detail in [35] and utilizing the J-operator [9]. That chapter goes
step by step through the creation of a phrasal construction by exploring diÔ¨Äerent
mechanisms handling each single issue in the construction. The following shows
the template as it is used here:
Field Topology and Information Structure 199
(def-phrasal-cxn determiner-nominal-phrase-cxn
(def-phrasal-skeleton determiner-nominal-phrase-cxn
:phrase
(?nominal-phrase
:cxn-form (== (meets ?determiner-unit ?nominal-unit))
:sem-function referring
:phrase-type nominal-phrase)
:constituents
((?determiner-unit
:sem-function reference
:syn-function determiner)
(?nominal-unit
:sem-function identifier
:syn-function nominal)))
(def-phrasal-agreement determiner-nominal-phrase-cxn
(?nominal-phrase
:sem-cat (==1 (determined +)
(definite ?definiteness)
referent)
:syn-cat (==1 (definite ?definiteness)
(determined +)
(pos (== ref-expression))
(case-number-gender ?case) referent))
(?determiner-unit
:sem-cat (==1 (definite ?definiteness))
:syn-cat (==1 (definite ?definiteness)
(pos determiner)
(case-number-gender ?case)))
(?nominal-unit
:sem-cat (==1 entity)
:syn-cat (==1 (case-number-gender ?case))))
(def-phrasal-linking determiner-nominal-phrase-cxn
(?nominal-phrase
:args (?referent))
(?determiner-unit
:args ?referent)
(?nominal-unit
:args (?referent))))
The construction created by the template does not add a constructional mean-
ing but only speciÔ¨Åes a constructional form (constituent order). However, the
choice in semantic or syntactic categories presents the main diÔ¨Äerences to the
construction creation described in [35]. To ensure agreement in case, number
and gender, the case-number-gender categories of both the determiner and the
nominal units carry the same value ?case.
The rule‚Äôs application is triggered by the presence of a ?determiner-unit
and a ?nominal-unit complying with the semantic and syntactic constraints
imposed on those units. Each nominal and its associate determiner are made
200 V. Micelli
subunits of a newly created noun phrase unit. Depending on which kind of de-
terminer has triggered the application of the determiner-nominal-phrase-cxn,
the respective deÔ¨Åniteness value, (definite +) or (definite -), is percolated
both to the semantic and syntactic poles of the newly created noun phrase.
Similarly, the value of the variable ?case, which is a complete feature matrix
including case, number and gender information, is percolated to the new unit
?nominal-phrase where the same variable name is used. The part of speech
of each newly created unit is ref-expression. This attribute is needed for the
unit‚Äôs later use in the ditransitive construction.
One of the created noun phrases is going to be the one that carries the pitch
accent, i.e. that is focus-marked. On the form side, this is expressed by adding
the marker "FOC" to the noun phrase that was asked for in the previously asked
question ("einem Jungen"). Also a syntactic category will be added: (f-marked
+). On the meaning side, this is represented by the meaning (f-marking indiv
-boy). The semantic category (focused +) is additionally added. The construc-
tion which takes care of focus-marking that noun phrase is created with the
same def-phrasal-cxn template. The only diÔ¨Äerences are in the choice of se-
mantic and syntactic categories. Most important are those in the def-phrasal
-agreement template:
(def-phrasal-agreement focus-unit-construction
(?emphasized-phrase
:sem-cat (==1 (focused +) referent)
:syn-cat (==1 (f-marked +)
(pos (== ref-expression))
(case-number-gender ?case))))
After successful construction application, the newly created unit ?emphasized
-phrase contains the listed semantic and syntactic categories. They will later
be needed to determine the value of the focus constraint in the ?top-unit to
determine the order of the two objects in the Mittelfeld. (See Section 5.3.) Ad-
ditionally, case, number and gender information of the unit to be emphasized is
percolated from the noun phrase to ?emphasized-phrase.
Argument Structure. The main task of argument structure constructions
is to link semantic roles of event participants to their grammatical roles [34].
This section brieÔ¨Çy examines the ditransitive construction needed to produce
the utterance. For a complete chapter on how to deal with argument structure
of utterances and how they can be created see [43]. There are several diÔ¨Äerences
between the argument structure construction used here and argument structure
constructions presented in that chapter:
1. It does not explicitly add any meaning in form of a meaning predicate, but
it assigns semantic and syntactic roles to the event participants.
Field Topology and Information Structure 201
2. It does not impose constituent order on its subunits. The main reason for
that design choice is that it can be used both in questions and declarative
sentences, diÔ¨Äering in their surface structure. Constituent order is only ac-
counted for by ordering the topological Ô¨Åelds. (See Section 5.3.)
3. It creates a new unit-feature constraint-status in the top-unit and adds
three attribute-value pairs to this unit-feature which are needed to determine
the order of the nominal objects in the Mittelfeld:
(constraint-status (==1 (focus-constraint ?fc)
(definiteness-constraint ?dc)
(case-constraint ?cc))
After the application of the ditransitive construction, the values of those
three attributes are still underspeciÔ¨Åed (marked by the preceding question
mark (?) of the symbol name). They become atomic (either + or ‚Äì) after their
truth-value has been checked by the respective constructions (cf. Section 5.3).
This is a requirement to decide whether or not a scenario as listed in Table
1 is valid.
The decision which sentence constituent plays which semantic or syntactic role
in a sentence has been delayed to a point where it can unambiguously be de-
cided. After application of that construction all event roles are speciÔ¨Åed, i.e. the
mapping of semantic roles like agent and syntactic roles like subject has been
taken care of, which means that the respective cases of the event participants
can ultimately be assigned. For instance the feature matrix for the determiner
noun phrase "der Mann" looks now as follows:
(syn-cat (==1 (case-number-gender ((nom + + - -)
(acc - - - -)
(dat - - - -)))))
Morphological Constructions. Morphological constructions operating solely
on the syntactic part of the structure determine the eventual form of the arti-
cles. Since the case, number and gender of determined noun phrases has been
determined by the argument structure construction, the determiners‚Äô case, num-
ber and gender is known, as well. Therefore, their form can be assigned at this
point in processing. The template to create a morphological construction for the
determiner der looks like the following:
(def-morph-cxn der-morph
:syn-cat (==1 (pos determiner)
(case-number-gender ?case)
(definite +)
(syn-function determiner))
:string "der")
202 V. Micelli
form
syn-subunits
footprints
syn-cat
nominal-phrase-10
((meets
determined-entity-unit-6
word-mann-2))
(word-mann-2
determined-entity-unit-6)
(determiner-nominal-phrase-cxn
marked-phrasal)
((case-number-gender
((gen - - - -) (acc - - - -)
(dat - - - -)
(nom + + - -)))
(pos (ref-expression))
(definite +) (determined +)
(phrase-type nominal-phrase)
(syn-role subject))
footprints
syn-cat
determined-entity-unit-6
(determiner-construction)
((case-number-gender
((nom + + - -)
(acc - - - -)
(dat - - - -)
(gen - - - -)))
(pos determiner)
(syn-function
determiner)
(definite +))
footprints
form
syn-cat
word-mann-2
(mann-cxn)
((string word-mann-2
"Mann"))
((pos noun)
(syn-function nominal)
(case-number-gender
((nom + + - -)
(acc - - - -)
(dat - - - -)
(gen - - - -))))
Fig. 12. The syntactic part of the noun phrase unit with its two subunits
footprints
syn-subunits
syn-cat
form
nominal-phrase-10
(determiner-nominal-phrase-cxn
marked-phrasal)
(determined-entity-unit-6
word-mann-2)
((case-number-gender
((gen - - - -) (acc - - - -)
(dat - - - -)
(nom + + - -)))
(pos (ref-expression))
(definite +) (determined +)
(phrase-type nominal-phrase)
(syn-role subject))
((meets
determined-entity-unit-6
word-mann-2))
footprints
form
syn-cat
word-mann-2
(mann-cxn)
((string word-mann-2
"Mann"))
((pos noun)
(syn-function nominal)
(case-number-gender
((nom + + - -)
(acc - - - -)
(dat - - - -)
(gen - - - -))))
form
syn-cat
footprints
determined-entity-unit-6
((string
determined-entity-unit-6
"der"))
((case-number-gender
((nom + + - -)
(acc - - - -)
(dat - - - -)
(gen - - - -)))
(pos determiner)
(syn-function determiner)
(definite +))
(determiner-construction
der-morph)
Fig. 13. The same unit as above after the application of a morphological construction
having added the form feature to the determination unit
Figure 12 shows the syntactic part of the noun phrase unit combining the
Mann-unit and the determination-unit before the application of the morpho-
logical construction. After its application the form feature with the string "der"
has been added to the determination-unit, depicted in Figure 13.
Field Topology and Information Structure 203
Constraint-Checking Constructions. Constraint-checking constructions
determine which of the three constraints, whose status is monitored in the
top-unit, are met, regarding a certain order of noun phrases in the Mittelfeld.
Depending on the result of the test, the value of each attribute will be either +
or ‚Äì. When the case constraint is met (dative NP precedes accusative NP), none
of the other constraints no longer have to be checked (see Scenarios 1, 3, 4 and 5
of Table 1), which means their attribute value can stay underspeciÔ¨Åed. Only in
the second scenario, i.e. when marked constituent order is chosen, the values of
the deÔ¨Åniteness and the focus constraint have to be validated. (See description
of the decision process in Section 3.)
To account for the utterance in (19), only the construction checking the case
constraint applies. All constructions checking any kind of constraint look very
similar and are created with the def-constraint-check template. The following
creates the case-check-construction-positive construction.
(def-constraint-check case-check-construction-positive
:constituent-order (?first-object ?second-object)
:meaning (unmarked)
:constraint-status (case-constraint +)
:constituents ((?first-object
:args (?recipient)
:sem-cat (==1 (sem-role recipient))
:syn-cat (==1 (syn-role (== indirect-object))))
(?second-object
:args (?patient)
:sem-cat (==1 (sem-role patient))
:syn-cat (==1 (syn-role (== direct-object))))))
On its syntactic side, the construction imposes a constituent order on its
two constituents ?first-object and ?second-object. This constituent order
is speciÔ¨Åed in the slot :constituent-order, then the construction‚Äôs meaning is
given. The following slot allows for the manipulation of the values of the con-
straints that are in the top-unit. Here, it is speciÔ¨Åed, that the case-constraint
is going to be met (it is positive). When applied, the construction assigns a +
to the previous variable ?cc of the case constraint (constraint-status (==1
(case-constraint +))). In the slot :constituents, both semantic and syntac-
tic categories of all constituents (here ?first-object and ?second-object) are
speciÔ¨Åed. The constituent ?first-object must have the (sem-role recipient)
and the (syn-role (== indirect-object)). Similarly, it is constrained that
the constituent ?second-object must have the (sem-role patient) and the
(syn-role (== direct-object)). Those constraints and the imposed
constituent order on the constituents equal the case constraint: dative NP pre-
cedes accusative NP.
The following shows what the created construction looks like. The information
which has been provided by the template is printed in bold:
204 V. Micelli
(def-cxn case-check-construction-positive ()
((?top (sem-subunits (== ?first-object ?second-object))
(sem-cat (==0 question-to-be-answered))
(meaning (== (unmarked)))
(footprint (==0 case-check-construction)))
(?first-object
(sem-cat (==1 (sem-role recipient)))
(args ?recipient))
(?second-object
(sem-cat (==1 (sem-role patient)))
(args ?patient))
((J ?top)
(constraint-status (==1 (case-constraint +)))
(footprint (== case-check-construction))))
<-->
((?top (syn-subunits (== ?first-object ?second-object))
(form (== (meets ?first-object ?second-object)))
(syn-cat (==0 question-to-be-answered))
(footprint (==0 case-check-construction)))
(?first-object
(syn-cat (==1 (syn-role (== indirect-object)))))
(?second-object
(syn-cat (==1 (syn-role (== direct-object)))))
((J ?top)
(constraint-status (==1 (case-constraint +)))
(footprint (== case-check-construction)))))
After it has been determined that the case constraint is positive, the stage is
set for the topological constructions to apply.
Topological Constructions. To account for sentence structure in German, a
Ô¨Åeld topology approach is followed as brieÔ¨Çy described in Section 2. Each Ô¨Åeld is
considered as a box in which constituents are put when they meet several condi-
tions. They all look very similar and apply in exactly the same way as all previ-
ously discussed constructions. The following shows the template def-field-cxn
used to create constructions that build Ô¨Åelds:
(def-field-cxn field name
:constituent-order list constituents that should follow each other
:constituents ( ?unit-name
:args arguments
:sem-cat features
:syn-cat features))
In the Ô¨Årst slot :constituent-order the constituents that are supposed to
follow each other are listed. The slot :constituents can capture a varying
number of constituents. Those constituents will be put into the respective Ô¨Åeld.
Field Topology and Information Structure 205
This is operationalized by creating a new Ô¨Åeld-unit and making the constituents
subunits of that Ô¨Åeld-unit. A new unit-feature is introduced in the newly created
Ô¨Åeld unit called field-role. This unit-feature is needed later by the sentential
construction which puts the Ô¨Åelds into linear order. The value of this feature
is the actual name of the respective Ô¨Åeld the unit designates. The following
subsections show how that template is used to create the linke Klammer, Vorfeld
and Mittelfeld.
Linke Klammer. The Ô¨Årst Ô¨Åeld to be inspected is the linke Klammer. The fol-
lowing shows the template creating it:
(def-field-cxn linke-klammer-full-verb-constituent
:constituents ((?clause-constituent
:args (?referent)
:sem-cat (==1 event)
:syn-cat (==1 (verb-form finite)
(pos (== full-verb))
(syn-role predicate)))))
This Ô¨Åeld is the simplest one here, as there is only one option which sentence
constituent it can capture: the Ô¨Ånite verb. Therefore, the semantic category of
this clause constituent have to be of type event (sem-cat (== event)) and
the syntactic categories have to include (syn-cat (==1 (verb-form finite)
(pos (== verb)) (syn-role predicate))).
After the application of this construction, a new unit is created which captures
the constituent and takes it as its subunit. To both its syntactic and semantic
pole a new unit-feature is added:
(field-role (== linke_klammer))
Vorfeld. Generally, each sentence constituent except the Ô¨Ånite verb are allowed
in the Vorfeld. There are, however, exceptions which are discussed in detail in
[25]. With an interest in the double object construction in the Mittelfeld, only
the subject is permitted in the Vorfeld in this grammar implementation. It is,
however, also possible to implement the Vorfeld construction in a way so that it
accepts other sentence constituents, but this construction will not be described
here. To make sure that the subject will be put into the Vorfeld, the syntac-
tic category of the constituent the construction applies on is required to be of
(syn-role subject) and the semantic category of (sem-role agent). Again ‚Äì
behind the scenes ‚Äì a field-role unit-feature and a footprint are added to the
newly created unit.
The following shows the def-field-cxn template used to create a construc-
tion that builds the Vorfeld:
206 V. Micelli
(def-field-cxn Vorfeld-construction
:constituent-order (?clause-constituent ?left-bracket)
:constituents ((?clause-constituent
:args (?agent)
:sem-cat (==1 (sem-role agent))
:syn-cat (==1 (syn-role subject)))
(?left-bracket
:field-role (==1 linke_klammer))))
Mittelfeld. In our implementation, there are two diÔ¨Äerent constructions that
can create a Mittelfeld, however, only one of them can apply here based on the
positive value of the case-constraint: (constraint-status (==1 (case
-constraint +))).
Below, the def-field-cxn template is used to create that Mittelfeld:
(def-field-cxn Mittelfeld-construction
:constraint-status (case-constraint +)
:word-order (?first-object ?second-object)
:constituents ((?first-object
:sem-cat (==1 (sem-role recipient))
:syn-cat (==1 (syn-role (==1 indirect-object))))
(?second-object
:sem-cat (==1 (sem-role patient))
:syn-cat (==1 (syn-role (==1 direct-object))))))
In parsing, the Mittelfeld-construction applies when two subunits are
present fulÔ¨Ålling the syntactic constraints that both of their syn-roles have
to be objects, one being (syn-role (== indirect-object)) and the other one
(syn
-role (== direct-object)) respectively.
In production, the construction imposes semantic constraints on its
constituents, i.e. their sem-role has to be either patient or recipient:
(sem-cat (==1 (sem-role (== patient)))) or
(sem-cat (==1 (sem-role (== recipient)))) respectively.
As soon as those constraints are met, a Mittelfeld-unit is created, taking the
direct object and the indirect object as subunits and imposing constituent order
on them (form (== (meets ?first-object ?second-object))). By now, all
necessary sentence constituents are captured in a topological Ô¨Åeld. The created
Ô¨Åelds are still in no speciÔ¨Åc order. Sentential constructions put the Ô¨Åelds into
linear order, how exactly is explained in the following.
Sentential Constructions. Sentential constructions, as for instance an inter-
rogative or a declarative construction, put the created Ô¨Åelds into linear order.
The declarative construction is triggered as soon as there are three Ô¨Åelds, here
Field Topology and Information Structure 207
called ?vorfeld, ?linke-klammer and ?mittelfeld, which fulÔ¨Åll the following
constraints on both semantic and syntactic poles of the source structure:
(?vorfeld (field-role (== vorfeld)))
(?linke-klammer (field-role (== linke_klammer)))
(?mittelfeld (field-role (== mittelfeld)))
The declarative construction does not add additional conceptual meaning, how-
ever it contributes to the meaning by adding a semantic and a syntactic category
to the top-unit: (sem-cat (==1 assertion)) and (syn-cat (== declarative
-clause)). It additionally does not care about the number and type of con-
stituents captured in the Ô¨Åelds. It solely sorts the Ô¨Åelds by imposing meets-
constraints on them in its form feature:
(form (== (meets ?vorfeld ?linke-klammer)
(meets ?linke-klammer ?mittelfeld)))
Finally, all constructions which are needed to create the utterance in (19) have
applied and the utterance, therefore, can be rendered.
6 Discussion and Conclusion
There are various eÔ¨Äorts operationalizing German constituent order which have
inspired this work. In [12], for instance, the implementation of a grammar is
described, dealing with German constituent order based on a topological model
starting from a syntactic dependency tree. The main emphasis of that work is,
however, to cover all acceptable linear orders of German declarative sentences.
There is no semantic or contextual information integrated in their formalism
yet. Furthermore, they do not account for syntactic structure of the sentence
at all, playing a fundamental role in constituent order, but only care about the
topological phrase structure, i.e. about the order or the Ô¨Åelds per se and not
the order of elements within those Ô¨Åelds or other phrases‚Äô structure. The hpsg
description of German constituent order in [20] also describes linearization rules
exclusively based on the topological structure of sentences.
Information structure is usually ignored in present-day computational
systems, however, there are some eÔ¨Äorts where its inclusion is regarded ben-
eÔ¨Åcial. [39] reports on the incorporation of information structure into UCCG
‚Äì UniÔ¨Åcation-based Combinatory Categorial Grammar. The main goal of the
involvement of information structure in that grammar implementation is to im-
prove the performance of speech generation systems. Similar to the account
taken here, pitch accents are implemented as autonomous units which can be
combined with the constituent that has to be emphasized. This ensures that
the lexicon is not unnecessarily expanded as it is, for instance, in Combinatory
Categorial Grammar [33] where each lexical word is represented multiple times
in the lexicon: one separate entry is created for the non-emphasized word and
several entries for each possible accent that word can carry. However, that gram-
mar implementation includes a much more Ô¨Åne-grained analysis of intonation as
208 V. Micelli
its main purpose is completely diÔ¨Äerent to the grammar presented here, which
is to be further used in a speech generating system.
In [11], the integration of information structure into the hpsg framework is de-
scribed. This study is conform with this approach in several points, such as that
information structure should be an integral part of the grammar instead of rep-
resenting it independently. However, their analysis has never been expressed as a
working computational implementation, but only describes a potential computa-
tional system. From the point of view taken here, it is considered to be essential
to implement the analyses proposed to validate their assumptions.
There are other eÔ¨Äorts in hpsg dealing with the implementation of grammars
including aspects of information structure. For instance [4] describes an hpsg
grammar implementation which takes into account the thematic role of clitic left
dislocated arguments in Spanish, assuming that part of the focus of an utterance
depends on that thematic role.
Most inspiring to our work is the approach taken in [6] who presents a detailed
analysis ‚Äì only descriptive and not computationally implemented ‚Äì based on Opti-
mality Theory grammar, accounting for the same linguistic constraints mentioned
in Section 2.2. His main focus, the same proposed here, is to present a case study
of the interaction of constituent order, prosody and focus. As we did in our study,
he is limiting his discussion mainly to the double object construction.
This paper has presented an operational solution illustrating a Ô¨Åeld topology
approach and including one aspect of information structure. The grammar can
be used to produce and parse WH-questions and corresponding answers which
not only include the most eÔ¨Écient and also context-sensitive focus-marking, but
also account for a complete phrase structure of both questions and answers.
Various design choices have been made to achieve the desired grammar. One
main aspect includes the tight integrating of focus-marking into the grammar
which highlights the non-modular approach to language that fcg is attributed
to. This way, the grammar can use information structure to determine con-
stituent order (and vice versa). Besides several other design choices, a novel
design pattern of representing the status of constraints in the top-unit of the
transient structure has been explored. It has been shown that fcg is open enough
to oÔ¨Äer an appropriate framework to deal with the mentioned issues. Future work
includes the further exploration of the monitoring of constraint status and the
integration of further aspects of information structure into the grammar, such
as for instance focus/background marking.
Acknowledgements. Research reported in this paper was funded by the Sony
Computer Science Laboratory Paris and the EU FP7 ALEAR project. I thank
Luc Steels and the whole team working on FCG at the University of Brussels
(VUB AI lab) and at Sony CSL for their contributions in making FCG such a su-
perb environment for doing sophisticated experiments in construction grammar.
Also I would like to thank Remi van Trijp for his help in bug-Ô¨Åxing the grammar
and Stefan M√ºller and Philippa Cook for helpful comments on an earlier version
of this chapter. All remaining errors are mine.
Field Topology and Information Structure 209
References
[1] Behaghel, O.: Beziehung zwischen Umfang und Reihenfolge von Satzgliedern. In-
dogermanische Forschungen 25, 110‚Äì142 (1909)
[2] Behaghel, O.: Von deutscher Wortstellung. Zeitschrift f√ºr Deutschkunde 44, 81‚Äì89
(1930)
[3] Beuls, K.: Construction sets and unmarked forms: A case study for Hungarian
verbal agreement. In: Steels, L. (ed.) Design Patterns in Fluid Construction Gram-
mar. John Benjamins, Amsterdam (2011)
[4] Bildhauer, F.: Clitic left dislocation and focus projection in Spanish. In: Pro-
ceedings of the 15th International Conference on Head-Driven Phrase Structure
Grammar, pp. 346‚Äì357. CSLI Publications (2008)
[5] Bleys, J., Stadler, K., De Beule, J.: Search in linguistic processing. In: Steels, L.
(ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Amster-
dam (2011)
[6] B√ºring, D.: Let‚Äôs phrase it!‚ÄîFocus, word order, and prosodic phrasing in German
double object constructions. In: M√ºller, G., Sternefeld, W. (eds.) Competition in
Syntax. Studies in Generative Grammar, vol. 49, pp. 101‚Äì137. de Gruyter, Berlin
(2001)
[7] Comrie, B.: Language universals and linguistic typology: Syntax and morphology.
University of Chicago Press, Chicago (1981)
[8] Cook, P.: The datives that aren‚Äôt born equal. BeneÔ¨Åciaries and the dative passive.
In: Hole, D. (ed.) Datives and Other Cases. Between Argument Structure and
Event Structure, pp. 141‚Äì184. John Benjamins, Amsterdam (2006)
[9] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[10] Drach, E.: Grundgedanken der deutschen Satzlehre. Diesterweg, FRANKFURT
(1937)
[11] Engdahl, E., Vallduv√≠, E.: Information packaging in HPSG. In: Edinburgh Working
Papers in Cognitive Science, pp. 1‚Äì32 (1996)
[12] Gerdes, K., Kahane, S.: Word order in German: a formal dependency grammar us-
ing a topological hierarchy. In: ACL 2001: Proceedings of the 39th Annual Meeting
on Association for Computational Linguistics, pp. 220‚Äì227. Association for Com-
putational Linguistics, Morristown (2001)
[13] Grice, M., Baumann, S., Benzm√ºller, R.: German intonation in autosegmental
phonology. In: Prosodic Typology (2003)
[14] Halliday, M., Hasan, R.: Notes on transitivity and theme in English. Journal of
Linguistics 3, 199‚Äì244 (1967)
[15] Hawkins, J.: A performance theory of order and constituency. Cambridge Univer-
sity Press, Cambridge (1994)
[16] Hoberg, U.: Die Wortstellung in der geschriebenen deutschen Gegenwartssprache.
Heutiges Deutsch. Linguistische Grundlagen. Forschungen des Instituts f√ºr
deutsche Sprache, vol. 10. Max Hueber Verlag, M√ºnchen (1981)
[17] H√∂hle, T.N.: Explikation f√ºr ‚ÄúNormale Wortstellung". In: Abraham, W. (ed.)
Satzglieder im Deutschen - Vorschl√§ge zur Syntaktischen, Semantischen und Prag-
matischen Fundierung. Studien zur deutschen Grammatik, pp. 75‚Äì153. Gunter
Narr Verlag, T√ºbingen (1982)
[18] H√∂hle, T.N.: Topologische Felder. ms, K√∂ln (1982)
210 V. Micelli
[19] H√∂hle, T.N.: Der BegriÔ¨Ä Mittelfeld, Anmerkungen √ºber die Theorie der topologis-
chen Felder. In: Weiss, W., Wiegand, H.E., Reis, M. (eds.) Textlinguistik Contra
Stilistik? Wortschatz und W√∂rterbuch - Grammatische Oder Pragmatische Or-
ganisation von Rede? Kontroversen, alte und neue, pp. 329‚Äì340. Max Niemeyer
Verlag, T√ºbingen (1986)
[20] Kathol, A.: Linearization-based German Syntax. Ph.D. thesis, Ohio State Univer-
sity, Berkeley (1995)
[21] Kempen, G., Harbusch, K.: A corpus study into word order variation in Ger-
man subordinate clauses: Animacy aÔ¨Äects linearization independently of gram-
matical function assignment. In: Pechman, T., Habel, C. (eds.) Multidisciplinary
Approaches to Language Production, pp. 173‚Äì181. Mouton de Gruyter, Berlin
(2004)
[22] Kurz, D.: A statistical account on word order variation in german. In: Proceedings
of the COLING Workshop on Linguistically Interpreted Corpora (2000)
[23] Lambrecht, K.: Information Structure and Sentence Form: Topic, Focus, and the
Mental Representations of Discourse Referents (Cambridge Studies in Linguistics).
Cambridge University Press (1996)
[24] Lenerz, J.: Zur Abfolge nominaler Satzglieder im Deutschen. Narr, T√ºbingen
(1977)
[25] M√ºller, S.: Deutsche Syntax deklarativ. Head-Driven Phrase Structure Grammar
f√ºr das Deutsche. Linguistische Arbeiten, vol. 394. Max Niemeyer Verlag, T√ºbin-
gen (1999)
[26] M√ºller, S.: Multiple frontings in German. In: J√§ger, G., Monachesi, P., Penn,
G., Winter, S. (eds.) Proceedings of Formal Grammar 2002, Trento, pp. 113‚Äì124
(2002), http://hpsg.fu-berlin.de/~stefan/Pub/mehr-vf.html
[27] M√ºller, S.: Zur Analyse der scheinbar mehrfachen Vorfeldbesetzung. Lin-
guistische Berichte 203, 297‚Äì330 (2005), http://hpsg.fu-berlin.de/Àústefan/
Pub/mehr-vf-lb.html
[28] M√ºller, S.: Elliptical constructions, multiple frontings, and surface-based syntax.
In: J√§ger, G., Monachesi, P., Penn, G., Winter, S. (eds.) Proceedings of Formal
Grammar 2004, Nancy. CSLI Publications, Stanford (to appear)
[29] Reis, M.: On justifying topological frames: Positional Ô¨Åeld and the order of non-
verbal constituents in German. Documentation et Recherche en Linguistique Alle-
mande Contemporaine 22/23, 59‚Äì85 (1980)
[30] Rooth, M.: A theory of focus interpretation. Ph.D. thesis, University of Mas-
sachusetts, Amherst (1985)
[31] Selkirk, E.: Sentence prosody: Intonation, stress, and phrasing. In: Goldsmith, J.
(ed.) Handbook of Phonological Theory, pp. 550‚Äì569. Blackwell (1995)
[32] Stechow, A.V., Uhmann, S.: Some remarks on focus projection. In: Topic, Focus,
and ConÔ¨Ågurationality, pp. 295‚Äì320 (1986)
[33] Steedman, M.: The Syntactic Process. MIT Press, Cambridge (2000)
[34] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[35] Steels, L.: A design pattern for phrasal constructions. In: Steels, L. (ed.) Design
Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
[36] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[37] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
Field Topology and Information Structure 211
[38] Steels, L. (ed.): Computational Issues in Fluid Construction Grammar. Springer,
Berlin (2012)
[39] Traat, M.: Information Structure in a Formal Framework. In: Gelbukh, A. (ed.)
CICLing 2009. LNCS, vol. 5449, pp. 28‚Äì40. Springer, Heidelberg (2009)
[40] Twain, M.: A Tramp Abroad. Oxford University Press Inc. (1880)
[41] Uszkoreit, H.: Word Order and Constituent Structure in German. CSLI Publica-
tions, Stanford (1987)
[42] Vallduv√≠, E.: The dynamics of information packaging. In: Engdahl, E. (ed.) Infor-
mation Structure into Constraint-Based Categorial Approaches. HCRC Publica-
tions, University of Edinburgh, Edinburgh (1994)
[43] van Trijp, R.: A design pattern for argument structure constructions. In: Steels,
L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Ams-
terdam (2011)
[44] van Trijp, R.: Feature matrices and agreement: A case study for German case. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[45] Van Valin, R.D., LaPolla, R.J.: Syntax: Structure, Meaning, and Function. Cam-
bridge University Press, Cambridge (1998)
[46] Wegener, H.: Der Dativ im heutigen Deutsch. Studien zur deutschen Grammatik,
vol. 28. Originally Gunter Narr Verlag now StauÔ¨Äenburg Verlag, T√ºbingen (1985)
[47] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar. John Benjamins, Amsterdam (2011)
A Formal Deconstruction of Fluid
Construction Grammar
Joachim De Beule
ArtiÔ¨Åcial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium
Abstract. Fluid construction grammar was primarily developed for
supporting the on-line processing and learning of grammatical language
in robotic language game setups, and with a focus on semantics and
constructrion grammar. In contrast, many related formalisms were de-
veloped to support the formulation of static, primarily syntactic theories
of natural language. As a result, many of fcg‚Äôs features are absent in
other formalisms, or take a somewhat diÔ¨Äerent form. This can be con-
fusing and give fcg a ‚Äòpeculiar‚Äô status from the perspective of those
more familiar with other formalisms. This chapter aims to clarify some
of these peculiarities by providing a formal deconstruction of fcg based
on a reconstruction of it‚Äôs history.
1 Introduction
Fcg was primarily developed for supporting the on-line processing and learning
of grammatical language in robotic language game setups.1
In contrast, many
related formalisms were developed to support the formulation of static theories
of natural language. As a result, many of fcg‚Äôs features are absent in other
formalisms, or take a somewhat diÔ¨Äerent form. This can be confusing and give
fcg a ‚Äòpeculiar‚Äô status from the perspective of those more familiar with other
formalisms. This chapter aims to clarify some of these peculiarities.
In the hope that this will help to accomplish this goal, our strategy will be
to reconstruct (most of) fcg in a bottom up fashion. We start from the fact
that the history and development of fcg are part of a longer tradition to make
use of robotic and computational setups for investigating the emergence and
evolution of language. As the complexity of these setups grew, the need arose to
handle ever more complex aspects of language. Many of fcg‚Äôs peculiarities today
represent concrete solutions to speciÔ¨Åc problems encountered in this process. The
strategy taken in this paper is therefore to give a deconstruction of fcg based
on a reconstruction of its history.
It would also be possible to achieve clariÔ¨Åcation in another way, by providing
a detailed account of the formal diÔ¨Äerences that exist between fcg and related
formalisms. Although this is not the main approach taken here, some high level
1
In a language game setup, robotic agents interact in order to establish a communi-
cation system or artificial language [17].
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 215‚Äì238, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
216 J. De Beule
diÔ¨Äerences are touched upon in the next section. This will at least provide some
dimensions along which such a comparison could take place, and helps to set the
stage for the rest of the paper.
2 General Considerations
One of the most distinguishing and, perhaps, confusing aspects of fcg is that it
lacks any notion of well formedness, at least not in the sense as is customary in
other approaches. For instance, in most uniÔ¨Åcation or constraint based formal-
izations of language, one is typically interested in the minimal consistent set of
constraints that speciÔ¨Åes, say, all of English (see e.g. [15].) In contrast, in fcg,
the validity of a constraint or construction is not measured by its consistency or
by how it restricts the set of well formed sentences. Rather, it is measured by
how it enables communication. This calls for a functional approach to language
rather than a declarative one.
The notion of ‚ÄúuniÔ¨Åcation‚Äù in fcg is also somewhat peculiar. In general, uni-
Ô¨Åcation is about Ô¨Ånding conditions under which certain things can be done, that
is, are ‚Äúvalid‚Äù or ‚Äúwell formed‚Äù. Particularly, in other approaches, the set of well
formed structured equals the the set of structures entailed by a given grammar
through the process of uniÔ¨Åcation. A particular sentence, in this view, speciÔ¨Åes
a number of speciÔ¨Åc constraints ‚Äì the particular word forms in the sentence and
their order. These carve out a subset of the set of all well formed sentences. As
mentioned, determining this subset is what processing in most uniÔ¨Åcation based
approaches is about. In fcg, uniÔ¨Åcation is used for somewhat diÔ¨Äerent purposes,
and therefore in diÔ¨Äerent ways.
According to Construction Grammar (CxG), linguistic knowledge is orga-
nized in constructions. These are entrenched routines that are generally used in
a speech community and that involve a pairing of meaning components to form
elements [6]. In fcg, constructions are more speciÔ¨Åcally routines for express-
ing a meaning and for understanding a form. Like functions, fcg constructions
transform meaning speciÔ¨Åcations to form speciÔ¨Åcations during production, and
vice versa during parsing. In this view, a particular sentence speciÔ¨Åes a number
of ‚Äòseeds‚Äô rather than constraints. Each ‚Äòseed‚Äô (e.g. a word or speciÔ¨Åc syntactic
category) triggers constructions which in turn add more ‚Äòseeds‚Äô (e.g. the meaning
or semantic category of the word). This is the reason why, in fcg, there are two
sorts of ‚ÄúuniÔ¨Åcation‚Äù: one for determining the set of ‚Äúvalid‚Äù constructions (those
that are triggered), and one that governs the actual application of activated
constructions (‚Äúmerge‚Äù).
Another important distinction in fcg is the notion of processing direction.
In the tradition of generative grammar, the two processing modes normally dis-
tinguished are parsing and generation. Parsing refers to bottom-up process by
which a particular sentence is analyzed in terms of production rules. Genera-
tion refers to the top-down process of determining all possible sentences that
can be generated with the production rules. The two processing modes in fcg,
normally called parsing and production, have nothing to do with all this. In fcg,
A Formal Deconstruction of Fluid Construction Grammar 217
parsing refers to the process of determining the meaning of a given sentence,
and production refers to the process of determining a form by which a mean-
ing can be expressed. The duality between fcg‚Äôs processing modes is thus of a
diÔ¨Äerent nature than the one typically conceived of in the generative tradition.
Some of fcg‚Äôs peculiarities, like the fact that feature structures have two poles
(a semantic and a syntactic pole), directly derive from this diÔ¨Äerence.
Finally, since fcg was developed for supporting artificial language processing,
it makes the least possible amount of claims about the structure or nature of
language.2
Almost everything in fcg was introduced because it was required for
solving a problem of language processing. For instance, certain generalizations
require that it is possible to distinguish between speciÔ¨Åc word forms and the word
classes they can belong to (e.g. their part of speech). Fcg provides ways to make
such kinds of distinctions, but it does not specify what particular distinctions
should be made. There are no type hierarchies ‚Äìat least none that can not be
easilly circumvented or changed or extended; no intrinsic restrictions on the
number or sort of features in feature structures; no restrictions on the values of
features, etc.
In the following, we trace back the origins of these and other features of fcg
by incrementally building up the machinery required to process an increasingly
complex set of language phenomena. Throughout the paper, it will be useful
to keep in mind a robotic agent that faces the task of parsing or producing
an utterance. Producing an utterance amounts to transforming a given mean-
ing specification into a form specification. Parsing amounts to transforming a
given form speciÔ¨Åcation into a meaning speciÔ¨Åcation. This bi-directional prob-
lem structure is formalized throughout the chapter with the help of production
and parsing functions, denoted as g‚Üí and g‚Üê respectively. The precise form of
these functions, as well as of the meaning and form speciÔ¨Åcations upon which
they operate, will gradually be changed and their complexity increased, mim-
icking the evolution of fcg itself. In the next section, we start by specifying the
most basic elements of meaning and form speciÔ¨Åcations, called components, in
more detail.
3 Meaning and Form Specifications
In general, with language processing we mean the transforming of meaning speci-
Ô¨Åcations into form speciÔ¨Åcations and vice versa. By deÔ¨Ånition, such speciÔ¨Åcations
are built from primitive meaning and form components respectively. As is cus-
tomary in fcg, such components will be represented as expressions in preÔ¨Åx-list
notation. Furthermore, names of frames and frame relations will be used in com-
ponents as speciÔ¨Åed in the on-line FrameNet database [2, 8]. For example, the
following meaning component speciÔ¨Åes the ‚Äò[line]‚Äô frame:
(frame x [line]).
2
Although recent advances, e.g. so calles ‚Äúdesign patterns‚Äù, can be seen as such.
218 J. De Beule
The symbol ‚Äòx‚Äô is a skolem constant: it represents a speciÔ¨Åc instance of the
[line] frame. I will sometimes further refer to skolem constants in meaning
components as meaning constants.
By deÔ¨Ånition, meaning speciÔ¨Åcations are collections of meaning components.
For example, the meaning of the phrase ‚Äúnatural line‚Äù is
{(frame x [line]), (frame y [natural]),
(fe-relation y [entity] x)}.
The second component in this set introduces ‚Äòy‚Äô as an instance of the ‚Äò[natural]‚Äô
frame. The third component speciÔ¨Åes that the ‚Äò[entity]‚Äô frame element of this
frame is the frame ‚Äòx‚Äô.
Similarly, form speciÔ¨Åcations are collections of form components. The form of
the phrase ‚Äúnatural line‚Äù for example is represented as below.
{(lexeme a "line"), (lexeme b "natural"), (meets a b)}.
The skolem constants ‚Äòa‚Äô and ‚Äòb‚Äô are form constants.
In the next section, we start investigating the processing of language in the
case of the simplest meaning and form speciÔ¨Åcations possible: those consisting
of a single meaning and form component only.
4 Holistic Language Processing
We Ô¨Årst restrict the discussion to ‚Äúholistic languages‚Äù. In a holistic language,
phrases are always ‚Äòatomic‚Äô: they are not structured or made out of smaller
components in any meaningful way. Formally, this corresponds to the case that
meaning and form speciÔ¨Åcations specify exactly a single component each. In
other words, we only consider singleton speciÔ¨Åcations in this section.
4.1 Constructions
The bi-directional processing of singleton meaning and form speciÔ¨Åcations calls
for a bi-directional lookup table. Each entry in the table associates a meaning
component with a form component, and in this sense is a construction. The
following is an example construction that associates the meaning speciÔ¨Åcation
‚Äò{(frame x [line])}‚Äô with the form speciÔ¨Åcation ‚Äò{(lexeme a "line")}‚Äô.
c_1(x, a) = {(frame x [line])} ‚Üî {(lexeme a "line")}) . (1)
This construction is not in full concordance with contemporary practices in
fcg however, and we will change its form again later. Nevertheless, the con-
vention of displaying constructions in a box will be maintained throughout the
chapter. The meaning side is separated from the form side by a double arrow.
The meaning and form sides of a construction ‚Äòc‚Äô will also be referred to as ‚Äòcm
‚Äô
and ‚Äòcf
‚Äô, respectively. For example, with c1 as above:
cm
1 (x) = {(frame x [line])} ; cf
1 (a) = {(lexeme a "line")}.
A Formal Deconstruction of Fluid Construction Grammar 219
The semantic part of a construction will generally be referred to as the construc-
tion‚Äôs semantic pole. Likewise, the syntactic part is referred to as the construc-
tion‚Äôs syntactic pole.
4.2 Variables and Bindings
When faced with the problem of expressing the meaning speciÔ¨Åcation ‚Äò{(frame x
[line])}‚Äô, an agent can retrieve the construction c1(x) from its lookup table and
notice that it speciÔ¨Åes the exact same meaning speciÔ¨Åcation in its semantic pole.
It can therefore conclude that this meaning is expressed by the construction‚Äôs
syntactic pole.
But when given instead, say, the speciÔ¨Åcation ‚Äò{(frame y [line])}‚Äô, a prob-
lem arises. The problem is that the construction speciÔ¨Åes the skolem constant ‚Äòx‚Äô,
whereas the new speciÔ¨Åcation speciÔ¨Åes the constant ‚Äòy‚Äô. In consequence, there
will be no match during lookup. A proper construction, therefore, should specify
a variable instead of a constant, so that it matches all instances of the ‚Äò[line]‚Äô
frame.
By convention, variables will be marked by a leading question mark, as in
‚Äò?x‚Äô. Variables are implicitly and universally quantiÔ¨Åed over, so the introduction
of variables is like the inverse of skolemization. A variable can take any (but only
one) value. A speciÔ¨Åc assignment [?x/x] of a variable ?x to a value x is called
a binding or a basic substitution. A set of bindings B of variables ?x1, ?x2, ... to
values x1, x2, ... is represented as B = [?x1/x1, ?x2/x2/, ...]. Every set of bindings
B induces a substitution function œÉB(e), which replaces all variables that occur
in an expression e by their value according to the bindings in B.
Replacing the skolem constants ‚Äòx‚Äô and ‚Äòa‚Äô in construction c1 by variables and
using the abbreviations
m1(?x) = (frame ?x [line]) and f1(?a) = (lexeme ?a "line"),
thus gives the following more general deÔ¨Ånition of construction c1:
c1(?x, ?a) = {m1(?x)} ‚Üî {f1(?a)} (2)
This construction associates any [line] frame with any ‚Äúline‚Äù lexeme.
4.3 Component Matching
We now put everything together. Suppose that C is a constructicon ‚Äìa collection
of constructions, that is, a bi-directional lookup table between singleton meaning
speciÔ¨Åcations and singleton form speciÔ¨Åcations‚Äì and suppose that some speci-
Ô¨Åcation {m(x)} needs to be expressed. For that, the agent goes through the
constructions in C and compares their semantic poles to the given speciÔ¨Åcation.
The meaning and form components in constructions now contain variables. The
operation with which components containing variables can be compared is called
component matching. We denote it by U0. This function takes a pattern compo-
nent p and a source component s and computes all sets of minimal substitutions
220 J. De Beule
œÉB that make the pattern identical to the source, that is, for which œÉB(p) = s.3
An example of component matching is given below.
U0(m1(?x), m1(x)) = {[?x/x]}.
We are now ready to give a Ô¨Årst deÔ¨Ånition for the production and parsing func-
tions. The production function g‚Üí for now operates on a singleton meaning
speciÔ¨Åcation {m(x)} and computes the set of form speciÔ¨Åcations that express it
according to the constructicon C:
g‚Üí(m(x), C) = {cf
: c ‚àà C, U0(cm
(?x), m(x)) = ‚àÖ}.
Thus, this set contains the syntactic poles of all constructions of which the
semantic side matches the given meaning component m(x). For example, with
c1 as deÔ¨Åned earlier:
g‚Üí({(frame y [line])}, {c1}) = {{(lexeme ?a "line")}} .
The parsing function g‚Üê is deÔ¨Åned in a similar way. It takes a singleton form
speciÔ¨Åcation and computes a set of singleton form speciÔ¨Åcations:
g‚Üê({f(a)}, C) =

cm
: c ‚àà C, U0(cf
(?a), f(b)) = ‚àÖ

.
For example:
g‚Üê({(lexeme b "line")}, {c1}) = {{(frame ?x [line])}}.
It is possible that several constructions are available in a given constructicon that
all express the same meaning (synonyms) or cover the same form (homonyms).
In this case, the agent will have to select one among them. This could be done
for instance on the basis of preference scores. We return to this issue in section 7.
This concludes our discussion of the processing of holistic language. In sum-
mary, it requires a bi-directional lookup table of constructions ‚Äì associations
between singleton meaning and form speciÔ¨Åcations containing variables ‚Äì, and
a component matching function for determining which constructions express
a given singleton meaning speciÔ¨Åcation or parse a given singleton form
speciÔ¨Åcation.
5 Compositionality
We now relax the assumptions that meaning and form speciÔ¨Åcation may only
contain a single component. This opens up the way to compositional language,
in which phrases are structured and consist of several parts.
3
A minimal substitution is one that does not specify bindings for variables that do
not occur in the pattern or source. Component matching corresponds to the notion
of standard uniÔ¨Åcation in ArtiÔ¨Åcial Intelligence and logic (See e.g. [13].)
A Formal Deconstruction of Fluid Construction Grammar 221
5.1 Set Matching
Suppose again that C is a constructicon (a collection of constructions). As be-
fore, it is assumed that meaning and form constants are replaced with variables
in constructions. Suppose further that the meaning speciÔ¨Åcation that needs to
be expressed is denoted by Œº. As before, Œº will have to be compared to the se-
mantic poles of constructions in C. This time, however, it is possible that some
construction only expresses part of Œº. This is the case for those constructions of
which the meaning pole is a subset of Œº. The operation that checks whether one
set of components is a subset of another is called set matching. It is denoted as
U1. This function takes a pattern set p and a source set s and computes the set
of minimal substitutions œÉB that make the pattern set a subset of the source,
that is, for which œÉB(p) ‚äÇ s. More formally, if Œº and Œº
are two meaning or form
speciÔ¨Åcations, then:
U1(Œº, Œº
) = {B : œÉB(Œº) ‚äÇ Œº
} (3)
New versions of the production and parsing functions that use this enhanced
matching power can now be deÔ¨Åned as follows:
g‚Üí(Œº, C) = {cf
: c ‚àà C, U1(cm
, Œº) = ‚àÖ},
g‚Üê(œÜ, C) =

cm
: c ‚àà C, U1(cf
, œÜ) = ‚àÖ

.
These functions now operate on arbitrary meaning and form speciÔ¨Åcations in-
stead of just singletons. For example, if Œº1(x) = {m1(x)} and œÜ1(a) = {f1(a)},
then:
U1({m1(?x)}, Œº1(x)) = {[?x/x]} ; U1({f1(?a)}, œÜ1(a)) = {[?a/a]}
and, with C = {c1(?x, ?a)} (see equation 2),
g‚Üí(Œº1(x), C) = {œÜ(?a)} ; g‚Üê(œÜ1(a), C) = {Œº1(?x)}
Now consider the following meaning speciÔ¨Åcation:
Œº(x, y) = {m1(x), m2(y)} = {(frame x [line]), (frame y [natural])}.
It must be transformed into the following form speciÔ¨Åcation:
œÜ(?a, ?b) = {f1(?a), f2(?b)}={(lexeme ?a "line") (lexeme ?b "natural").
This is achieved with the following construction h.
h = {m1(?x), m2(?y)} ‚Üî {f1(?a), f2(?b)}
Indeed, the semantic side of h matches Œº:
U1(hm
(?x, ?y), Œº(x, y)) = {[?x/x, ?y/y]}.
222 J. De Beule
From this, and from the deÔ¨Ånition of g‚Üí, it follows that
g‚Üí(Œº, {h}) = {œÜ(?a, ?b))}
In a sense this is a ‚Äúholistic‚Äù production because the construction h maps both
meaning components to two form components in one go. In contrast, a composi-
tional encoding should involve two constructions: one for the ‚Äòline‚Äô part and one
for the ‚Äònatural‚Äô part. Let us call these constructions c1 and c2. Then c1 is as in
equation (2) and c2 is as below.
c2(?y, ?b) = {m2(?y)} ‚Üî {f2(?b)}
= {(frame ?y [natural])} ‚Üî {(lexeme ?b "natural")} . (4)
The semantic sides of both constructions match the given speciÔ¨Åcation Œº(x, y),
so that the ‚Äúlookup‚Äù part of processing succeeds for both of them:
U1(cm
1 (?x, ?a), Œº(x, y)) = {[?x/x]} ; U1(cm
2 (?y, ?b), Œº(x, y)) = {[?y/y]}.
However, the production function g‚Üí as deÔ¨Åned above produces two incomplete
productions instead of a single compositional production.
g‚Üí(Œº, C) =

{cf
1 }, {cf
2 }

.
Compositional language processing is thus more demanding than holistic lan-
guage processing, beyond the fact that it requires a more general mode of uniÔ¨Åca-
tion (set matching). It also requires a transient linguistic structure for collecting
intermediate results (partial meaning and form speciÔ¨Åcations).
5.2 The Transient Linguistic Structure and Merge
We introduce the transient linguistic structure for keeping track of intermediate
processing results. Since this is needed in the case of compositional encoding
regardless of the direction of processing (parsing or production), and since this
will turn out to be useful in the following, we deÔ¨Åne the transient linguistic
structure to be an association between a meaning and a form speciÔ¨Åcation. As
in the case of constructions, the semantic and syntactic poles of a transient
structure s are denoted as sm
and sf
respectively.
The initial meaning and form speciÔ¨Åcations from which processing starts and
that are given as input to the production and parsing functions can also con-
veniently be speciÔ¨Åed as transient linguistic structures by simply leaving the
appropriate pole empty, that is, the syntactic pole in case of production and the
semantic polle in case of parsing. Thus, the meaning speciÔ¨Åcation Œº which is
given before production starts, corresponds to the transient structure sŒº below.
sŒº = Œº ‚Üî ‚àÖ .
A Formal Deconstruction of Fluid Construction Grammar 223
Now the semantic poles of the constructions c1 and c2 match the semantic pole
of the transient structure sŒº:
U1(cm
1 , sm
Œº ) = U1(cm
1 (?x), Œº(x, y)) = {[?x/x]}
and
U1(cm
2 , sm
Œº ) = U1(cm
2 (?y), Œº(x, y)) = {[?y/y]}.
As before, this indicates that both constructions can be considered for further
processing by the production function. The idea is that each of the constructions
adds its own parts to the transient structure. This is done through merging.
In this section, we do not consider any other relationships between meaning or
form components besides the fact that they appear together in meaning and form
speciÔ¨Åcations. In this case, all that needs to happen during merging is that the
missing constructional form components are added to the transient structure. In
other words, for now we can deÔ¨Åne the merge operation to be the set theoretic
union operation. More formally, we introduce the merge function U2(œÜ, œÜ
) for
merging two component sets œÜ and œÜ
into a single component set as:
U2(œÜ, œÜ
) = œÜ ‚à™ œÜ
.
Clearly, the merge function applies both to meaning and form speciÔ¨Åcations,
since these are all sets.
The notion of merge in fcg should not be confused with Chomsky‚Äôs merge
introduced in [4]. Rather, merging corresponds to uniÔ¨Åcation in traditional uni-
Ô¨Åcation and constraint based formalisms: both result in extra ‚Äòconstraints‚Äô in
the transient linguistic structure. As mentioned in the introduction, in fcg such
‚Äòconstraints‚Äô can also be considered ‚Äòseed material‚Äô. This will become relevant
when even more complex meaning and form speciÔ¨Åcations are considered below.
We are now in a position to redeÔ¨Åne the production and parsing functions
again such that they operate on transient linguistic structures and make use of
the merge function U2. Since these functions now should embody an iterative
process of applying all applicable constructions one after the other, this is most
easily done through induction. Thus, in case that the constructicon only speciÔ¨Åes
a single construction c, and with s a transient linguistic structure, we have that:
g‚Üí(s, {c}) =

{ sm
‚Üî U2(sf
, sf
) } if U1(cm
, sm
) = ‚àÖ
{s} otherwise.
(5)
In words, this says that the production function, when given a transient linguistic
structure s and a singleton constructicon {c} such that the semantic poles sm
and cm
match (according to U1), produces a transient linguistic structure with
a modiÔ¨Åed syntactic pole that is equal to the union of the syntactic poles of the
given transient structure and the construction. This deÔ¨Ånition is easily extended
to larger collections of construction through the following induction step on
larger constructicons:
g‚Üí(s, {c} ‚à™ C) = {g‚Üí(s
, C) : s
‚àà g‚Üí(s, {c})} .
224 J. De Beule
Note that this deÔ¨Ånition assumes that the order in which constructions are con-
sidered does not matter. If it did, then the constructions would not be indepen-
dent and a search would be required over possible orderings. This possibility is
further discussed in section 7.
Note also that, whereas the processing functions are deÔ¨Åned by induction,
this does not mean that they are also recursive functions. In recent years, there
has been quite a debate over whether or not humans are the only species that
possess the capacity for recursion, so this issue is a matter of some importance
[7, 9, 11, 12]. However, there is an important diÔ¨Äerence between genuinely re-
cursive functions and merely tail recursive representations of iterative functions
[1]. Only genuinely recursive functions also require a recursive implementation
for computation. Compositional language processing as deÔ¨Åned in this section
does not.
In any case, we now have that:
g‚Üí(sŒº, {c1}) =

Œº ‚Üî {f1(?a)}

,
g‚Üí(sŒº, {c2}) =

Œº ‚Üî {f2(?b)}

.
And:
g‚Üí(sŒº, {c1, c2}) =

Œº ‚Üî œÜ(?a, ?b)

.
This accomplishes a compositional encoding of Œº into œÜ. The parsing function is
deÔ¨Åned in a similar fashion.
This concludes our discussion of bi-directional processing in the case that
meaning and form speciÔ¨Åcations are sets of ‚Äòindependent‚Äô meaning or form com-
ponents. The fact that the components are ‚Äòindependent‚Äô means for instance
that they are not allowed to share any of their skolem constants. In summary,
in this case a set uniÔ¨Åcation function U1 is required for matching sets of compo-
nents and for testing which constructions apply. This corresponds to the ‚Äòlookup‚Äô
step in processing. Furthermore, actually applying matching constructions in a
compositional fashion amounts to adding their constructional components to a
transient linguistic structure through a merge operation. The transient linguistic
structure functions to keep ‚Äòintermediate results‚Äô (partial productions or parses)
during processing.
6 Constituent Structure and Hierarchy
So far, we have been considering the English example phrase ‚Äúnatural line‚Äù with-
out bothering about the fact that the two lexemes in it are ordered. Indeed,
consider again the form speciÔ¨Åcation œÜ(?a, ?b) from the previous section, which
is the result of applying the production function to the meaning Œº(x, y):
œÜ(?a, ?b)={f1(?a), f2(?b)}={(lexeme ?a "line"), (lexeme ?b "natural")}
A Formal Deconstruction of Fluid Construction Grammar 225
Something is missing in this speciÔ¨Åcation. In fact, it fails to specify the order of
lexemes, so that both ‚Äúnatural line‚Äù and ‚Äúline natural‚Äù are consistent with it. As
mentioned already in section 3, a more correct speciÔ¨Åcation should specify this
order, like œà below.
œà = {f1(?a), f2(?b), f3(?b, ?a)}
= {(lexeme ?a "line"), (lexeme ?b "natural), (meets ?b ?a)}.
Here, the component f3(?b, ?a) or ‚Äò(meets ?b ?a)‚Äô represents a further con-
straint on the variables ?a and ?b besides the fact that they stand for the lex-
emes ‚Äòline‚Äô and ‚Äònatural‚Äô. This component speciÔ¨Åes that these lexemes should
be rendered in a particular order. Only the phrase ‚Äúnatural line‚Äù is consistent
with this speciÔ¨Åcation, whereas the alternative ‚Äúline natural‚Äù is ruled out.
Similarly, nothing in the meaning speciÔ¨Åcation Œº(x, y) = {m1(x), m2(y)} spec-
iÔ¨Åes that it is actually the line (represented by x) that has the property of being
natural or, in FrameNet terminology, that fulÔ¨Ålls the ‚Äò[entity]‚Äô Frame Element
relation of the ‚Äò[natural]‚Äô frame. The phrase ‚Äúnatural line‚Äù therefore expresses
not Œº(x, y), but the more elaborate meaning speciÔ¨Åcation Œ∑ below.
Œ∑ = {m1(x), m2(y), m3(x, y)}
= {(frame x [line]), (frame y [natural]), (6)
(fe-relation y x [entity])}.
As on the form side in œà, components are no longer independent in Œ∑: some of
the skolem constants are shared between them. In the remainder of this section
we investigate what modiÔ¨Åcations need to be made to the machinery developed
so far so that it becomes possible to deal with such dependencies.
We start by recalling that, in English, the order of words in the example phrase
‚Äúnatural line‚Äù is licensed by a modiÔ¨Åer-head construction for combining adjec-
tives with nouns. On the meaning side, this construction links the corresponding
meaning components by specifying an [entity] frame element relation. How
could such a construction be deÔ¨Åned with the representational tools developed
so far? The answer, unfortunately, is that it can not.
To see this, consider that it should apply to the transient structure obtained
from applying the lexical constructions c1 and c2 to the extended meaning spec-
iÔ¨Åcation Œ∑. Since
U1(cm
1 (?x, ?a), Œ∑(x, y)) = {[?x/x]} and U1(cm
2 (?y, ?b), Œ∑(x, y)) = {[?y/y]},
this transient structure looks as follows:
g‚Üí(Œ∑, {c1, c2}) =
‚éß
‚é™
‚é®
‚é™
‚é©
{m1(x), m2(y), m3(x, y)}
‚Üî
{f1(?a), f2(?b)}
‚é´
‚é™
‚é¨
‚é™
‚é≠
.
The correspondence that exists between the meaning component ‚Äòm1‚Äô and the
form component ‚Äòf1‚Äô (as it is captured in construction c1) is not reÔ¨Çected in the
226 J. De Beule
above transient linguistic structure. Similarly, nothing in the structure shown
above indicates that there is a connection between the meaning component m2
and the form component f2. However, the modiÔ¨Åer head construction needs
access to this information.
Once again we will extend our representational toolkit. PArticularly, we will
make the poles of constructions and of the transient linguistic structure to be
feature structures instead of plain sets. In other words, constructions (and the
transient structure) now become coupled feature structures (or cfs‚Äôs in short).
6.1 Coupled Feature Structures
In general, a feature structure is a set of named units. Each unit represents a
lexical or phrasal constituent. In order to Ô¨Ånd the form components that are
associated with the meaning components in a unit, it suÔ¨Éces to look in the cor-
responding unit (the unit with the same name) on the syntactic side. Units are
further organized into features. The meaning feature holds the unit‚Äôs meaning
speciÔ¨Åcation. The form feature holds its form speciÔ¨Åcation. Furthermore, like
constituents, one unit may be part of another one. This is encoded in the sub-
units feature. Meaning and form constants are kept in the referent feature.
This can be summarized as follows using bnf notation:
cfs ::= sem-unit-structure <--> syn-unit-structure
unit-structure ::= {regular-unit*}
regular-unit ::= <unit-name,{regular-feature*}>
regular-feature ::= <feature-name,feature-value>
feature-value ::= feature-value-element
| {feature-value-element*}.
The asterisk represents the Kleene star operation, specifying that one or more
elements of the type marked with it are possible. So ‚Äòregular-unit*‚Äô stands for
zero or more regular units. The notation .	 denotes an ordered list of elements,
i.e. a sequence. Sets, which are unordered lists of elements, are denoted with
curly brackets as usual.
Here is an example. The cfs that holds the meaning speciÔ¨Åcation Œ∑ and nothing
else appears as follows:
sŒ∑ = {u0, meaning, Œ∑		} ‚Üî {} (7)
This cfs has one unit named u0 (not to be confused with the component uni-
Ô¨Åcation function U0). In turn, this unit has the speciÔ¨Åcation Œ∑ as value for its
meaning feature.
By using feature structures instead of plain sets for representing the poles
of constructions and of the transient structure, it becomes possible to capture
hierarchical constituent structure relations in them. For instance, as will be ex-
plained shortly, the transient linguistic structure after applying the constructions
c1 and c2 to the coupled feature structure sŒ∑ above will look as below:
A Formal Deconstruction of Fluid Construction Grammar 227
s12 = g‚Üí(sŒ∑, {c1, c2})
=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1, u2}	 ,
meaning, {m3(x, y)}	 ,
u1, meaning, {m1(x)}	 ,
referent, x		 ,
u2, meaning, {m2(y)}	 ,
referent, y		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
‚Üî
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1, u2}	 ,
form, {f3(?b, ?a)}	 ,
u1, form, {f1(?a)}	 ,
referent, ?a		 ,
u2, form, {f2(?b)}	 ,
referent, ?b		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
(8)
Among other things, this cfs captures precisely the fact that the components m1
and f1 ‚Äòbelong together‚Äô since they are part of the same unit u1 (although they
are in diÔ¨Äerent poles). Importantly, the constituent structure in this cfs is a result
of applying the constructions c1 and c2 to the initial linguistic structure sŒ∑ (which
itself only has a Ô¨Çat constituent structure). So it is indeed the construction c1
that deÔ¨Ånes the meaning-form pair m1(?x) ‚Üî f1(?a) as a constituent, but now
this is also reÔ¨Çected in the transient linguistic structure.
In fcg, the correspondence between constructions and constituents is not
merely one-to-one. In particular, fcg expects that constructions explicitly specify
the way in which they change the constituent structure of the transient linguistic
structure (i.e. add new units and/or move components around etc.) Thus, the
modiÔ¨Åer head construction we aim to deÔ¨Åne will have to specify that a new unit
can be created that groups an existing adjective unit with an existing noun unit
in a speciÔ¨Åc order. In the next section, it is explained how such manipulations
of the transient structure can be speciÔ¨Åed in constructions through the usage of
tags and ‚ÄòJ-units‚Äô.
6.2 Tags and J-Units
Following the developments in the previous section, we now deÔ¨Åne constructions
as an extension over coupled feature structures as follows:
cxn ::= sem-pole <--> syn-pole
pole ::= {unit*}
unit ::= regular-unit | J-unit |
<unit-name, {[regular-feature | tag]*}>
tag ::= (TAG [tag-variable regular-feature]*)
J-unit ::= <(J . ?focus ?parent {?child*}),
{[tag-variable | regular-feature]*}>
All coupled feature structures are thus constructions, but not the other way
around: constructions, in addition, may contain tags and J-units. J-units are
easily recognized by the fact that they do not have a proper name. Instead
their name is a list of the form ‚Äò(J . ?focus-unit ?parent-unit child*)‚Äô. The Ô¨Årst
element in this list is called the ‚ÄòJ-operator‚Äô. The dot after the J-operator in
the deÔ¨Ånitions above indicates that the arguments that follow the operator are
optional.
228 J. De Beule
J-units are ignored during the matching or ‚Äòlookup‚Äô process. The workings
of the J-operator during merging is most easily explained with an example.
Consider therefore again the lexical construction c1 that couples the meaning
component m1 to the form component f1. In our new notation it looks as follows:
c1 =

?u, (tag ?m meaning, {m1(?x)}	)	
(J ?new ?u), {?m, referent, ?x	}	

‚Üî

?u, (tag ?f form, {f1(?a)}	)	
(J ?new ?u), {?m, referent, ?a	}	
 (9)
This construction speciÔ¨Åes one J-unit in both poles. The focus of the J-units
is the variable ‚Äò?new‚Äô. Their parent is the variable ‚Äò?u‚Äô, which also is the name
of a regular unit in the construction. The fact that the focus variable does not
refer to a regular unit indicates that a new subunit is introduced by this con-
struction in the transient linguistic structure during merge. This unit will be
made a subunit of the parent unit. On the semantic side, the new unit will have
a referent feature with value (the binding value of) ?x. It will also have a
meaning feature with value {m1(?x)}, as speciÔ¨Åed by the tag variable ?m. On
the syntactic side, it will have a referent feature with value ?a and a form
feature with value {f1(?a). The latter is speciÔ¨Åed by the tag variable ?f. By
deÔ¨Ånition, when meaning and form components are tagged and speciÔ¨Åed in J-
units as described, they will be removed from the unit in which they originally
occurred. This explains why, in structure (8) above, which is the result of ap-
plying constructions c1 and c2 to the initial structure (7), the meaning and form
components covered by these two constructions only occur in the newly created
units u1 and u2. The process is explained in more detail in the following.
6.3 Unit Structure Matching and Merging
We now specify the process explained in the previous section in more detail. We
Ô¨Årst consider the matching or comparing of unit structures for lookup.
Recall the deÔ¨Ånition of coupled feature structures in bnf notation. In partic-
ular, notice that a unit structure is a set of units. It follows that unit structures
can be matched with the set matching function U1, provided that the matching
of the set elements, which are units now, is properly deÔ¨Åned. Two units match
when their names match and when their sets of features match. The latter is a
case of set matching again, and calls for a proper deÔ¨Ånition of feature matching.
It is clear that, continuing in this way and following the bnf deÔ¨Ånition of coupled
feature structure, matching of unit structures can fully be deÔ¨Åned in terms of
symbol matching (for the names of units and regular features) and the set and
component matching functions U1 and U0.
A Formal Deconstruction of Fluid Construction Grammar 229
It remains to specify how J-units and tags aÔ¨Äect the matching process. As
mentioned, J-units are simply ignored during matching. Their purpose is to spec-
ify how a construction modiÔ¨Åes constituent structure, given that the (appropriate
pole of) the construction matches with the (appropriate pole of) the transient
linguistic structure.
We now turn to tags. On the one hand, the purpose of tags is to mark parts of
the transient structure for later reference. Thus, when the semantic pole of con-
struction c1 is matched against the initial unit structure sŒ∑, the tag variable ?m
receives the binding meaning, {m1(x)}	. On the other hand, their purpose is to
allow to move components between units during merge. So we turn to the merg-
ing of unit structure. Ignoring the details having to do with the bookkeeping of
names of units and features etc., merging regular parts of unit structures boils
down to taking their union. J-units additionally change constituent structure and
extract tagged components. For simplicity, we continue to use the symbol ‚ÄòU2‚Äô for
the extended merge operation that accomplishes all this. Below is given the result
of merging the semantic pole of construction c1 with the initial structure sm
Œ∑ :
U2

cm
1 , sm
Œ∑

=

u0, meaning, {m2(y), m3(x, y)}		
u1, meaning, {m1(x)}	}	

(10)
The resulting structure has two units instead of just one (with the new unit
arbitrarily named u1). As explained, this is due to the J-operator in cm
1 . The
tagged part of meaning m1(x) was extracted from the original unit and moved
to the new unit.
We can now deÔ¨Åne new production and parsing functions that work with
coupled feature structures. The main diÔ¨Äerence with the previous versions is that
now merging should occur for both poles, regardless of the processing mode. The
reason for this is that both constructional poles may contain J-units, implying
that both sides of the transient linguistic structure may change. Thus we have:
g‚Üí(t, {c}) =

U2(tm
, cm
) ‚Üî U2(tf
, cf
) if U1(cm
, tm
) = ‚àÖ
t otherwise.
and
g‚Üí(t, C ‚à™ {c}) = g‚Üí(g‚Üí(t, {c}), C).
A new parse function is readily deÔ¨Åned in a similar way. Note that, as before,
these deÔ¨Ånitions assume that the order in which constructions are applied is
arbitrary. This is not a valid assumption in general, and the consequences of
relaxing this assumption are investigated in section 7. Note also that, since it
is now possible that constructions specify changes to the transient linguistic
structure on the side that was previously only matched, we have entered the
domain of context sensitive language processing.
6.4 Grammatical Constructions
We now Ô¨Ånish the discussion on constituent structure and hierarchy by working
towards a modiÔ¨Åer-head construction for processing the phrase ‚Äúnatural line‚Äù.
Consider again construction c1:
230 J. De Beule
c1 =

?u, (tag ?m meaning, {m1(?x)}	)	
(J ?new ?u), {?m, referent, ?x	}	

‚Üî

?u, (tag ?f form, {f1(?a)}	)	
(J ?new ?u), {?m, referent, ?a	}	
 (11)
Its semantic side matches that of the initial cfs sŒ∑ repeated below.
sŒ∑ = {u0, meaning, {m1(x), m2(y), m3(x, y)}		} ‚Üî {} (12)
Indeed:
U1(cm
1 , sm
Œ∑ ) = [?u/u0, ?x/x, ?m/ meaning, {m1(x)}	]. (13)
The focus variable ‚Äò?new‚Äô of the J-unit in the construction c1 does not receive a
binding according to the above expression. As explained, merging this construc-
tion into the structure sŒ∑ therefore results in an additional unit u1:
s1 = g‚Üí(sŒ∑, {c1}) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™
‚é©
u0, subunits, {u1}	 ,
meaning, {m2(y), m3(x, y)}	 ,
u1, meaning, {m1(x)}	 ,
referent, x		
‚é´
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é≠
‚Üî
‚éß
‚é®
‚é©
u0, subunits, {u1}		 ,
u1, form, {f1(?a)}	 ,
referent, ?a		
‚é´
‚é¨
‚é≠
(14)
The additional unit contains the tagged part of meaning that was previously in
the top unit u0. Now consider c2 below.
c2 =

?u, (tag ?m meaning, {m2(?y)}	)	
(J ?new ?u), {?m, referent, ?y	}	

‚Üî

?u, (tag ?f form, {f2(?b)}	)	
(J ?new ?u), {?m, referent, ?b	}	
 (15)
We have that
U1(cm
2 , s1) = {[?u/u0, ?y/y, ?m/ meaning, {m2(y)}	]},
and
U2(cm
2 , sm
1 ) = sm
12 , U2(cf
2 , sf
1 ) = sf
12,
A Formal Deconstruction of Fluid Construction Grammar 231
with s12 as before:
s12 = g‚Üí(sŒ∑, {c1, c2})
=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1, u2}	 ,
meaning, {m3(x, y)}	 ,
u1, meaning, {m1(x)}	 ,
referent, x		 ,
u2, meaning, {m2(y)}	 ,
referent, y		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
‚Üî
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1, u2}	 ,
form, {f3(?b, ?a)}	 ,
u1, form, {f1(?a)}	 ,
referent, ?a		 ,
u2, form, {f2(?b)}	 ,
referent, ?b		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
(16)
This cfs explicitly couples the meanings m1(x) and m2(y) to the forms f1(?a) and
f2(?b) respectively, and this way provides the necessary information required to
express the remaining component m3(x, y). We are Ô¨Ånally in a position to specify
the modiÔ¨Åer head construction c3 that expresses this component:
c3 =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
?u0, subunits, {?u1, ?u2}	 ,
(tag ?m meaning, {m3(?x, ?y)}	),
?u1, referent, ?x		 ,
?u2, referent, ?y		 ,
(J ?u2 ?u1), ‚àÖ	 ,
(J ?u1), {?m}	
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
‚Üî
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
?u0, subunits, {?u1, ?u2}	 ,
(tag ?f form, {f3(?b, ?a)}	),
?u1, referent, ?a		 ,
?u2, referent, ?b		 ,
(J ?u2 ?u1), ‚àÖ	 ,
(J ?u1), {?f}	
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
This construction further transforms structure s12 to structure s123:
s123 = g‚Üí(sŒ∑, {c1, c2, c3})
=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1}		
u1, subunits, {u2}	
meaning, {m1(?x), m3(?x, ?y)}	
referent, ?x		
u2, meaning, {m2(?y)}	
referent, ?y		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
‚Üî
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
u0, subunits, {u1}		
u1, subunits, {u2}	
form, {f1(?a), f3(?b, ?a)}	
referent, ?a		
u2, form, {f2(?b)}	
referent, ?b		
‚é´
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é¨
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é≠
(17)
232 J. De Beule
The construction c3 enforces a head-complement relation between its head and
complement units ?u1 and ?u2 respectively. This is accomplished by the Ô¨Årst
J-units on both sides, which make unit ?u2 a subunit of ?u1. The second J-units
moves the covered meaning and form components m3 and f3 to the head unit.
Thus, together, constructions c1, c2 and c3 successfully parse and produce the
form speciÔ¨Åcation œà into the meaning speciÔ¨Åcation Œ∑. In other words, we have
Ô¨Ånally accomplished the parsing and production of the English phrase ‚Äúnatural
line‚Äù.
Note that the usefulness of the referent feature now becomes apparent as
well: without it, it would not have been possible to formulate a modiÔ¨Åer-head
construction c3, unless through a reference to the particular meaning components
that are being combined. In our case these are m1 and m2, but a diÔ¨Äerent
modiÔ¨Åer-head construction would be needed for a diÔ¨Äerent pair of components.
This would undermine the whole purpose of the modiÔ¨Åer-head construction,
which is to separate the expression of a linking relation between components
from the expression of the components themselves.
This almost concludes our discussion of constituent structure and hierarchy.
For completeness, we mention that the processing of natural language in general
requires many more reÔ¨Ånements to the machinery introduced so far. Consider for
instance that our modiÔ¨Åer-head construction c3 for pairing an adjective an a noun
actually does not refer to the notions of ‚Äúadjective‚Äù or ‚Äúnoun‚Äù. In French, and
in many other languages, there are even diÔ¨Äerent types of adjectives and nouns.
For instance, in the phrase ‚Äúle grand ballon rouge‚Äù, both ‚Äúgrand‚Äù and ‚Äúrouge‚Äù are
adjectives (‚Äúbig‚Äù and ‚Äúred‚Äù in English respectively), but they combine diÔ¨Äerently
with the noun ‚Äúballon‚Äù. These distinctions are clearly important for language
and language processing, and it should be possible to deal with them in fcg.
Luckily, the bulk of the machinery required for this is already in place, and no
further extensions need to be introduced besides new types of unit features and
new types of operators.
In fcg, semantic and syntactic types and categories are usually speciÔ¨Åed in
the sem-cat and syn-cat features. Next to the meaning, form and referent
features, these are the most commonly used features in fcg, although the set of
possible features is open ended. Testing for the semantic or syntactic category
of a constituent is easily performed during matching by including the type de-
scription in the corresponding regular unit in a construction. Most grammatical
languages also involve more reÔ¨Åned sorts of restrictions on semantic and syntac-
tic categories. Consider for example the sentence (a) below, which is an instance
of the Caused Motion construction.
(a) ‚ÄúJoe broke the vase onto the Ô¨Çoor.‚Äù
Golberg notes that the Caused Motion construction only applies if the cause is
not an instrument [10], rendering sentence (b) below ungrammatical.
(b) *‚ÄúThe hammer broke the vase onto the Ô¨Çoor‚Äù
As is discussed at length elsewhere, such and other types of restrictions can be
speciÔ¨Åed with special operators.
A Formal Deconstruction of Fluid Construction Grammar 233
7 Constructional Dependencies and Search
So far we have ignored any intricacies that might arise from dependencies be-
tween constructions. Such dependencies may interfere with processing. To see
this, consider once more the example phrase ‚Äúnatural line‚Äù. It does not matter
in what order the lexical constructions c1 and c2 for ‚Äúnatural‚Äù and ‚Äúline‚Äù are
applied, the resulting structure will be the same. But the modiÔ¨Åer-head con-
struction only applies after them. In other words, there is a dependency between
these constructions. It is also possible that two constructions are conflicting, for
instance synonyms which both cover the same (set of) form components. In this
case there will be several possible parses or productions. Finally if, as in the
context of language game experiments, constructions are marked with conven-
tionality or preference scores, then some analysis will be more preferable than
others. All of these things imply that processing involves search.
7.1 General Aspects of Processing as Search
In general, search involves the exploration of a search space of possible analysis
(parses or productions) with the goal to Ô¨Ånd a suitable one. The search space
is not directly accessible however: it needs to be constructed through the actual
application of constructions, starting from the initial linguistic structure. All
constructions that apply to the initial structure give rise to a new (partial)
analysis or state in the search space. At each moment during processing, it
therefore needs to be decided which analysis to consider further and, if it triggers
several constructions, which construction to actually apply to it. This process
of repeatedly selecting a previously obtained transient linguistic structure and
selecting and applying a construction to it in order to get a modiÔ¨Åed transient
structure is what search is all about. DiÔ¨Äerent search strategies, like breadth
Ô¨Årst or depth Ô¨Årst, merely correspond to diÔ¨Äerent selection strategies, that is, to
diÔ¨Äerent strategies for exploring the search space.
In fcg, we are not primarily interested in all possible analysis (i.e. the set
of all well formed feature structures compatible with the input initial struc-
ture). Rather, processing is goal-driven, and the primary aim is to Ô¨Ånd a suitable
analysis as fast as possible. What is a suitable analysis depends on the task at
hand. During production, one will typically want that all meaning components
are expressed, or that the produced phrase is unambiguous. If there are several
alternatives, e.g. synonyms, then the most conventional one is preferred etc. Dur-
ing parsing, all form components should be processed, and the parsed meaning
speciÔ¨Åcation should ‚Äòmake sense‚Äô, e.g. unambiguously determine a referent in the
discourse context.
It is often the case that several analysis (parses or productions) are possi-
ble that all meet these primary criteria. For instance, an idiom might express
a meaning more concisely than a regular analysis. This situation is somewhat
similar to the one that arises when both a holistic and a compositional analysis
are possible (see sections 4 and 5). Selecting among such alternative analysis
requires additional criteria. In human language, such criteria are often related
234 J. De Beule
to frequency and alignment eÔ¨Äects: words and constructions that are more com-
mon or were used in the nearby past are typically preferred over others. In the
following section it is discussed in more detail how the availability of frequency
or related constructional scores can be used to guide search such that more
desirable analysis are found Ô¨Årst before others.
7.2 Optimal Processing
The problem investigated in this section is how to select among a set of available
partial analysis for further expansion during processing. To be precise, an anal-
ysis consists of an ordered set of constructions that, when applied one after the
other to the initial linguistic structure (the input to processing), leads to a mod-
iÔ¨Åed transient linguistic structure. Obviously, if one of the modiÔ¨Åed structures
meets a given set of primary processing criteria (see section 7.1), then processing
stops (a ‚Äòsolution‚Äô is found). If not, however, one of the available analysis and a
construction that applies to it are selected. Applying the construction then gives
rise to a new, additional analysis, and the process is repeated.
If constructions are marked with a ‚Äúpreference score‚Äù, for instance reÔ¨Çecting
the frequency of usage, then a global score can be calculated for each analysis
by combining the scores of the constructions in it. One possibility is to sum all
constructional preference scores. However, this introduces a bias towards analy-
sis with many constructions, that is, towards compositional rather than holistic
or idiomatic analysis. An alternative is to average over all constructional pref-
erence scores. Neither of these approaches take into account that some analysis
might be less complete than others (e.g. leave more meaning or form components
unanalyzed). As such, an analysis that covers only a small part of all compo-
nents with highly scored constructions will be preferred over one that covers all
components, but with only moderately scored constructions.
The question arises whether there is an objective or otherwise ‚Äòoptimal‚Äô way
of combining constructional scores. The answer in general depends on the precise
nature of these scores. If they reÔ¨Çect the probability that the construction will
‚Äúget the message through‚Äù, that is, is shared between the interlocutors, then
one possibility is to optimize the expected communicative success. This makes
sense particularly in the context of language evolution experiments, where the
aim is precisely to simulate the evolution of an eÔ¨Écient communication system or
language between robots, and scores typically reÔ¨Çect a degree of ‚Äúconventionality‚Äù
or ‚Äúsharedness‚Äù.4
So let Œ±(s0, c) denote the fraction of components in the initial structure s0
that is covered by a construction c. For example, if Œ∑ = {m1(x), m2(y), m3(x, y)}
and c1, c2 and c3 are as before, then each of the constructions covers one third of
the components in Œ∑. The holistic construction h of section 5.1 covers two thirds.
Furthermore, let Œ≤(c) denote the (positive) preference score of the construction c,
4
Note however that not just any scoring mechanism allows an interpretation in terms
of probabilities. For one thing, probabilities must be positive and are subject to
normalization constraints etc.
A Formal Deconstruction of Fluid Construction Grammar 235
and let A be a (partial) analysis (an ordered set of constructions). An optimistic
(or admissible) yet informative heuristic score of the analysis A is the best still
achievable score Œ≥(A) deÔ¨Åned as follows:
Œ≥(A) =

c‚ààA
Œ±(s0, c)Œ≤(c) + (1 ‚àí

c‚ààA
Œ±(s0, c))
The Ô¨Årst term in the above expression is the contribution of the constructions in
A, that is, in the set of constructions that already applied, modulated by their
proper preference scores. The second part is an optimistic estimate of what can
still be achieved for the remaining components not yet covered in the analysis.
This term assumes that it will be possible to cover the remaining components
with constructions of maximum preference score 1. Considering constructions
in order of preference and adjusting the still achievable score accordingly may
considerably improve the accuracy of the heuristic, and hence the time and
memory required for processing.5
In summary, given that a constructional score can be interpreted as the proba-
bility that the construction is shared, optimal processing optimizes the expected
communicative success. This is particularly relevant within the context of lan-
guage game experiments, where the goal is to optimize communicative success
amongst a population of (simulated) language users, but might also be relevant
in relation to frequency eÔ¨Äects observed in human language.
7.3 EÔ¨Éciency Issues and Specialized Techniques
Many other specialized techniques exist for optimizing symbolic language pro-
cessing. However, many of them rely on assumptions that do not hold in fcg.
For instance, a well known optimization technique is chart parsing. In computer
science terms, this is a memoization technique, which ensures that the same sub-
phrase is never analyzed more than once. Instead, the result is calculated once
and ‚Äòmemoized‚Äô, so that it can be retrieved again later if needed. Most chart
parsing techniques rely on pre-deÔ¨Åned and often linear representations of form.
Fcg adopts a more Ô¨Çexible representation of form that may involve a tree, or
even a graph of form components. Nevertheless, some degree of memoization can
still be achieved by checking for similarities between diÔ¨Äerent analysis. This can
still greatly reduce processing load, particularly during lexical processing where
the order in which constructions are applied often does not matter.
Another optimization technique is the usage of ranks or independent construc-
tion sets. For some constructions it is known that they will not apply unless
certain other constructions applied (consider again the modiÔ¨Åer-head construc-
tion for instance), so it makes sense to put them in diÔ¨Äerent constructicons.
Considering that increasing the size of the constructicon can quickly lead to
5
This is not a trivial matter however, since in general it cannot be excluded that a
highly scored construction is only triggered at a later stage, for instance because it
depends on other constructions.
236 J. De Beule
a combinatorial explosion of the search space, such a ‚Äòdivide and conquer‚Äô ap-
proach might considerably reduce processing load. More generally, we can keep a
detailed record of all dependencies that exist between constructions and compile
them into a constructional dependency network. This might eliminate search al-
together. However, if the language changes, constructional dependencies change
too, so that a ‚Äòone time compilation‚Äô approach is not possible and more dy-
namic programming techniques are required. These issues are further discussed
elsewhere, e.g. [18] or [5].
8 Discussion and Conclusion
Fcg was developed as a computational framework to support artiÔ¨Åcial language
processing in robotic setups. From this perspective, it is actually surprising that
it has grown into a formalism in which even complex phenomena of natural
language can be captured. This in itself, in my opinion, makes it worthwhile to
compare fcg with other formalisms that were developed for capturing natural
language from the start.
Thus fcg, like hpsg [14] or ecg [3], is feature structure and uniÔ¨Åcation based.
However, despite these similarities, a detailed comparison is not easily made
due to fact that these techniques are sometimes employed for diÔ¨Äerent reasons.
As such, whereas uniÔ¨Åcation in hpsg is seen as a falsiÔ¨Åability problem that
determines the set of well formed structures, in fcg it is sometimes used as
a way to perform a ‚Äúlookup‚Äù of constructions during processing (match), and
sometimes, in a diÔ¨Äerent form, as an active step in processing itself (merge).
This reÔ¨Çects the fact that the development of fcg was driven primarily by the
problem of language processing rather than that of language representation.
Another distinguishing feature of fcg is that linguistic knowledge is organized
into constructions. As in construction grammar, these are meaning form pair-
ings. In fcg, constructions are furthermore routines for (partially) transforming
meaning speciÔ¨Åcations into form speciÔ¨Åcations during production, and vice versa
during parsing. There is thus an inherent duality between two processing modes
‚Äìparsing and production‚Äì that is not usually found in other formalisms. This
duality should not be confused with the one that exists between parsing and
generation in generative approaches.
With this chapter, we aimed to clarify some of these and other ‚Äòpeculiarities‚Äô
by tracing them back in the history of fcg. This history more or less follows
the development of processing machinery for processing increasingly complex
forms of language. For purely holistic language processing, a simple bi-directional
lookup table between meaning and form speciÔ¨Åcations suÔ¨Éces. Matching then
amounts to a simple comparison of patterns (component matching) and merg-
ing is not even relevant. For compositional language processing of independent
components, a slightly more involved form of matching is required, namely set-
matching. Merging then amounts to taking the union of sets. It also becomes
necessary to introduce the notion of a transient linguistic structure for captur-
ing intermediate processing results. When components are no longer independent
A Formal Deconstruction of Fluid Construction Grammar 237
but form a network, additionally relations between meaning and form compo-
nents as captured in constructions need to be represented in the transient lin-
guistic structure as well. This is the reason for introducing feature structures
in fcg. Matching now becomes a kind of pattern-matching between feature
structures. Merging now formally corresponds to the notion of uniÔ¨Åcation of fea-
ture structures in other uniÔ¨Åcation-based language formalisms, augmented with
special machinery for specifying manipulations to the constituent structure of
the transient linguistic structure. Chapters [16] and [5] can be consulted for a
further entanglement of diÔ¨Äerences and commonalities between fcg and other
approaches to uniÔ¨Åcation and constraint based language processing.
Acknowledgements. This work was mainly funded by the FWO through the
European Complexity-Net project ‚ÄúEvoSym‚Äù. The author wishes to thank Luc
Steels for making the development of fcg possible and for helping to improve
this paper.
References
[1] Abelson, H., Sussman, G.J.: Structure and Interpretation of Computer Programs,
2nd edn. MIT Press (1996)
[2] Baker, C.F., Fillmore, C.J., Lowe, J.B.: The Berkeley FrameNet Project. In: Pro-
ceedings of the 17th International Conference on Computational Linguistics. As-
sociation for Computational Linguistics, Morristown (1998)
[3] Bergen, B., Chang, N.: Embodied Construction Grammar in simulation-based
language understanding. In: √ñstman, J.O., Fried, M. (eds.) Construction Gram-
mar(s): Cognitive and Cross-Language Dimensions. Johns Benjamins (2005)
[4] Chomsky, N.: The Minimalist Program. MIT Press, Cambridge (1995)
[5] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraint
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[6] Croft, W.: Logical and typological arguments for radical construction grammar.
In: Ostman, J., Fried, M. (eds.) Construction Grammars: Cognitive Grounding
and Theoretical Extensions. John Benjamin Publ. Cy., Amsterdam (2005)
[7] De Beule, J.: Compositionality, Hierarchy and Recursion in Language, a Case
Study in Fluid Construction Grammar. Ph.D. thesis, VUB ArtiÔ¨Åcial Intelligence
Lab. (2007)
[8] Fillmore, C.J.: Frame semantics. In: Linguistics in the Morning Calm, Seoul,
pp. 111‚Äì137 (1982)
[9] Gentner, T.Q., Fenn, K.M., Margoliash, D., Nusbaum, H.C.: Recursive syntactic
pattern learning by songbirds. Nature (2006)
[10] Goldberg, A.: Constructions: A Construction grammar approach to argument
structure. University of Chicago Press, Chicago (1995)
[11] Hauser, M.D., Chomsky, N., Fitch, W.T.: The faculty of language: What is it,
who has it, and how did it evolve? Science 298, 1569‚Äì1579 (2002)
[12] JackendoÔ¨Ä, R., Pinker, S.: The nature of the language faculty and its implica-
tions for evolution of language (reply to Ô¨Åtch, hauser, and chomsky). Cognition
(September 2005)
238 J. De Beule
[13] Norvig, P.: Paradigms of AI: Case studies in Common Lisp. PWS Publishing
Company (1992)
[14] Pollard, C., Sag, I.: Head-driven phrase structure grammar. University of Chicago
Press, Center for the Study of Language and Information of Stanford University,
Chicago (1994)
[15] Sag, I.A., Wasow, T., Bender, E.M.: Syntactic Theory, A Formal Introduction.,
2nd edn. CSLI Publications, Leland Stanford Junior University, United States
(2003)
[16] Santib√°√±ez, J.S.: A Logic Programming Approach to Parsing and Production in
Fluid Construction Grammar. In: Steels, L. (ed.) Computational Issues in FCG.
LNCS (LNAI), vol. 7249, pp. 239‚Äì255. Springer, Heidelberg (2012)
[17] Steels, L., Vogt, P.: Grounding adaptive language games in robotic agents. In:
Husbands, P., Harvey, I. (eds.) Proceedings of the Fourth European Conference
on ArtiÔ¨Åcial Life (ECAL 1997). Complex Adaptive Systems. The MIT Press, Cam-
bridge (1997)
[18] Wellens, P.: Organizing constructions in networks. In: Steels, L. (ed.) Design Pat-
terns in Fluid Construction Grammar., John Benjamins, Amsterdam (2011)
A Logic Programming Approach to Parsing
and Production in Fluid Construction Grammar
JoseÔ¨Åna Sierra-Santib√°√±ez
Universidad Polit√©cnica de Catalu√±a,
Campus Nord, 08034 Barcelona, Spain
Maria.Josefina.Sierra@upc.edu
Abstract. This paper presents a Logic Programming approach to pars-
ing and production in Fluid Construction Grammar (FCG) [13]. It builds
on previous work on the formalisation of FCG in terms of First Order
Logic (FOL) concepts, more specifically on the definition of its core in-
ference operations, unification and merge, in terms of FOL unification
and search in the space of a particular set of FOL terms called structure
arrangements. An implementation of such inference operations based on
Logic Programming and Artificial Intelligence techniques such as unifi-
cation and heuristic search is outlined.
1 Introduction
Fluid Construction Grammar (FCG) [10] is a grammatical formalism imple-
mented in Lisp [6] which incorporates ideas from Construction Grammar [3] and
Cognitive Grammar [5].
It has been used in a number of experiments [11, 15] investigating the symbol
grounding problem [4] in populations of autonomous agents connected to their
environment through sensors and actuators. These experiments focus on the
study of the evolution and the acquisition of language [9] in particular on the
acquisition of grammar and the role of grammar in language grounding, empha-
sising the communicative function of grammar as well as the relation between
grammar and meaning [14].
FCG also draws inspiration from observations of language usage [18], which
suggest that natural languages constantly adapt and evolve to cope with new
meanings and variations in the behaviour of language users. The experiments
themselves are designed to implement and test a constructivist approach to lan-
guage development [16], in which grammatical constructions are acquired grad-
ually, beginning with concrete linguistic structures based on particular words,
from which they are progressively abstracted.
From a computational point of view, FCG is fully operational [1, 17] and it has
been used in a considerable number of experiments. However its basic inference
operations, uniÔ¨Åcation and merge, are only deÔ¨Åned intuitively in the linguistics
literature. A formalisation of the uniÔ¨Åcation and merge algorithms used in FCG
has been proposed by its developers in [12]. Formal deÔ¨Ånitions of FCG concepts
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 239‚Äì255, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
240 J. Sierra-Santib√°√±ez
in terms of First Order Logic and Order-Sorted Feature Constraint Logic have
also been presented in [8] and [2]. The present paper outlines an approach to
parsing and production in FCG based on Logic Programming and ArtiÔ¨Åcial
Intelligence techniques such as uniÔ¨Åcation and heuristic search.
The rest of the paper is organised as follows. Section 2 describes the repre-
sentation formalism used in FCG. Section 3 summarises the formal deÔ¨Ånition
of unification and merge proposed in [8]. Section 4 illustrates the usefulness of
such deÔ¨Ånition with two examples of construction application. Finally, section 5
presents an outline of an FCG-uniÔ¨Åcation algorithm based on logic programming
techniques through an extended example.
2 Representation Formalism
2.1 Semantic and Syntactic Structures
Linguistic and semantic information is represented using syntactic and semantic
structures in FCG. A semantic or syntactic structure consists of a set of units,
which correspond to lexical items or constituents such as noun phrases or rel-
ative clauses. A unit has a name and a number of feature-value pairs. In this
paper, we will assume that semantic units contain the features sem-subunits,
referent, meaning and sem-cat, in that order; and syntactic units the features
syn-subunits, utterance, form and syn-cat. Feature values depend on the type of
feature: referent and utterance have a single value, whereas the values of sem-
subunits and syn-subunits are sets of unit names. The values of the rest of the
features are sets of facts about diÔ¨Äerent aspects of the components of a structure:
meaning is a set of facts which can be used to identify the referent (e.g. its shape,
colour, type of entity or event); semantic categories describe more abstract as-
pects of the referent (e.g. its role as the agent, object or recipient in an action);
form and syntactic categories specify diÔ¨Äerent aspects of the utterance, such as
its number, part of speech, stem or grammatical role (e.g. subject, predicate or
object). The set of facts which may be included in the values of these features
is not restricted to those just mentioned but open ended.
We will use lists to represent those facts. For example, the fact that unit-2
is a noun will be represented by the list (part-of-speech unit-2 noun). This
notation allows using First Order Logic variables for syntactic and semantic cat-
egories [7]. In particular, we will use a many-sorted language with two types: list
and atom1
. We shall also assume that the elements of the lists representing facts
are always variables or constants of type atom, and that any symbol preceded
by a question mark is a variable.
1
There is a binary function symbol cons: Atom √ó List ‚àí‚Üí List and a constant
symbol NIL of type list, which allow constructing terms of type list. For ex-
ample, the term (part-of-speech unit-2 noun) is an abbreviation for the first
order logic term (cons part-of-speech (cons unit-2 (cons noun NIL))), where
part-of-speech, unit-2 and noun are constant symbols of type atom.
A Logic Programming Approach to Parsing and Production in FCG 241
2.2 Constructions
In FCG inference is performed applying constructions to source structures. A
construction is a pair <left-pole> ‚áî <right-pole> of pattern structures which
usually associates a syntactic pattern with a semantic pattern (see Ô¨Ågures 2 and
1). Constructions play therefore the role of grammar rules in construction gram-
mars [3]. However they not only relate syntactic patterns to semantic ones but
also supply information required for parsing and generation which is not included
in lexical items, making it possible to construct sentences whose meaning is more
than the sum of the meanings of their parts.
Source structures (i.e. semantic and syntactic structures of the type we have
described before) constitute the input to parsing and production processes in
FCG, whereas constructions are used to add semantic and syntactic information
to source structures, that is, to complete missing aspects in these structures,
such as the identity of the agent in an event or the subject of a verb.
Formally, the application of a construction is a combination of two operations:
Unification, which is used to check whether a construction is compatible with
a source structure; and merge, which extends the structure with information
contained in the construction [12].
3 Unification and Merge
3.1 Feature-Value Unification
UniÔ¨Åcation for feature-values depends on the type of feature. First Order Logic
unification can be used to compute the most general unifier (mgu) of two features
whose values are single terms. However, when feature values are sets of terms
(unit names or facts represented by lists of atoms), a number of issues must be
taken into account before First Order Logic uniÔ¨Åcation can be applied.
Feature-value Arrangement. Let s = {t1, . . . , tn} be a feature value of type set
of terms (unit names or facts represented by lists of atoms) of a semantic or
syntactic source unit. An m-arrangement of s is a list v = (ti1 , . . . , tim ), where
tij ‚àà s for j = 1 . . . m, and tij are all distinct. An m-arrangement is thus a list
in which m distinct elements of s are organised in a particular order.
Feature-value Unification. Let s = {a1, . . . , an} be a feature value of type set of
terms of a source unit and p = (== b1, . . . , bm) a feature value of type set of
terms of a pattern unit2
. We say that s and p are FCG-unifiable if there is an
m-arrangement s
of s such that the First Order Logic terms s
and p of type
list of terms are uniÔ¨Åable, and we call the most general uniÔ¨Åer œÉ of s
and p an
FCG-uniÔ¨Åer of s and p.
The symbol == in the pattern feature value is used in FCG to indicate that
the source feature value should include the pattern feature value, but that they
2
Note that we use list notation (round brackets), rather than set notation (curly
brackets), for specifying pattern feature values of type set of terms. The reason is
that we need not consider the m-arrangements of pattern values.
242 J. Sierra-Santib√°√±ez
need not be exactly the same set. If the symbol == is omitted from the list
representing the pattern feature value, then it is understood that both sets, the
source and the pattern, must be equal after uniÔ¨Åcation.
Feature values of type set of terms in FCG patterns may take thus one of the
following forms:
1. (== t1, . . . , tm), specifying a set of terms which should be included in the
value of a particular feature in a source structure; or
2. (t1, . . . , tm), specifying a set of terms which should be equal to the value of
a particular feature in a source structure.
Note that there can be several FCG-uniÔ¨Åers for a pair (s, p) of source and pattern
feature values. Because two diÔ¨Äerent arrangements s1 and s2 of s might be such
that p and s1 are uniÔ¨Åable, and so are p and s2, but s1 and s2 are not.
3.2 Feature-Value Merge
Merge is used to extend a semantic or syntactic source structure with additional
information contained in a pattern structure.
If the pattern and source feature values are FCG-uniÔ¨Åable, merge is equivalent
to uniÔ¨Åcation3
. However, when the pattern and source are not FCG-uniÔ¨Åable,
the source feature value is minimally extended so that its extension and the
pattern are uniÔ¨Åable. The source feature value is extended only if this can be
done without introducing inconsistencies. Consider the following example:
p: ((?unit (sem-cat (== (agent ?e ?a) (entity-type ?a human)))))
s: {(unit (sem-cat {(agent e a) (event-type e motion)}))}
The values of the feature sem-cat are not uniÔ¨Åable. But if we add the fact
(entity-type ?a human) to the source value, both feature values can be uniÔ¨Åed
yielding the following extended value, which is the result of merging s with p.
s‚Äô: {(unit (sem-cat {(agent e a) (event-type e motion)
(entity-type a human)}))}
The steps involved in merging the feature value in source structure s with the
feature value in pattern structure p above are:
1. Finding a minimal subset pc = {(entity-type ?a human)} of p such that
s

pc and p are FCG-uniÔ¨Åable, and an FCG-uniÔ¨Åer œÉ of p and s

pc.
2. Applying œÉ = {?a = a, ?e = e} to s

pc in order to obtain the extended
source feature value (s

pc)œÉ, which is the result of merging s with p.
In general the result of merging a source feature value s with a pattern feature
value p is not unique, because there might be diÔ¨Äerent minimal extensions s
of s
such that s
and p are uniÔ¨Åable; and there might be as well diÔ¨Äerent FCG-uniÔ¨Åers
for a given extension s
and the pattern p.
3
In this case, the source feature value is not extended as a result of merging it with
the pattern feature value, although some of its variables might be instantiated when
an FCG-unifier of both feature values is applied to it.
A Logic Programming Approach to Parsing and Production in FCG 243
The Set of Facts Consistency Condition. The Ô¨Årst step above requires
further clariÔ¨Åcation. Let us consider another example, where s and p denote the
source and pattern structures to be merged respectively.
p: ((?unit (form (== (string ?unit car)))
(syn-cat (== (number ?unit singular)))))
s: {(unit (form {(string unit cars)})
(syn-cat {(number unit plural)}))}
In this case, s should not be merged with p, because neither the values of the
form feature nor those of the syn-cat feature are consistent with each other.
The value of the source feature syn-cat and the value of the same feature
in the pattern are not uniÔ¨Åable. But the union of the minimal subset of the
pattern feature value pc = {(number ?unit singular)} and the source feature
value s = {(number unit plural)} leads to a contradiction, once the most general
uniÔ¨Åer œÉ = {?unit = unit} is applied to it: the number of a unit cannot be
singular and plural at the same time.
(s

pc)œÉ = (syn-cat {(number unit plural) (number unit singular)})
In fact, the pattern and source structures above cannot be merged. The minimal
subset of the pattern feature value pc such that s

pc and p are FCG-uniÔ¨Åable
must satisfy an additional condition which we will call the set of facts consis-
tency: the extended source feature value resulting from merging the source with
the pattern should not contain any pair of facts (f a1 . . . an u) and (f a1 . . . an v)
such that their elements are all equal but for the last one (u = v). The reason
for imposing this condition is that a function cannot assign diÔ¨Äerent values to a
single tuple of elements, and we are assuming that a fact described by a list such
as (f a1 . . . an v) represents a statement of the form f(a1, . . . , an) = v, where
f denotes a function symbol, a1, . . . , an its arguments, and v the value that f
assigns to (a1, . . . , an).
In FCG the symbol =1 is used in pattern feature values of type set of terms to
indicate that no repetitions are allowed. For example, the pattern of the previous
example should be speciÔ¨Åed as follows in FCG:
p: ((?unit (form (=1 (string ?unit car)))
(syn-cat (=1 (number ?unit singular)))))
We need not use =1, because we assume a functional interpretation of lists
representing facts and the set of facts consistency condition. The reader should
be warned that lists representing facts in FCG are interpreted relationally and
that FCG does not make the set of facts consistency assumption.
Feature-Value Merge. Let s be a source feature value of type set of terms, p a
pattern feature value of the same type, pc a minimal subset of p such that s

pc
and p are FCG-uniÔ¨Åable4
, and œÉ an FCG-uniÔ¨Åer of s

pc and p. If (s

pc)œÉ
4
A subset pc of a pattern feature-value p is minimal with respect to a source feature-
value s if no subset pt of p satisfies that: (1) pt ‚äÇ pc; (2) p and s

pt are FCG-
unifiable; and (3) (s

pt)œÉ is fact set consistent.
244 J. Sierra-Santib√°√±ez
satisÔ¨Åes the set of facts consistency condition, then the extended feature value
(s

pc)œÉ is a valid result of merging s with p.
3.3 Unification and Merge for Units
Let p = (pname (f1 uÃÑ1) (f2 u2) (f3 uÃÑ3) (f4 uÃÑ4)) be a pattern unit, where
f1, . . . , f4 are the feature names sem-subunits, referent, meaning and sem-cat,
if p is a semantic unit; or the feature names syn-subunits, utterance, form and
syn-cat, if p is a syntactic unit.
Unit Arrangement. A p-arrangement of a source unit s is a Ô¨Årst order logic term
of the form (sname (f1 vÃÑ1) (f2 v2) (f3 vÃÑ3) (f4vÃÑ4)), where sname is the name of s;
n1, n3 and n4 are the number of elements in uÃÑ1, uÃÑ3 and uÃÑ4; vÃÑ1, vÃÑ3, vÃÑ4 are n1, n3
and n4-arrangements of the values of features f1, f3 and f4 in s, respectively;
and v2 is the value of feature f2 in s.
A p-arrangement. of a source unit s is thus a unit obtained from s substituting
each of its feature values for arrangements of such feature values with respect to
the corresponding feature values in the pattern unit p.
Unit Unification. Let p be a pattern unit and s a source unit. We say that s and
p are FCG-unifiable if there is a p-arrangement s
of s such that the Ô¨Årst order
logic terms p and s
are uniÔ¨Åable. The most general uniÔ¨Åer œÉ of s
and p is an
FCG-uniÔ¨Åer of s and p.
Unit Merge. Let s be a source unit (sname (f1 sv1) (f2 sv2) (f3 sv3) (f4 sv4));
p a pattern unit (pname (f1 pv1) (f2 pv2) (f3 pv3) (f4 pv4)); pvc
1, pvc
3 and
pvc
4 minimal subsets of pv1, pv3 and pv4 such that the extended unit se
=
(sname (f1 sv1

pvc
1) (f2 sv2) (f3 sv3

pvc
3) (f4 sv4

pvc
4)) and the pat-
tern unit p are FCG-uniÔ¨Åable; and œÉ an FCG-uniÔ¨Åer of se
and p. If every feature
value in se
œÉ satisÔ¨Åes the set of facts consistency condition, then se
œÉ is a valid
result of merging s with p.
3.4 Unification and Merge for Structures
Structure Arrangement. Let s = {u1 . . . un} be a source structure and p =
(== v1 . . . vm) a pattern structure. An m-arrangement of s is a list of m-units
s
= (uv1
i1
, . . . , uvm
im
), where each u
vj
ij
is a vj-arrangement of some uij ‚àà s for
j = 1 . . . m, and the uij are all distinct.
Structure Unification. Let s = {u1 . . . un} be a source structure and p = (==
v1 . . . vm) a pattern structure. We say that s and p are FCG-unifiable if there
is an m-arrangement s
of s such that the Ô¨Årst order logic terms s
and p are
uniÔ¨Åable. The most general uniÔ¨Åer œÉ of s
and p is an FCG-uniÔ¨Åer of s and p.
Structure Merge. Let s be a source structure; p a pattern structure(== v1 . . . vm);
pc a minimal subset of p such that for each unit ui ‚àà s

pc i = 1 . . . n there
A Logic Programming Approach to Parsing and Production in FCG 245
is a unit ue
i which is either equal to ui or an extension of ui with respect to
a unique unit vj ‚àà p, such that the extended structure se
= {ue
1, . . . , ue
n} and
the pattern structure p are FCG-uniÔ¨Åable; and œÉ an FCG-uniÔ¨Åer of se
and p.
If every feature-value in se
œÉ satisÔ¨Åes the set of facts consistency condition, then
se
œÉ is a valid result of merging s with p.
4 Examples of Construction Application
The semantic and syntactic source structures constructed at an intermediate
stage during the parsing process of the sentence John slides blocks to Mary are
shown in Ô¨Ågure 1. These structures result from applying morphological, lexical,
semantic categorisation and phrase structure rules (constructions) to an initial
structure containing just the words that make up the sentence. Morphological
rules decompose words into a stem and a set of syntactic categories (e.g. "slides"
into a stem "slide" and the categories verb and singular). Number is grammatical
as opposed to natural, because it does not contribute to meaning. Lexical rules
map the stem of a lexical item into a set of facts specifying its meaning, and
natural syntactic categories (e.g. number for nouns) into additional meaning.
Semantic categorisation rules add semantic categories to the semantic structure
(e.g. the arguments of "slide" can be mapped into the semantic roles agent,
object and recipient in a transfer-to-recipient (tr) event). Finally, phrase structure
rules relate structural properties of a sentence, such as word order, to syntactic
categories, such as subject, direct object or indirect object.
Note that the variables associated with the referents of semantic units jo,
bl and ma, which represent John, blocks and Mary respectively, are diÔ¨Äerent
from those associated with the roles in the transfer-to-recipient event in unit sl.
Figure 2 shows an example of a construction whose purpose is to ensure that the
variables associated with the roles agent, object and recipient (ag, obj and rec
in unit ?eu) in a transfer-to-recipient (tr) event in a semantic structure become
equal to the variables associated with the referents of semantic units ?au, ?ou
and ?ru, which represent the participants in such an event.
Let us see how the construction shown in Ô¨Ågure 2 can be applied to the
syntactic and semantic structures associated with the sentence John slides blocks
to Mary, in order to make the variables representing the roles in the transfer-to-
recipient event equal to those associated with the referents of the units for John,
blocks and Mary.
From a computational point of view, construction application is a combination
of two operations: uniÔ¨Åcation and merge. Unification is used to check whether
a construction is compatible with a source structure; and merge to extend the
structure with information contained in the construction.
In our example uniÔ¨Åcation is Ô¨Årst applied to the syntactic pattern of the
construction and the syntactic source structure, to determine whether the con-
struction can be used to extend the structure. In this case both structures are
246 J. Sierra-Santib√°√±ez
uniÔ¨Åable. Then the uniÔ¨Åer built during this process {?su=u, ?eu=sl, ?au=jo,
?tu=t, ?ou=bl, ?ru=ma} is applied to the semantic pattern of the construction
and the semantic source structure. Next, the semantic source structure is merged
with the semantic pattern of the construction.
If the semantic source structure and the pattern are uniÔ¨Åable, merge is equiv-
alent to applying one of their FCG-uniÔ¨Åers to the semantic source structure.
In our example they are uniÔ¨Åable. Therefore the result of merging the semantic
source structure with the semantic pattern is obtained applying the uniÔ¨Åer œÑ =
{?s=?e, ?j=?a, ?b=?o, ?m=?r} to the semantic structure. As a consequence of
this, the variables associated with the roles agent, object and recipient in the
transfer to recipient event become equal to those associated with the referents
of the units representing John, blocks and Mary in the semantic structure.
{(u (sem-sub {sl jo bl ma})) {(u (syn-sub {sl jo bl t ma})
(form {(order u (jo sl bl t ma))})
(syn-cat {SVOtoO-sentence}))
(sl (referent ?s) (sl (form {(string sl slides)})
(meaning {(act ?s slide) (arg1 ?s ?a) (syn-cat {(stem sl slide)
(arg2 ?s ?o) (arg3 ?s ?r)}) (numb gram sl singular)
(sem-cat {(ev-type ?s tr) (ag ?s ?a) (speech-part sl verb)
(obj ?s ?o) (rec ?s ?r)})) (role sl pred)}))
(t (form {(string t to)})
(syn-cat {(speech-part t prep)}))
(jo (referent ?j) (jo (form {(string jo John)})
(meaning {(entity-type ?j person) (syn-cat {(stem jo john),
(count ?j one)})) (numb nat jo singular)
(speech-part jo noun))
(role jo subject)}))
(bl (referent ?b) (bl (form {(string bl blocks)})
(meaning {(entity-type ?b block) (syn-cat {(stem bl block)
(count ?b several)})) (numb nat bl plural)
(speech-part bl noun))
(role bl dir-obj)}))
(ma (referent ?m) (ma (form {(string ma Mary)})
(meaning {(entity-type ?m person) (syn-cat {(stem ma mary)
(count ?m one)})) } (numb nat ma singular)
(speech-part ma noun)
(role ma ind-obj)})) }
Fig. 1. Semantic (left) and syntactic (right) source structures built at an intermediate
stage during the parsing process of the sentence John slides blocks to Mary
(= (=
(?su (sem-sub (= ?eu ?au ?ou ?ru))) (?su (syn-sub (= ?eu ?au ?tu ?ou ?ru))
(syn-cat (= SVOtoO-sentence)))
(?eu (referent ?e) (?eu (syn-cat (= (role ?eu pred))))
(sem-cat (= (ev-type ?e tr) (ag ?e ?a)
(obj ?e ?o) (rec ?e ?r)))) (?tu (form (= (string ?tu to))))
(?au (referent ?a)) (?au (syn-cat (= (role ?au subject))))
(?ou (referent ?o)) (?ou (syn-cat (= (role ?ou dir-obj))))
(?ru (referent ?r))) (?ru (syn-cat (= (role ?ru ind-obj)))))
Fig. 2. Construction which associates a transfer-to-recipient (tr) semantic pattern
structure (left) with a Subject + Verb + Dir-Object + to + Indir-Object (SVOtoO)
syntactic pattern structure (right). Features whose values are the empty set or vari-
ables which appear only once in the construction are omitted.
A Logic Programming Approach to Parsing and Production in FCG 247
However, uniÔ¨Åability is not a necessary requirement for merge. If source and
pattern are not uniÔ¨Åable, the source structure might still be merged with the
pattern, provided it can be minimally extended so that its extension and the
pattern are uniÔ¨Åable, and the result of merge does not violate the set of facts
consistency condition.
Let us see an example of construction application where merge cannot be
reduced to uniÔ¨Åcation. Figure 3 shows a morphological construction which de-
composes the word "slides" into a stem and a number of syntactic categories.
We apply this construction to the source structure in Ô¨Ågure 4. First, uniÔ¨Åcation
is applied to the left pattern of the construction and the source structure (see
Ô¨Ågure 5), to determine whether the construction can be used to extend the struc-
ture. Then the uniÔ¨Åer œÉ constructed during this process is applied to the right
pattern of the construction and the source structure.
(= (?s (form (= (string ?s slides))))) (= (?s (form (= (stem ?s slide)))
(syn-cat (= (number ?s singular)
(speech-part ?s verb)))))
Fig. 3. Construction which decomposes the word "slides" into a stem and a number of
syntactic categories
{ (sl (syn-sub {})
(utter ?u2)
(form {(string sl slides)})
(syn-cat ?sc2)) }
Fig. 4. Extended form of a syntactic source structure containing a syntactic unit asso-
ciated with the word "slides" at an initial stage during the parsing process
(= (?s (syn-sub {}) { (sl (syn-sub {})
(utter ?u1) (utter ?u2)
(form (= (string ?s slides))) (form {(string sl slides)})
(syn-cat ?sc1)) ) (syn-cat ?sc2)) }
Fig. 5. Unification is applied to the left pattern of the construction and the source
structure, yielding the unifier œÉ = {?s = sl, ?u1 = ?u2, ?sc1 = ?sc2}
Next, the source structure is merged with the right pattern of the construc-
tion. Given that the pattern and the source structure are not uniÔ¨Åable, the source
structure is minimally extended so that its extension and the pattern are uniÔ¨Å-
able. In particular, the value of feature form in the source structure is extended
with the subset {(stem sl slide)} of the value of the same feature in the pattern
(see Ô¨Ågure 6).
Finally, the extended source structure and the right pattern of the construc-
tion are uniÔ¨Åed, and the uniÔ¨Åer œÑ = {?sc2 = {(number sl singular) (speech-part
sl verb)}} constructed during this step is applied to the extended source struc-
ture in order to obtain the result of merging the source structure with the right
pattern of the construction (see Ô¨Ågure 7).
248 J. Sierra-Santib√°√±ez
{ (sl (syn-sub {}) (= (sl (syn-sub {})
(utter ?u2) (utter ?u2)
(form {(string sl slides) (form (= (stem sl slide)))
(stem sl slide)})
(syn-cat ?sc2)) } (syn-cat (= (number sl singular)
(speech-part sl verb)))))
Fig. 6. Unifier œÉ is applied to the right pattern of the construction, and the source
structure is minimally extended so that it unifies with the pattern in the sense of FCG
{ (sl (syn-sub {})
(utter ?u2)
(form {(string sl slides) (stem sl slide)})
(syn-cat {(number sl singular) (speech-part sl verb)})) }
Fig. 7. Result of merging the source structure with the instantiated right pattern of
the construction
5 Outline of an FCG-Unification Algorithm
Let p = (== v1 . . . vm) be a pattern structure and s = {u1 . . . un} a source
structure. For each unit vi in p we deÔ¨Åne the set Ci = {(uk
j , œÉk
j ) | j = 1 . . . n, k =
1 . . . nj}, where uk
j is a vi-arrangement of unit uj in s such that uk
j and vi are
uniÔ¨Åable in the sense of First Order Logic and œÉk
j = mgu(vi, uk
j ).
For example, let p = (== v1 . . . v6) be the syntactic pattern structure in
Ô¨Ågure 2 and s = {u1 . . . u6} the syntactic source structure in Ô¨Ågure 1. In order
to construct C2, we Ô¨Årst try to unify unit v2 (i.e. ?eu) in the pattern and unit u1
(i.e. u) in the source. Units in Ô¨Ågures 1 and 2 appear in abbreviated form, where
features which do not contain relevant values are omitted. UniÔ¨Åcation requires
using the extended form of these units, which is shown below.
(?eu (syn-sub ()) (u (syn-sub {sl jo bl t ma})
(utter ?u1) (utter ?u2)
(form ?f ) (form {(order u (jo sl bl t ma))})
(syn-cat (= (role ?eu pred)))) (syn-cat {SVOtoO-sentence}))
In order to unify two units, it is necessary to unify their feature values, and
it is clear that the values of feature syn-cat are not FCG-uniÔ¨Åable: there is no
1-arrangement of {SVOtoO-sentence} which can be made equal to ((role ?eu
pre)). Therefore units v2 and u1 are not uniÔ¨Åable.
We consider now the pair of units v2 (i.e. ?eu in the pattern) and u2 (sl in
the source). The extended form of these units is shown below.
(?eu (syn-sub ()) (sl (syn-sub {})
(utter ?u1) (utter ?u2)
(form ?f) (form {(string sl slides)})
(syn-cat (= (role ?eu pred)))) (syn-cat {(stem sl slide)
(numb gram sl singular)
(speech-part sl verb)
(role sl pred)}))
The values of features syn-sub, utter and form in units sl and ?eu are uniÔ¨Åable.
The value of feature syn-cat has four 1-arrangements, however only one of them,
A Logic Programming Approach to Parsing and Production in FCG 249
((role sl pred)), satisÔ¨Åes the uniÔ¨Åability condition. It is easy to check that unit
?eu does not unify with the rest of the units in the source structure. Therefore,
set C2 consists only of the pair (u1
2, œÉ1
2), where œÉ1
2 is the uniÔ¨Åer {?eu = sl, ?u1
= ?u2, ?f = ((string sl slides))} and u1
2 the ?eu-arrangement of unit u2 (i.e. sl)
shown below.
(?eu (syn-sub ()) (sl (syn-sub ())
(utter ?u1) (utter ?u2)
(form ?f) (form ((string sl slides)))
(syn-cat (= (role ?eu pred)))) (syn-cat ((role sl pred))))
The same reasoning can be applied to units v3, v4, v5 and v6 (i.e. ?tu, ?au, ?ou
and ?ru) in the pattern. Only one arrangement of unit u3 (i.e. t) and unit v3 (i.e.
?tu) are uniÔ¨Åable, and the same happens to the pairs of units (?au, jo), (?ou, bl)
and (?ru, ma).
Unit v1 (i.e. ?su) is more interesting though, because several v1-arrangements
of source unit u1 (i.e. u) satisfy the uniÔ¨Åability condition. In fact, the set C1 con-
tains 120 pairs of the form (v1-arrangement, uniÔ¨Åer), one for each permutation
of the set {sl jo bl t ma}. We just show two of them.
The uniÔ¨Åer œÉ1
1 = {?su = u, ?eu = sl, ?au = jo, ?tu = t, ?ou = bl, ?ru = ma, ?u1
= ?u2, ?f = ((order u (jo sl bl t ma)))} corresponds to u1
1, the ?su-arrangement
of unit u1 (i.e. u) shown below.
(?su (syn-sub (= ?eu ?au ?tu ?ou ?ru)) (u (syn-sub (sl jo t bl ma))
(utter ?u1) (utter ?u2)
(form ?f) (form ((order u (jo sl bl t ma))))
(syn-cat (= SVOtoO-sentence))) (syn-cat (SVOtoO-sentence)))
The uniÔ¨Åer œÉ2
1 = {?su = u, ?eu = sl, ?au = jo, ?tu = t, ?ou = ma, ?ru = bl, ?u1
= ?u2, ?f = ((order u (jo sl bl t ma)))} corresponds to u2
1, the ?su-arrangement
of unit u1 (i.e. u) shown below.
(?su (syn-sub (= ?eu ?au ?tu ?ou ?ru)) (u (syn-sub (sl jo t ma bl))
(utter ?u1) (utter ?u2)
(form ?f) (form ((order u (jo sl bl t ma))))
(syn-cat (= SVOtoO-sentence))) (syn-cat (SVOtoO-sentence)))
Given a pattern structure p = (== v1 . . . vm), a source structure s = { u1 . . .
un } and a tuple of sets (C1, . . . , Cm) of the sort deÔ¨Åned above, the set of FCG-
uniÔ¨Åers of p and s can be deÔ¨Åned as follows.
{œÉ | ‚àÉi1 . . . ‚àÉim(ai1
1 ‚àà C1 ‚àß . . . ‚àß aim
m ‚àà Cm ‚àß œÉ = mgu(p, (ai1
1 , . . . , aim
m ))}
That is, the set of FCG-uniÔ¨Åers of p and s is the set of most general uniÔ¨Åers of
p and s
, where s
is any p-arrangement of s of the form (ai1
1 , . . . , aim
m ) such that
s
and p are uniÔ¨Åable.
Clearly, constructing all the p-arrangements of a source structure s, and check-
ing whether p and any of them are uniÔ¨Åable is not a practical approach to uniÔ¨Å-
cation. Consider the uniÔ¨Åcation example discussed above. Sets C2 to C6 contain
a single pair of the form (arrangement, uniÔ¨Åer), but set C1 has 120 pairs. There-
fore, in the worst case we would have to construct 120 structure arrangements
and check whether each of them and the pattern are uniÔ¨Åable.
250 J. Sierra-Santib√°√±ez
Instead, we use a heuristic depth first search strategy to explore the space of
structure arrangements. The depth Ô¨Årst search part of our approach consists in
applying the uniÔ¨Åer associated with a unit arrangement in a set Ci to the whole
pattern and source structures. This requires undoing substitutions in backtrack-
ing steps, but it can be easily implemented in Prolog. The heuristic part is used
to determine the order in which the sets Ci will be used to explore the set of
structure arrangements. For example, if set Ci has fewer elements than set Cj,
then we instantiate the i-esim component of an arrangement earlier than the
j-esim one. Similarly, semantic relevance is used as a criterion for determining
order of instantiation. For example a unit representing the predicate of a sen-
tence should take precedence over other units representing its subject or its
complements. Figure 8 shows part of a preliminary Prolog implementation of
the FCG-uniÔ¨Åcation algorithm outlined in this section.
Let us illustrate these ideas describing the application of the algorithm to
our previous example of uniÔ¨Åcation of the syntactic pattern of the construc-
tion in Ô¨Ågure 2 and the syntactic source structure in Ô¨Ågure 1. In accordance
with the heuristics just mentioned the unit-arrangement and uniÔ¨Åer in set C2
would be used in Ô¨Årst place, because unit u2 describes a predicate and the set
C2 only has one element. Sets C3 to C6 also have one element. They might be
explored in order of semantic relevance: C4 subject, C5 direct object, C6 indi-
rect object and C3 preposition. Finally, the last set to be used would be C1,
because it has 120 elements. In fact, as we will see later, set C1 will not even
be constructed explicitly. All its arrangements but one will be pruned out by
uniÔ¨Åcation during the depth Ô¨Årst search process. It is possible to estimate the
number of elements of a set Ci without actually computing it5
. Therefore, we
need not assume that the sets Ci must be computed before starting the depth
Ô¨Årst search process.
First, uniÔ¨Åcation is applied to units v2 and u2, the v2-arrangement u1
2 and
uniÔ¨Åer œÉ1
2 in C2 are used as follows: unit u2 (i.e. sl) in the source is substituted
for arrangement u1
2, and uniÔ¨Åer œÉ1
2 = { ?eu = sl, ?u3 = ?u4, ?f2 = ((string sl
slides)) } is applied to the construction and the source structure (see Ô¨Ågure 9).
Next, sets Ci = {(u1
i , œÉ1
i )}, i = 4, 5, 6, 3 are used in that order: unit ui in the
source is substituted for arrangement u1
i , and uniÔ¨Åer œÉ1
i is applied to the pattern
and the source structures. The result is shown in Ô¨Ågure 10.
As we said before, once variables ?eu, ?au, ?ou, ?tu and ?ru have been
instantiated during the heuristic depth Ô¨Årst search process (see Ô¨Ågure 10), the
set C1 of arrangements of units in the source structure which can be made equal
to unit v1 consists of a single element rather than 120. That is, C1 = {(u1
1, œÉ1
1)},
where uniÔ¨Åer œÉ1
1 is {?su = u, ?u1 = ?u2, ?f1 = ((order u (jo sl bl to ma)))} and
arrangement u1
1 is as follows.
5
This is clear in the case of C1, because the value of feature syn-sub in unit ?su is
a set consisting of five variables, therefore all the permutations of such a set unify
with the value of the same feature in unit u. For the rest of the units one can simply
check whether their single element in feature syn-cat belongs to the value of the same
feature in each of the units in the source structure.
A Logic Programming Approach to Parsing and Production in FCG 251
% fv_unif(P,S,A)
% P a pattern feature-value and S a source feature-value. If P and S
% are FCG-unifiable this predicate succeeds and A is instantiated to
% Ps, S‚Äô is a P-arrangement of S unifiable with P and s = mgu(P,S‚Äô).
% unit_unif(P,S,A)
% P a pattern unit and S a source unit. If P and S are FCG-unifiable
% this predicate succeeds and A is instantiated to Ps, where S‚Äô is a
% P-arrangement of S unifiable with P and s = mgu(P,S‚Äô).
% str_unif(P,S,A)
% P a pattern structure and S a source structre. If P and S are
% FCG-unifiable this predicate succeeds and A is instantiated to
% Ps, S‚Äô is a P-arrangement of S unifiable with P and s=mgu(P,S‚Äô).
str_unif(P,S,A) :- sort_heur(P,S,SP), str_arr(SP,S,A).
st_arr([],_,[]).
st_arr([H|T],S,[AH|R]) :- member(U,S), unit_unif(H,U,AH),
delete(S,U,Rest), st_arr(T,Rest,R).
% sort_heur(P,S,SP)
% P is a pattern structure and S a source structure.
% This procedure instantiates SP to a list containing the units in
% P sorted in accordance with the heuristics used by the algortihm.
% Units in P which should be instatiated in first place are charac-
% terised as ‚Äôgood‚Äô with respect to the source structure S, and are
% placed at the front of SP. A predicate better is used to indicate
% that a unit u1 should be instantiated earlier than another u2, i.e.
% that u1 should precede u2 in SP. The following rules describe some
% heuristics used by the FCG-unification algorithm.
good(U,S) :- unique_unifier(U,S).
better(U1,U2,S) :- more_unifiers(U2,U1,S), !.
better(U1,U2,S) :- \+ better(U2,U1,S), predicate_unit(U1),
\+ predicate_unit(U2), !.
% similar rules for subject, direct object, indirect object...
Fig. 8. Partial description of the Prolog code of the FCG-unification algorithm (\+
denotes negation by failure)
252 J. Sierra-Santib√°√±ez
(= (?su (syn-sub (= sl ?au ?tu ?ou ?ru)) {(u (syn-sub {sl jo bl t ma})
(utter ?u1) (utter ?u2)
(form ?f1) (form {(order u (jo sl bl t ma))})
(syn-cat (= (SVOtoO-sentence))) (syn-cat {SVOtoO-sentence}))
(sl (syn-sub ()) (sl (syn-sub {})
(utter ?u4) (utter ?u4)
(form ((string sl slides))) (form ((string sl slides)))
(syn-cat (= (role sl pred)))) (syn-cat ((role sl pred))))
(?tu (syn-sub ()) (t (syn-sub {})
(utter ?u5) (utter ?u6)
(form (= (string ?tu to))) (form {(string t to)})
(syn-cat ?s1) (syn-cat {(speech-part t prep)}))
(?au (syn-sub ()) (jo (syn-sub {})
(utter ?u7) (utter ?u8)
(form ?f3) (form {(string jo John)})
(syn-cat (= (role ?au subject)))) (syn-cat {(stem jo john)
(numb nat jo singular)
(speech-part jo noun)
(role jo subject)}))
(?ou (syn-sub ()) (bl (syn-sub {})
(utter ?u9) (utter ?u10)
(form ?f4) (form {(string bl blocks)})
(syn-cat (= (role ?ou dir-obj)))) (syn-cat {(stem bl block)
(numb nat bl plural)
(speech-part bl noun)
(role bl dir-obj)}))
(?ru (syn-sub ()) (ma (syn-sub {})
(utter ?u11) (utter ?u12)
(form ?f5) (form {(string ma Mary)})
(syn-cat (= (role ?ru ind-obj)))) (syn-cat {(stem ma mary)
(numb nat ma plural)
(speech-part ma noun)
(role ma ind-obj)})) }
Fig. 9. C2 = {(u1
2, œÉ1
2)} is used in first place: unit u2 in the source is substituted for
arrangement u1
2, and unifier œÉ1
2 is applied to pattern and source
(= (?su (syn-sub (= sl jo t bl ma)) {(u (syn-sub {sl jo bl t ma})
(utter ?u1) (utter ?u2)
(form ?f1) (form {(order u (jo sl bl t ma))})
(syn-cat (= (SVOtoO-sentence))) (syn-cat {SVOtoO-sentence}))
(sl (syn-sub ()) (sl (syn-sub ())
(utter ?u4) (utter ?u4)
(form ((string sl slides))) (form ((string sl slides)))
(syn-cat ((role sl pred)))) (syn-cat ((role sl pred))))
(t (syn-sub ()) (t (syn-sub ())
(utter ?u6) (utter ?u6)
(form ((string t to))) (form ((string t to)))
(syn-cat ((speech-part t prep)))) (syn-cat ((speech-part t prep))))
(jo (syn-sub ()) (jo (syn-sub ())
(utter ?u8) (utter ?u8)
(form ((string jo John))) (form ((string jo John)))
(syn-cat ((role jo subject)))) (syn-cat ((role jo subject))))
(bl (syn-sub ()) (bl (syn-sub ())
(utter ?u10) (utter ?u10)
(form ((string bl blocks))) (form ((string bl blocks)))
(syn-cat ((role bl dir-obj)))) (syn-cat ((role bl dir-obj))))
(ma (syn-sub ()) (ma (syn-sub ())
(utter ?u12) (utter ?u12)
(form ((string ma Mary))) (form ((string ma Mary)))
(syn-cat ((role ma ind-obj))))) (syn-cat ((role ma ind-obj))))}
Fig. 10. Result of using the arrangements and unifiers in sets C4, C5, C6 and C3 in
that order to explore the space of structure arrangements
A Logic Programming Approach to Parsing and Production in FCG 253
(u (syn-sub (sl jo t bl ma))
(utter ?u2)
(form ((order u (jo sl bl t ma))))
(syn-cat (SVOtoO-sentence)))
The result of using the arrangement and uniÔ¨Åer in C1, that is of substituting
unit u1 in the source structure for arrangement u1
1, and applying uniÔ¨Åer œÉ1
1 to
the source structure, is a complete arrangement s
of source structure s which
satisÔ¨Åes the uniÔ¨Åability condition.
The heuristic depth Ô¨Årst search process described above has allowed us to
check that the syntactic pattern of the construction and the syntactic source
structure are uniÔ¨Åable. The uniÔ¨Åer built during this process can be stored for
later use. But in order to implement construction application, we apply the
substitutions of previous steps not only to the syntactic source structure and the
syntactic pattern of the construction, but also to the semantic source structure
and the semantic pattern of the construction (see Ô¨Ågure 11).
(= (u (sem-sub (= sl jo bl ma)) {(u (sem-sub {sl jo bl ma})
(referent ?r1) (referent ?2)
(meaning ?m1) (meaning ?m2)
(sem-cat ?sc1)) (sem-cat ?sc2))
(sl (sem-sub ()) (sl (sem-sub {})
(referent ?e) (referent ?s)
(meaning ?m3) (meaning {(act ?s slide) (arg1 ?s ?a)
(arg2 ?s ?o) (arg3 ?s ?r)})
(sem-cat (= (ev-type ?e tr) (ag ?e ?a) (sem-cat {(ev-type ?s tr) (ag ?s ?a)
(obj ?e ?o) (rec ?e ?r)))) (obj ?s ?o) (rec ?s ?r))})
(jo (sem-sub ()) (jo (sem-sub {})
(referent ?a) (referent ?j)
(meaning ?m4) (meaning {(entity-type ?j person)
(count ?j one)})
(sem-cat ?sc7)) (sem-cat ?sc8))
(bl (sem-sub ()) (bl (sem-sub {})
(referent ?o) (referent ?b)
(meaning ?m5) (meaning {(entity-type ?b block)
(count ?b several)})
(sem-cat ?sc9)) (sem-cat ?sc10))
(ma (sem-sub ()) (ma (sem-sub {})
(referent ?r) (referent ?m)
(meaning ?m6) (meaning {(entity-type ?m person)
(count ?m one)})
(sem-cat ?sc11))) (sem-cat ?sc12))}
Fig. 11. Result of applying the unifiers constructed during the heuristic depth first
search process to the semantic pattern of the construction (left) and the semantic
source structure (right)
As we explained before, construction application consists of two steps. First,
the syntactic pattern of the construction and the syntactic source structure are
uniÔ¨Åed. Then the instantiated semantic source structure is merged with the se-
mantic pattern of the construction. In this example, the semantic source struc-
ture and the pattern are uniÔ¨Åable, therefore merge is equivalent to applying one
of their uniÔ¨Åers to the semantic source structure.
254 J. Sierra-Santib√°√±ez
The result of unifying the instantiated semantic source structure and the
instantiated semantic pattern is substitution œÑ = { ?r1 = ?r2, ?m1 = ?m2, ?sc1
= ?sc2, ?e = ?s, ?m3 = ((act ?s slide) (arg1 ?s ?a) (arg2 ?s ?o) (arg3 ?s ?r)),
?a = ?j, ?m4 = ((entity-type ?j person) (count ?j one)), ?sc7 = ?sc8, ?o =
?b, ?m5 = ((entity-type ?b block) (count ?b several)), ?sc9 = ?sc10, ?r = ?m,
?m6 = ((entity-type ?m person) (count ?m one)), ?sc11 = ?sc12 }, which makes
variables ?j, ?b and ?m, associated with the referents of units jo, bl and ma in
the semantic source structure, equal to variables ?a, ?o and ?r, associated with
the roles in the transfer to recipient event (tr) in that structure.
6 Conclusions
This paper has presented a logic programming approach to parsing and produc-
tion in Fluid Construction Grammar (FCG). It builds on previous work on the
formalisation of the unification and merge operations used in FCG in terms of
First Order Logic (FOL) uniÔ¨Åcation and search in the space of a particular set
of FOL terms called structure arrangements.
Its main contribution is to outline a method for implementing uniÔ¨Åcation and
merge based on Logic Programming and ArtiÔ¨Åcial Intelligence techniques such
as uniÔ¨Åcation and heuristic search. The formulation of the uniÔ¨Åcation and merge
problems in FCG as heuristic search problems in the space of structure arrange-
ments not only allows understanding the problems of parsing and production
with constructions in FCG as deduction problems, but also opens the door to
the application of eÔ¨Écient automated deduction techniques to these problems.
Acknowledgements. Partially supported by BASMATI MICINN project
(TIN2011-27479-C04-03) and by SGR2009-1428 (LARCA). I would like to thank
Luc Steels and Joachim De Beule for valuable comments on an earlier version of
this paper.
References
[1] Bleys, J., Stadler, K., De Beule, J.: Search in linguistic processing. In: Steels, L.
(ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Amster-
dam (2011)
[2] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraints
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[3] Goldberg, A.: A Construction Grammar Approach to Argument Structure. Univ.
Chicago Press (1995)
[4] Harnad, S.: The symbol grounding problem. Physica D 42, 335‚Äì346 (1990)
[5] Langacker, R.: Foundations of Cognitive Grammar. Stanford Univ. Press (1991)
[6] McCarthy, J.: Recursive functions of symbolic expressions and their computation
by machine. Communications of the ACM 3(4), 184‚Äì195 (1960)
[7] McCarthy, J.: Formalizing Common Sense. Papers by John McCarthy. Ablex
(1990); Lifschitz, V. (ed.)
A Logic Programming Approach to Parsing and Production in FCG 255
[8] Sierra-Santib√°√±ez, J.: First order logic concepts in Fluid Construction Grammar.
In: Biologically Inspired Cognitive Architectures 2011, pp. 344‚Äì350. IOS Press
(2011)
[9] Steels, L.: The synthetic modeling of language origins. Evolution of Communica-
tion 1(1), 1‚Äì35 (1997)
[10] Steels, L.: Constructivist development of grounded construction grammars. In:
Proceedings of the Annual Meeting of the Association for Computational Linguis-
tics Conference, pp. 9‚Äì19 (2004)
[11] Steels, L.: Modeling the Formation of Language: Embodied Experiments. In:
Evolution of Communication and Language in Embodied Agents, pp. 235‚Äì262.
Springer, Heidelberg (2010)
[12] Steels, L., De Beule, J.: Unify and Merge in Fluid Construction Grammar. In:
Vogt, P., Sugita, Y., Tuci, E., Nehaniv, C.L. (eds.) EELC 2006. LNCS (LNAI),
vol. 4211, pp. 197‚Äì223. Springer, Heidelberg (2006)
[13] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[14] Steels, L.: Design Methods for Fluid Construction Grammar. In: Steels, L. (ed.)
Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 3‚Äì36. Springer,
Heidelberg (2012)
[15] Steels, L. (ed.): Experiments in Cultural Language Evolution. John Benjamins,
Amsterdam (2012)
[16] Tomasello, M., Brooks, P.: Early syntactic development: A Construction Gram-
mar approach. In: The Development of Language, pp. 161‚Äì190. Psychology Press
(1999)
[17] van Trijp, R.: A Reflective Architecture for Language Processing and Learn-
ing. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 51‚Äì74. Springer, Heidelberg (2012)
[18] Wittgenstein, L.: Philosophical Investigations. Macmillan, New York (1953)
Computational Construction Grammar:
Comparing ECG and FCG
Nancy Chang1
, Joachim De Beule2
, and Vanessa Micelli1
1
Sony Computer Science Laboratory Paris, France
2
ArtiÔ¨Åcial Intelligence Laboratory, Vrije Universiteit Brussel, Belgium
Abstract. This chapter compares two computational frameworks devel-
oped over the last decade to support investigations into the emergence
and use of language, Fluid Construction Grammar (FCG) and Embod-
ied Construction Grammar (ECG). Both of these representational for-
malisms are rooted in the construction grammar tradition, sharing basic
assumptions about the nature of linguistic units and the crucial role
played by contextual factors. Nonetheless, they have arisen from diÔ¨Äer-
ent perspectives and with diÔ¨Äerent goals: FCG was designed to support
computational language game experiments that address the evolution
of communication in populations of robotic agents, while ECG was de-
signed to support cognitive modeling of human language acquisition and
use. We investigate how these diÔ¨Äering emphases motivated diÔ¨Äerent de-
sign choices in the two formalisms and illustrate the linguistic and com-
putational consequences of these choices through a concrete case study.
Results of this comparison sharpen issues relevant to computational con-
struction grammar in general and may hold lessons for broader compu-
tational investigations into linguistic phenomena.
1 Introduction
This chapter compares two computational formalisms developed over the last
decade: Fluid Construction Grammar (FCG) and Embodied Construction Gram-
mar (ECG). Both formalisms draw broad inspiration from construction grammar
and cognitive linguistics, sharing basic assumptions about the nature of linguis-
tic units and the crucial role played by meaning in context. But unlike most
other work in this area, both FCG and ECG aspire to provide computational
implementations of all proposed linguistic structures and processes. This formal-
ization (or operationalization) requirement reÔ¨Çects an emphasis not just on how
linguistic knowledge is represented but also on how it is used: conceptual and
linguistic structures should be seamlessly integrated with processes of language
learning and use.
Each formalism is also the centerpiece of a broader scientiÔ¨Åc framework tack-
ling similar issues, albeit from diÔ¨Äerent perspectives and with diÔ¨Äerent motiva-
tions. These may best be captured by examining the core goals and questions
driving these respective investigations:
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 259‚Äì288, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
260 N. Chang, J. De Beule, and V. Micelli
‚Äì FCG supports language game experiments that explore answers to the ques-
tion: How can communication emerge in populations of embodied agents? Its
roots are in artiÔ¨Åcial intelligence, and historically it has been oriented toward
artiÔ¨Åcial languages evolved and acquired by robotic agents. More recently,
however, it has begun to address phenomena inspired by natural languages,
as exempliÔ¨Åed by the case studies in this and other volumes.
‚Äì ECG supports cognitive modeling of human language learning and use,
within a framework that asks: What is the neural, embodied basis of thought
and language? Its roots are in cognitive science and cognitive linguistics,
though it is also motivated by psychological, biological and especially devel-
opmental considerations.
While these endeavors are theoretically compatible, they have diÔ¨Äering orienta-
tions and emphases that have shaped their respective formalizations. Some of
the resulting diÔ¨Äerences may be described as superÔ¨Åcial notational variations,
but others reÔ¨Çect more substantial divergences.
The two formalisms are thus ideal candidates for comparison. In this chapter,
we aim to identify the core diÔ¨Äerences between FCG and ECG, as well as the
open research issues suggested by these diÔ¨Äerences. We center the discussion
around a concrete comparison of how the two formalisms realize the key ideas of
construction grammar, using a case study that allows a detailed comparison of
several lexical and phrasal constructions (Sections 3-5), as well as the processing
models (Section 6) associated with each formalism. Section 7 considers how the
results of our comparison sharpen issues relevant to computational construction
grammar in general, and what lessons they may hold for broader computational
investigations into linguistic phenomena.
Shared Theoretical and Methodological Commitments. Before turning
to our case study, we brieÔ¨Çy summarize some basic theoretical commitments
shared by the two research frameworks under consideration. Broadly speaking,
both are identiÔ¨Åed with constructional, cognitive and usage-based approaches to
language. Constructions (mappings between form and meaning), are taken to be
the basic units of language [9, 10], and meanings correspond to particular ways
of conceptualizing or construing a situation [11, 12]. Language is also assumed
to be inherently embodied, grounded and communicative: language users have
sensorimotor capacities that shape their conceptual categories, and they are
grounded in particular environments with speciÔ¨Åc communicative goals.
Most relevantly, both formalisms were designed to support working systems
that actually instantiate structures and processes that are elsewhere typically de-
scribed only discursively. This commitment to supporting language use means
that it is not suÔ¨Écient merely to represent linguistic knowledge in formal no-
tation; rather, the processes that interact with that knowledge must also be
speciÔ¨Åed, and considerations related to processing (e.g., search space, storage,
eÔ¨Éciency) must guide representational choices at the level of both individual
constructions and the formal notation itself.
Computational Construction Grammar 261
Linguistic representations in both frameworks are also assumed to interact
closely with structures in other domains, including in particular embodied, sit-
uational and world knowledge. The two frameworks diÔ¨Äer in the details of how
such interactions are modeled, and even in how terms like embodiment are used.1
For the pursposes of this chapter, however, we focus on the speciÔ¨Åcally linguistic
knowledge expressed by the two grammatical formalisms and their mechanisms
of use. Both frameworks take these to be conceptually distinguishable from the
details of sensorimotor representations; world (ontological) knowledge; general
mechanisms of inference and belief update; and speciÔ¨Åc mechanisms of contex-
tual grounding and reference resolution. We will also refrain from addressing
in detail how language learning is modeled in each framework, though we will
highlight some connections to these topics where relevant.
This chapter is not intended as a comprehensive description of either formal-
ism; this volume and [20] provide a detailed introduction to FCG, and overviews
of ECG and its associated research framework can be found elsewhere [1, 4, 7].
But to ground our discussion, in the sections to follow we introduce the notational
basics of each, suÔ¨Écient for discussing the noun phrase the mouse (also addressed
in [21]). Despite the relative simplicity of this example, the side-by-side compar-
ison it aÔ¨Äords helps reveal some fundamental design issues and diÔ¨Äerences.
2 Informal Constructional Analysis of the Mouse
A traditional analysis of the phrase the mouse might identify a determiner (the),
a noun (mouse), and a noun phrase (NP) combining the determiner and noun
in that order. For a construction-based approach, it is crucial to consider the
utterance‚Äôs meaning as well: a speaker uttering ‚Äúthe mouse‚Äù is engaging in an
act of reference, picking out an individual mouse uniquely identiÔ¨Åable to the
hearer in the discourse context. A straightforward constructional analysis might
have the structure shown in Figure 1, with three constructions:
‚Äì The: The word form the constrains the referent to be uniquely identiÔ¨Åable
to the hearer in context; other determiners may restrict features like number
(some mice) or proximity (these mice).
‚Äì Mouse: The word form mouse speciÔ¨Åes that the referent‚Äôs ontological cat-
egory is a mouse. It might also specify that the referent refers to a single
thing (in contrast to the greater quantity speciÔ¨Åed by mice), or that it is an-
imate (or not, in the case of a computer mouse). Other nouns may constrain
additional qualities of the referent (e.g., semantic role, gender, countability).
‚Äì DeterminedNP: This construction has two constituents, corresponding to
the two constructions above. It imposes a word order constraint (the must
precede mouse), and its meaning is a referent in context‚Äîin fact the same
1
Broadly speaking, embodiment in FCG emphasizes the constraints of using physically
embodied agents, while embodiment in ECG emphasizes the constraints of the human
sensorimotor system.
262 N. Chang, J. De Beule, and V. Micelli
FORM MEANING
Referent
ont-category mouse
quantity 1
givenness uniquely-identifiable
DETERMINEDNP
THE
the Referent
givenness uniquely-identifiable
mouse MOUSE
Referent
ont-category mouse
quantity 1
Fig. 1. A graphical depiction of one analysis of example phrase. Constructions (in the
center) link the domains of form (left) and meaning (right). Each of the constructions
shown here (the DeterminedNP construction and its two constituents, the The and
Mouse constructions) contributes to and constrains the particular referent speciÔ¨Åed
by the phrase.
referent constrained by the two constituents. Here, the relevant constraints
do not conÔ¨Çict; in general, such compatibility or agreement in features must
be met between determiners and nouns (hence *a mice, *these mouse).
The constructions in the middle of the Figure 1 reÔ¨Çect the phrase‚Äôs constituent
structure, mirroring that of a traditional syntactic parse tree (based on a phrase
structure analysis). (See Section 5.3 for an alternative dependency analysis.)
However, since these are not just syntactic symbols but constructions, each con-
struction also has a link (shown by horizontal bars) to form (on the left) and
meaning (on the right). The form domain contains the relevant word forms,
where the dotted arrow indicates the time line (and therefore word order).
The meaning domain contains several structures labeled Referent, each listing
features constrained to particular values (where ont-category is an abbreviation
for ontological category). Essentially, this structure summarizes any information
that is important for determining the actual referent of an expression in the
current context. (Determination in both formalisms is further discussed in section
3.3.) The double-headed arrows between the Referents indicate that their values
are shared (with values that originate non-locally, i.e. through such a binding,
shown in italics). The dashed border of the two Referent structures contributed
by the lexical constructions indicates a slightly diÔ¨Äerent relationship than that
between the DeterminedNP construction and its Referent; we return to this
point below.
As should be apparent, even a noun phrase as simple as the mouse involves
many representational choices, with reasonable alternatives varying in both the
Computational Construction Grammar 263
complexity of the structures deÔ¨Åned and the generality of the phenomena they
account for. Our goal here is not to argue for the particular analysis adopted
here as the best or most general one possible; rather, we focus on the basic
representational toolkit involved for expressing a variety of concepts and relations
and compare those available in the ECG and FCG formalisms.
3 Formalizing Lexical Constructions
Diving now into the formal constructional analysis, we consider in this section
how the lexical constructions for our example are deÔ¨Åned in each of the two
formalisms. We begin with the mouse construction shown in Figure 2. Both
structures capture a relatively straightforward pairing of form (the orthographic
string ‚Äúmouse‚Äù) and meaning (the mouse ontological category associated with a
referent, whose quantity is additionally speciÔ¨Åed as 1). They also include gram-
matical information (e.g., that mouse is a singular noun), though they diÔ¨Äer in
precisely how this information is expressed.2
;; "mouse" in FCG (template-based)
(def-lex-cxn Mouse-Cxn
(def-lex-cat Mouse-Cxn
:sem-cat ((schema ?ref [ReferentDescriptor])
(quantity ?ref 1))
:syn-cat ((schema ?w [WordDescriptor])
(type Noun)
(number singular)))
(def-lex-skeleton Mouse-Cxn
:meaning (== (ont-category ?ref [mouse]))
:form (== (orth ?w "mouse"))))
// "mouse" in ECG
construction Mouse-Cxn
subcase of Noun
constructional
self.number ‚Üê singular
form : Word
self.f.orth ‚Üê ‚Äúmouse‚Äù
meaning
evokes ReferentDescriptor as ref
ref.ont-category ‚Üê @mouse
ref.quantity ‚Üê 1
Fig. 2. Lexical constructions for mouse in FCG (left) and ECG (right)
A few diÔ¨Äerences in basic format are apparent even at Ô¨Årst glance. Roughly
speaking, the format of FCG reÔ¨Çects the inÔ¨Çuence of the Lisp programming lan-
guage: internal structure is indicated with parenthesized lists employing preÔ¨Åx-
list notation, and variable names are marked with a leading question mark. In
contrast, the format of ECG reÔ¨Çects the inÔ¨Çuence of constraint programming
languages and inheritance-based ontologies: special keywords (in boldface) are
used to indicate internal structure and express inheritance relations and other
constraints, and dotted slot chains are used to refer to non-local structures.
2
Both distinguish a language-speciÔ¨Åc number categorization (in English, nouns can be
either singular or plural) from a more general concept of number, which for clarity
will be called quantity in the notation.
264 N. Chang, J. De Beule, and V. Micelli
The sections below take a closer look at the two constructions in Figure 2. To
ease comparison, we focus on how each captures the informal linguistic analysis
described in the previous section, deferring until Section 6 the details of how
constructions are used during language processing.
3.1 Nominal Constructions in FCG
The FCG deÔ¨Ånition for mouse shown on the left in Figure 2 uses the def-lex-cxn
template for deÔ¨Åning lexical units (described in [20]). This notation organizes the
various elements of the informal analysis in two parts. First, the def-lex-cat
clause speciÔ¨Åes the linguistic categories (both semantic and syntactic) associated
with mouse: a variable ?ref is associated with the schema ReferentDescriptor
and the quantity 1, and a variable ?w is associated with the schema Word, the type
Noun and the number singular. Second, the def-lex-skeleton clause speciÔ¨Åes
the ontological category (where square brackets on [mouse] denote reference to
an ontology item) and orthographic string.
In fact, this template is an abbreviation for a more elaborate ‚Äúnative‚Äù FCG
deÔ¨Ånition; we show the expanded version in Figure 3. Both styles of FCG deÔ¨Å-
nition contain the same information, but the template-based construction omits
details shared with other lexical constructions, allowing a more concise deÔ¨Åni-
tion. As should become apparent, the template-based version is closer to the
level of abstraction used in the corresponding ECG deÔ¨Ånition, but we describe
the expanded version here to shed some light on how these structures are used.
The full lexical deÔ¨Ånition consists of two main sections (or poles) separated by
a double-headed arrow (<‚Äì>), corresponding to the meaning (or semantic) and
form (or syntactic) domains. Each pole includes two units, one named ?top-unit
and one named ?mouse-unit (where the leading question mark indicates that
these are variable names); this latter unit is a J-unit (as indicated by the op-
erator J). These units specify the constraints and categorizations relevant to
each domain, but they diÔ¨Äer in the kinds of information they typically contain.
J-units generally contain speciÔ¨Åcally linguistic information, typically expressed
using semantic and syntactic categories (in the sem-cat and syn-cat lists, re-
spectively). Other (‚Äúregular‚Äù) units, like ?top-unit here) tend to be based on
perceptual or cognitive categorizations (here, the ontological category and the
perceived word string).3
3.2 Nominal Constructions in ECG
We now turn to the right side of Figure 2, which shows a simple ECG con-
struction for mouse. The high-level structure of the construction includes three
blocks, where keywords (in boldface) indicate special terms and structures. The
constructional block contains information relevant to the construction as a whole,
3
Regular units and J-units also behave diÔ¨Äerently during language processing, where
the J-operator and other notations (such as the TAG and footprints) notations play
a special role. Language processing will be discussed in more detail in Section 6.1.
Computational Construction Grammar 265
(def-cxn Mouse-Cxn
((?top-unit (TAG ?meaning
(meaning (== (ont-category ?ref [mouse]))))
(footprints (==0 Mouse-Cxn)))
((J ?mouse-unit ?top-unit)
?meaning
(sem-cat ((schema ?ref [ReferentDescriptor])
(quantity ?ref 1)))
(footprints (Mouse-Cxn))))
<-->
((?top-unit (TAG ?form
(form (== (orth ?w "mouse"))))
(footprints (==0 Mouse-Cxn)))
((J ?mouse-unit ?top-unit)
?form
(syn-cat ((schema ?wd [WordDescriptor])
(type Noun)
(number Singular)))
(footprints (Mouse-Cxn))))))
Fig. 3. Lexical construction for mouse in FCG, expanded form
while the form and meaning blocks (or poles) contain information relevant to
each domain. These poles are themselves structured, and can be referenced and
constrained within the construction. The term self allows reference to the con-
struction being deÔ¨Åned, and self.f and self.m refer to the construction‚Äôs form and
meaning poles, respectively.
The Mouse construction is deÔ¨Åned as a subcase, i.e. a more speciÔ¨Åc instance,
of the Noun construction. In fact, ECG constructions are all deÔ¨Åned in a multiple
inheritance lattice, and a separate lattice deÔ¨Ånes represent schematic form and
meaning categories, or schemas. (Both inheritance and schemas will be discussed
further in Section 4.) Accessible structures can be constrained to instantiate
particular schema categories. Each block contains various constraints that apply
to the relevant domain, drawn from a Ô¨Åxed set of possibilities. We highlight a
few of the notations that express these constraints:
‚Äì Category constraints are indicated with a colon (e.g., the form pole must be
a Word), and role-Ô¨Åller constraints of the form x ‚Üê‚àí y indicate that role (or
feature) x is Ô¨Ålled by the (atomic) value y (e.g., the form pole is associated
with the orthographic string shown).
‚Äì The evokes ReferentDescriptor as ref declaration indicates that there is an in-
stance of category ReferentDescriptor present, accessible using its local name
ref. Subsequent constraints specify that its feature ont-category be Ô¨Ålled by
@mouse and its quantity set to 1. (Like the square brackets in the FCG deÔ¨Åni-
tion, the @ symbol indicates reference to an external conceptual ontology.)
In short, the construction indicates that the Mouse-Cxn is a kind of Noun;
asserts constraints on the constructional (or grammatical) number feature and
266 N. Chang, J. De Beule, and V. Micelli
the particular orthographic form; and evokes a ReferentDescriptor of a speciÔ¨Åed
ontological category and quantity.
For comparison, it may be useful to see how the ECG construction deÔ¨Ånition
is expanded during processing. Figure 4 shows the corresponding feature struc-
ture representation. Note that the feature structure for Mouse-Cxn also contains
two subsidiary feature structures for the Word and ReferentDescriptor categories
mentioned in the deÔ¨Ånition. As discussed in Section 4.2 and illustrated in Fig-
ure 6 below, these additional schematic structures are also deÔ¨Åned as part of the
ECG formalism.
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
Mouse
number : singular
f :

Word
orth : ‚Äùmouse‚Äù

m :
ref :

ReferentDescriptor
ont-category : @mouse
quantity : 1

‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
Fig. 4. Feature structure corresponding to the ECG mouse construction
3.3 Determiners in ECG and FCG
The basic lexical constructions just deÔ¨Åned are easily modiÔ¨Åed for the determiner
the. In accord with earlier accounts (e.g. [1]), we assume that determiners provide
cues that help a hearer identify a referent in the discourse context. Thus, like
the mouse construction, they constrain a referent, but instead of specifying its
ontological category, they typically constrain features like number, gender and
proximity. In the case of the, the referent is asserted to be uniquely identiÔ¨Åable.
The constructions in Figure 5 are structurally similar to the mouse construc-
tions deÔ¨Åned above. Each speciÔ¨Åes that the is a Determiner (as the syntactic
category (type Determiner) in FCG and the subcase of Determiner constraint
in ECG); each speciÔ¨Åes the relevant orthographic string; and each speciÔ¨Åes a
value for the referent‚Äôs givenness feature (in FCG using the predicate (givenness
?ref uniquely-identifiable), and in ECG with the constraint ref.givenness
‚Üê‚àí uniquely-identifiable).
The two formalisms diÔ¨Äer slightly in how they handle the feature of number.
The FCG deÔ¨Ånition adds a number category to its list of syntactic categories,
whose value remains underspeciÔ¨Åed (as indicated by the variable ?number). The
ECG deÔ¨Ånition does not mention number explicity. Note that ECG deÔ¨Ånitions
for determiners like the plural some or singular a) would include a constructional
block with a constraint on the number feature, thus more closely resembling the
mouse construction.
Computational Construction Grammar 267
;; "the" in FCG (template-based)
(def-lex-cxn The-Cxn
(def-lex-cat The-Cxn
:sem-cat ((schema ?ref [ReferentDescriptor]))
:syn-cat ((schema ?w [WordDescriptor])
(type Determiner)
(number ?number)))
(def-lex-skeleton The-Cxn
:meaning (== (givenness ?ref uniquely-identifiable))
:form (== (orth ?w "the"))))
// "the" in ECG
construction The-Cxn
subcase of Determiner
form : Word
self.f.orth ‚Üê ‚Äúthe‚Äù
meaning
evokes ReferentDescriptor as ref
ref.givenness ‚Üê uniquely-identifiable
Fig. 5. Lexical constructions for ‚Äòthe‚Äô in FCG (left) and ECG (right)
4 A First Comparison
The parallel deÔ¨Ånitions of lexical constructions in FCG and ECG given in Sec-
tion 3 are based on the same linguistic analysis and designed to maximize simi-
larity across the two formalisms. It is not entirely surprising, then, that they have
much in common: each represents the basic forms and meanings involved, as well
as additional grammatical information associated with reference, as expressed by
common nouns (like mouse) and determiners (like the).
But these examples also exhibit some striking diÔ¨Äerences. Perhaps the most
important distinction between the formalisms is the treatment of categories and
inheritance. ECG structures are all deÔ¨Åned within inheritance lattices specifying
constructional and other relationships. Many ECG notations thus allow refer-
ence to other existing structures, for example to inherit features and values, or
to assert values or bindings on connected structures. FCG constructions, on the
other hand, rely on category lists associated with each domains; each construc-
tion is thus relatively stand-alone, and deÔ¨Åned independently of other structures
that may contain similar information. In the sections below we discuss several
representational consequences of this fundamental diÔ¨Äerence.
4.1 Inheritance and Categorization
Categories play a prominent role in most linguistic theories: they capture gener-
alizations about shared structure and behavior across diÔ¨Äerent linguistic units.
Part of speech categories, semantic (or thematic) roles, lexical subcategorization
types, speech act types, and phonological categories are all well-established ways
of carving up various linguistic domains into groups exhibiting similar proper-
ties. Both ECG and FCG allow such categories to be expressed, but they diÔ¨Äer
in the approaches taken, as well as the degree to which the relationships among
categories is made explicit.
Inheritance hierarchies in ECG. The ECG approach to categories is based on
inheritance networks, where shared properties are expressed at the highest level
of generalization possible and inherited by subsidiary categories and instances.
268 N. Chang, J. De Beule, and V. Micelli
That is, ECG constructions are deÔ¨Åned (using the subcase of relation) within a
multiple inheritance hierarchy (or lattice); structures and constraints deÔ¨Åned in
a base (or parent) construction are inherited by and accessible to their subcases,
and thus need not be explicitly speciÔ¨Åed. The subcase can impose additional
constraints, or reÔ¨Åne existing ones.
construction Mouse
subcase of SingularNoun
form: Word
self.f.orth <- "mouse"
meaning
ref.ont-category <- @mouse
general construction Singular
constructional: AgreementFeatures
self.number <- singular
general construction SingularNoun
subcase of Noun, Singular
general construction Noun
constructional: NominalFeatures
form
meaning
evokes ReferentDescriptor as ref
schema NominalFeatures
subcase of AgreementFeatures
case
gender
schema AgreementFeatures
number
person
schema ReferentDescriptor
ont-category
givenness
schema Word
orth
phon
schema Mouse
construction The
subcase of Determiner
form: Word
self.f.orth <- "the"
meaning
ref.givenness <- uniquely-identifiable
construction Determiner
constructional: NominalFeatures
form
meaning
evokes ReferentDescriptor as ref
Fig. 6. A portion of the ECG construction lattice for the lexical items in the ex-
ample, showing both constructions (white boxes) and schemas (shaded boxes). (Solid
arrows indicate subcase (or inheritance) relations, while dotted lines indicate other
links through the constructional, form or meaning domains.)
A fragment of the constructional lattice relevant to the lexical constructions
in our example is shown in Figure 6, where both the Mouse and The con-
structions have been redeÔ¨Åned to exploit inheritance. Focusing on the white
construction boxes, we can see that this version of the Mouse construction is
deÔ¨Åned as a subcase of the SingularNoun construction, which in turn is a
subcase of both Noun and Singular. These abstract ancestral constructions‚Äî
marked general to indicate their lack of concrete form constraints‚Äîcontain some
constraints shared across noun constructions (the evokes statement and number
‚Üê‚àí singular constraint), leaving only the most speciÔ¨Åc constraints for the Mouse
construction.
These examples illustrate how certain linguistic generalizations can be con-
cisely captured through inheritance. Though not shown, the construction for the
irregular plural mice inherits from the Plural and PluralNoun constructions,
Computational Construction Grammar 269
which are analogous to Singular and SingularNoun, respectively. Similarly,
determiners that specify number (such as these or a) are deÔ¨Åned as subcases of
both Determiner and the appropriate number-specifying construction.4
Categories in FCG. Categories are a fundamental notion in FCG, expressed
as predicates in the sem-cat and syn-cat lists. Constructions that have such
predicates in common implicitly form a category: hence both mouse and the are
associated with the syntactic category schema, which is further speciÔ¨Åed to be
a WordDescriptor, and they also both include the syntactic category number.
Inheritance networks like those of ECG have not yet been much explored in
FCG: there is no explicit notion of inheritance for constructions, meaning or
form components, or semantic and syntactic categories. Recent developments,
however‚Äîsuch as the use of templates [20] and distinctive feature matrices [22]‚Äî
can be seen as moving in this direction.5
Templates, for example, provide a means
of capturing similarities across constructions, allowing a more concise, uniform
declaration of constructions (as illustrated by the alternate deÔ¨Ånitions for mouse
above). Note, however, that templates currently serve mainly as an abbreviation:
they do not specify inheritance relationships. That is, there is no mechanism for
allowing one construction to refer to or inherit from another, and more general
lexical categories like Noun are not themselves deÔ¨Åned as structures that can
inherit features.
Of course, the use of templates in FCG is relatively recent and their precise
form is still under development. Thus it may be possible to extend the template
approach (as proposed in Section 5) to exploit the beneÔ¨Åts of inheritance and
type hierarchies. These beneÔ¨Åts become especially important as grammars grow
larger: keeping track of the various dependencies between constructions for any
non-trivial language phenomenon is a tedious undertaking. Adopting approaches
based on inheritance would enable more concise grammars that reduce errors.
4.2 Form and Meaning Representations
The lexical examples we have seen also illustrate diÔ¨Äerent approaches to repre-
senting the domains of form and meaning. Organizationally, FCG distinguishes
speciÔ¨Åcally linguistic categorizations (as listed in sem-cat and syn-cat) from
the concrete forms and meanings taken to be based on perceptual or cognitive
categorizations (associated with the meaning and form parameters. ECG con-
structions do not explicitly represent this diÔ¨Äerence in the notation itself (except
for the use of @ to denote ontological categories).
4
Inheritance is only one way of capturing complex category structure of the kind
described by [11], and the particular multiple inheritance lattices used by ECG are
intended only as an approximation. While current versions of ECG allow overriding of
inherited constraints and the incorporation of some probabilistic information, further
reÔ¨Ånements would be needed to handle categories including scalar and continuous
quantitative values, prototype structures and other aspects of human categorization.
5
See also [5], which describes FCGlight (a core subset of FCG that uses of lattices of
constructions); and [2].
270 N. Chang, J. De Beule, and V. Micelli
A more important diÔ¨Äerence lies in how these categories are represented. As
noted before, all categorizations (linguistically speciÔ¨Åc or not) in FCG are ex-
pressed in predicate-argument format, and are independently deÔ¨Åned as part of
each relevant consruction. The particular style of semantic representation can
vary; though the examples shown in this section have a declarative Ô¨Çavor (fol-
lowing the informal analysis presented in Section 2), other studies show how it
is also possible to adopt procedural semantics [19] or frame semantics [15].
In ECG, both forms and meanings are represented using a special-purpose
schema formalism, similar to that used for constructions and also deÔ¨Åned within
an inheritance lattice (see Figure 6 for some examples, shown in shaded boxes).
ECG schemas resemble depictions of semantic frames [8] and image schemas in
the literature, and are similarly used to bring together a set of associated and
interdeÔ¨Åned roles or features comprising a complex concept. The roles deÔ¨Åned in
a schema can be referred to and constrained by other schemas and constructions.
Hence, both lexical constructions assert form constraints on the orth role of the
Word schema, as well as meaning constraints on the roles of the ReferentDescriptor.
As with constructions, we see that ECG emphasizes the interdeÔ¨Åned nature
of constructions and their associated forms and meanings. Separately deÔ¨Åned
schemas capture various linguistic generalizations and expectations, allowing
brevity in deÔ¨Ånitions and enforcing some consistency across constructions. FCG
constructions, meanwhile, each independently deÔ¨Åne their relevant predicates,
which are therefore less constrained. This tradeoÔ¨Ä‚Äîbetween explicit represen-
tation of generalizations on the one hand, and freedom of expression on the
other‚Äîwill manifest itself in several other ways to be discussed.
4.3 Constructional Features and Grammatical Categories
The two formalisms diÔ¨Äer, Ô¨Ånally, in how certain kinds of grammatical informa-
tion are treated. SpeciÔ¨Åcally, while all categories and constraints in FCG must be
in either the meaning or form pole, ECG allows some information to be expressed
in the constructional lattice:
‚Äì Constructional inheritance: Lexical and grammatical categories (like noun
and verb) can themselves be represented as constructions and associated with
speciÔ¨Åc roles and values. Thus, the Mouse construction can be deÔ¨Åned as a
subcase of the SingularNoun construction, inheriting relevant properties
it may share with other singular nouns.
‚Äì Constructional features: The constructional domain itself can be deÔ¨Åned as
having particular features, often inherited from ancestral types. In Figure 6,
AgreementFeatures and NominalFeatures are schemas in the constructional do-
main that list various grammatical features. These are not strictly about
either the form or meaning domain; rather, they are associated with the
constructional connection between the two.
Computational Construction Grammar 271
In both cases above, the equivalent information can be expressed in FCG but
must be explicitly included in every constructional deÔ¨Ånition (unless the tem-
plate system could be extended to do this, though this would be a non-trivial
modiÔ¨Åcation).
In each formalism, it remains largely at the discretion of the grammar writer
how to decide precisely which features ought to be deÔ¨Åned and what domain
they belong in.
5 Constituent Structure and Agreement
We now turn our attention to the DeterminedNP construction. This construc-
tion combines a determiner and a noun into a larger phrasal unit. Combining
smaller units into larger chunks and phrases and thus exhibiting hierarchical con-
stituent structure is a deÔ¨Åning feature of grammatical constructions. Like lexical
constructions, such constructions can impose constraints in both the form and
meaning domains, such as word order (form) or role-Ô¨Åller bindings (meaning).
They may also enforce compatibilities, or agreement, across constituents. Both
ECG and FCG have ways of introducing constituents, specifying relational con-
straints and enforcing agreement.
5.1 Determined NPs in ECG
The DeterminedNP construction in Figure 7 shows how determined noun
phrases with constituent structure might be deÔ¨Åned in ECG. The intuition be-
hind the analysis is that such phrases draw on both determiners and nouns to
provide crucial information for constraining an act of reference, resulting in a sin-
gle larger unit (as in our informal analysis). Like lexical constructions, phrasal
constructions have a form and meaning pole; they also, however, have a con-
structional block within which constructional constituents as well as additional
constraints‚Äîfor example, to enforce agreement‚Äîare speciÔ¨Åed.
Here, the two constituents have local variable names det and nom, and they are
typed respectively as Determiner and Noun. These constituent names allow
simple access to their respective form and meaning poles. In the form block,
their form poles (det.f and nom.f) are speciÔ¨Åed as coming in a particular order
(expressed using the before relation). The meaning of the overall expression is
itself constrained to be a ReferentDescriptor‚Äîwhich, recall, is also the type of
the ref argument evoked in the meanings of each of the two constituents. That
is, all three (the composite structure and each of the two constituents) have
accessible ReferentDescriptors. Thus, the last two constraints simply identify the
evoked referents of the constituents with the meaning of the overall phrasal
construction. Note that these constraints enforce all the roles deÔ¨Åned within the
ReferentDescriptor structures to have the same value, including the ont-category,
givenness, and quantity roles. This can be seen as a kind of semantic agreement:
the referent that all of these constructions describes is the same, and therefore
the constraints that apply to it as also the same.
272 N. Chang, J. De Beule, and V. Micelli
construction DeterminedNP
constructional
constituents
det : Determiner
nom : Noun
constraints
self.number ‚Üê‚Üí det.number
self.number ‚Üê‚Üí nom.number
form
det.f before nom.f
meaning : ReferentDescriptor
self.m ‚Üê‚Üí det.ref
self.m ‚Üê‚Üí nom.ref
Fig. 7. A complex DeterminedNP construction
Turning to the constructional domain, we see another kind of agreement en-
forced by the constraints in the constructional block. These simultaneously en-
code agreement between the two constituents‚Äô number features (notated here as
det.number and n.number) and ensure that this value is shared by the noun phrase
(self.number). All of these require that these constructions are typed so that they
have an accessible number feature (in our analysis, their constructional poles are
all constrained to be of type NominalFeatures). This agreement might be seen as
the more prototypical grammatical agreement, based on explicitly grammatical
features like number that may not have any basis in the meaning domain alone.6
5.2 Determined NPs in FCG
An account of how determined noun phrases might be handled in FCG using
phrasal construction templates is given in [20]. This section provides an alterna-
tive analysis that is as close as possible to the one given for ECG, while remaining
within the limits of what is currently possible in FCG. Besides enabling a more
detailed comparison, this variation is also intended to add another perspective
to the relatively recent development of FCG templates that may help shed light
on the beneÔ¨Åts and drawbacks of diÔ¨Äerent approaches.
Concretely, we deÔ¨Åne a phrasal construction for determined noun phrases
in Figure 8, where the Ô¨Årst deÔ¨Ånition expands (using the appropriate tem-
plate code for def-phrasal-cxn) to the second. Like the lexical constructions,
the DeterminedNP construction has both meaning and form components, each
including both regular units (?top-unit, ?determiner, and ?noun) and a J-
unit. The basic idea of constituency is captured by the speciÔ¨Åcation that the
6
Of course, it is not always possible to draw a neat boundary between the semantic and
constructional domains, especially with respect to a linguistically oriented schema
like ReferentDescriptor.
Computational Construction Grammar 273
?top-unit lists the other two regular units in its subunits, corresponding re-
spectively to a determiner and a noun (again, in both the meaning and form
domains).
On the syntactic side, the construction furthermore speciÔ¨Åes the constraint
(before ?det ?N) on the word order of its constituents. On the semantic side it
requires that the ReferentDescriptor schemas of both constituents are
the same (through a variable equality). Agreement in number is also achieved
through variable equalities.
;; DeterminedNP (template-based definition)
(def-phrasal-cxn DeterminedNP
:syn-cat ((type DeterminedNP) (number ?number))
:sem-cat ((schema ?ref [ReferentDescriptor]))
:constituents
((lex-cxn ?Determiner
:syn-cat ((type Determiner) (number ?number))
:sem-cat ((schema ?ref [ReferentDescriptor]))
:meaning ((givenness ?ref ?givenness))
:form ((orth ?det ?orth-det)))
(lex-cxn ?Noun
:syn-cat ((type Noun) (number ?number))
:sem-cat ((schema ?ref [ReferentDescriptor]))
:meaning ((ont-category ?ref ?ont-cat))
:form ((orth ?N ?orth-N))))
:form ((before ?det ?N)))
;; DeterminedNP (expanded definition)
(def-cxn DeterminedNP
((?top-unit (footprints (==0 DeterminedNP))
(sem-subunits (?Determiner ?Noun)))
(?Determiner
(meaning (== (giveness ?ref ?giveness)))
(sem-cat (==1 (schema ?ref [ReferentDescriptor]))))
(?Noun
(meaning (== (ont-category ?ref ?ont-cat)))
(sem-cat (==1 (schema ?ref [ReferentDescriptor]))))
((J ?DeterminedNP ?top-unit (?Determiner ?Noun))
(sem-cat ((schema ?ref [ReferentDescriptor])))))
<-->
((?top-unit
(TAG ?form (form (== (before ?det ?N))))
(footprints (==0 DeterminedNP))
(syn-subunits (?Determiner ?Noun)))
(?Determiner
(form (== (orth ?det ?orth-det)))
(syn-cat (==1 (type Determiner)
(number ?number))))
(?Noun
(form (== (orth ?N ?orth-det)))
(syn-cat (==1 (type Noun) (number ?number))))
((J ?DeterminedNP ?top-unit (?Determiner ?Noun))
?form
(syn-cat ((type DeterminedNP) (number ?number))))))
Fig. 8. DeterminedNP construction in FCG, both template and expanded versions
274 N. Chang, J. De Beule, and V. Micelli
5.3 Comparing Complex Constructions
The two approaches to representing complex constructions demonstrated in the
preceding sections are both capable of expressing constituency, word order and
agreement. They diÔ¨Äer, however, in several key respects.
First, as elsewhere, the ECG formalism avails itself of type lattices for both
constructions and schemas. Thus, various constraints require that relevant fea-
tures are deÔ¨Åned and accessible for a given structure (i.e., a slot chain like
det.number implies that det is deÔ¨Åned as having inherited a number role). This
stands in sharp contrast with FCG, which does not require typing of this kind:
previously unspeciÔ¨Åed features are added during processing if not already de-
Ô¨Åned, and only if it is explicitly indicated that this should be the case.
The less type-constrained approach of FCG may be seen as a double-edged
sword: while it leaves more freedom of choice, it also requires that the gram-
mar writer maintain the soundness of his or her grammars and ensure that the
relevant semantic and syntactic categories of constituent units are percolated
properly to newly created units. For instance, although the ?DeterminedNP in
the DeterminedNP construction unit is speciÔ¨Åed as an instance of the
ReferentDescriptor schema, neither its givenness or ont-category values
are speciÔ¨Åed. These could be inferred from its constituents, and the template
could perhaps be changed to do this automatically, but again, doing so would
be far from trivial. In contrast, ECG makes some structural assumptions that
allow certain constraints to be succinctly stated, though possibly at the cost
of Ô¨Çexibility. Thus the identiÔ¨Åcation of the various ReferentDescriptors allows all
their roles to be bound with one constraint, both across constituents and with
the overall resulting construction.
Second, the two formalisms allow somewhat diÔ¨Äerent options with respect to
how particular kinds of features are expressed. As noted earlier, grammatical
features and categories are typically expressed in the constructional domain in
ECG (though as demonstrated above, agreement can also be enforced just in
the form or meaning domain). As with the lexical constructions, FCG tends to
express such grammatical information by including it as a syntactic category.
This diÔ¨Äerence may not ultimately aÔ¨Äect expressive power, but it does reÔ¨Çect
diÔ¨Äerent theoretical views of particular linguistic concepts.
6 Processing
Both frameworks under comparison are committed to the idea that grammatical
formalisms should do more than just describe language: they should also support
processes of language use. In this section we compare how processes of language
use interact with the linguistic representations encoded by the two grammatical
formalisms we have described.
Computational Construction Grammar 275
6.1 Parsing and Production in FCG
The FCG formalism was designed to support processes of both parsing (mapping
from form to meaning) and production (mapping from meaning to form). These
processes have been described in detail elsewhere; we review them brieÔ¨Çy here.
The internal structure of the FCG construction reÔ¨Çects a number of sym-
metries in how the diÔ¨Äerent components are used during language processing,
depending on whether parsing or production is performed. In particular:
‚Äì Each pole corresponds to the input to one process and to the output of the
other: an utterance representation in the form pole is the input to parsing
and the output of production, and vice versa for meaning representations in
the meaning pole.
‚Äì The regular units and J-units together specify constraints and categoriza-
tions relevant to each domain, but they behave diÔ¨Äerently with respect
to the match and merge operations at the core of language processing in
FCG. BrieÔ¨Çy, matching is used to test whether a transient structure Ô¨Åts
(i.e., matches) a given construction; it thus acts as a Ô¨Ålter on applicable
constructions; merging then eÔ¨Äects the construction‚Äôs application and con-
tributes additional information. Regular units in the input pole are matched,
and thus are typically used to select which constructions to apply. J-units
and regular units in the output pole are merged and thus provide additional
constraints and categorizations.
In both processes, constructions operate on a transient linguistic structure. Be-
fore processing starts, the transient structure is initialized with the meaning that
needs to be verbalized (production), or with the form that needs to be parsed
(parsing); this structure is then gradually transformed to the desired output
structure. We describe both processes for our example below.
Parsing. The aim of the parsing process is start from an empty meaning and
gradually add content until a full meaning speciÔ¨Åcation (and a complete parse)
is achieved. The initial transient structure for parsing the mouse is as follows:
((top))
<-->
((top (form ((orth W1 "the") (orth W2 "mouse")
(before W1 W2)))))
The form side of the linguistic structure speciÔ¨Åes a single constituent named top,
containing three predicates that together fully specifying the string ‚Äúthe mouse‚Äù.
These predicates include the constants W1 and W2 representing the actual words.
The application of the mouse-cxn to this structure is licensed through the
match and merge operations mentioned above. The syntactic side of the con-
struction is matched against the syntactic side of the transient structure (exclud-
ing J-units), resulting in a set of bindings for the variables in the construction.
276 N. Chang, J. De Beule, and V. Micelli
The features marked by the special TAG operator (e.g., the meaning and form
features in the mouse-cxn of Figure 2) cause the tag-variable (e.g., ?meaning
and ?form) to be bound to the matched set of feature values.
In the example, the mouse-cxn is triggered by the predicate (== (orth
?word "mouse")) in its top unit, where the includes operator == indicates that
other components besides the speciÔ¨Åed meaning are also allowed. The construc-
tion therefore matches the initial structure with the following bindings: ‚Äò[?top-
unit/top, ?form/(form ((orth W1 ‚Äúmouse‚Äù))),?w/W1].7
The merge operation then results in a new, modiÔ¨Åed transient linguistic struc-
ture that is the union of the matched structure with the additional constraints
speciÔ¨Åed in the construction. Merging in FCG thus roughly corresponds to uniÔ¨Å-
cation in ECG and other uniÔ¨Åcation- or constraint-based formalisms. Given the
match-bindings obtained earlier, both sides of the mouse-cxn also merge with
the transient linguistic structure.
In parsing, the resulting structure is as below:
((top (subunits (mouse-unit)))
(mouse-unit
(meaning ((ont-category ?ref-1 [mouse])))
(sem-cat ((schema ?ref-1 [ReferentDescriptor])
(quantity ?ref-1 1)))))
<-->
((top (form ((orth W1 "the") (before P1 W1 W2)))
(subunits (mouse-unit)))
(mouse-unit
(form ((orth W2 "mouse")))
(syn-cat ((schema W2 [WordDescriptor])
(type Noun)
(number singular)))))
Note that the transient structure now includes a new unit named mouse-unit
on each side, corresponding to the constructional J-unit. This new unit includes
the tagged form predicate matched by the mouse-cxn, and its meanings have
additional semantic categories as speciÔ¨Åed by the mouse-cxn)
Production. Production in FCG is entirely analogous to parsing, but with the
role of the poles reversed. The initial structure for producing our example is as
follows:
((top (meaning
((ont-category Ref [mouse])
(giveness Ref uniquely-identifiable)))))
<-->
((top))
7
If variable ‚Äò?x1‚Äô is bound to value X1, and variable ‚Äò?x2‚Äô to X2 etc., this is denoted
as [?x1/X1, ?x2/X2, ...].
Computational Construction Grammar 277
Similar to the parsing situation, the semantic side of the mouse-cxn matches
the semantic side of the initial transient linguistic structure above because the
construction requires only that there is a unit, with variable name (?top-unit),
which contains a meaning feature including the component (ony-category ?ref
[mouse]). Matching results in the bindings: ‚Äò[?top/top, ?meaning/(meaning
((ont-category Ref [mouse]))), ?ref/Ref]‚Äô.
Merging then results in the following modiÔ¨Åed structure:
((top (meaning ((giveness R uniquely-identifiable]))
(subunits (mouse-unit)))
(mouse-unit
(meaning ((ont-category R [mouse])))
(sem-cat ((schema R [ReferentDescriptor])
(quantity R 1)))))
<-->
((top (subunits (mouse-unit))
(mouse-unit
(form ((orth ?word-1 "mouse")))
(syn-cat ((schema ?word-1 [WordDescriptor])
(type Noun)
(number singular))))))
As in parsing, all constraints in the construction missing in the initial transient
structure have been added, and the new mouse-unit includes in its meaning the
tagged component corresponding to the matched meaning of mouse-cxn.
Although not an issue for our simple example, many problems can arise in
the search for matching constructions during processing and the selection of
the best set of constructions to apply. FCG provides several mechanisms for
coping with these challenges. These include the use of diÔ¨Äerent goal tests (such as
reentrance, in which a produced utterance is re-parsed using the current grammar
to test for interpretability); the option of continuing processing if an analysis
is insuÔ¨Écient; and the possibility of associating conventionality and preference
scores with constructions as heuristics for guiding search. These strategies are
explained in more detail elsewhere [20].
6.2 Constructional Analysis in ECG
In this section we brieÔ¨Çy summarize how ECG constructions support language
comprehension, as implemented by the construction analyzer described by [3].
The term constructional analysis as used here is analogous to parsing in FCG:
it is the constructional analogue to syntactic parsing‚Äîthat is, the identiÔ¨Åcation
of which linguistic structures are instantiated in a particular utterance‚Äîwhere
the structures crucially include semantic information.
Overview. The input to constructional analysis is an ECG grammar (including
both schema and construction lattices), along with the utterance to be analyzed,
and (optionally) a situation description. All schemas and constructions are Ô¨Årst
278 N. Chang, J. De Beule, and V. Micelli
translated into a feature structure representation, ensuring that all inherited
roles, constituents and constraints are included. Earlier we showed the feature
structure for mouse in Figure 4; Figure 9 shows a feature structure version of
the DeterminedNP construction.
‚é°
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é¢
‚é£
DeterminedNP
det :
‚é°
‚é¢
‚é¢
‚é£
Determiner
m :
ref : 1
number : 2
‚é§
‚é•
‚é•
‚é¶
nom :
‚é°
‚é¢
‚é¢
‚é£
Noun
m :
ref : 1
number : 2
‚é§
‚é•
‚é•
‚é¶
number : 2
m : 1

ReferentDescriptor
ont-category :
givenness :

‚é§
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é•
‚é¶
Fig. 9. Translation of the DeterminedNP construction into a feature structure. The
features shown correspond to the two constituents (det and nom), the number con-
structions feature and the meaning pole m. IdentiÔ¨Åcation bindings are repre-
sented using boxed index numbers, where indices with the same number are
bound to the same value.
The analyzer processes utterances from left to right, incrementally building
up an analysis graph (a set of constructional instances or constructs linked by
constituency relations) and a semantic specification, or semspec (a graph of the
meaning schemas associated with all constructs in the analysis). In the broader
research context for which ECG was developed, this semspec is an intermediate
structure whose purpose is to support two connected language understanding
processes: (1) contextual resolution, which grounds this interpretation in the sit-
uational context; and (2) embodied simulation, which draws on richer embodied
structures to yield further context-sensitive inferences [1]. Here we focus on how
the semspec is built up during analysis.
The construction analyzer described by Bryant (2008) uses uniÔ¨Åcation as the
basic mechanism for composing constructions and verifying that their constraints
are consistent, where both constructions and schemas are represented as typed
feature structures with uniÔ¨Åcation constraints as speciÔ¨Åed by the ECG formal-
ism. But the search for the best analysis also exploits many heuristics to improve
eÔ¨Éciency, limit search and approximate aspects of human language processing,
including:
‚Äì Incremental interpretation: the analyzer allows incremental left-to-right in-
terpretation of the utterance. To do this, it employs left-corner parsing tech-
Computational Construction Grammar 279
niques [13] to keep track of competing analyses and update their scores,
where partially matched subportions of complex constructions provide top-
down expectations about which constructions may next be encountered.
‚Äì Best-Ô¨Åt interpretation: the analyzer deÔ¨Ånes a quantitative heuristic for com-
bining information from disparate domains, ranking candidate interpreta-
tions, and guiding parsing decisions. The implementation is a Bayesian prob-
abilistic model that integrates information aÔ¨Äecting the likelihood of the
analysis (e.g., lexical and constructional frequencies; the likelihood that one
construction has another as a constituent; and the likelihood that a schema
has a particular kind of Ô¨Åller in a given role).
‚Äì Partial interpretation: the analyzer produces partial analyses even when the
input utterance is not covered by the grammar or is missing constituents.
An extension to the analyzer permits analyses with omitted constituents (as
often encountered in, for example, Mandarin) by integrating the score of an
interpretation with the results of the contextual resolution process.
In sum, the analyzer is consistent with the constructional view, drawing on
all available information at every step to ensure that syntactic, semantic and
constructional constraints are satisÔ¨Åed. Crucially, the early incorporation of se-
mantic, pragmatic and statistical constraints can dramatically reduce the search
space that may result from purely syntactic approaches.
Example. We consider the simple case of analyzing the input sentence string
‚Äúthe mouse‚Äù given a grammar containing just the constructions deÔ¨Åned earlier.
Following the left-corner parsing algorithm, the analyzer maintains a stack of
all the constructs (instances of constructions) recognized so far, all labeled as
incomplete or complete; incomplete constructs are also annotated with which
constituents still remain to complete it. Processing unfolds in several steps:
‚Äì The analyzer reads in the Ô¨Årst word ‚Äúthe‚Äù and retrieves the The construction
based on the orthographic form and adds it to the current stack of available
constructs. Since it has no constituents remaining, it is recorded as complete.
‚Äì All constructions of which The is a subcase (here, just the Determiner
construction) are added to the stack as complete.
‚Äì Because the Ô¨Årst constituent of the DeterminedNoun construction is typed
as a Determiner, it is placed on the stack and a constituent binding (be-
tween the The construction and its Ô¨Årst constituent) is attempted. The bind-
ing is successful, resulting in a partial semspec consisting of the Determiner
construction‚Äôs evoked ReferentDescriptor being bound with the ReferentDescrip-
tor of the DeterminedNoun construction; this structure is also speciÔ¨Åed
having a givenness status of uniquely-identifiable. The DeterminedNoun con-
struction has now scanned past the Determiner constituent.
‚Äì The analyzer reads in the second word ‚Äúmouse‚Äù and retrieves the Mouse con-
struction. Similar to before, it places Mouse as well its parent construction
type Noun on the stack as complete.
‚Äì The DeterminedNoun construction placed on the stack earlier successfully
scans its next unfulÔ¨Ålled constituent, adding the constituent binding to its
nom constituent and updating the semspec with the relevant bindings.
280 N. Chang, J. De Beule, and V. Micelli
‚Äì The DeterminedNoun is now marked as complete; since the utterance string
has been exhausted, it has been successfully parsed.
Figure 10 shows the output of the ECG constructional analyzer on our simple
example of the mouse. In fact, this structure shows both (a portion of) the
analysis graph and its associated semspec. (The form domain is not shown.)
In brief, each large box corresponds to an instantiated construction or schema,
shown with its constituents or roles. Thus, the box labeled DeterminedNP has
as top-level features its two constituents det and nom, its constructional number
feature, its meaning pole m and the evoked ReferentDescriptor ref. The boxed
numbers indicate shared values, many referring to structures not shown in this
reduced Ô¨Ågure, but note that the boxed 2 indicates that ReferentDescriptor is
shared in several places: the overall meaning of the DeterminedNoun construction,
its ref slot as well as those of its two constituents.
Fig. 10. The semantic speciÔ¨Åcation resulting from analyzing ‚Äúthe mouse‚Äù
Though beyond the scope of the example, it may be illuminating to take the
analysis above a few steps further. Once the DeterminedNP has been suc-
cessfully matched, various constructions with an initial constituent matching
that construction would be added to the stack for consideration. These include
constructions corresponding to a variety of possible completions, including The
mouse ran, The mouse ran past, The mouse ran past the barn and even The
mouse ran past the barn fell. Depending on the actual input, these construc-
tions would diÔ¨Äer in, for example, how much of the form they account for, the
Computational Construction Grammar 281
semantic likelihood of the associated semspec, and the constructional likelihood.
The combined scores is used to prune the set of candidate parser actions and
select the best one.
The constructional analyzer has been applied to a variety of linguistic phe-
nomena, including modeling families of related argument structure constructions
[6], early Mandarin constructions [16] and Hebrew morphological constructions
[18]. Besides serving as a platform for linguistic analysis, it has also been applied
as a psycholinguistic model of reading time data [3], and versions of the analyzer
have been integrated in models of child language acquisition [4, 16]. Ongoing
research has integrated ECG representations of mental spaces and metaphor
into the constructional analysis process (Feldman & Gilardi, In prep.), similar
to earlier proposals [1, 17].
6.3 Two Processing Models
Major diÔ¨Äerences between FCG and ECG can be seen in their processing models.
Although in some ways not surprising, given their diÔ¨Äerent goals, it is neverthe-
less interesting to compare how the two frameworks handle essentially the same
input. The comparison is most direct for the comprehension models: the two
formalisms are subject to the same high-level requirements that they must se-
lect candidate constructions, check whether they Ô¨Åt with the current transient
structure (in FCG) or partial analysis (in ECG), and choose the overall best
set of such constructions. Where they diÔ¨Äer is in what kinds of information are
available for each of these steps, and what criteria they use for making decisions
and prioritizing their respective searches. We discuss these diÔ¨Äerences below.
Bidirectionality. The most obvious diÔ¨Äerence between the two formalisms is
deÔ¨Åned by an absence: ECG currently lacks an implemented model of process-
ing, and cannot thus be said to provide a full model of both sides of the usage
coin. This asymmetry is due in part to the focus in ECG on building cogni-
tively plausible models, since the preponderance of psycholinguistic evidence is
in comprehension. In principle, however, ECG grammars are declarative sets of
constraints that state relationships between form and meaning that should hold
in production just as in comprehension. Thus, it is possible that production
in ECG would draw on similar data structures and processes as used in com-
prehension (best-Ô¨Åt combination of evidence, prioritization based on semantic
and cognitive heuristics, etc.). One hypothesis is that production may employ
the same grammar structures (i.e., construction and schema deÔ¨Ånitions) as in
comprehension, but with diÔ¨Äerent usage statistics.
As noted earlier, the structural components of FCG constructions are used
diÔ¨Äerently in parsing and production: in parsing, regular syntactic units are
matched and J-units are merged, whereas in production the regular semantic
units are matched, and J-units are merged. FCG thus makes a more speciÔ¨Åc
claim about the relation between parsing and production than ECG can yet
282 N. Chang, J. De Beule, and V. Micelli
make‚Äîand it may well be that a working production model for ECG would
make quite diÔ¨Äerent kinds of claims, especially if (as conjectured above) the
declarative structures of ECG are able to support both kinds of processes.
Matching, Merging and UniÔ¨Åcation. Both parsing and production in FCG
rely on the distinction between matching and merging: the match performs the
check or Ô¨Ålter on candidate constructions, and the merge causes additional con-
straints from applicable constructions to be uniÔ¨Åed into the transient structure.
Comprehension in ECG similarly involves determining which constructions out
of the whole grammar apply, and then using uniÔ¨Åcation to produce the interim
semantic speciÔ¨Åcation. The Ô¨Årst step employs some heuristics to reduce the set
of possible constructions: speciÔ¨Åc forms (typically orthographic strings) observed
in the utterance are directly associated with constructions including those forms;
and (as described earlier) the combination of left-corner parsing with construc-
tional types restricts the set of candidate constructions at any given stage of
processing. Constructions passing through this initial Ô¨Ålter must still be tested
for whether they can be uniÔ¨Åed with the analysis in progress; successful uni-
Ô¨Åcation at this stage acts as both a Ô¨Ålter on candidate constructions and the
mechanism for combining all relevant constructional constraints. It thus corre-
sponds to both matching and merging in FCG.
Essentially, both frameworks have devised diÔ¨Äerent strategies to cope with
the computational expense of uniÔ¨Åcation. In FCG, the split between simpler
matching heuristics and more expensive merging operations allows some degree
of pre-optimization. In ECG, costly uniÔ¨Åcation is part of the matching process,
but the availability of a lattice of constructional types helps to compensate for
that expense by supplying useful heuristics that restrict the search space of
constructions.
Note, however, that the increased eÔ¨Éciency aÔ¨Äorded by the use of inheritance
in ECG may come at a price: changes to the grammar have potentially wide-
ranging eÔ¨Äects, and may necessitate costly measures to ensure consistency in the
inheritance network. While such changes can be restricted to those that have
minimal impact on the network, in general the cost of maintaining consistency
may make inheritance impractical for situations in which grammars are liable
to undergo frequent changes. But it is precisely situations involving dynamically
changing grammars that are the overriding (and titular) concern in FCG.
It should also be mentioned that it is possible in FCG to skip the matching
and directly apply merging. Although this strategy has not yet been fully inves-
tigated, initial results indicate that it indeed leads to an explosion of the search
space. But it also facilitates less restricted and hence more creative usages of
constructions, which may be useful both for learning and for achieving robust
handling of unfamiliar input.
Structural Flexibility. At Ô¨Årst glance the two formalisms diÔ¨Äer in the sur-
face impressions they make. In both content and appearance, ECG is heavily
inÔ¨Çuenced by work in frame semantics and cognitive linguistics. The notation it-
self, though integrated with processes of language learning and use, is expressed
Computational Construction Grammar 283
in a constraint language that avoids explicitly procedural information. ECG‚Äôs
schema and construction deÔ¨Ånitions act as data structures that are created, used
and altered by the language learning and comprehension models. FCG, on the
other hand, stems more directly from work in artiÔ¨Åcial intelligence and symbolic
programming. Though FCG constructions include many declarative constraints,
they also have operations that are closely tied to aspects of processing (espe-
cially when shown in their expanded form). In a way, FCG constructions act like
programs that transform a transient linguistic structure as data.
It is diÔ¨Écult, however, to draw too Ô¨Åne a line between declarative and pro-
cedural aspects of each formalism. Both formalisms are, of course, data in the
sense that a separate processing engine ultimately controls their execution, veri-
fying that the constraints they specify hold or performing the actions they entail.
By the same token, the various notations employed by each formalism have di-
rect eÔ¨Äects on processing and thus include procedural information in that sense.
Hence, despite the surface diÔ¨Äerences, most of the constraints expressed in each
language can be seen in both lights.
One possible way in which FCG may exhibit a more procedural orientation
is provided by TAGs and J-units. With TAGs, a construction can explicitly
instruct the match process to remember a binding for a tag variable. Such a
variable acts as a local variable in standard programs, and serves to temporarily
store a value until it is needed again later, e.g. in a J-unit. J-units in turn
serve to provide explicit instructions to the merge process. They specify how to
change constituent structure and, in combination with tags, and how to move
information between constituents.
Again, however, such eÔ¨Äects could be viewed in terms of a set of constraints
on the intermediate and Ô¨Ånal structures involved. The crucial observation here
might center not on how these eÔ¨Äects are described, but instead on what they
do‚Äîin particular, the fact that they change constituent structure in this manner.
As noted earlier, each FCG constructions speciÔ¨Åes precisely the eÔ¨Äects (agree-
ment, categories, etc.) that apply to the resulting transient structure, which
means that they are relatively free to change the internal structure. As a result,
the constituent structure at the end of processing may be diÔ¨Écult to infer di-
rectly from constructional deÔ¨Ånitions. In ECG, on the other hand, constituent
structure generally follows that declared in the constructional domain; while the
semantic structure need not mirror this structure, the Ô¨Ånal constructional struc-
ture is related relatively directly to that speciÔ¨Åed in construction deÔ¨Ånitions.
This diÔ¨Äerence reÔ¨Çects yet again the tendency toward Ô¨Çexibility and freedom in
FCG, versus the importance of motivated constraints in ECG.
Cognitively Motivated Processing. Last, but not least, the two processing
models diÔ¨Äer markedly in the phenomena they target. FCG models are designed
to be functional: they are intended to satisfy the input and output constraints of
communication systems, often those exempliÔ¨Åed by particular human linguistic
phenomena. The particular processing mechanisms involved are not, however,
intended to reÔ¨Çect the implementations of language processing in the human
brain. In contrast, ECG‚Äôs language comprehension model is speciÔ¨Åcally designed
284 N. Chang, J. De Beule, and V. Micelli
to be cognitively plausible: not only does it fulÔ¨Åll the basic task of identifying
constructions instantiated by an utterance and producing the corresponding in-
terpretations, but it does so in a way that reÔ¨Çects the robust, incremental and
best-Ô¨Åt nature of human language processing. It thus exploits many eÔ¨Éciencies
that come from psycholinguistic evidence about online sentence processing.
Recent work by Wellens (this volume) explores how usage-based networks of
FCG constructions can be used to facilitate processing. Such work takes a step
in the direction of cognitively motivated processing. Heuristics used to guide
search during language processing may also capture some cognitively motivated
factors, but thus far little work has been done to fully exploit the potential for
learning from the constraints of human language processing in FCG.
7 Discussion and Outlook
The preceding sections describe two computational formalisms that implement
ideas from construction-based approaches to grammar. Relative to the range of
approaches in the literature, the similarities between the two formalisms and
their associated research frameworks far outnumber their diÔ¨Äerences. Both in-
clude notational means of expressing constructional mappings between form and
meaning, and both provide the basic representational toolkit for representing
categories, agreement and constituent structure.
In addition to these theoretically inspired commitments, the two frameworks
also share many methodological assumptions. Both formalisms aim to build
working systems that not only describe but in fact instantiate the structures
and processes proposed. Unlike many other approaches, they do not stop at de-
scribing linguistic knowledge in formal notation but rather oÔ¨Äer models of how
they are actually used in communication. Processing considerations have thus
shaped both formalisms.
The many shared qualities discussed in the preceding sections might be seen
as independent requirements for any computational construction grammar for-
malism. Their diÔ¨Äerences are perhaps even more revealing of the speciÔ¨Åc issues
that computational implementations of construction-based grammar must face;
we summarize some of these below.
7.1 Freedom of Expression
Perhaps the main recurring theme in this comparison has involved the rela-
tively restricted nature of ECG as compared to FCG: in general, ECG allows a
more restricted set of notational possibilities, as exempliÔ¨Åed by its inclusion of
a schema formalism for expressing constructional form and meaning; its limited
set of expressible constraints; its stronger assumptions about (some) structural
parallels between the form and meaning domains; and the relative monotonicity
of the internal structures built up during processing.
By contrast, FCG has been designed to be as open-ended as possible, al-
lowing grammar-writers (and, not coincidentally, evolving agents) a free hand
Computational Construction Grammar 285
in exploring diÔ¨Äerent styles of representation and strategies for achieving suc-
cessful communication. This freedom is apparent not only in the broad array
of representational devices allowed in form and meaning, but also in the choice
of syntactic and semantic categories; the Ô¨Çexible independence of units in the
form and meaning domains; and the possibility of fundamental alterations of
constituent structure allowed during processing.
These fundamental diÔ¨Äerences beg the question: how much freedom of expres-
sion is enough, and can you have too much? These questions must, of course,
be posed relative to the kinds of phenomena the respective formalisms are in-
tended to account for. While ECG is a simpler formalism, it has thus far proven
suÔ¨Éciently expressive for its purposes‚Äîto wit, capturing linguistic insights, ac-
counting for psycholinguistic evidence, and being learnable in a developmentally
plausible way. It has not, of course, been deployed in the context of language
evolution experiments, so it is as yet unclear whether its restricted set of possibil-
ities would give rise to the same unbounded range of communicative creativity,
or allow the degree of representational Ô¨Çuidity, fostered by FCG. On the other
hand, to the extent that FCG has interest in the speciÔ¨Åc questions of human
communication, it would be worthwhile to Ô¨Ånd concrete, realistic cases in natu-
ral language that demand the amount of freedom and corresponding complexity
aÔ¨Äorded by FCG.
7.2 Structure and Process
A related issue concerns the directness of the connection between the structures
appearing in the formalism and the particular procedures employed during pro-
cessing. The structure of ECG deÔ¨Ånitions speciÔ¨Åes constraints on the function
of processing, but it does not specify precisely how the analyzer proceeds. This
aÔ¨Äords it a certain amount of stability across particular implementations of pro-
cessing. The same structures are also intended to be useful for both language
comprehension and language production, though a concrete implementation of
the latter will be necessary before this idea can be explored and validated.
FCG constructions are not only useful in both language production and com-
prehension, but their internal structure also reÔ¨Çects some more speciÔ¨Åc claims
FCG makes about the relation between those two processes. In particular, the
ways in which diÔ¨Äerent kinds of constraints are expressed (e.g., whether used
for matching or merging) correspond directly to the (symmetric) ways in which
they are used in these both processing modes.
These diÔ¨Äerences raise the question of whether and how directly the declara-
tive constraints relevant to each construction can be abstracted from processes
of use. A related question is how and whether such construction content must
change in order to satisfy the constraints of both kinds of processing. Perhaps
FCG‚Äôs experience in this area could lead to predictions about how these ques-
tions would be answered for ECG.
286 N. Chang, J. De Beule, and V. Micelli
7.3 BeneÔ¨Åts and Drawbacks of Inheritance
The organization of FCG and ECG grammars reÔ¨Çects a major representational
diÔ¨Äerence between the two formalisms. ECG makes explicit use of constructional
and schematic inheritance relationships, as expressed by type lattices. Such rela-
tions capture various linguistic generalizations and naturally lead to more concise
and coherent grammars. Not coincidentally, they are also more reminiscent of
the kinds of linguistic structures typically proposed by cognitive linguists (and
hence perhaps easier for them to understand), and exploit object-oriented design
principles from computer science.
FCG grammars have mechanisms for achieving some of the eÔ¨Äects of inheri-
tance, such as the templates to notate shared structure. Some FCG grammars
also employ frame-based ontologies that are comparable to the schema hierar-
chies of ECG (see for instance [14]). And, as mentioned, some relations implicit
from the use and interaction of constructions during processing may be captured
in constructional dependency networks, thus making constructional relations a
directly usage-based matter. On the whole, however, FCG has not yet employed
explicit notions of inheritance.
As noted earlier, this diÔ¨Äerence is consistent with FCG‚Äôs emphasis on the in-
dependence of constructions, and the need for making small, local changes: it is
relatively easy to change the Ô¨Çow of processing by modifying existing construc-
tions or by adding new constructions to the constructicon (though it may be
diÔ¨Écult to predict their consequences). By contrast, in grammars like ECG that
employ extensive inheritance relations, small changes may aÔ¨Äect a large number
of constructions, necessitating more complicated measures for maintaining con-
sistency or re-initializing to reÔ¨Çect updates. The eÔ¨Äects of these diÔ¨Äerences on
processing depend, of course, on particular implementational choices, and how
much change and Ô¨Çuidity is necessary. The arena of language learning, though not
discussed in the current chapter, may oÔ¨Äer the best domain for exploring these
questions: both formalisms have associated models of learning, though ECG‚Äôs is
developmental while FCG‚Äôs is evolutionary; the parallels and diÔ¨Äerences between
these endeavors should reward further investigation.
7.4 DiÔ¨Äerent Formalisms for DiÔ¨Äerent Goals
Many of the diÔ¨Äerences between FCG and ECG reÔ¨Çect their respective back-
grounds and priorities. ECG was intended from the start as a theory of hu-
man cognition, embracing the foundational ideas of cognitive linguistics. Its goal
has been to capture patterns of human categorization and processing, while ex-
pressing linguistic and conceptual generalizations. The roots of FCG in artiÔ¨Åcal
language evolution have given it a more dynamic and Ô¨Çuid view of linguistic rep-
resentations, which crucially requires a certain amount of independence among
representations. The developmental path of each formalism reÔ¨Çects these biases
and accounts for many of the phenomena we have illustrated here.
But stepping back, it should be clear that these diÔ¨Äerent approaches provide
complementary perspectives on the same underlying phenomena of embodied,
Computational Construction Grammar 287
situated communication. Though they ask diÔ¨Äerent versions of the question‚Äî
emphasizing, respectively, the constraints imposed by human cognition, versus
the freedom to evolve diverse communicative strategies‚Äîthey nevertheless both
provide important ways of framing any complete approach to modeling language
structure, use and acquisition. Perhaps most signiÔ¨Åcantly, the fact that both for-
malisms have concrete implementations of their various structures and processes
gives them an additional dimension of considerations not typically available for
non-implemented grammatical theories and permits a much more nuanced com-
parison of approaches than would otherwise be possible. Only when such com-
putationally precise descriptions are available can issues like those raised here
be recognized and explored across the broader Ô¨Åeld of constructional approaches
to grammar.
References
[1] Bergen, B., Chang, N.: Embodied Construction Grammar in simulation-based
language understanding. In: √ñstman, J.O., Fried, M. (eds.) Construction Gram-
mar(s): Cognitive and Cross-Language Dimensions. Johns Benjamins (2005)
[2] Bleys, J., Stadler, K., De Beule, J.: Search in linguistic processing. In: Steels, L.
(ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Amster-
dam (2011)
[3] Bryant, J.: Best-Ô¨Åt Constructional Analysis. Ph.D. thesis, UC Berkeley (2008)
[4] Chang, N.: Constructing grammar: A computational model of the emergence of
early constructions. Ph.D. thesis, Computer Science Department, University of
California, Berkeley (2008)
[5] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraint
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[6] Dodge, E.: Conceptual and constructional composition. Ph.D. thesis, Computer
Science Department, University of California, Berkeley (2010)
[7] Feldman, J.: From Molecule to Metaphor: A Neural Theory of Language. MIT
Press, Cambridge (2006)
[8] Fillmore, C.J.: Frame semantics. In: Linguistics in the Morning Calm, Seoul,
pp. 111‚Äì137 (1982)
[9] Goldberg, A.E.: Constructions: A Construction Grammar Approach to Argument
Structure. University of Chicago Press, Chicago (1995)
[10] Kay, P., Fillmore, C.: Grammatical constructions and linguistic generalizations:
the whats x doing y? construction. Language 75(1) (1999)
[11] LakoÔ¨Ä, G.: Women, Fire, and Dangerous Things: What Categories Reveal about
the Mind. University of Chicago Press, Chicago (1987)
[12] Langacker, R.W.: Foundations of Cognitive Grammar. Theoretical Prerequisites,
vol. I. Stanford University Press, Stanford (1987)
[13] Manning, C., Carpenter, B.: Probabilistic parsing using left-corner language mod-
els. In: Proceedings of the 5th International Workshop on Parsing Technology
(1997)
[14] Micelli, V.: Field Topology and Information Structure: A Case Study for Ger-
man Constituent Order. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 178‚Äì211. Springer, Heidelberg (2012)
288 N. Chang, J. De Beule, and V. Micelli
[15] Micelli, V., Van Trijp, R., De Beule, J.: Framing Ô¨Çuid construction grammar. In:
Proceedings of the 2009 Annual Meeting of the Cognitive Science Society, COGSCI
(2009), http://www.csl.sony.fr/downloads/papers/2009/micelli-09a.pdf
[16] Mok, E.H.: Contextual Bootstrapping for Grammar Learning. Ph.D. thesis, Com-
puter Science Department, University of California, Berkeley (2008)
[17] Mok, E.H., Bryant, J., Feldman, J.: Scaling understanding up to mental spaces.
In: Proceedings of the 2nd International Workshop on Scalable Natural Language
Understanding (ScaNaLU 2004), Boston, MA (2004)
[18] Schneider, N.: Computational cognitive morphosemantics: modeling morpholog-
ical compositionality in hebrew verbs with embodied construction grammar. In:
Proc. of the 36th Annual Meeting of the Berkeley Linguistics Society, Berkeley,
CA (2010)
[19] Spranger, M., Loetzsch, M.: Syntactic indeterminacy and semantic ambiguity: A
case study for German spatial phrases. In: Steels, L. (ed.) Design Patterns in Fluid
Construction Grammar. John Benjamins, Amsterdam (2011)
[20] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
[21] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[22] van Trijp, R.: Feature matrices and agreement: A case study for German case. In:
Steels, L. (ed.) Design Patterns in Fluid Construction Grammar. John Benjamins,
Amsterdam (2011)
Fluid Construction Grammar and Feature
Constraint Logics
Liviu Ciortuz and Vlad Saveluc
Department of Computer Science, ‚ÄúAl.I. Cuza‚Äù University, Ia≈üi, Romania
Abstract. Fluid Construction Grammars (FCGs) are a Ô¨Çavor of Con-
struction Grammars, which are themselves uniÔ¨Åcation-based grammars.
The FCG syntax is similar to that of other uniÔ¨Åcation-based gram-
mars only to a small extent. Additionally, up until now, FCG has lacked
a comprehensively-deÔ¨Åned declarative semantics, whereas its procedural
semantics is truly particular compared to other uniÔ¨Åcation-based gram-
mar formalisms.
Here we propose the re-deÔ¨Ånition of a core subset of the FCG formal-
ism (henceforth called FCG light) within the framework of order-sorted
feature constraint logics (OSF-logic) that would assign FCG a rigorous
semantics, both declarative and procedural, that is suitable for both
parsing, production and grammar learning.
This new framework allows us to clearly compare FCG to other
uniÔ¨Åcation-based grammars. We will also have the advantage of associ-
ating FCG with another classical paradigm for learning (‚Äúevolving‚Äù) new
grammars, namely learning in hierarchies (lattices) of concepts. This
learning technique exploits the natural partial order relation of gener-
alization/ specialization between grammars. The learning method cur-
rently used by FCG, is (inspired by) reinforcement learning. We claim
that learning in a hierarchy of grammar versions enables us to establish
a rather natural link with linguistic background knowledge when devis-
ing the grammar repair strategies. It also sets a stage on which we may
compare diÔ¨Äerent grammars that could be learned by an agent at each
step during the grammar evolution process.
1 Introduction
Here we present FCG light, a core subset of Fluid Construction Grammars intro-
duced by [33] [15] [34] which is currently implemented on a simpliÔ¨Åed version of
the LIGHT platform [9].
The LIGHT system was developed with the explicit aim of doing eÔ¨Écient pro-
cessing of HPSG-like uniÔ¨Åcation grammars[25], but it is by no means restricted to
working with HPSGs.1
LIGHT comprises several feature structure (FS) uniÔ¨Åers2
1
HPSG stands for Head-driven Phrase Structure Grammars.
2
More exactly, LIGHT currently has 6 uniÔ¨Åers, of both typed and un-typed kinds: a.
non-compiled (lazy) typed uniÔ¨Åcation, b. compiled (eager) typed uniÔ¨Åcation, c. com-
piled (eager) typed uniÔ¨Åcation specialized for active, bottom-up, chart-based parsing
and their un-typed counterparts (a
, b
, c
). For technical details, the interested reader
should consult [12].
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 289‚Äì311, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
290 L. Ciortuz and V. Saveluc
and a control level (actually performing active bottom-up chart-based parsing)
upon the uniÔ¨Åcation level. An important number of optimizations were incorpo-
rated into the LIGHT system. In the past these optimizations were Ô¨Åne-tuned so
as to achieve eÔ¨Écient parsing with ERG [17], the large-scale HPSG grammar for
English developed at CSLI, Stanford University.
The present work leads to deÔ¨Åning FCG light as a new Ô¨Çavor of uniÔ¨Åcation
grammars, which is derived from the FCG formalism and is transposed into the
LIGHT setup, thus beneÔ¨Åtting from a rigorous semantics (both a declarative and
a procedural one) based on OSF-logic, which was introduced in [3] and [1].3
We argue that by using this logic-based semantics we are able to:
‚Äì redeÔ¨Åne the procedural semantics of the chosen subset of FCG and associate
it with a declarative semantics which we claim is not clearly visible in the
FCG setup;
‚Äì gain certain beneÔ¨Åts through this framework arising from the natural partial
order relation between grammars deÔ¨Åned via generalization/specialization;
‚Äì replace grammar learning, as a consequence of the above issue, in FCG
(which is based on the reinforcement learning paradigm) through learning
in a lattice of grammars. We argue that the latter paradigm is more natu-
rally suitable for integrating linguistic background knowledge, and it leads
to more eÔ¨Écient learning because it enables us to deÔ¨Åne certain heuristics
that are very helpful for guiding the search for appropriate (rule) candidates
in the grammar lattice;
‚Äì in certain conditions,4
deÔ¨Åne parsing and production in FCG light in a declar-
ative manner (as it is the case of uniÔ¨Åcation grammars, in particular head-
driven grammars).
This paper is organized as follows: Section 2 makes a review of the (core) FCG
formalism from the feature constraint point of view. Section 3 goes through the
details of FCG light language‚Äôs deÔ¨Ånition, at both syntactic and semantic levels.
Section 4 is concerned with grammar learning aspects in FCG light. Section 5
scrutinizes several tasks that we have planned, demonstrating further usefulness
of FCG light.
3
OSF-logic is closely related to Carpenter‚Äôs logic of typed feature structures [5]. It has
been associated with an abstract machine for compilation of FS uniÔ¨Åcation [2], which
was further extended by [10] to compiled typed FS uniÔ¨Åcation. OSF is not concerned
with appropriateness constraints; however, we have shown that in certain conditions
one could automatically infer these constraints from the given input grammar [7].
For a good introduction to feature constraint logics, the reader should consult [31].
4
When constraint reduction actions (see Section 3.1) are performed in ‚Äúsoft‚Äù mode,
they do not aÔ¨Äect logical entailment. This is why in FCG light the reduction operation
is replaced (at uniÔ¨Åcation level) by constraint marking for deletion (to be cared of
by the parser/producer).
FCG and Feature Constraint Logics 291
((?top-unit
(tag ?meaning (meaning (== (read ?event)
(reader ?event ?agent)))))
((J ?verb-unit ?top-unit)
?meaning
(referent ?event)
(sem-cat (==1 (base-type ?event event)))))
<-->
((?top-unit
(tag ?form (form (== (string ?verb-unit "cita")))))
((J ?verb-unit ?top-unit)
?form
(syn-cat (==1 (pos verb)
(gender ?agent ?agent-gender)
(case ?object accusative)))))
Fig. 1. An FCG construction that acts as lexical entry for the Russian verb ‚Äúcita‚Äù,
similar to the verb ‚Äúrisova‚Äù presented by [18], Chapter 3
2 FCG Revisited: A Feature Constraint-Based
Perspective
Here we summarize the basic notions in the FCG formalism, relative to both its
syntax and procedural semantics.
An FCG grammar is a set of structures called constructions, which are written
in the FCG format, as exempliÔ¨Åed in Figure 1. Unlike FCG authors [32] [14],
here we give a constraint-based view on the deÔ¨Ånition of construction struc-
tures. To this aim, we need some basic notions of feature constraint logics. We
brieÔ¨Çy describe them here, yet without going into formal details. Elementary con-
straints considered here are of three kinds: sort constraints, feature constraints
and equality constraints.5
It is useful to make the following preliminary remark:
In HPSG/LIGHT rules are expressed simply as FSs, enabling the user to em-
ploy a unique formalism for both the grammar rules and the structures to which
they apply. However, in FCG formalisms, the constructions that express rules
diÔ¨Äer from the structures to which they are applied, namely the coupled feature
structures. This diÔ¨Äerence is due to the fact that certain operations ‚Äî beyond
the level of deductive parsing and production ‚Äî that have to be performed by
the parser/producer are speciÔ¨Åed in the constructions representing rules.
5
In FCG light, like in other formalisms, the equality constraints are not explicitly
used at the syntax level. Instead they are automatically derived while building cer-
tain variable substitutions, i.e. during operations manipulating the FSs: subsump-
tion, uniÔ¨Åcation (computation of the GLB for two FSs), and generalization (LUB
computation).
292 L. Ciortuz and V. Saveluc
syn
top
sem
(form (string cita‚àí4 "cita"))
top
cita‚àí4
(reader ?event‚àí5 ?agent‚àí5))
meaning ((read ?event‚àí5)
referent ?event‚àí5
sem‚àícat ((base‚àítype ?event‚àí5 event))
(form (string cita‚àí4 "cita"))
(syn‚àícat (pos verb)
(gender ?agent‚àí5 ?agent‚àígender‚àí5))
(case ?object‚àí5 accusative))
cita‚àí4
syn
top top
sem
Fig. 2. Two simple couple feature structures. The lower CFS is obtained from the
upper one by application of the construction given in Figure 1 in parsing mode.
This fact unfortunately leads to the disruption in FCG of the really nice cor-
respondence between declarative and procedural semantics and also the orthog-
onality between the uniÔ¨Åer level and the parser/producer level that characterize
main-stream uniÔ¨Åcation grammars, in particular HPSGs. This disruption seems
to be the price to be paid by FCG for the beneÔ¨Åt of oÔ¨Äering the grammar writer
the capacity to play with subtleties in the learning (evolvable) grammars.
Similar to HPSG/LIGHT, in deÔ¨Åning FCG light we aim to reduce to a minimum
(and, in certain conditions, even eliminate) the diÔ¨Äerence between the form of
rules and the CFSs to which they apply, thus enabling our parser/producer to
work very smoothly.
At this point, we can provide a set of informal deÔ¨Ånitions that can be seen as
constraint-based alternatives to the ones that have been introduced in [34]:
A coupled feature structure (CFS) can be seen as a set of elementary constraints,
partitioned into two disjoint subsets named poles. These poles are usually referred
to as the syntactic pole and the semantic pole (more generally: the left pole and the
right pole) of the given CFS. Each of the two poles further partitions its set of
elementary constraints into several units. The units in a CFS are explicitly linked
into a graph (usually a tree) using the multi-valued features syn-subunits (in
the syntactic pole) and sem-subunits (in the semantic pole). Further on, each
unit partitions its set of elementary constraints under several slots.
To illustrate the above notions, consider the CFS shown in the lower part of
Figure 2, in which the top-unit has as sub-unit the verb-unit, and examples of
slots in the latter unit are syn-cat and sem-cat.6
The FCG constraints (read
?event-5) and (base-type ?event-5 event) correspond in OSF-logic to the
elementary sort constraint #event-5:read and respectively the feature constraint
#event-5.base-type ‚áí event.
CFSs and constructions in FCG are characterized by a certain, de facto
user-speciÔ¨Åed correspondence between syntax and semantics. This correspon-
dence starts with the meaning and form constraints in a top-unit and is down-
propagated to the other units via parsing and production.
6
The reader will see that this CFS can be obtained from the very simple CFS shown
in the upper part of Figure 2 by the application of the FCG construction in Figure 1
in parsing mode.
FCG and Feature Constraint Logics 293
Basically, the set of elementary constraints that constitute a CFS can be
treated in either match/subsumption mode or merge/uniÔ¨Åcation mode. The ac-
tual way in which the elementary constraints are processed is dependent on the
parsing or production process (not detailed here) carried by the application of
construction rules [14] [4].
The notion of construction extends the deÔ¨Ånition given above for CFS by
adding the following:
‚Äì two operators, namely:
the J operator that (indirectly) indicates syn/sem-subunits constraints
and also separates the merge zone from the match zone in a pole;
the tag operator that indicates a substructure (set of elementary con-
straints) to be deleted and eventually moved elsewhere;
‚Äì several restrictors (‚Äô==1‚Äô,‚Äô==0‚Äô, etc.), which can be seen as meta-constraints
to be checked while the match and merge operations are performed. For
further details, the reader should consult [34].
In FCG, the scope of the match and merge operations is limited to slots. In
FCG light we replace slots with features, whose values are implicitly -sorted,
where  is the top sort in the sort hierarchy.7
In FCG light the constraints asso-
ciated with a slot must represent a rooted feature structure.
Similar to the LIGHT system, in FCG light we make no use of negation ((0==)
in FCG), whereas the single-valued restriction ((1==) in FCG) is considered
implicit for feature constraints.8
Multi-valued features (designated using the
=>> symbol) are restricted to SYN-SUBUNITS and SEM-SUBUNITS.9
The
treatment of these two features is reserved for the parser and the producer. In
FCG light, features names are always capitalized.
Two additional features SYN and SEM, corresponding to the two poles in a
CFS are introduced.10
A syntactico-semantic graph, henceforth abbreviated as
syn-sem graph, can be derived from each CFS. The notion of syn-sem graph is
used in the sequel as an alternative/replacement for the notion of CFS.
From the restrictions and syntactic transformations listed above, it follows
that a CFS in FCG can be naturally written as a FS in OSF/LIGHT.
3 FCG light Language Definition
Here we formally introduce in Subsection 3.1 the syntax of the FCG light sub-
set of FCG, basically showing how constructions in FCG get translated into
the OSF/LIGHT syntax (which in the past also supported HPSG grammars).
7
For these slot-derived features, appropriateness constraints [5] with corresponding
new sort values can be further added.
8
Therefore, the symbol ‚áí in OSF functional constraints is dropped.
9
Multi-valued features are found, for instance, in F-logic [21]. OSF-logic can be nat-
urally extended so as to accommodate such features.
10
These features are not (necessarily) shown in the sequel, if the sets of syntactic slots
and semantic slots are disjoint.
294 L. Ciortuz and V. Saveluc
production
precond.
top-unit.MEANING = event, event:read,
event.READER = agent
reduction top-unit.MEANING = event, event:read, event.READER = agent
main
top-unit.SEM-SUBUNITS  verb-unit, verb-unit.MEANING=event,
event:read, event.READER = agent, verb-unit.REFERENT = event,
verb-unit.SEM-CAT = 1, 1.BASE-TYPE(event) = 2, 2:event
parsing
precond. top-unit.FORM  verb-unit, verb-unit.STRING = 1, 1:"cita"
reduction top-unit.FORM  verb-unit, verb-unit.STRING = 1, 1:"cita"
main
top-unit.SYN-SUBUNITS  verb-unit, verb-unit.STRING = 1,
1:"cita", verb-unit.SYN-CAT = 2, 2:verb, verb:pos,
2.GENDER(agent) = agent-gender, 2.CASE(object) = 3,
3:accusative
Fig. 3. The sets of elementary constraints used in production and respectively parsing
with the ‚Äúcita‚Äù lexical entry given in Figure 1. The hash symbol (#) introduces variables,
while the colon (:) precedes the sort of a variable (or a supersort of a sort). The
symbols = and  designate values for single-valued features and respectively multi-
valued features. Feature names are written in upper case.
Then, in Subsection 3.2, we introduce the two basic aspects of FCG light seman-
tics ‚Äî the declarative one and the procedural one ‚Äî, that further support the
FS subsumption and FS uniÔ¨Åcation operations used in parsing, production and
grammar learning.
3.1 FCG light Syntax
Now we will (re)deÔ¨Åne for FCG light the notion of construction by getting it as
close as possible to the notion of FS in OSF/LIGHT. (Re)deÔ¨Åning the notion of
construction for FCG light requires getting it as close as possible to the notion
of FS in OSF/LIGHT.
DeÔ¨Ånition: In FCG light, a construction is a set of elementary (i.e. atomic) con-
straints which is divided into the following two (not necessarily disjoint) triplets
of sets:
‚Äì a set of precondition constraints, a set of constraints marked for reduction
actions and the set of main constraints used for parsing,
‚Äì a set of precondition constraints, a set of constraints marked for reduction
actions and the set of main constraints used for production.
FCG and Feature Constraint Logics 295
production
precond. #top-unit[ MEANING =>> #event:read
[ READER #agent ] ]
reduction
#top-unit[ MEANING =>> #event:read
[ READER #agent[ TO-BE-REDUCED + ],
TO-BE-REDUCED + ] ]
main
#top-unit
[ SEM-SUBUNITS =>> #verb-unit
[ MEANING #event:read
[ READER #agent ],
REFERENT #event,
SEM-CAT top
[ BASE-TYPE( #event ) event ] ] ]
parsing
precond. #top-unit[ FORM =>> #verb-unit[ STRING "cita" ] ]
reduction
#top-unit[ FORM =>> #verb-unit[ STRING "cita"
[ TO-BE-REDUCED + ],
TO-BE-REDUCED + ] ]
main
#top-unit
[ SYN-SUBUNITS =>> #verb-unit
[ STRING "cita",
SYN-CAT verb:pos
[ GENDER( #agent ) #agent-gender,
CASE( #object ) accusative ] ] ]
Fig. 4. The OSF rooted terms (FSs) corresponding to the sets of elementary constraints
identiÔ¨Åed for the ‚Äúcita‚Äù lexical entry (Figure 1), that have been shown in Figure 3.
Compared to Figure 3, here above we did not show OSF variables that occur only once.
Also, multi-valued feature constraints corresponding to the J operator were added; see
the SYN-SUBUNITS and SEM-SUBUNITS features.
In FCG light we explicitly impose the following restrictions:11
For both parsing
and production, the constraints to be reduced must constitute a subset of the
precondition set of constraints, and the set of main constraints must be disjoint
from the precondition set.
In order to give an exempliÔ¨Åcation of the above deÔ¨Ånition of construction in
FCG light, the sets of elementary constraints that build up the ‚Äúcita‚Äù construction
‚Äî which was given in FCG format in Figure 1 ‚Äî are presented in Figure 3.
Further on, Figure 4 shows these sets of constraints represented as rooted FSs
in OSF/LIGHT format.12
11
These demands are generally met by FCG grammar writers.
12
The correspondence between sets of elementary constraints and (multi-rooted) fea-
ture structures should be familiar to the reader acquainted with feature constraints
logics.
296 L. Ciortuz and V. Saveluc
/* cita ; production */
#top-unit
[ SEM-SUBUNITS =>> #verb-unit
[ REFERENT #event,
MEANING #event:read
[ READER #agent ],
SEM-CAT top[ BASE-TYPE < #event, event > ],
STRING <! "cita" !>,
SYN-CAT verb
[ GENDER < #agent, #agent-gender >,
CASE < #object, accusative > ] ],
SYN-SUBUNITS =>> #verb-unit,
ARGS < #top-unit[ MEANING #event:read
[ READER #agent ] ] > ]
/* cita ; parsing */
#top-unit
[ SYN-SUBUNITS =>> #verb-unit
[ SYN-CAT verb
[ GENDER < #agent, #agent-gender >,
CASE < #object, accusative > ],
REFERENT #event,
MEANING #event:read
[ READER #agent ],
SEM-CAT top[ BASE-TYPE < #event, event > ] ],
SEM-SUBUNITS =>> #verb-unit,
ARGS < #top-unit[ FORM =>> #verb-unit[ STRING <! "cita" !> ] ] > ]
Fig. 5. The two FCG light rules that are associated to the construction ‚Äúcita‚Äù given in
Figure 1. The ARGS feature designates the right hand side (RHS) of the rule. The syntax
<! !! > is a ‚Äúsugar-ed‚Äù notation for diÔ¨Äerence lists. Using such a special structure is a
very convenient way to replace the (interpretable) constraint meets used in FCG.
In many cases, it is possible to actually get rid of constraint reduction, which
is why in the current implementation of FCG light we opted for a ‚Äúsoft‚Äù treatment
of reduction. In other words, the set of constraints designated for reduction are
marked at uniÔ¨Åcation and/or subsumption level by using the reserved feature
TO-BE-REDUCED that takes boolean values. The parser and the producer
subsequently analyze these markings. Such treatment in FCG light is absolutely
suÔ¨Écient for reproducing a quite elaborate example of learning in FCG, such as
the one described in Gerasymova‚Äôs MS thesis [18].
Instead of having one construction/form treated in two diÔ¨Äerent ways during
parsing and respectively production (as it is done in FCG), in FCG light we
explicitly associate each construction with two rules that are treated in exactly
the same manner ‚Äî the subsumption, reduction and uniÔ¨Åcation sequence ‚Äî in
both parsing and production. The general form of a parsing or production rule
that corresponds to an FCG light construction is
FCG and Feature Constraint Logics 297
Œº : ‚àí œà; Œ±.
where Œº is the main set of constraints, œà is the precondition, and Œ± is a set of
to-be-reduced constrains. Here, Œº, œà and Œ± should be seen as rooted FSs.
If the reduction actions are implemented in soft mode, and Œ±
is the marked
FS (using the TO-BE-REDUCED feature) that corresponds to Œ±, then the rule
Œº : ‚àí œà, Œ± becomes Œº, Œ±
: ‚àí œà.
The latter can be even written as
Œº
: ‚àí œà.
where Œº
is the uniÔ¨Åcation result for Œº and Œ±
.
The algorithm responsible for getting these two FCG light rules is presented
in Figure 6. It has three main steps, each step translating/transforming in a
certain way the output of its preceding step. Before we will comment on them,
we show via an example what these steps are supposed to do. When applied
on the ‚Äúcita‚Äù construction given in Figure 1 the ‚Äòinitial‚Äô translation step in this
algorithm builds the sets of elementary constraints shown in Figure 3. In the
‚Äòintermediate‚Äô translation step, these sets of constraints are put under the form
of (single-)rooted FSs, as shown in Figure 4. These FSs will be subject to a
number of simple operations in the ‚ÄòÔ¨Ånal‚Äô translation step, and their ultimate
form (for this example) is given in Figure 5.
The idea behind the Ô¨Årst part of the ‚Äòinitial‚Äô translation step of our FCG-into-
LIGHT algorithm is the following: Consider an arbitrary FCG construct and
assume that we want to obtain an OSF/LIGHT rule that corresponds to the appli-
cation of this construct in parsing mode. Among all the elementary constraints in
which this construction is decomposed, those which are subject to (FCG) match-
ing will be placed in the precondition part of the to-be-created LIGHT rule for pars-
ing. Similarly, the constraints used for (FCG) merging will be put into the rule‚Äôs
main part. The (FCG) tag-ed constraints will be placed Ô¨Årstly into the rule‚Äôs re-
duction part and secondly wherever the tag re-appears. The remaining part of the
‚Äòinitial‚Äô translation step is concerned with building the two (parsing and produc-
tion) rules out of the sets of elementary constraints that have just been built. As
formalized above, each rule is of the form RHS :‚àí LHS.
Something important is to be explained here: The application of the J operator
in FCG will correspond in FCG light to (checking and enforcing) certain elemen-
tary constraints. These constraints will be expressed using the reserved features
SYN-SUBUNITS for parsing, and respectively SEM-SUBUNITS for production.
For instance, the FCG code (J ?verb-unit ?top-unit) in the left/semantic
pole of the ‚Äúcita‚Äù construction given in Figure 1 will be translated as the con-
straint ?top-unit.SEM-SUBUNITS ?verb-unit.13
The ‚Äòintermediate‚Äô step of our algorithm puts sets/conjunctions of constraints
under the form of rooted FSs. FCG light, which is oriented toward eÔ¨Éciency of
13
In FCG light, where the use of multi-valued feature constraints is limited to the
reserved SYN-/SEM-SUBUNITS features, the parser/producer will fully take care
of them. In this way, the uniÔ¨Åcation/subsumption procedure is exempted from this
(ineÔ¨Éciency causing!) overhead.
298 L. Ciortuz and V. Saveluc
Input: a construction given in FCG format
1. The initial translation step
‚àí by following the guidelines for construction application in FCG,
build the sets of elementary OSF constraints corresponding to
precondition, reduction and main body,
for parsing and respectively production
‚àí then, for parsing do the following:
place the parsing precondition and reduction constraints
into the RHS of the newly to-be-created (parsing) rule
the rest, i.e. the constraints corresponding to the parser‚Äôs J actions, and
all stuÔ¨Ä in the left/semantic pole,
including the producer‚Äôs J constraints
but not its reduction constraints
is placed into the LHS part of the new (parsing) rule
‚àí for production: proceed similarly.
2. The intermediate translation step:
for each rule of the two rules resulted from the ‚Äòinitial‚Äô step,
‚àí in the LHS unify the FSs having the same root identiÔ¨Åer
‚àí check whether the FSs in the precondition
is a connex tree, i.e. single-rooted FS
‚àí do the same for the LHS part
‚àí do the same for the reduction part if necessary.
3. The final translation step:
for each rule of the two rules resulted from the ‚Äòintermediate‚Äô step,
‚àí put reduction actions unto soft form
i.e. mark constraints for reduction, using the TO-BE-REDUCED feature
‚àí replace the (‚Äúinterpretable‚Äù) feature MEETS with diÔ¨Äerence lists;
constrain accordingly the variables in the diÔ¨Äerence lists
‚àí transform features whose names are non-atomic terms
‚àí extract sort (s1:s2) declarations
‚àí use the reserved feature ARGS to designate the rule‚Äôs RHS.
Output: the two LIGHT rules obtained above.
Fig. 6. The FCG-into-LIGHT translation algorithm which, starting from a construction
given in FCG format, obtains the two rules to be used in FCG light for parsing and
respectively production. For instance, for the ‚Äúcita‚Äù construction which was given in Fig-
ure 1, the two FCG light rules produced by this algorithm are those shown in Figure 5.
The sets of elementary constraints (represented as FSs) into which that construction
was de-composed (see Step 1 from above), were previously presented in Figure 3. They
were further down translated as FSs, and the result of Step 2 was shown in Figure 4.
FCG and Feature Constraint Logics 299
uniÔ¨Åcation and subsumption, imposes that these (precondition, reduction and
main) FSs be single-rooted.
The ‚ÄòÔ¨Ånal‚Äô translation step is concerned with a. soften-ing the constrain
reduction, i.e. marking the constraints which must be reduced; b. replacing ‚Äúin-
terpretable‚Äù, i.e. procedurally deÔ¨Åned FCG predicates like MEETS with non-
procedural ones; c. transforming non-atomic feature names, and d. extracting
is-a relationships between sorts (unary predicates in FCG).
We think it is useful to show how we transform constraint features identiÔ¨Åed
by non-atomic terms (see Step 3 in Figure 6). For instance, the constraint
CASE( #object ) accusative
becomes:
CASE <#object, accusative>.
One Ô¨Ånal remark: The reader will note that in those two FCG light rules in
Figure 5 we purposely omitted the (markings responsible for) constraint reduc-
tion. This is due to the fact that in FCG light the parser/producer itself (and
not the uniÔ¨Åer) takes care of constraint reduction. We should also add that in
FCG light constraint reduction is restricted to the scope of form and meaning.
To summarize this section, we say that a grammar in FCG is a set of con-
structions (written in FCG format), each one of which is automatically translated
using the algorithm in Figure 6 into a pair of rules (in OSF/LIGHT format), one
for parsing and the other for production.
3.2 FCG light Semantics
The OSF-logic provided the declarative semantics to the LIGHT system. It does
the same for FCG light ‚Äî if reduction actions are implemented in soft mode
‚Äî both at the FS uniÔ¨Åcation and FS subsumption levels and at the deductive
control level over FSs, i.e. parsing and production [28] [30].14
In FCG light all rules are unary rules, unlike the LIGHT system which supports
both binary and unary rules. However, the argument ‚Äî or the pre-condition, or
the right hand side (RHS) ‚Äî of each rule is not necessarily a phrase structure.
Instead, it is the description of a rooted subgraph in the syn-sem graph created
during parsing and production. The same is true about the rule‚Äôs left hand
side (LHS). More precisely, one of the restrictions that we impose on FCG light
grammars is the following: all units speciÔ¨Åed in a construction should constitute
a rooted graph, where edges are deÔ¨Åned via the SYN-SUBUNITS and SEM-
SUBUNITS features.
Concerning the procedural semantics, as outlined in Section 3.1, each construc-
tion in FCG light is associated with two rules, one for parsing and the other for
14
We mention that unlike LIGHT when used for the HPSG ERG grammar, FCG light
works with the un-typed counterpart of OSF-logic, since FCG does not impose ap-
propriateness constraints on FSs.
300 L. Ciortuz and V. Saveluc
production. Unlike LIGHT, for which the application of rules is fully uniÔ¨Åcation-
based, in FCG light the unique argument of a rule is checked for compatibility
(with a syn-sem graph) by using FS subsumption (match, in the FCG formula-
tion). The rule‚Äôs LHS is treated via FS uniÔ¨Åcation.15
In FCG light, the parsing and production can be partial. For parsing, this
means that we drop oÔ¨Ä the usual requests that i. all lexical entries should be
deÔ¨Åned in the given grammar, and ii. a syntactic tree should be built so as
to span the whole input sentence and to be subsumed by the grammar‚Äôs start
symbol. Just as for HPSG, there is usually no designated start symbol in FCG
grammars. The function of such a symbol is taken by the top-unit, to which all
the other units (morphological, lexical, syntactic or semantic) get linked in one
way or another.
Given œÑ, the syn-sem graph whose root is the top-unit and whose arcs are
given by the features SYN-SUBUNITS and SEM-SUBUNITS, an FCG light rule
of the form Œº : ‚àíœà, Œ± is applied as follows:
if subsume( œÑ
, œà ), and œÉ is the corresponding most general substitution,
then
perform the reduction of the constraints Œ±œÉ and
unify( ŒºœÉ, œÑ
)
where œÑ
is an arbitrary (single-rooted, maximally connected) subgraph of œÑ, and
œÑ
is the subgraph of œÑœÉ whose root is identiÔ¨Åed by the root of œÑ
œÉ.
It should be noted that a rule application has not necessarily a unique out-
come, since œÑ
is not always unique. Here above, the uniÔ¨Åcation operation is seen
as a constraint satisfaction problem in OSF-logic. Such a problem is solved using
for instance the so-called clause normalization procedure. If ŒºœÉ and œÑ
are trees,
then the usual FS uniÔ¨Åcation algorithm can be used and the result is unique (up
to variable renaming). Subsumption is also regarded in the classical way.
The following simple algorithm formalizes the way parsing is done in FCG light:
Input:
a grammar G, and
œÑ the (initial) syn-sem graph corresponding to
the FORM of a given input sentence.
Procedure:
as long as parsing rules in G apply successfully on œÑ,
build up the corresponding new syn-sem graph(s).
Concerning the parsing output: syn-sem graphs that span the whole input are
(eligible for) the output; the user may impose additional constraints on them.
If there is no graph that satisÔ¨Åes these constraints, then other (partial) graphs
may be considered.
Similarly one can formalize production in FCG light.
15
For other perspectives on the uniÔ¨Åcation and merge operations in FCG, the reader
may consult [29] and [16].
FCG and Feature Constraint Logics 301
4 Grammar Learning in FCG light
In FCG, the learning process is reinforcement-based, i.e. each construct receives a
weight which is a real number between 0 and 1, and it is increased whenever the
construction is used in successful parsing/production. If unsuccessful, the weight
is decreased. One of our objectives has been to explore in FCG light a diÔ¨Äerent
paradigm for deÔ¨Åning strategies for construction learning (as used, for instance,
in grammar repairing), compared to the paradigm that is currently used by FCG.
In FCG light, learning is based on searching in a lattice of grammar versions,
i.e. it amounts to searching in a version space which is partially ordered by
means of a generalization/specialization (actually subsumption-based) relation
between grammars, as illustrated in Figure 7 [22]. The version space is meant
to induce a certain discipline while searching for new grammars (and, at lower
level, new rules) during the learning process.16
For a discussion on using lattices
for learning in Embodied Construction Grammars (ECG) and comparison with
FCG, the reader is referred to [6].
Learning in the FCG light system is performed in on-line (i.e. interactive) mode,
via language games played by 2 agents, as in FCG. For a schematic view on the func-
tional architecture used by FCG light for learning, the reader should see Figure 8.
In order to be able to go into more detail when explaining the learning strategy
used by FCG light, we give in Figure 9 the pseudo-code of the procedure that
implements in FCG lightthe language game presented by Gerasymova in Chapter
4 of her MS thesis [18]. This language game strategy supports the learning of an
FCG grammar for the Russian verb aspects. During the language game played by
the two agents, a number of holophrasis constructions are learned (see Step 1 in
Figure 9). The generalization procedure which is called (see Step 2 in Figure 9)
to elaborate new rules based on the previously produced holophrases is given
also in pseudo-code in Figure 10.
Gerasymova‚Äôs target grammar, which was translated in FCG light following the
guidelines that have been presented in Section 3, is able to parse and produce
sentences like ‚ÄúMisha pocital‚Äù, ‚ÄúMasha narisoval lico‚Äù, ‚Äúkto pocital?‚Äù.17
In the
beginning of the language game, from the target grammar ‚Äî which is used
as such by the ‚Äòteacher‚Äô agent ‚Äî, the syntactic construction ‚Äòpo-‚Äô, and the
associated ‚Äòmapping‚Äô rule and ‚Äòsemantic‚Äô rule were eliminated in order to get
the start grammar, which is to be used (in the beginning of the language game)
16
One could merge the two learning paradigms by associating each rule (of each gram-
mar) in the version space a weight and then updating it, as done in FCG. As a
consequence, this new, composed paradigm would be a generalization of the two
previous ones. One could think of the rule weights in the current implementation of
FCG light as being initially set to 1; removing a rule from a grammar amounts to
setting its weight to 0. As for FCG, in the new, compound paradigm one would have
to keep track of the generalization/specialization relationships between newly cre-
ated rules and the previously existing ones, and similarly between diÔ¨Äerent grammar
versions.
17
These sentences translate into English as ‚ÄúMichael read for a while‚Äù, ‚ÄúMasha has
drown the face‚Äù, and ‚ÄúWho read for a while?‚Äù respectively.
302 L. Ciortuz and V. Saveluc
grammar 2 grammar n
grammar
start
grammar i
grammar j
grammar 1
generalize
specialize
. . .
. . .
. . .
. . .
. . . . . .
. . .
. . .
. . .
Fig. 7. Illustrating the notion of version space for the process of learning grammars
in in the FCG light system. Upward arrows signify the generalization relation between
grammars. Conversely we have the specialization relation. During the grammar learning
process, the ‚Äòstart grammar‚Äô can be generalized for instance to ‚Äògrammar 1‚Äô (which in
turn can be generalized to ‚Äògrammar j‚Äô), or can be specialized to ‚Äògrammar 2‚Äô or
‚Äògrammar n‚Äô.
lcc
abc
test suite
fcg
abc
lcc
learner teacher
language game
Fig. 8. Schematic view on the learning architecture in FCG light. Here lcc (a name
which is an abbreviation for: LIGHT into C Compiler) designates the module in the
LIGHT system that is in charge with the pre-processing and compilation of the input
grammar; abc is the parser‚Äôs name (abbreviation for: Active, Bottom-up Chart-based),
while fcg is the learner module of FCG light. The dotted arrow corresponds to questions
that the learner may ask the teacher in order to guide his or her search for better
inferred rules/grammars.
FCG and Feature Constraint Logics 303
Target grammar: ;
the given given in Chapter 3 of Gerasymova‚Äôs MS thesis [18];
Input/start grammar: ;
obtained from the target grammar by deleting for instance the lexical construction
for ‚Äúpo-‚Äù and the associated ‚Äòmapping rule‚Äô and ‚Äòsemantic‚Äô rule.
Language game: ;
1. choose a setup, for inst. Misha read for-a-while; Masha read ongoing;
teacher: generate a question, for instance ‚Äúkto pocital?‚Äù
learner:
parse the question,
get the corresponding meaning,
try to disambiguate it wrt the given setup,
if disambiguation is successful, then go to Step 1,
otherwise (since in this case ‚Äòpo-‚Äô is unknown to him/her),
send to the teacher the failure message;
teacher: reveal the correct answer to the above question (‚ÄúMisha‚Äù);
learner:
after correlating the CFS previously obtained by parsing
with the meaning pointed to by the teacher‚Äôs answer,
induce a holophrasis construction (corresponding to ‚Äòpocita‚Äô);
2. after performing a number of times the Step 1,
use the procedure given in Figure 10 to
generalize over the learned holophrases, and then
extract new construction rules
by decomposing the generalized holophrasis.
Fig. 9. The pseudo-code for the language game strategy which was designed for learning
for Russian verb aspects as presented inGerasymova‚Äôs MS thesis [18], Chapter 4. The
teacher agent uses the ‚Äòtarget‚Äô grammar, while the learner agent starts the game with
an altered version of it, called the ‚Äòstart‚Äô grammar.
and later on improved by the ‚Äòlearner‚Äô agent. Skimming through the execution
of the procedures given in Figures 9 and 10 during this language game allows us
to make a couple of remarks:18
First, concerning Step 1 in the procedure given in Figure 9:
In FCG light a holophrasis (like ‚Äòpocita‚Äô) is obtained by generalizing the CFSs
obtained during parsing. More speciÔ¨Åcally, this holophrasis construction is
obtained by:
‚Äì applying the LUB operation on the syn-sem CFSs that have been obtained
after parsing slightly similar parsed sentences like ‚ÄúMisha pocital‚Äù and ‚ÄúMasha
pocitala‚Äù; the LUB operation generalizes them with respect to the subject
(Misha, Masha, kto) and the endings (-l/-la) indicating the perfect tense;19
18
The reader may Ô¨Ånd useful to follow the explanations below by taking also a look
at the whole picture of the learning process, as shown in Figure 13.
19
[18] does not explicitly call this a generalization. Nor does it explicitly names the
LUB operation.
304 L. Ciortuz and V. Saveluc
Input: a set of holophrases produced (or, even the CFSs from which they originated)
during the application of Step 1 of a series of language games played according to the
strategy presented in Figure 9;
Output: a set of pair of constructions (each one made of a lexical entry and a lexical
rule) corresponding to each preÔ¨Åx and its associated event-type;
Procedure: ‚Ä¢ Group (the CFSs that correspond to) all holophrases that have
‚àí the same preÔ¨Åx (for example ‚Äòpo-‚Äô),
‚àí the same value for the EVENT-TYPE feature for the event which is associ-
ated to the respective verb‚Äôs occurrence (for example, ‚Äòpocita‚Äô, ‚Äòporisova‚Äô etc.
correspond to the event-type ‚Äòfor-a-while‚Äô);
‚Ä¢ for each such group g
generalize: apply the least upper bound (LUB) operation on the CFSs (representing
the holophrases) in the group g; let‚Äôs denote it LUB(g);
decompose: split the generalized holophrasis construction corresponding to LUB(g)
into a lexical construction and a lexical rule;
to get this done, it is necessary to introduce a new (‚ÄòAKTIONSART‚Äô) feature; this
feature makes the link between the preÔ¨Åx and the verb‚Äôs EVENT-TYPE value. For
example:
SYN-CAT top[ AKTIONSART delimitative ];
SEM-CAT top[ AKTIONSART( #event ) delimitative ];
replace g in the current grammar with the above created rules.
Fig. 10. The procedure for generalizing over (CFSs corresponding to) the holophrases
learned during a series of language games for acquiring the Russian verb aspects.
‚Äì then inducing a rule construction from the generalized (via LUB) CFSs ob-
tained above, this is a construction which when starting from the FORM
(‚Äòpocita‚Äô) gets the associated MEANING (read for-a-while) and vice-versa.
Here above it became evident an advantage that FCG light has over the FCG
approach, due to the fact that we use a feature constraint logics as support: the
LUB operation is a well known operation deÔ¨Åned on feature structures with a
well deÔ¨Åned correspondent in feature logics.
Second, concerning Step 2 in the language game strategy outlined in Figure 9:
Here we do not stick (strictly) to the 3-step learning scheme used by Gerasymova,
inspired by [35], so to produce a syntactic rule, a mapping rule and a semantic
rule. We use instead a two-step strategy for building a lexical entry and a lexical
rule. This is common practice for the HPSGs that have been implemented in
the LIGHT system. We mention that the lexical construction and the lexical
rule produced in the decompose step in Figure 10 correspond respectively to the
syntactic rule and (a slightly simpliÔ¨Åed version of) the composition result of the
mapping rule and the semantic rule in [18].20
20
We are not interested here in maintaining the relationship between what we automat-
ically learn in FCG light and the learning schemata discussed in Tomasello‚Äôs work,
as it was done in Gerasymova‚Äôs thesis for the following reason: while being useful
for didactic presentation purposes, we consider it a rather too diÔ¨Écult and complex
endeavor to be conveniently followed (as such) by autonomous learning robots.
FCG and Feature Constraint Logics 305
A. By simply analyzing the association of (prefix, event-type) pairs associated to verbs
during the language game, it can be inferred that:
not all verbs can get preÔ¨Åxed (with ‚Äòpo‚Äô-like prepositions), therefore:
‚Ä¢ to distinguish between those verbs that accept preÔ¨Åxes and those that don‚Äôt,
introduce a new sort, ‚Äòperfective‚Äô, and
‚Ä¢ add (it as the value of) a new feature, ‚ÄòASPECT‚Äô at the verb‚Äôs SYN-CAT level:
SYN-CAT top[ ASPECT perfective ];
B. By simply analyzing the values of the EVENT-TYPE feature for events correspond-
ing to the verbs whose ASPECT is ‚Äòperfective‚Äô it follows that:
only events whose EVENT-TYPE value is diÔ¨Äerent from ‚Äòongoing‚Äô are associated (as
meaning) to those verbs, therefore:
‚Ä¢ invent a new sort, name it for instance ‚Äònon-ongoing‚Äô, and
‚Ä¢ add (it as the value of) a new feature, ‚ÄòVIEW‚Äô at the verb‚Äôs SEM-CAT level, for
all perfective verbs, i.e. those that can be preÔ¨Åxed:
SEM-CAT top[ VIEW( #event ) non-ongoing ].
Fig. 11. The procedure for specializing over verbs while learning in FCG light the
Russian verb aspects. Like in the generalization procedure, our approach is slightly
diÔ¨Äerent from the one presented in [18]. A couple of remarks could be added here,
namely 1. for step A: the complementary sort to ‚Äòperfective‚Äô would be ‚Äònon-perfective‚Äô,
and 2. for step B: in the FCG light‚Äôs sort hierarchy, the ‚Äònon-ongoing‚Äô sort will be the
parent sort for all values taken by the EVENT-TYPE feature which are diÔ¨Äerent from
‚Äòongoing‚Äô, as graphically illustrated in Figure 12.
The generalization procedure given in Figure 10 is a signiÔ¨Åcantly revised ver-
sion of the one in [18]. Concerning its application in the afore mentioned lan-
guage game, the reader should note that due to the one-step rule decomposition
(producing a ‚Äòsyntactic‚Äô construction and a ‚Äòcombined‚Äô rule), it is enough to
use the AKTIONSART feature at the verb‚Äôs SYN-CAT level. Further rule split-
ting/decomposition of the ‚Äòcombined‚Äô rule is possible, and so a ‚Äòmapping‚Äô rule
and a ‚Äòsemantic‚Äô rule can be obtained (√† la Tomasello).
After the work performed by the generalization procedure in Figure 10, a
specialization task can be performed on constructions for preÔ¨Åxed verbs, as pre-
sented in Gerasymova‚Äôs MS thesis [18].21
This task, which consists of two steps,
namely A and B in Figure 11, can be performed by alternative means compared
to those used in [18]. We claim that in FCG light these means are simpler, more
diverse and more naturally Ô¨Åtted into the framework.
Indeed, in OSF-logics it is easy to consider/introduce new sorts by gener-
alizing/grouping some already existing sorts. This is for instance the case of
‚Äònon-ongoing‚Äô when learning Russian verb aspects, as implemented at Step B in
Figure 11 and illustrated in Figure 12. Also, instead of introducing new features
21
Alternatively, this specialization can be applied before generalization. In such a case
it would work on syn-sem CFSs directly, not on the rules created afterwards based
on these CFSs.
306 L. Ciortuz and V. Saveluc
ongoing
non‚àíongoing
event‚àítype
. . . . . .
event‚àítype
. . .
. . . ongoing
. . .
. . .
Fig. 12. Example of sort signature reÔ¨Ånement in FCG light. Such a reÔ¨Ånement can be
commanded during the specialization procedure, see Figure 11
FORM
MEANING
generalized
holophrasis
po+verb
holophrasis
po+verb1
holophrasis
po+verb2
holophrasis
po+verb1+end1
holophrasis
po+verb1+end1
generalized
holophrases
po+verb
. . .
. . .
na+verb
rule
map.
rule
sem.
VIEW,
ASPECT
syn.
rule
complem.
rule
AKTIONSART
decomposition
rule
generalization
+
rule
decomposition
specialization
Fig. 13. An overview on grammar repairing, i.e. rule learning in FCG light, as done dur-
ing the language game for acquiring the Russian verb aspects. For the rule composition
scheme (acting on syntactic, mapping and semantic rules) please refer to [19].
‚Äî like ASPECT, at Step A in Figure 11 ‚Äî, one could opt for redeÔ¨Åning the sort
hierarchy. In our example, we mean introducing the sort ‚Äòperfective-verb‚Äô as a
subsort to the sort ‚Äòverb‚Äô.
After having presented the procedures that support the learning process (Fig-
ures 9-11), we add the remark that they make explicit a heuristics responsible
for guiding the learning agent ‚Äî based on background linguistics knowledge ‚Äî
to rightly choose a (certain) construction among the (possibly many) diÔ¨Äerent
ones which are situated in the lattice of rule versions between the most speciÔ¨Åc
and the most general constructions that are compatible with the sentences to be
learned in the current language game.
FCG and Feature Constraint Logics 307
generation
hipothesis
evaluation
hipothesis
abc
user:
affect
input
grammar
not suitable
ilp
. . . . . .
output 2 output n
output 1
while
abc abc abc
grammar 1 grammar 2 grammar n
test suite
golden
start
grammar
grammar
target
Fig. 14. The learning architecture of the ilpLIGHT extension/conÔ¨Åguration of
the LIGHTsystem. The abc and ilp modules are the parser and respectively the
ILP-based learner components of LIGHT.
For Gerasymova‚Äôs example, we could be formulate as follows the simple lin-
guistic reason that supports the learning of the construction for the ‚Äòpo-‚Äô lexical
entry and the corresponding lexical rule via generalization on the ‚Äòpocital‚Äô-like
holophrases (see Step 2 in Figure 9):
Because ‚Äòpo-‚Äô is a preÔ¨Åx morpheme inside the word ‚Äòpocital‚Äô, the gram-
mar learning process should concentrate on elaborating the relationship
between the newly learned holophrasis and the already existing construc-
tions or CFSs for the other two morphemes that compose that word,
namely the verb root (‚Äòcita‚Äô) and the ending (‚Äò-l‚Äô/‚Äò-la‚Äô).
It turns out that this speciÔ¨Åc relationship can be identiÔ¨Åed by a heuristics that
generalizes twice on the CFSs corresponding to learned holophrases, namely:
Ô¨Årstly generalizing on the ending ‚Äò-l‚Äô/‚Äò-la‚Äô (by simply using the LUB operation,
see Step 1 in Figure 9), and secondly generalizing on the verb (followed by
application of the rule decomposition procedure, see Figure 11). The ‚Äúinvention‚Äù
of holophrasis constructions ‚Äî starting from CFSs relating morphemes/words
unknown to the learner to the meaning that the teacher points to ‚Äî followed by
rule creation is the essence of the grammar learning process during this language
308 L. Ciortuz and V. Saveluc
game. A synthesis of learning in FCG light the aspect of Russian verbs is shown
in Figure 13.
Finally we should note that diÔ¨Äerent language games in FCG and FCG light
require diÔ¨Äerent language strategies. Therefore learning in such a setup is not
general-purpose. DeÔ¨Åning and implementing a set of useful, wider-range learning
strategies should be the focus of further research.
5 Conclusion and Further Work
This chapter introduces FCG light, a core subset of FCG, which is (re)deÔ¨Åned
using as framework a feature constraint logic, namely OSF-logic. The latter
provides FCG light with a well-deÔ¨Åned semantics and allows its clear compari-
son with other uniÔ¨Åcation-based formalisms. We showed how FCG light can be
implemented by using a simpliÔ¨Åed version of LIGHT ‚Äî a platform on which
HPSG grammars have previously been implemented. For further details on the
actual implementation, the reader is referred to [27]. In order to proof-check the
functionality of our FCG light‚Äôs implementation we reproduced the experiment
for learning the FCG grammar of Russian verb‚Äôs aspects [18]. Instead of using
reinforcement-based learning as done in the current implementation of FCG,
we opted for learning in a lattice/hierarchy of diÔ¨Äerent grammar versions. This
lattice is naturally provided by the OSF-logic setup by exploiting the specializa-
tion/generalization relationship among grammars. Building on this experiment,
in our recent paper [13] we have shown how to model in FCG a Slavic-based
phenomenon present in a regional dialect of the Romanian language (more ex-
actly, a certain verbal aspect), and how to model in FCG the transformation
that presumably takes place in a child‚Äôs brain when ‚Äúlearning over‚Äù that Slavic
construction a Latin-rooted phrasal construction in modern Romanian.
Apart from our experiment and that of Gerasymova‚Äôs, both using FCG for
learning phenomena related to Slavic languages, there is already another one
done for Polish [20].
We intend to apply such, and other, learning strategies to learn the clitic
pronouns in the Romanian language, which is a rather diÔ¨Écult issue for non-
native speakers. The result of the Romanian clitics‚Äô formation in FCG light could
then be compared, for instance, to the HPSG description of these clitics as done
in the Paola Monachesi‚Äôs PhD thesis [23].
Also, inspired by the FCG approach to grammar learning, we are now able to
suggest new ways for learning grammars in other uniÔ¨Åcation-based formalisms.
In particular, we aim to test these ideas on ilpLIGHT [8]. This is an exten-
sion/conÔ¨Åguration of the LIGHT system which adapted the learning paradigm of
Inductive Logic Programming (ILP, [24]) so as to work with HPSG-like uniÔ¨Åca-
tion grammars.
In ilpLIGHT, the learning process ‚Äî also based on searching in a lattice of
grammar versions, as in FCG light ‚Äî is done in oÔ¨Ä-line/batch mode, by using
FCG and Feature Constraint Logics 309
a ‚Äúgolden‚Äù test suite given to the learner by the supervisor/teacher.22
For the
learning architecture of ilpLIGHT, the reader is referred to Figure 14. [11] has
demonstrated that it is possible to induce each of three basic HPSG principles ‚Äî
the head principle, the subcategorization principle and the saturation principle,
as presented by [25] ‚Äî given that the grammar contains the other two principles
and a simply annotated test suite is provided.
We suggest that ilpLIGHT can be substantially improved by using certain
ideas borrowed from FCG:
‚Äì instead of using a given ‚Äúgolden‚Äù test suite (on which parsing is performed
and against which the progress of grammar learning is checked), this test
suite can be dynamically produced during the language game played by two
agents;
‚Äì the grammar learning process can be ‚Äúgrounded‚Äù, something which, up to
our knowledge, was not considered before for HPSGs;
‚Äì new rules can be learned by generalizing upon several already learned rules,
instead of simply modifying one or at most two rules, as is currently done in
ilpLIGHT, thus constituting a signiÔ¨Åcant step forward.
Upgrading the ilpLIGHT system so to do parsing and production with SBCG
grammars [26] would further enhance the possibilities to compare FCG with
other construction-based systems.
Acknowledgements. This work has been done in the framework of the Eu-
ropean FP7 research project ‚ÄúALEAR‚Äù and its sister project ‚ÄúALEAR 37EU‚Äù
funded by the Romanian Ministry of Education and Research‚Äù. The authors
wish to thank Joachim De Beule and Kateryna Gerasymova for their useful
comments on an earlier draft of this chapter.
References
[1] A√Øt-Kaci, H., Podelski, A., Goldstein, S.: Order-sorted feature theory uniÔ¨Åcation.
Journal of Logic, Language and Information 30, 99‚Äì124 (1997)
[2] A√Øt-Kaci, H., Di Cosmo, R.: Compiling order-sorted feature term uniÔ¨Åcation. Tech.
rep., Digital Paris Research Laboratory (1993), pRL Technical Note 7
[3] A√Øt-Kaci, H., Podelski, A.: Towards a meaning of LIFE. Journal of Logic Pro-
gramming 16, 195‚Äì234 (1993)
[4] Bleys, J., Stadler, K., De Beule, J.: Search in linguistic processing. In: Steels, L.
(ed.) Design Patterns in Fluid Construction Grammar. John Benjamins, Amster-
dam (2011)
[5] Carpenter, B.: The Logic of Typed Feature Structures ‚Äì with applications
to uniÔ¨Åcation grammars, logic programs and constraint resolution. Cambridge
University Press (1992)
22
The test suite is a set of sentences with associated parsing trees and eventually other
informations.
310 L. Ciortuz and V. Saveluc
[6] Chang, N., De Beule, J., Micelli, V.: Computational Construction Grammar: Com-
paring ECG and FCG. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 259‚Äì288. Springer, Heidelberg (2012)
[7] Ciortuz, L.: Expanding feature-based constraint grammars: Experience on a large-
scale HPSG grammar for English. In: Proceedings of the IJCAI 2001 co-located
Workshop on Modelling and Solving Problems with Constraints, Seattle, USA
(2001)
[8] Ciortuz, L.: A Framework for Inductive Learning of Typed-UniÔ¨Åcation Grammars.
In: Adriaans, P.W., Fernau, H., van Zaanen, M. (eds.) ICGI 2002. LNCS (LNAI),
vol. 2484, pp. 299‚Äì301. Springer, Heidelberg (2002)
[9] Ciortuz, L.: LIGHT ‚Äî A Constraint Language and Compiler System for Typed-
UniÔ¨Åcation Grammars. In: Jarke, M., Koehler, J., Lakemeyer, G. (eds.) KI 2002.
LNCS (LNAI), vol. 2479, pp. 3‚Äì17. Springer, Heidelberg (2002)
[10] Ciortuz, L.: LIGHT AM ‚Äì Another abstract machine for feature structure uniÔ¨Å-
cation. In: Oepen, S., Flickinger, D., Tsujii, J., Uszkoreit, H. (eds.) EÔ¨Éciency in
UniÔ¨Åcation-based Processing, pp. 167‚Äì194. CSLI Publications, The Center for the
Study of Language and Information, Stanford University (2002)
[11] Ciortuz, L.: Inductive learning of attribute path values in typed-uniÔ¨Åcation gram-
mars. ScientiÔ¨Åc Annals of the ‚ÄúAl.I. Cuza‚Äù, University of Iasi, Romania. Computer
Science Series, pp. 105‚Äì125 (2003)
[12] Ciortuz, L.: Parsing with UniÔ¨Åcation-Based Grammars ‚Äî The LIGHT Compiler.
EditDan Press, Iasi (2004)
[13] Ciortuz, L., Saveluc, V.: Learning to unlearn in lattices of concepts: A case study
in Fluid Construction Grammars. In: Proceedings of SYNASC 2011, pp. 160‚Äì167.
IEEE Computer Society, Timi≈üoara (2011)
[14] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[15] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[16] Fernando, C.: Fluid Construction Grammar in the Brain. In: Steels, L. (ed.)
Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 312‚Äì330. Springer,
Heidelberg (2012)
[17] Flickinger, D., Copestake, A., Sag, I.A.: HPSG analysis of English. In: Wahlster,
W. (ed.) Verbmobil: Foundations of Speech-to-Speech Translation. ArtiÔ¨Åcial In-
telligence, pp. 254‚Äì263. Springer (2000)
[18] Gerasymova, K.: Acquisition of aspectual grammar in artiÔ¨Åcial systems through
language games, Humboldt Universitaet zu Berlin, Germany, MS thesis (2009)
[19] Gerasymova, K.: Expressing Grammatical Meaning with Morphology: A Case
Study for Russian Aspect. In: Steels, L. (ed.) Computational Issues in FCG. LNCS
(LNAI), vol. 7249, pp. 91‚Äì122. Springer, Heidelberg (2012)
[20] H√∂fer, S.: Complex Declension Systems and Morphology in Fluid Construction
Grammar: A Case Study of Polish. In: Steels, L. (ed.) Computational Issues in
FCG. LNCS (LNAI), vol. 7249, pp. 143‚Äì177. Springer, Heidelberg (2012)
[21] Kifer, M., Lausen, G., Wu, J.: A logical foundation of object-oriented and frame-
based languages. Journal of the ACM 42(4), 741‚Äì843 (1995)
[22] Mitchell, T.M.: Machine Learning. McGraw-Hill, New York (1997)
[23] Monachesi, P.: A grammar of Italian clitics. Ph.D. thesis, Tilburg University, iTK
Dissertation Series 1995-3 and TILDIL Dissertation Series 1995-3 (1995)
[24] Muggleton, S., De Raedt, L.: Inductive logic programming: Theory and methods.
Journal of Logic Programming 19(20), 629‚Äì679 (1994)
FCG and Feature Constraint Logics 311
[25] Pollard, C., Sag, I.A.: Head-driven Phrase Structure Grammar. CSLI Publications,
Stanford (1994)
[26] Sag, I.A.: Sign-Based Construction Grammar: An informal synopsis. In: Boas,
H., Sag, I.A. (eds.) Sign-Based Construction Grammar. CSLI Publications, The
Center for the Study of Language and Information, Stanford University (2010)
(Version of August 23, 2010)
[27] Saveluc, V., Ciortuz, L.: FCGlight, a system for studying the evolution of natural
language. In: Proceedings of SYNASC 2010, pp. 188‚Äì193. IEEE Computer Society,
Timi≈üoara (2010)
[28] Shieber, S.M., Schabes, Y., Pereira, F.: Principles and implementation of deductive
parsing. Journal of Logic Programming, 3‚Äì36 (1995)
[29] Santib√°√±ez, J.S.: A Logic Programming Approach to Parsing and Production in
Fluid Construction Grammar. In: Steels, L. (ed.) Computational Issues in FCG.
LNCS (LNAI), vol. 7249, pp. 239‚Äì255. Springer, Heidelberg (2012)
[30] Sikkel, K.: Parsing Schemata. Springer (1997)
[31] Smolka, G.: Feature-constraint logics for uniÔ¨Åcation grammars. Journal of Logic
Programming 12, 51‚Äì87 (1992)
[32] Steels, L.: A Ô¨Årst encounter with Fluid Construction Grammar. In: Steels, L. (ed.)
Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam
(2011)
[33] Steels, L., De Beule, J.: A (very) brief introduction to Fluid Construction Gram-
mar. In: ScaNaLU 2006: Proceedings of the Third Workshop on Scalable Natural
Language Understanding, pp. 73‚Äì80. Association for Computational Linguistics,
Morristown (2006)
[34] Steels, L., De Beule, J.: Unify and Merge in Fluid Construction Grammar. In:
Vogt, P., Sugita, Y., Tuci, E., Nehaniv, C.L. (eds.) EELC 2006. LNCS (LNAI),
vol. 4211, pp. 197‚Äì223. Springer, Heidelberg (2006)
[35] Tomasello, M.: Construction grammar for kids. Constructions (2007)
Fluid Construction Grammar in the Brain
Chrisantha Fernando1,2
1
School of Electronic Engineering and Computer Science,
Queen Mary University of London, UK
2
Department of Informatics, University of Sussex, Falmer, Brighton, UK
Abstract. I propose how symbols in the brain could be implemented
as spatiotemporal patterns of spikes. A neuron implements a re-write
rule; Ô¨Åring when it observes a particular symbol and writing a particular
symbol back to the neuronal circuit. Then I show how an input/output
function mapped by a neuron can be copied. This permits a population
of neuron-based rules to evolve in the brain. We are still very far from
understanding how FCG could be implemented in the brain; however,
understanding how a basic physical symbol system could be instantiated
is a foundation for further work.
1 Introduction
Fluid Construction Grammar is a formalism for deÔ¨Åning and operationaliz-
ing the highly complex symbolic operations that occur in language processing
[11, 53, 55, 57]. The implementations of FCG made so far are all carried out
through symbolic programming languages, mostly in LISP but also in PROLOG
(as discussed in other chapters of this volume [54]). How can the brain do Fluid
Construction Grammar (FCG)? Constructions are rules that act on structured
symbolic representations. To implement FCG the brain would need to implement
a physical symbol system (PSS) [21]. Therefore my aim is to discuss the validity
or otherwise of a PSS and how it can be implemented. So far I have not been
able to propose any plausible neuronal mechanisms capable of the more com-
plex matching and merging operations required by FCG. However, I am able to
hypothesize neuronal implementations of symbolic re-write rules [16], to show
at an algorithmic level how these rules could be evolved in the brain to develop
syntactic conventions [15], and to then show at an implementation level how
such rules could replicate in neuronal tissue.
My approach rests on two novelties. The Ô¨Årst is the recent formulation of
polychronous computing [31, 34], i.e. computing on the basis of spike patterns.
This suggests a neural substrate for symbol structures [16]. The second is the
neural replicator hypothesis proposed by E√∂rs Szathm√°ry and myself that sug-
gests that rules operating on such symbols could be units of evolution in the
brain [43]. We hypothesise that constructions of FCG replicate in the brain and
evolve using a kind of neurally implemented learning classiÔ¨Åer system [15].
Historically, purely symbolic architectures whilst in principle endlessly ex-
pressive, in practice have been hard to train, e.g. SOAR [24]. The FCG is no
L. Steels (Ed.): Computational Issues in FCG, LNAI 7249, pp. 312‚Äì330, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
Fluid Construction Grammar in the Brain 313
exception. Why is this? I suggest that it is because a grounding of FCG in
lower level perceptual mechanisms is needed. This would allow local synaptic
learning rules to become available to the symbolic learning system. For example,
it is conceivable that a symbolic system would be able to exapt (re-use for a
diÔ¨Äerent function) visual and auditory shift-invariant pattern recognition mech-
anisms for the matching operation of FCG [37, 58]. Alternatively, it is possible
that hierarchical predictive model building mechanisms originally formulated in
visual perception could be re-used to construct conceptual categories [49], or
that mechanisms for causal learning could be used to learn causal dependencies
between symbol tokens, e.g syntactic regularities [44]. So far, such links have
been poorly explored. To some extent this is because of a sociological divide
between the symbolic and the connectionist factions in cognitive science [21, 23].
To help to bridge this divide it is useful to consider how chemical information is
symbolic in a sense, and to realize that symbolic computation takes place in the
biochemical systems of cells.
2 A Chemical Symbol System
Chemical machines, or in other words Ô¨Çuid automata [22] are constructed from
interacting chemicals. Chemistry can be usefully thought of as containing a kind
of physical symbol system. These chemical machines are very far from serial
Turing machines at the implementation level, although they may well be Turing
complete at the computational level [39]. An archetypical example of such a
chemical machine is a cell.
What are molecules? They are objects composed of atoms that have speciÔ¨Åc
structural relationships between them. A molecule is assembled according to a
combinatorial syntax, i.e. a set of chemical structural constraints such as valance,
charge, etc. . . that determine how atoms can legally join together to make the
molecule. Combinatorial semantics determine how a molecule with a particular
structure will react or behave in a given environment. So, semantic content in
the case of the chemical symbol structure equates to chemical function, or in
other words reactivity. The function of a molecule is itself a function of the
semantic content of its parts, e.g. the reactivity of a benzene ring is modiÔ¨Åed by
side-groups such as methyl groups. The physical symbols and their structural
properties cause the system behaviour.
Note that a chemical system, whilst consisting of molecules that are sym-
bol structures, operates in parallel (rather than in series). It is constrained by
kinetic and other dynamic aspects. It is subject to non-encoded (implicit) inÔ¨Çu-
ences such as temperature. All these aspects were not aspects which naturally
came into the picture when thinking about physical symbol systems, but they do
enter when considering chemical symbol systems. For good example of a symbol-
ically speciÔ¨Åed computation in chemistry is a chemical clock. The two coupled
autocatalytic cycles of the BZ reaction constitute a Ô¨Çuid automaton that im-
plements a chemical clock [2, 22]. Whilst it is the symbolic (as deÔ¨Åned above)
314 C. Fernando
organization of its molecules that speciÔ¨Åes the reaction network topology, it is
by the analog operation of the assembled reaction network that the clock like
phenomena of the BZ reaction arises.
The properties of atoms and molecules described above give chemistry a very
special set of macroscopic characteristics. For example, chemistry is produc-
tive. The capacity for chemical reactivity is unlimited, i.e. there are many more
possible reactions than could be implemented in any realistically sized system.
IndeÔ¨Ånitely many molecules can be produced allowing indeÔ¨Ånitely many reac-
tions. This is possible with only a Ô¨Ånite set of distinct atomic types. Therefore,
an unbounded set of chemical structures must be composite molecules. In the
same way, an indeÔ¨Ånite number of propositions can be entertained, or sentences
spoken. This is known as the productivity of thought and language, Therefore if
neural symbols exist, they must have the same capacity for being combined in
unlimited ways. This is not merely a crude analogy. No non-human animal has
the capacity for productive thought [45].
Secondly, chemistry is systematic; the capacity for atoms to be combined in
certain ways to produce some molecules is intrinsically connected to their ability
to produce others. Consider how a chemist might learn chemistry. There are
rules of thumb that help a chemist to guess how a molecule will react based on
its structure. A chemist does not learn just a list of valid reactions. In the same
way, there is systematicity in language, e.g. the ability to produce or understand
a sentence is intrinsically connected with the ability to produce and understand
other sentences. Languages aren‚Äôt learned by learning a phrasebook. Languages
have syntax.
Thirdly, the same atom makes approximately the same contribution to each
molecule in which it occurs. For example, the contribution of hydrogen to a water
molecule is to aÔ¨Äect all sorts of properties of the reactivity of that molecule.
For example, hydrogen atoms have reducing power (i.e. they suck electrons)
wherever they bind in a molecule and this eÔ¨Äect is a property of the hydrogen
atom itself. This means that there is systematicity in reactivity (semantics) as
well as in structure (syntax). This is known as compositionality. In the same
way, lexical items in sentences have approximately the same contribution to each
expression in which they occur. This approximate nature suggests that there is
a more fundamental set of ‚Äòatoms‚Äô in language than words themselves.
Let us also consider brieÔ¨Çy why the idea of a chemical symbol system was
entertained in chemistry, that is, why scientists Ô¨Årst came to believe in discrete
atoms coming together systematically to form molecules. The crucial discoveries
were of the systematic nature of chemistry. In Hudson‚Äôs ‚ÄúThe History of Chem-
istry‚Äù he describes the following discoveries [28]. Lavoisier discovered a systematic
relationship in chemical reactions, i.e. the conservation of mass. Proust discov-
ered the law of deÔ¨Ånite proportions, i.e. that compounds when broken down,
produce constituents in Ô¨Åxed proportions. Dalton extended this to the law of
multiple proportions that explained that when two elements came together to
form diÔ¨Äerent compounds (notably the oxides of metals), they would come to-
gether in diÔ¨Äerent small integer proportions [28]. These results could elegantly
Fluid Construction Grammar in the Brain 315
be explained by an atomic theory. We see that there are analogous reasons to
believe in symbols in the brain, based on an examination of the properties of
human thought and language.
However, there are extra properties required of the PSS in cognition compared
to the PSS in chemistry. Cognition includes the capacity to learn an appropriate
PSS, not just to implement a PSS. Children can learn and manipulate explicit
rules [10, 36] which implies the existence of a neural physical symbol system
capable of forming structured representations and learning rules for operating
on these representations [41]1
.
The following is a concise deÔ¨Ånition of a symbol system adapted from Har-
nad to emphasize the chemical aspects [26]. A symbol system contains a set of
arbitrary atoms (or physical tokens) that are manipulated on the basis of
‚Äúexplicit rules‚Äù that are likewise physical tokens or strings (or more complex
structures, e.g. graphs or trees) consisting of such physical tokens. The explicit
rules of chemistry generate reactions from the structure of atoms and molecules
(plus some implicit eÔ¨Äects, e.g. temperature). The rule-governed symbol-token
manipulation is based purely on the shape of the symbol tokens (not their ‚Äúmean-
ing‚Äù), i.e., it is purely syntactic, and consists of ‚Äúrulefully combining‚Äù and
recombining symbol tokens, in chemical reactions. There are primitive atomic
symbol tokens and composite symbol-token strings (molecules). The entire
system and all its parts ‚Äì the atomic tokens, the composite tokens, the syntactic
manipulations both actual and possible and the rules ‚Äì are all ‚Äúsemantically
interpretable:‚Äù The syntax can be systematically assigned a meaning e.g., as
standing for objects or as describing states of aÔ¨Äairs [26]. For example, semantic
interpretation in chemistry means that the chemical system exhibits chemical
reactivity, and in biochemistry it means that the intra-cellular chemical system
stands for states of aÔ¨Äairs in the environment outside the cell, for example the
conformation of a signaling molecule may represent the glucose concentration
1
Gary Marcus has shown that 7 month old infants can distinguish between sound pat-
terns of the form ABA versus ABB, where A and B can consist of diÔ¨Äerent sounds
e.g. ‚Äúfoo‚Äù, ‚Äúbaa‚Äù etc. Crucially, these children can generalize this discrimination ca-
pacity to new sounds that they have never heard before, as long as they are of the
form ABA or ABB. Marcus claims that performance in this task requires that the
child must extract ‚Äúabstract algebra-like rules that represent relationships between
placeholders (variables), such as ‚Äúthe Ô¨Årst item X is the same as the third item Y‚Äù,
or more generally that ‚Äúitem I is the same as item J‚Äù [42]. Several attempts have
been made to explain the performance of these children without a PSS (e.g. using
connectionist models) [50] but Marcus has criticized these as smuggling in symbolic
rules in one way or another by design [41, p.70]. For Marcus it seems that the system
itself must discover the general rule. In summary, the problem with a large set of
connectionist learning devices is that a regularity learned in one component of the
solution representation is not applied/generalized eÔ¨Äectively to another part [41].
Marcus calls this the problem of training independence [42]. Marcus considers this
one of the fundamental requirements for a learning system to be described as sym-
bolic or rule based, and I agree.
316 C. Fernando
outside the cell. In the same way a neural symbol system exhibits behavior such
as the child‚Äôs capacity to distinguish ABA from ABB in grammar learning tasks.
This chemical formulation may not seem of beneÔ¨Åt, and may even be confusing
to linguists, but it certainly helps me to link these two domains of computation,
the biochemical and the cognitive, and this allows one to consider a new range
of computations.
3 A Neural Physical Symbol System
In this section I present the outline of a neural framework for arbitrary phys-
ical tokens (atoms) arranged into molecules or symbol structures. I show how
they can undergo explicit rule-governed symbol-token manipulation (reactions).
Finally I show how these explicit rule sets can be learned.
In a recent paper [16] we simulated a network of cortical spiking neurons [30,
32] with synaptic weight dynamics governed by spike-time-dependent plasticity
(STDP). STDP is an empirically observed process by which synaptic weights
change as a function of the timing of pre- and post-synaptic spike activity. If
a pre-synaptic spike reaches the post-synaptic neuron before the post-synaptic
neuron Ô¨Åres, then the strength of that synapse will increase. However, if a pre-
synaptic spike reaches a post-synaptic neuron after that post-synaptic neuron
Ô¨Åres, then the synaptic strength will decrease. This implements a kind of causal-
ity detector. If the pre-synaptic neuron caused the post-synaptic neuron to Ô¨Åre,
the synaptic strength will increase. When the extent of STDP is modulated by a
reward molecule such as dopamine, it is possible to solve reinforcement learning
tasks [32].
Consider Ô¨Årst a possible neural representation of an atomic symbol token, see
Figure 1. At the top we see four examples of symbol-tokens consisting of spa-
tiotemporal patterns of spikes. The y-axis indicates which neuron the spike will
stimulate, and the x-axis indicates the axons down which the spikes are passing
from left to right. Thus, the depiction of the (purple) spatiotemporal pattern on
the left indicates that the middle neuron is stimulated 10ms later than the top
and bottom neurons (because the spikes have travelled further to the right in
the top and bottom axons than the spike on the middle axon). The remainder of
the Ô¨Ågure shows the consequences of stimulating a chain of neural connections
with this spike pattern in the top left box. Each chain consists of three synapses
in series. There are three chains. The chain is activated by asynchronously stim-
ulating the Ô¨Årst three neurons on the left of the chain. That is, the top and
bottom neurons are stimulated Ô¨Årst, and then 10ms later the middle neuron is
simulated. The spikes will then Ô¨Çow down the axons of the chain (from left to
right) asynchronously activating the second and third layer neurons. It is this
spatiotemporal pattern of spikes that we deÔ¨Åne as an atomic neural symbol-
token. The diagram shows that detector neurons at various locations along the
chain can detect this spatiotemporal spike pattern if the axonal delays from the
pre-synaptic neuron to the detector neuron are properly matched to the spa-
tiotemporal pattern such that depolarization reaches the detector neuron body
Fluid Construction Grammar in the Brain 317
Fig. 1. Four possible spatiotemporal spike pattern based symbol-tokens are shown at
the top. Below one of these spike patterns is injected into a chain of neurons running
from left to right (three synaptic layers are shown). From top to bottom we see three
snapshots over time as this injected symbol-tokens passes from left to right along a
chain of parallel axons. Three possible detector neuron sites are shown in purple. The
detector neurons inputs are arranged with a set of delays such that all three spikes
reach the body of the detector neuron at the same time.
318 C. Fernando
simultaneously. If a summed voltage contribution from each neuron is necessary
to Ô¨Åre the detector, then only when the appropriate spike pattern is present
will the detector Ô¨Åre. This implementation of neural symbol-tokens (atoms) uses
the concept of polychronous computing and a modiÔ¨Åcation of the concept of
wavefront computing [33, 34]. Of course, in real spiking neural networks with
much noise, it may be necessary to use a much larger spatial dimension in order
to deal with the temporal uncertainty of the position of any one spike, and with
low probability transmission at each synapse. However, the principles described
here remain unchanged. Also, one should not expect the chain to be neatly visible
in space. The chain is a topological concept and not a spatial concept.
The construction of molecular symbol structures from atomic symbol-tokens
requires binding of atomic symbol-tokens together [3, 40] such that they can
be subsequently manipulated (reacted) as a function of the structure of the
molecule. In my framework, compositional neural symbolic structures exist as
temporally ordered sequences of symbols along chains of neurons, see Figure 2.
Fig. 2. A chain carrying 4 diÔ¨Äerent spike patterns as a concatenated string
This shows a snapshot of the state of a neural chain that carries the four
symbol-tokens shown in Figure 1. Imagine producing this pattern by stimulat-
ing the Ô¨Årst three neurons on the left with the blue (far right), purple, green and
Ô¨Ånally pink (far left) spike patterns in succession. Let us allocate each spatiotem-
poral pattern an arbitrary label, e.g. Pink (far left) = A, Green = B, Purple =
C, and Blue (far right) = D for convenience. Then this symbol-structure can be
described as a string or linear molecule of the form ABCD. I hypothesize that
a great many such short chains exist in the brain. Each chain can be consid-
ered to be a kind of register in a computer, blackboard or tape that can store
symbol-tokens of the appropriate size. A single symbol-token could be read by
a detector neuron with the appropriate axonal delay pattern when interfacing
with the chain. Similar detector neurons can exist for the symbol-tokens A, B
and D and as many others as the spatial width of the chain and the temporal
resolution of the neuronal detector allows.
Thus, I envisage a potentially large parallel symbol system in the brain con-
sisting of a population of such chains, each capable of storing a set of symbol-
token strings and operating on these strings in parallel. Interaction between
Fluid Construction Grammar in the Brain 319
(and within) such chains constitutes the operations of symbol-manipulation.
Returning to the chemical metaphor, such interactions can be thought of as
chemical reactions between molecules contained on separate chains, and rear-
rangements within a molecule expressed on the same chain. Whilst in a sense a
chain can be thought of as a tape in a Turing machine (due to the serial nature
of the strings), it also can be thought of as a single molecule in a chemical system
(due to the existence of multiple parallel chains). This constitutes the core rep-
resentational substrate on which symbol manipulation will act. The reactivity
of symbol structures on these chains is described in the next Section.
A fundamental operation on a symbol token is to replace it with another
symbol-token, or simply to transform it in some way, see Figure 3. The network
Ô¨Ågure shows a chain, again of three neurons width. Receiving input from the
chain and writing activity back into the chain is done by a detector neuron with
speciÔ¨Åc input and output delays in relation to the chain. A detector neuron (blue,
bottom) only Ô¨Åres when the correct pattern of input is detected (as described
above). In this case, the neuron‚Äôs input delays are set so that it recognizes (Ô¨Åres
for) patterns only of type D.
In the experiment the pattern of stimulation was given shown in Figure 3B.
The spike raster plot and the voltage plot (Figure 3C) show two spatiotemporal
patterns input to the input neurons, input pattern 1 and input pattern 2. These
both fail to make the classiÔ¨Åer neuron Ô¨Åre. It can be seen that in this case
where the classiÔ¨Åer fails to Ô¨Åre, the same pattern enters the chain as leaves the
chain. This is because the spatiotemporal organization of these patterns does not
match the spatiotemporal tuning curve of the detector neuron. Only when the
third spatiotemporal spike pattern is input does the detector neuron Ô¨Åre. Once
Ô¨Åred, the output of the detector neuron is injected back to the neurons of the
chain. If the output of the detector neuron slightly precedes the normal passage
of the untransformed pattern through the chain, then the refractory period of the
output neurons of the chain prevents interference by the original untransformed
pattern, which is thereby replaced by the new pattern speciÔ¨Åed by the detector
neuron. Such a detector neuron we will now call a classiÔ¨Åer neuron because it
is a simple context free re-write rule with a condition (detection) and an action
pole of the type seen in Learning ClassiÔ¨Åer Systems (LCS) [27].
It can be seen that such classiÔ¨Åer neurons are selective Ô¨Ålters, i.e. the classiÔ¨Åer
neuron is only activated if the spatiotemporal pattern is suÔ¨Éciently matched
with the axonel delays aÔ¨Äerent upon the neuron. The above classiÔ¨Åer implements
an implicit rule. An implicit rule is a rule that operates on atomic or molecular
symbol structures without being speciÔ¨Åed (encoded/determined/controlled) by
a symbol structure itself. There is no way that a change in the symbol system,
i.e. the set of symbols in the population of chains, could modify this implicit
matching rule. The implicit rule is speciÔ¨Åed external to the symbol system.
Whenever the symbol D passes along this chain, it will be replaced by the new
symbol, irrespective of the presence of other symbols in the system.
320 C. Fernando
Fig. 3. The above circuit implements a context-free re-write rule. There are three input
channels in this case, although it is trivial to add more. The direct pathway is by a delay
line via an intermediate layer. The indirect pathway to the outputs is via a classiÔ¨Åer
neuron (blue, bottom). Only if the delays match the inter-spike interval of the input
spike ensemble does the recognizer Ô¨Åre. Once Ô¨Åred, it sends signals down outputs with
delays that are set so that the desired output pattern is produced. Part B. A spike
raster showing the 3 input patterns and 3 output patterns produced in an experiment.
Patterns that do not match the re-write rule pass through the classiÔ¨Åer neuron, but
those that do match the re-write rule are converted, and the passage through by the
original pattern is inhibited due to the refractory period of the output neurons (see
Part C which shows the voltages of input, output and classiÔ¨Åer neuron). Also it is
possible to explicitly inhibit the passage of the original input, but this is not needed
here.
Fluid Construction Grammar in the Brain 321
In a symbol system (as in chemistry), symbols are manipulated (partly) on
the basis of ‚Äúexplicit rules‚Äù 2
. This means that the operations or reactivity of
symbols depends on/is controlled by/is causally inÔ¨Çuenced by their syntactic and
semantic relationship to other symbols within the symbol-structure and between
symbol structures. Figure 3 above showed a classiÔ¨Åer neuron implementing an
implicit rule. This rule was not controlled by any symbols in the system; it
merely operated on symbols in the system. Figure 4 below shows a classiÔ¨Åer
neuron and an inhibitory gating neuron can implement an explicit rule within
our framework.
The classiÔ¨Åer and chain shown in Figure 3 is simply modiÔ¨Åed to include an
inhibitory gating unit that must receive a particular pattern of spikes (T for
trigger) in order for it to become active. The simplest relation is where T im-
mediately precedes X. Only when this is the case will the classiÔ¨Åer neuron be
disinhibited. Only when the classiÔ¨Åer neuron is disinhibited will X be converted
to Y. Otherwise X will pass through an inactive classiÔ¨Åer (as will all other sym-
bols). This is formally a context-sensitive re-write rule. The rule is called context
sensitive because the conversion of X to Y depends on the relation of X to an-
other contextual symbol T. A set of context-sensitive re-write rules is capable of
generating a grammar of spike-patterns. Consider starting the system oÔ¨Ä with a
single symbol-token S. Probabalistic application of the rules to the initial sym-
bol S would result in the systematic production of spike patterns consisting of
grammatically correct context-sensitive spike pattern based sentences. A major
implementation issue in real neuronal tissue would be the Ô¨Ådelity of transmission
of spatiotemporal spike patterns. The information capacity of such a channel may
fall oÔ¨Ä with decreasing Ô¨Ådelity of copying in that channel in a manner analogous
to Eigen‚Äôs error catastrophe in genetic evolution [14].
However, the system so far described could not easily implement the kind of
rule that Marcus wishes a symbol-manipulation system to learn, namely to ex-
tract ‚Äúabstract algebra-like rules that represent relationships between placehold-
ers (variables), such as ‚Äòthe Ô¨Årst item X is the same as the third item Y‚Äô, or more
generally that ‚Äòitem I is the same as item J‚Äù‚Äô [42]. This kind of rule requires hash
symbols which implement the concept of same and diÔ¨Äerent, namely, If #1##1
then S, Else If #2##1 then D. That is, if the Ô¨Årst and last string are the same,
2
Quoting [26, p.335]: ‚ÄúWittgenstein (1953) emphasized the diÔ¨Äerence between explicit
and implicit rules: It is not the same thing to ‚Äôfollow‚Äô a rule (explicitly) and merely to
behave ‚Äôin accordance with‚Äô a rule (implicitly). The critical diÔ¨Äerence [between an im-
plicit and explicit rule] is in the compositeness (7) and systematicity (8) criteria.
The explicitly represented symbolic rule is part of a formal system, it is decompos-
able (unless primitive), its application and manipulation is purely formal (syntactic,
shape-dependent), and the entire system must be semantically interpretable, not
just the chunk in question. An isolated (‚Äômodular‚Äô) chunk cannot be symbolic; be-
ing symbolic is a systematic property. . . For systematicity it must be possible to
combine and recombine entities rulefully into propositions that can be semantically
interpreted. . . It is possible to devise machines whose function is the transformation
of symbols, and whose operation are sensitive to the syntactical structure of the
symbols that they operate upon.‚Äù
322 C. Fernando
Fig. 4. An explicit rule implemented by a classiÔ¨Åer neuron and an inhibitory gating
neuron. The classiÔ¨Åer neuron (blue, bottom) only Ô¨Åres if it is disinhibited by the neuron
at the top (red). This occurs only if T preceeds X as these spike patterns pass down
the chain from left to right. If T preceeds X, then X is converted into Y.
Fluid Construction Grammar in the Brain 323
write S = same, and if the Ô¨Årst and last strings are diÔ¨Äerent write D = diÔ¨Äerent.
In the absence of hash symbols of this type, a classiÔ¨Åer system would have to
learn all the explicit rules for each possible pair of symbols at the Ô¨Årst and last
position, instead of learning the general rule. Both systems would be systematic,
however, the system with hashes would allow a more concise speciÔ¨Åcation of the
same level of systematicity, and may be easier to learn. But how can such hashes
be implemented within my framework? One method for obtaining hashes is that
a classiÔ¨Åer neuron contains many delay lines from one channel so that it Ô¨Åres
for a range of spike delays along that channel. Another is that it is suÔ¨Écient for
a classiÔ¨Åer to be activated by only a subset of the spatiotemporal components
of a symbol-token. Another possibility for implementing a same/diÔ¨Äerent rule is
shown in Figure 5.
Fig. 5. A method for detecting whether successive symbol-tokens are the same or diÔ¨Äer-
ent (Left) Two pairs of sequentially presented symbols, AA and AB are shown (Right).
A device that is capable of identifying consecutive symbol pairs that are diÔ¨Äerent, using
three XOR circuits in parallel.
On the left, the Ô¨Ågure shows two pairs of sequentially presented symbols Ô¨Çow-
ing down two reaction chains, in this case, AA on the top chain and AB on the
bottom chain. On the right we see that the symbols AA from the top chain have
been sent to a chain that is capable of recognizing same/diÔ¨Äerent. This circuit
is very simple and consists only of three XOR gates implemented by spiking
neurons. The XOR function is at the heart of same/diÔ¨Äerent classiÔ¨Åcation be-
cause it Ô¨Åres 1 for the inputs 01 and 10, but Ô¨Åres 0 for the inputs 00 and 11.
In this case, if two spikes are separated by 100ms along each channel then they
324 C. Fernando
will cancel each other out. However, if only one spike is present then it will be
capable of activating the XOR gate. By setting the threshold of the output neu-
ron it is possible to detect adjacent symbol tokens that diÔ¨Äer by some speciÔ¨Åed
number of spikes. The output neuron can write to the channel in the same way
as described for the implicit rule action, e.g. implementing the rule, If #1##1
then S.
It seems that the neural capacity for detection of same and diÔ¨Äerent is a signif-
icant departure from what can easily be achieved in chemistry! A neural physical
symbol system is capable of exploiting generalization mechanisms unavailable to
chemistry. In chemistry there is no known molecular mechanism by which one
molecule can determine whether two other molecules are the same or diÔ¨Äerent,
for any more than one pair of such molecules. The above mechanism of detecting
same and diÔ¨Äerent is a neural basis for simple matching. We now address the
more diÔ¨Écult question of how a symbol system can be learned, and later how
hash matching can be learned.
A powerful architecture for symbolic search is XCS (accuracy based classiÔ¨Åer
system) which combines Q-learning with a population of classiÔ¨Åers [7]. XCS
consists of a population of classiÔ¨Åers (which strongly resemble constructions)
with condition-action poles, C ‚Üí A. Each classiÔ¨Åer has a Ô¨Åtness F that is related
to its accuracy in predicting the reward obtained in the next time step. At each
point in time a subset of the classiÔ¨Åers (called the Match Set) will match the
state of the environment. ClassiÔ¨Åers proposing several possible actions may exist
in the Match Set. An action selection method is used to select the best classiÔ¨Åer
most of the time, although sometimes actions using sub-optimal classiÔ¨Åers are
also executed for the sake of exploration. When the action is executed and the
reward obtained, then the prediction accuracy of the classiÔ¨Åers in the action set
can be updated. Selection then takes place between classiÔ¨Åers in the Match Set,
i.e. those with lower Ô¨Åtness are removed from the population. This is eÔ¨Äectively a
niche-based selection that preserves representational diversity in the population
of classiÔ¨Åers. Learning classiÔ¨Åer system have been used to evolve classiÔ¨Åers for
reinforcement learning tasks such as navigation, robotic control, but also for
function approximation [6] and the systematic approach used may be of interest
in FCG algorithmics.
The FCG and XCS both are algorithms that require replication of classiÔ¨Åers
(constructions). The neuronal replicator hypothesis states that replicators exist
in the brain and can undergo natural selection [17‚Äì20, 56].
In order for the argument that an FCG or XCS is implemented in the brain
to be plausible, and if such spatiotemporal symbols do actually exist, then it
is a fundamental prior question to explain how it is possible to replicate clas-
siÔ¨Åers of the type shown in Figure 3 (implicit) and Figure 4 (explicit). There
are several steps to obtain replication of classiÔ¨Åers. The Ô¨Årst is to understand
how a single classiÔ¨Åer can be trained. Here we return to STDP. Using the STDP
based synaptic plasticity rules described previously it is possible to train a clas-
siÔ¨Åer neuron to Ô¨Åre only when exposed to a particular spatio-temporal pattern
of spikes. If we wish to train the output neuron to Ô¨Åre only for a particular
Fluid Construction Grammar in the Brain 325
interspike interval between two input neurons, it can be done as follows. We
assume that each input neuron has many pathways for communicating with
the output neuron. For example dendrites form the post-synaptic neuron may
connect with the axon of the pre-synaptic neuron at many locations, a not un-
reasonable assumption [8]. Alternatively, it may be the case that several neurons
are involved in the path from input to output neuron. In the model I assume
delays of 5ms, 10ms, 15ms, and 20ms each. Each weight from input to output
neuron is initially sub-threshold, i.e. insuÔ¨Écient to allow an action potential from
an input neuron to an output neuron to produce another action potential. In
fact 3 input neurons must Ô¨Åre for the output neuron to Ô¨Åre. Because only two
pre-synaptic neurons can contribute to a synchronous pulse, the output neuron
should therefore never Ô¨Åre! Indeed, only if a sub-threshold depolarization is pro-
vided by an external teacher to the output neuron, will it Ô¨Åre, if at that same
time it is suÔ¨Éciently stimulated by pre-synaptic neurons. In our experiments,
sub-threshold (training) depolarization of the post-synaptic output neuron was
given 20ms after the desired condition-spike-pattern was presented to the input
neurons. Due to STDP the appropriate weights from the input neurons to the
output neuron increased. The tuning curve of the output neuron was entrained,
conÔ¨Årm it was possible to train a classiÔ¨Åer neuron to recognize particular inter-
spike intervals [15]. The second step was to train a classiÔ¨Åer capable of reading
and writing a spatiotemporal spike pattern. During the training period the spike
pattern to be recognized entered along the 3 input channels with spikes at 0,
50ms and 100ms latency. This pattern was presented 9 times. A short Ô¨Åxed time
period after each input pattern was presented to the input neurons, a pattern of
sub-threshold depolarization was presented to the output neurons. This output
pattern was the desired output pattern, which in this case is an inversion of
the original pattern (although any pattern can be trained). A set of alternative
possible delay lines from each input neuron to the classiÔ¨Åer neuron, and another
alternative possible set of delay lines from the classiÔ¨Åer neuron to each output
neuron, was trained. In addition, the classiÔ¨Åer neuron was linked to a neuro-
modulatory inhibitory system blocked the passage of the original spike-pattern
if it was recognized. If it was not recognized then the original pattern passed
through to the outputs with a delay of 120ms, unchanged in form, see [15] for a
full description of the experiment.
This training procedure is suÔ¨Écient for the classiÔ¨Åer neuron to learn both the
input required to activate it, and the desired output. It should be clear that
the above supervised training regime for entraining the input-output function
mapped by one classiÔ¨Åer can be trivially extended to allow replication of input-
output functions. This is because once a single classiÔ¨Åer neuron has been trained,
this classiÔ¨Åer neuron can train other classiÔ¨Åer neurons in the following manner.
The plasticity of the Ô¨Årst (trained) classiÔ¨Åer neuron is held Ô¨Åxed. The input-
spike-pattern passes now to both classiÔ¨Åers, and the output of the Ô¨Årst classiÔ¨Åer
is used to produce sub-threshold output neuron depolarization in the second
classiÔ¨Åer.
326 C. Fernando
Systems that are capable of being trained by supervised learning, are typi-
cally also capable of training other such systems. The mechanism of copying by
supervised training/learning is exhibited in the mechanism of ‚Äúdidactic transfer‚Äù
of receptive Ô¨Åelds that occurs by horizontal STDP and synaptic gain modiÔ¨Å-
cation during deaÔ¨Äarentation of visual cortex [59]. It is also exhibited in the
mechanism of copying of connection topology shown previously [18]. Recent ex-
periments show that such temporal speciÔ¨Åc training is indeed possible [35].
4 FCG Specific Operations
Matching and merging is critical for FCG. Matching means comparison for equiv-
alence of two symbol structures X and Y [12][9][52]. In the simplest case, X and
Y are atomic symbols and there is a match if the atoms are identical. This can
trivially be done by writing X and Y to a chain. They should be separated by the
transformation interval; in the case of Figure 5 this is 100ms. If X and Y atoms
are identical then the classiÔ¨Åer Ô¨Åres. We admit the fact that this delay imposes
a very severe constraint on the number of possible matches, and it is necessary
to think carefully about how faster matching could be done. Let us assume that
matching requires sending the two patterns to a location in the brain that can
do the matching. The process by which such Ô¨Çexible transport can be achieved
is highly non-trivial and as yet we have no explanation for this. One possibility
is that matching occurs in one of the sub-cortical structures that receive many
incoming connections from a wide range of cortex, e.g. the cerebellum or the
basal ganglia. Indeed the striatum of the basal ganglia is responsible for match-
ing in Anderson‚Äôs ACT-R cognitive architecture, although he does not give an
explanation of how it should occur there [1].
The introduction alluded to how perceptual mechanisms could be exapted for
symbolic operations. An example is now given for the case of matching in FCG.
The experiments in [37] use rapid reversible synaptic plasticity (dynamic link
matching) to learn classes of visual transformation, e.g. reÔ¨Çection, rotation etc.
The same mechanism can be applied to the unsupervised learning of the concept
of same and diÔ¨Äerent in a symbol system. The power of the method is that it can
generalize, i.e. it is only necessary to show a subset of possible instances of same
and diÔ¨Äerent symbols for the system to be able to extend this same/diÔ¨Äerent
classiÔ¨Åcation to novel symbols or symbol structures. The dynamic link matching
algorithm has recently been applied to spiking neural networks [46]. Related
algorithms are used for auditory scene analysis [5]. It is conceivable that the
same perceptual mechanisms used for interpreting sensory input are also used
for interpreting internally generated symbolic inputs that are similarly encoded.
A more complex case of matching occurs where X and Y are not atomic but
consist of an unordered list of elements. Here X and Y are equivalent if the list
contains the same elements, e.g. match(‚Äô(a b c)‚Äô, ‚Äô(a b c)‚Äô) = true but also (‚Äô(a
b c)‚Äô, ‚Äô(b a c)‚Äô) = true. The next level of matching complexity occurs when X
and Y are trees. Matching can either ignore or take into consideration the order
of branching, e.g. if ignored a(bc) = a(cb) but in both cases a(b(c)) != a(bc).
Fluid Construction Grammar in the Brain 327
The next step is partial tree matching, which is when some elements of X are in
Y, but there are no elements in X that are not in Y: e.g. (a (d (e g))) partially
matches with (a (b c) (d (e f g))).
Following matching of two symbol structures there can be merging. Merge
takes already constructed objects and constructs from them a new object. Merge
assumes that there has been a partial match and then adds everything of Y that
is not in X to X. So when X = (a (d (e g))) partially matches with Y = (a (b
c) (d (e f g))), then X becomes X‚Äô = (a (b c) (d (e f g))). Note that Y is left
unchanged and can undergo further matches with other structures. The merge
operation involves the copying of a symbol on the basis of the result of a match
comparison. Therefore it is a type of explicit re-write rule. It is special because
it requires hash based re-write, i.e. the rule does not just say if XT write TX,
it says for example, if #1#2 write #2#1. That is, the re-write must work for
a range of symbols. Whether this is plausible within our framework is not yet
known. We are not yet able to provide plausible neuronal mechanisms capable
of dealing with the more complex merge operations described above.
5 Discussion
There are several alternative connectionist type theories for the implementation
of ‚Äômental representations‚Äô or symbol-structures in the brain, but these are not
considered in detail here [4, 38, 41, 47, 51]. I believe that it is more straightfor-
ward to face the problem head on. That is, to acknowledge that we need a full
physical symbol system in the brain, and then to relax our biases about how
such a physical symbol system could in fact be implemented. Thinking about a
chemical symbol system helps me to do this.
There is some weak neurophysiological evidence for spatiotemporal spikes
as symbol-tokens. The discovery of ‚Äúcortical songs‚Äù is suggestive that discrete
unique tokens such as symbols can be encoded as spatiotemporal patterns of
spikes. Cortical songs are higher-order sequences of spike patterns repeated
in the same sequential order observed in neocortical brain slices, of the form
[A,C,D,E,F][A,C,D,E,F] for example where each letter represents a stereotyped
polychronous pattern of activity [29]. Furthermore, there is evidence for the
training methods we used to train classiÔ¨Åers, for example, synaptic inputs at
distal dendrites can act as supervisory signals in the Hippocampus [13]. This
maps to the sub-threshold depolarization we used to train classiÔ¨Åer and output
neurons. Several other papers also demonstrate methods for supervised training
of spike classiÔ¨Åers, and so our classiÔ¨Åer replication mechanism is by no means
out of the blue. For example, the ‚ÄúTempotron‚Äù is an example of learning to clas-
sify speciÔ¨Åc spatiotemporal patterns of spikes using a gradient-descent type rule
to adjust weights on the basis of how rapidly a pattern results in Ô¨Åring of a
classiÔ¨Åer leaky-integrator neuron [25], see also [48]. Therefore, there is a growing
body of work showing how replication of spatiotemporal spike pattern classiÔ¨Åers
is possible.
328 C. Fernando
In short, Ô¨Årst I presented a plausible implementation of symbol-tokens in a
brain. I then presented the core operation of an algorithm for learning symbol
manipulation rules, i.e. replication of the input/output function of a classiÔ¨Åer
neuron. I have described elsewhere the details of a cognitive architecture based
on a learning classiÔ¨Åer system to learn simple syntactic rules [15]. These three
components serve may provide a core for further work on understanding the
neuronal basis of Ô¨Çuid construction grammar.
References
[1] Anderson, J.: How Can the Human Mind Occur in the Physical Universe. Oxford
University Press (2007)
[2] Belousov, B.P.: A periodic reaction and its mechanism. Compilation of Abstracts
on Radiation Medicine 147, 145 (1959)
[3] Biederman, I.: Recognition-by-components: A theory of human image understand-
ing. Phychological Review 94(2), 115‚Äì147 (1987)
[4] Bienenstock, E., Geman, S.: Compositionality in Neural Systems. MIT/Bradford
Books, Elsevier (1995)
[5] Bregman, A.S.: Auditory scene analysis. MIT Press, Cambridge (1990)
[6] Bull, L., Kovacs, T.: Foundations of Learning ClassiÔ¨Åer Systems. STUDFUZZ,
vol. 183. Springer, Heidelberg (2005)
[7] Butz, M.: Rule-Based Evolutionary Online Learning Systems: A Principled Ap-
proach to LCS Analysis and Design. STUDFUZZ, vol. 191. Springer, Heidelberg
(2006)
[8] Chklovskii, D., Mel, B., Svoboda, K.: Cortical rewiring and information storage.
Nature 431, 782‚Äì788 (2004)
[9] Ciortuz, L., Saveluc, V.: Fluid Construction Grammar and Feature Constraint
Logics. In: Steels, L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249,
pp. 289‚Äì311. Springer, Heidelberg (2012)
[10] Clark, A.: In defense of explicit rules. In: Ramsey, W., Stich, S.P., Rumelhart, D.
(eds.) Philosophy and Connectionist Theory. Lawrence Erlbaum (1991)
[11] De Beule, J., Steels, L.: Hierarchy in Fluid Construction Grammars. In: Furbach,
U. (ed.) KI 2005. LNCS (LNAI), vol. 3698, pp. 1‚Äì15. Springer, Heidelberg (2005)
[12] De Beule, J.: A Formal Deconstruction of Fluid Construction Grammar. In: Steels,
L. (ed.) Computational Issues in FCG. LNCS (LNAI), vol. 7249, pp. 215‚Äì238.
Springer, Heidelberg (2012)
[13] Dudman, J., Tsay, D., Siegelbaum, S.: A role for synaptic inputs at distal
dendrites: Instructive signals for hippocampal long-term plasticity. Neuron 56,
866‚Äì879 (2007)
[14] Eigen, M.: Selforganization of matter and the evolution of biological macro-
molecules. Naturwissenschaften 58(10), 465‚Äì523 (1971)
[15] Fernando, C.: Co-evolution of lexical and syntactic classiÔ¨Åers during a language
game. Evolutionary Intelligence 4(3), 165‚Äì182 (2011)
[16] Fernando, C.: Symbol manipulation and rule learning in spiking neuronal net-
works. Journal of Theoretical Biology 275, 29‚Äì41 (2011)
[17] Fernando, C., Goldstein, R., Szathm√°ry, E.: The neuronal replicator hypothesis.
Neural Computation 22(11), 2809‚Äì2857 (2010)
[18] Fernando, C., Karishma, K., Szathm√°ry, E.: Copying and evolution of neuronal
topology. PLoS ONE 3(11), e3775 (2008)
Fluid Construction Grammar in the Brain 329
[19] Fernando, C., Szathm√°ry, E.: Chemical, neuronal and linguistic replicators. In:
Pigliucci, M., M√ºller, G. (eds.) Towards an Extended Evolutionary Synthesis,
pp. 209‚Äì249. MIT Press, Cambridge (2009)
[20] Fernando, C., Szathm√°ry, E.: Natural selection in the brain. In: Glatzeder, B.,
Goel, V., von M√ºller, A. (eds.) Toward a Theory of Thinking, pp. 291‚Äì340.
Springer, Berlin (2009)
[21] Fodor, J., Pylyshyn, Z.: Connectionism and cognitive architecture: A critical anal-
ysis. Cognition 28, 3‚Äì71 (1988)
[22] G√°anti, T.: The Principles of Life. Oxford University Press, Oxford (2003)
[23] Gallistel, C., King, P.: Memory and the Computational Brain: Why Cognitive
Science Will Transform Neuroscience. Wiley-Blackwell (2010)
[24] Goertzel, B., Lian, R., Arel, I., de Garis, H., Chen, S.: World survey of artiÔ¨Åcial
brains, part ii: Biologically inspired cognitive architectures. Neurocomputing 74,
30‚Äì49 (2010)
[25] Gutig, F., Sompolinsky, H.: The tempotron: a neuron that learns spike timing-
based decisions. Nature Neuroscience 9(3), 420‚Äì428 (2006)
[26] Harnad, S.: The symbol grounding problem. Physica D 42, 335‚Äì346 (1990)
[27] Holland, J., Reitman, J.: Cognitive systems based on adaptive algorithms. ACM
SIGART Bulletin 63, 43‚Äì49 (1977)
[28] Hudson, J.: The History of Chemistry. MacMillan (1992)
[29] Ikegaya, Y., et al.: SynÔ¨Åre chains and cortical songs: Temporal modules of cortical
activity. Science 304, 559‚Äì564 (2004)
[30] Izhikevich, E.M.: Simple model of spiking neurons. IEEE Transactions on Neural
Networks 14, 1539‚Äì1572 (2003)
[31] Izhikevich, E.M.: Polychronization: computation with spikes. Neural Computa-
tion 18(2), 245‚Äì282 (2006)
[32] Izhikevich, E.M.: Solving the distal reward problem through linkage of stdp and
dopamine signaling. Cerebral Cortex 17, 2443‚Äì2452 (2007)
[33] Izhikevich, E.M., Gally, J.A., Edelman, G.M.: Spike-timing dynamics of neuronal
groups. Cereb. Cortex 14(8), 933‚Äì944 (2004)
[34] Izhikevich, E.M., Hoppensteadt, F.: Polychronous wavefront computations. Inter-
national Journal of Bifurcation and Chaos 19, 1733‚Äì1739 (2009)
[35] Johnson, H., Goel, A., Buonomano, D.: Neural dynamics of in vitro cortical net-
works reÔ¨Çects experienced temporal patterns. Nature Neurosci. 13(8), 917‚Äì919
(2010)
[36] KarmiloÔ¨Ä-Smith, A.: Beyond Modularity: A Developmental Perspective on Cog-
nitive Science. MIT Press, Cambridge (1996)
[37] Konen, W., von der Malsburg, C.: Learning to generalize from single examples in
the dynamic link architecture. Neural Computation 5(5), 719‚Äì735 (1993)
[38] Love, B.: Utilizing time: Asynchronous binding. In: Advances in Neural Informa-
tion Processing Systems, vol. 11, pp. 38‚Äì44 (1999)
[39] Magnasco, M.: Chemical kinetics is turing universal. Physical Review Letters 78,
1190‚Äì1193 (1997)
[40] von der Malsburg, C.: The what and why of binding: The modeler‚Äôs perspective.
Neuron 24, 95‚Äì104 (1999)
[41] Marcus, G.: The Algebraic Mind: Integrating Connectionism and Cognitive Sci-
ence. MIT Press (2001)
[42] Marcus, G., Vijayan, S., Bandi Rao, S., Vishton, P.: Rule learning by seven-month-
old infants. Science 283(5398), 77‚Äì80 (1999)
[43] Maynard Smith, J.: The problems of biology. Oxford University Press, Oxford
(1986)
330 C. Fernando
[44] Nessler, B., PfeiÔ¨Äer, M., Maass, W.: Bayesian computation emerges in generic
cortical microcircuits through spike-timing-dependent plasticity. Theoretical Com-
puter Science, 1‚Äì40 (2010)
[45] Penn, D., Holyoak, K., Povinelli, D.: Darwin‚Äôs mistake: Explaining the disconti-
nuity between human and nonhuman minds. Behavioral and Brain Sciences 31(2),
109‚Äì130 (2008)
[46] Pichevar, R., Rouat, J., Tai, L.: The oscillatory dynamic link matcher for spiking-
neuron-based pattern recognition. Neurocomputing 69 (2006)
[47] Pollack, J.B.: Recursive distributed representations. ArtiÔ¨Åcial Intelligence 46(1),
77‚Äì105 (1990)
[48] Ponulak, F., Kasinski, A.: Supervised learning in spiking neural networks with
resume: Sequence learning, classiÔ¨Åcation and spike-shifting. Neural Computation
(2009)
[49] Rao, R., Ballard, D.: Predictive coding in the visual cortex: A functional inter-
pretation of some extra-classical receptive-Ô¨Åeld eÔ¨Äects. Nature Neuroscience 2(1),
79‚Äì87 (1999)
[50] Seidenberg, M., Elman, J.: Networks are not ‚Äôhidden rules‚Äô. Trends in Cognitive
Sciences 3, 288‚Äì289 (1999)
[51] Shastri, L., Ajjanagadde, V.: From simple associations to systematic reasoning: A
connectionist representation of rules, variables and dynamic bindings. Behavioural
and Brain Sciences 16, 417‚Äì494 (1993)
[52] Santib√°√±ez, J.S.: A Logic Programming Approach to Parsing and Production in
Fluid Construction Grammar. In: Steels, L. (ed.) Computational Issues in FCG.
LNCS (LNAI), vol. 7249, pp. 239‚Äì255. Springer, Heidelberg (2012)
[53] Steels, L. (ed.): Design Patterns in Fluid Construction Grammar, Constructional
Approaches to Language, vol. 11. John Benjamins, Amsterdam (2011)
[54] Steels, L. (ed.): Computational Issues in FCG. LNCS (LNAI), vol. 7249. Springer,
Heidelberg (2012)
[55] Steels, L., De Beule, J., Neubauer, N.: Linking in Fluid Construction Grammars.
In: Proceedings of BNAIC, pp. 11‚Äì18. Transactions of the Belgian Royal Society
of Arts and Sciences, Brussels (2005)
[56] Szathm√°ry, E., Fernando, C.: Concluding remarks. In: Calcott, B., Sterelny, K.
(eds.) The Major Transitions in Evolution Revisited, pp. 301‚Äì310. MIT Press
(2011)
[57] van Trijp, R., Steels, L., Beuls, K., Wellens, P.: Fluid construction grammar: The
new kid on the block. In: Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Linguistics. ACL, Avignon (2012)
[58] Wiskott, L., von der Malsburg, C.: Recognizing faces by dynamic link matching.
In: Proceedings of ICANN 1995, pp. 347‚Äì352 (1995)
[59] Young, J., Waleszczyk, W., Wang, C., Calford, M., Dreher, B., Obermayer,
K.: Cortical reorganization consistent with spike timeing but not correlation-
dependent plasticity. Nature Neuroscience 10(7), 887‚Äì895 (2007)
Author Index
Beuls, Katrien 123
Chang, Nancy 259
Ciortuz, Liviu 289
De Beule, Joachim 215, 259
Fernando, Chrisantha 312
Gerasymova, Kateryna 91
HoÃàfer, Sebastian 143
Loetzsch, Martin 37
Micelli, Vanessa 178, 259
Saveluc, Vlad 289
Sierra-SantibaÃÅnÃÉez, Josefina 239
Stadler, Kevin 75
Steels, Luc 3
van Trijp, Remi 51
