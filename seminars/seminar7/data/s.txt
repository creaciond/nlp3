16  Autonomous modularity: syntax and semantics
to make a proposition; a transitive verb will belong to the category Faa in virtue
of its combining first with one argument, and the resulting function combining
with another argument to form a proposition. It follows that Fe (e the empty
string) is the same as the category of propositions, but I will continue to use
“Prop” as the symbol for this category for the sake of expository clarity.
Suppose ψ is a string of a’s and p’s such that x is the first symbol of the string
(the head of the string) and φ is the remainder (the tail). If Fxφ is a functor, then
when the function applies to a category of type x, the resulting category is Fφ,
where the first symbol x is no longer needed in the formation of a proposition.
The general rule of functional application is therefore:
(2)	 Rule of Functional Application
	 Fxφ(x) = Fφ
Such a rule can be taken to be an order-free phrase structure rule like (3) that
describes a tree fragment of the form (4), where order is irrelevant, and where
the comma on the right-hand side of the rule indicates that the rule prescribes
only constituency and not order.
(3)	 Fφ → Fxφ, x
In this way the semantic F/A structure of an expression can be represented
as an order-free phrase structure tree. The F/A structure of the sentence Ben
tickles Melanie, for example, would be (5), ignoring details which are irrele-
vant at this point:
Functors of the kind that lead ultimately to propositions are often realized
as verbs, but sometimes as other parts of speech as well. Here is a small list
of functor types that are commonly found in natural languages and some of
the lexical items that instantiate them in English, including verbs, nouns, and
adjectives:
(4) Fϕ
Fxϕ x
(5) Prop
Arg Fa
Faa Arg
BEN TICKLE MELANIE
Function-argument structure  17
(6)	 Some functors in English
	 a.	 Fa: intransitive predicates, e.g., sneeze, cat, cute.
	 b.	 Faa: relations, e.g., steal, fiancée, fond.
	 c.	 Fp: one-place operators, e.g., seem, longshot, likely.
	 d.	 Fpa: transitive operators, e.g., believe, idea, positive.
Category (6d) will enter into F/A trees such as the following, which represents
the structural semantic relations of the clause Ben believes/has the idea/is posi-
tive that Melanie sneezes:
The vast majority of lexical functors in natural languages, it seems, have
either one, two, or three items on the list of categories that they combine
with to form propositions. Thus there are only fourteen functor types that we
might expect to be found in the basic vocabularies of natural languages and
even among these types, a few seem to be rare. Examples of the others that
figure in the structure of English will be discussed in due course below.
Besides the various sorts of functors that were illustrated above, there is
another important kind of semantic function, namely modifiers – functions
from a category of type x to a more complex member of the category x.
We might expect that there should be one of these modificational types for
each of the fourteen types plus two for the basic categories of entity expres-
sions and propositions. But again, the types of semantic modifiers that are
easily attestable in natural language lexicons seem to be much more cir-
cumscribed than that. If we symbolize these modifying categories as Mx,
where x is the category that the function modifies (and hence the category
that the function produces when it is correctly applied) the only common
types seem to be:
(8)	 Types of F/A structure modifiers
	 a.	 Mp: propositional modifiers (identical to functors of the type Fp)
	 b.	 MFa: predicate modifiers
	 c.	 MFx: (where Fx is a variable over functors)
(7) Prop
Arg Fa
BEN
Prop Fpa
BELIEVE/IDEA/POSITIVE
Arg Fa
MELANIE SNEEZE
18  Autonomous modularity: syntax and semantics
	 d. 
Ma: argument modifiers that return more complex arguments when
applied to arguments
Propositional and predicate modifiers do not need any further description at
this point, but members of the type MFx, i.e., modifiers of functors of all sorts,
probably do. The class MFx is a single variable type, not a collection of several
different types. The adverb quickly, for example, can modify intransitive predi-
cates (walk quickly), transitive functors (slice all the bagels quickly, ambigu-
ous between “take little time to slice each bagel,” or “be quick to get all the
bagels sliced”), ditransitive functors (quickly give each child every pill, which
is multiply ambiguous), and so on. There are many modifiers of this kind, but
I do not know of any that are specific to, say, transitive functors or one-place
operators.
Inasmuch as the F/A structure component deals solely in relations of logical
hierarchy and logical scope, the grammatical phenomena that reflect these rela-
tionships are the best indicators of the form of expressions in the F/A dimen-
sion. Logical scope relations, antecedent–anaphor relations and the like are
sometimes determinable from surface syntax and can depend, at least in part,
on superficial features of utterance types such as linear precedence and inton-
ation. But it also seems clear that there are cases where scopal facts cannot be
conveniently mapped directly from the surface features of an expression. To
take just one example that has received some mention in the literature, con-
sider sentences that contain the sequence … can’t seem to … (e.g., Quirk 1965;
Langendoen 1970; Lawler 1974; Horn 1989; Jacobson 2006). A sentence such
as I can’t seem to find my glasses usually doesn’t mean “I am unable to give the
appearance of finding my glasses,” but rather something more along the lines
of “It seems that I am not able to find my glasses.” There is no reason to take
the syntactic form of this sentence to be anything other than the well-formed
syntactic structure that it appears to be, with can and not higher in the syntactic
tree than seem. The F/A structure, however, will have these hierarchical rela-
tions reversed; SEEM (the F/A structure counterpart of seem) is higher in the
functional tree than CAN and NOT:
(9) Prop
Fp
SEEM
Prop
Fp
NOT
Prop
Fp
CAN
Prop
Function-argument structure  19
Note that tree (9) is a completely well-formed F/A structure, conforming per-
fectly to the principles discussed so far. This is an indication of the genuine
independence of the level of F/A structure and the need to derive such struc-
tures in a component separate from syntax.
Pronominal antecedence is frequently correlated with surface syntax, but
here again there are cases where an independently motivated F/A structure
gives a better guide to accounting for such phenomena. To take a single simple
example – more will be discussed below – consider the asymmetrical antece-
dence properties of subjects and non-subjects in Kalaallisut (West Greenlandic).
In most cases only the subject of a clause can be the antecedent of a reflexive
element such as the reflexive possessor that is signaled by the 3R inflection
-minik in the examples below (from Sadock 2003b):
(10)	 Kaalat 	 uluminik	 pilappoq.
	 Kaalat=Ø	 ulu=minik	 pilak=Vuq
	 K.=ABS/s	 women’s.knife=INS/3Rs	 flense=IND/3s
	 “Kaalat is flensing with her (Kaalat’s) ulu [women’s knife].”
(11)	 Kaalap	 Hansi	 illumini	 takuaa.
	 Kaalat=p	 H.=Ø	 illu-mini	 taku=Vaa
	 K.=ERG/s  H.=ABS/s	 house=LOC/3Rs	 see=IND/3s/3s1
	 “Kaalat saw Hans in her (Kaalat’s, not Hansi’s) house.”
Note that surface case is irrelevant in this ergative language; either the absolu-
tive of the intransitive clause (10), or the ergative of the transitive clause (11)
can be the antecedent of the reflexive expression, but not the absolutive term of
the transitive clause. The house in (11) cannot be Hans’s. Order is also irrele-
vant. The first three terms in (11) can be found in any order, with a variety of
discourse effects, but no effect on the reference of illumini. The only other
surface syntactic relation that could provide a difference would be a structural
asymmetry between subjects and non-subjects such that the subject is higher in
the syntactic tree than non-subjects. But there are no convincing arguments for
the existence of syntactic VPs in West Greenlandic that cannot reasonably be
taken as evidence for F/A constituency rather than syntactic constituency. (See
Sadock 1994.) According to the grammar of semantic form discussed above,
the semantic subject ought to be KAALAT for both (10) and (11). I have made
the common assumption that functors apply to only one argument at a time,
and if that is correct, there will always be a structural asymmetry between outer
and inner arguments at F/A structure to which we can attribute the differential
power of subjects and objects to act as antecedents of the reflexive elements
in West Greenlandic and many other languages that don’t seem to have a syn-
tactic VP. Once again, an independent level of function-argument structure is
descriptively very useful.
20  Autonomous modularity: syntax and semantics
Furthermore, the relations that are expressed in this dimension of analysis
might well be universal in a fairly strong sense. Surely the fundamental ones –
what we might call, following Dowty (1991), semantic subject and object – seem
to be required for the straightforward description of the meaningful properties of
propositions in all languages. Syntactic configurations, on the other hand, while
falling within clear limits, have a much greater range of variability. Syntactic
subjecthood, for example, can be manifested as the phrase-structural property
of being the NP that combines with a VP to form an S, but it may also be sig-
naled by word order, morphological case, or agreement properties.
An additional argument for the autonomy of the level of F/A structure is
therefore that its categories are more similar from language to language than
are the categories of syntax. For example, semantic modifiers that are specific
to the category of propositions belong to several syntactic categories, includ-
ing verbs like seem, adverbs like surely, and adjectives like likely, not to men-
tion tense, negation, and the like that are often realized morphologically. All
languages of which I am aware present semantic modifiers, but they are not
all represented the same way in syntax. Many languages, for example, lack
adjectives with this function since they lack a morphosyntactic category of
adjectives altogether. But so far as I know, no language has modifiers that are
specifically suited to producing more restricted transitive verb meanings from
existing transitive verb meanings and only from them. There is no apparent rea-
son why a language could not have this sort of semantic function. The mean-
ing of such a modifier in English might be realized by an adverb like bruffly
that allowed one to say The train bruffly reached the station, but not The train
bruffly stopped. I know of no such lexical item. There seems to be an inventory
of functional types that are needed for the semantic description of any natural
language and others that fail to occur regardless of the syntactic particulars of
languages. This sort of fact is easily captured in terms of an autonomous F/A
module of the kind that has been sketched above.
The strongest argument for the F/A module, however, is the great gain in
descriptive elegance that results from assuming that it exists independently of
other descriptive components, in particular the phrasal syntax. With that demon-
stration in mind, I turn to a brief discussion of the autonomous syntactic module.
1.3	 Syntax
Because complexity in an automodular grammar arises from the interaction of
autonomous components, each component can be kept relatively simple. Once
semantic, morphological, and other non-syntactic considerations are factored
Syntax  21
out, it proves adequate to assume a very straightforward, context-free phrase
structure grammar as a device for specifying the syntactic structure of natural
languages. The syntactic module, notation aside, would seem to be a proper,
and rather small subpart of just about every reasonably well-articulated syn-
tactic theory, corresponding closely to the X′ component in various versions of
the transformational point of view. The categories are complexes of features
and the basic rules conform to the schemata below, where the comma again
indicates lack of ordering, since ordering in the present view is the province of
another independent component, as will be discussed in Chapter 4.
(12)	 X″ → X′ (, Y″ (, Z″))
(13)	 X′ → X0
(, Y″ (, Z″))
The two rules above indicate that a lexical-level category X0
may have zero to
two phrasal complements, and X′ categories may have zero to two specifiers,
somewhat controversial assumptions, perhaps, but not crucial to the descrip-
tions that follow. Languages do seem to differ with respect to how many of
these possibilities are realized in the language and the specifics of the categor-
ies involved. Many languages are determinerless and do not require specifiers
of N′. There are also many languages that allow two NPs at the same level that
specify the constituent headed by the verb, the so-called non-configurational
languages that lack a VP containing the object NP. The inventory of more spe-
cific versions of (12) and (13) that occurs in a language depends, of course,
on what syntactic categories are to be found in that language. There are many
languages with no syntactic adjectives and consequently no adjective phrases,
and many languages without syntactic adpositions and therefore no adposi-
tional phrases.
Notation and delicacy of feature structure aside, both of which will be made
somewhat more precise in the chapters that follow, the syntactic component of
English might include, among others, the following rules and rule schemata
(where XP is equivalent to X″ in (12) and (13)).
(14)	 Syntax (English)
	 a.	 S → NP, VP
	 b.	 VP → V (, XP (, YP))
	 c.	 PP → P, NP
	 d.	 NP → DetP, N′
	 e.	 N′ → N (, XP (, YP))
	 f.	 S′ → Comp, S
	 g.	 N′ → AP N′
	 h.	 AP → (ADVP,) A′
	 i.	 A′ → A (, XP (, YP))
22  Autonomous modularity: syntax and semantics
There are, of course, restrictions particular to any given language concern-
ing what complement types particular X′ categories can take and what kind
of specifiers occur in particular XP categories. Thus nouns in English can-
not take NP complements and with one or two lexical exceptions, neither can
adjectives.
I will assume that a simple, context-free phrase structure grammar such as
we find in (14) is a sufficient description of the syntax per se of any natural
language, provided other, potentially conflicting, autonomous modules are rec-
ognized. No rules of deformation, that is rules that change constituency by
moving, copying, deleting, or inserting elements, will be needed in the autono-
mous modular framework.
1.4	 Lexical items
Lexical items in automodular grammar are sets of instructions to the individ-
ual component grammars – the modules. In other words, a lexical entry must
separately specify what the value of a lexeme is in each module. With regard to
the two components that were just sketched out, a lexical entry will make pre-
cise how the item combines syntactically and how it combines in terms of F/A
structure. An ordinary intransitive verb, for example, will be able to constitute
a syntactic VP (i.e., V″) all by itself and will be a semantic functor that directly
combines with an argument to form a proposition, that is to say, it is a member
of the category Fa. A standard sort of transitive verb will combine with an NP
to form a VP in the syntax and will instantiate the F/A category Faa.2
For expository purposes, I will give each lexical entry a name that will be
the ordinary dictionary form of a word in italics, if one is available, or else a
description. The lexical entry itself consists of an unordered list of the values of
the lexical item in the various modules of grammar, which I will call its fields,
two of which are the syntactic field and the F/A structure field. The notation in
the following examples illustrates the style of lexical entries:
(15)	 sneeze
	 syntax: V in [VP__]
	 F/A: Fa
(16)	 take
	 syntax: V in [VP __, NP]
	 F/A: Faa
Two common-sense corollaries of the proposal that syntax and morph-
ology can be described by fully independent phrase structure grammars are
the following:3
Lexical items  23
(17)	 The Certainty Principle
	 A single element cannot be in two places in the same dimension.
(18)	 The Exclusion Principle
	 Two elements cannot occupy one position in the same dimension.
It remains to show what the interface rules that connect the diverse repre-
sentations of an expression are and how they operate. That will be done in the
next chapter.
24
2	 The interface
An autonomous modular grammar in which any combination of properties in
any dimensions is allowed would be vastly too powerful a descriptive system
and would wildly underdetermine the set of possible human languages. The
principal mechanism that constrains automodular grammar is the interface,
which will be developed and illustrated in this chapter.
The idea behind all interface constraints is that a certain degree of com-
patibility is required with respect to any pair of autonomous representations.1
There are three kinds of matching constraints that will be postulated and justi-
fied below, all of them obvious and pretheoretically plausible:
Lexical correspondence: the requirement that in any one expression, the same
•	
lexical entries be found in every dimension of its representation
Categorial correspondence: the tendency for certain categories in one mod-
•	
ule to match certain categories in another module. For the pair of modules
that were presented in Chapter 1, for example, syntactic NPs strongly tend to
match F/A structure arguments and syntactic VPs strongly tend to be associ-
ated with predicates, that is, functions from argument expressions to propos-
itions (Fa)
Geometric correspondence: the strong propensity for geometric relationships
•	
between elements of an expression in one dimension to correspond to the
same relationships between the corresponding values of those elements in
any orthogonal dimension.
Lexical correspondence appears to be an inviolable principle of grammar,
whereas both categorial redundancy and geometric correspondence are
violable and, in fact, violated when other demands of the system outweigh
them.
After introducing the modules and giving preliminary examples of failure of
categorial and geometric alignment, I will show how easy it is to treat some of
the most basic phenomena in English complementation. It will be shown that
the behaviors associated with raising-to-subject and subject-controlled Equi
predicates follow straightforwardly merely from assuming that the lexical
items concerned have the sorts of surface syntactic constituency and functional
Lexical correspondence  25
scope relations that are widely agreed upon and that common sense augmented
by syntactic or semantic tests confirms.
Several other fairly central phenomena in English grammar will then be
shown to yield to reasonable analyses in terms of independent syntactic and
functional representations.
Finally, there will be a discussion of conceptual similarities between trad-
itional derivational grammars and automodular grammar. It will be argued that
concepts such as the Theta Criterion and Case Theory follow from the very
architecture of componential modularity whereas they are stipulative in the
derivational tradition.
2.1	 Lexical correspondence
According to the automodular conception of grammar, the lexicon is an import-
ant part of the interface that connects the autonomous components.2
For an
expression to be fully well formed, the relevant requirements of each lexical
item that is found in any one dimension must also be satisfied in all the other
dimensions in which the item has representations. If, for example, there is an
occurrence in the syntax of the syntactic value of the lexical item cat, then
there must be an occurrence of the semantic value of that lexical item in F/A
structure, and vice versa. If there are two occurrences of the semantic value of
the lexical item cat in F/A structure, there must be two occurrences of the syn-
tactic value of cat in the syntactic representation, and so on. The following is a
more formal statement of this requirement:
(1)	 Intermodular Lexical Correspondence Principle
	 If the value of a lexical item occurs n times in dimension Dj, then the
	 dimensionally appropriate values of that lexical item must be present n
	 times in every other dimension of analysis.
For example, the sentence Cats eat mice cannot have a semantic representa-
tion along the lines of DOGS(CHASE(SQUIRRELS)) (i.e., it cannot mean
what Dogs chase squirrels means) because the lexical representation DOGS
is realized only in F/A structure, but not in syntax, or, looked at the other way
around, the lexical representation of cat would be realized only in syntac-
tic structure but not in F/A structure. Furthermore Cats eat mice cannot be
matched with the F/A structure CATS(EAT) (the appropriate structure for the
sentence Cats eat) and the sentence Cats eat cannot be matched with the F/A
analysis CATS(EAT(CATS)) (the right F/A structure for Cats eat cats) because
there are two instances of the semantic value CAT but only one instance of the
syntactic value of that lexical item in the syntactic representation.
26  The interface
The extension of Principle (1) to the phonological dimension will prevent
the F/A structure CATS(EAT(MICE)) and a corresponding syntactic struc-
ture [S[NPcats][VPeat[NPmice]]] from having a phonological representation that
begins with the sequence /dɔgz/ because the phonological value of cats is
/kæts/.
2.2	 Categorial redundancy
There is obviously a good deal of redundancy between the category of ordinary
transitive and intransitive verbs in syntax and F/A structure. Such redundancy
can easily be captured in a system that radically separates syntactic and seman-
tic combinatorics. Taking a cue from Construction Grammar (Goldberg 1995),
we could note default patterns as defective lexical items with syntactic and
semantic values, but no word-level content. The following two constructions
would cover most intransitive and transitive verbs:3
(2)	 Intransitive Verb
	 syntax: V in [VP__]
	 F/A: Fa
(3)	 Transitive Verb
	 syntax: V in [VP __ NP]
	 F/A: Faa
The lexical entries of ordinary intransitive and transitive verbs could then be
simplified so as to mention only those standard, bi-modular constructions they
participate in:
(4)	 sneeze
	 Intransitive Verb
(5)	 take
	 Transitive Verb
Another, and perhaps superior way of capturing the relation between syntactic
and F/A structure category membership would trade on the fact that there is
a strong tendency for higher categories of the syntax and higher categories of
combinatoric semantic representations to align such that:
(6)	 Syntax		 F/A
	 S	 ⇔	 Prop
	 NP	 ⇔	 Arg
Furthermore, if a language has a syntactic category VP, then the additional
intermodular correspondence in (7) is also generally valid.
Categorial redundancy  27
(7)	 Syntax 	 F/A
	 VP	 ⇔	 Fa
Surely there are deep psychological reasons having to do with the structure
of concepts and the structure of the expressions that represent them that are
responsible for the fact that categories of meaning and categories of form are
usually matched in this way, but, knowing little about the structure of concepts
other than what language tells us, an attempt to explore such issues here would
be premature. I will therefore take the correspondences in (6) and (7) to be
brute facts and leave the account of their existence to those who know more
about cognitive matters than I do at present.
It is possible to capture the redundancy in category membership between the
syntactic and F/A structure modules by mentioning the category membership
of a verb with respect to either one of the component modules and letting the
grammars of the two levels plus the default associations in (6) and (7) do the
work. But which one should we mention in the lexicon? The answer is pretty
clearly that it ought to be the syntax that is stipulated, since syntax is more
variable than semantics and one can better predict semantic properties from
syntax than the other way around. Knowing that a lexical item is an intransitive
verb strongly suggests that it is a member of the semantic category Fa, but if a
lexical item is a semantic Fa, there is a fairly high likelihood that it is a noun or
an adjective in the syntax. I will assume, then, that the proper redundancy-free
entry for run-of-the-mill intransitive and transitive verbs ought to be (8) and
(9), from which redundancy rules could fill in the functional-argument cat-
egory to give the constructions in (2) and (3).
(8)	 (intransitive verb)
	 syntax: V in [VP__]
(9)	 (transitive verb)
	 syntax: V in [VP __ NP]
The key observation that informs the automodular program is this: despite the
quite good correspondence that generally holds between representations at dif-
ferent levels, such correspondences are not perfect. Thus the categorial corre-
spondences given in tables (6) and (7) hold in default cases, but not invariably.
Exceptions of several kinds are easy to find and these exceptions underpin the
need for autonomous grammatical descriptions in different dimensions. We
can observe, for example, that violations present themselves in the form of
propositions that are encoded by noun phrases (I disapprove of our decision
to invest in Lingco Products), and NPs that count as predicates (Fa), rather
than arguments (e.g., Kirby is a Baha’i). As I will argue in detail below, there
28  The interface
are also propositions that are encoded as VPs, rather than clauses (for instance
I tried to play the accordion). Each of the autonomous levels, however, remains
coherent in the face of such discrepancies; the combinatoric properties of the
units that are found in each kind of representation remain intact. It is my con-
tention that much of the complexity of grammatical phenomena can be traced
to inexact matching between individually simple levels, rather than complexity
in any one of those levels.
A flexible interface allows such categorial mismatches to occur, but there
is a cost in terms of complication of the lexicon. Take, for example, a sen-
tence such as Sally is a carpenter. Following standard logical analyses that
go back at least to Frege (1892), the logical F/A structure of this sentence
is CARPENTER(SALLY), where CARPENTER is a predicate, an F/A elem-
ent of category Fa. Given this, we might expect that the way it should come
out in English would be *Sally carpenters, but we can’t say that. The reason
we don’t say *Sally carpenters is syntactic, not semantic. Carpenter is not an
intransitive verb meaning “do what a carpenter does,” it is a noun in the syntax
(and by default also in the morphology, according to (19) of Chapter 5), and
therefore cannot head a syntactic verb phrase (or support morphological verbal
inflection).
Such facts can be stated quite succinctly in automodular terms. There is
a syntactic noun carpenter in the lexicon of English and its basic meaning
is that of a predicate, a fact to be handled in the autonomous F/A structure
component.4
(10)	 carpenter:
	 syntax: N
	 F/A: Fa
We can’t say *Sally carpents because no such verb occurs in our lexicon
and we cannot say *Sally (a) carpenter, as one does in Russian and many
other languages, since according to the simple syntactic grammar in (14)
of Chapter 1, a clause in English requires a VP, and VPs must be headed by
verbs. So English seems to have got itself into something of an expressive
bind such that we have people who do carpentry for a living, whom we can
refer to as carpenters, but whom we cannot describe as such in a manner
that conforms to the logical organization of the attribution. Fortunately, the
social committee of the whole that shaped the language provided it with a
solution to this dilemma in the form of an empty verb be that counts as a verb
for syntactic and morphological purposes, but has no combinatoric semantic
function whatsoever.
Categorial redundancy  29
Because it does not fit the default transitive verb pattern, its lexical represen-
tation must be spelled out in detail. The following lexical entry for empty be
covers only the special case where it combines with an NP. But empty be also
occurs with VP complements, adjective phrases, prepositional phrases, and
various other miscellaneous syntactic categories. The entry will be general-
ized in (98) below in connection with the treatment of existential there. For the
purposes of the present discussion, (11) will serve.
(11)	 be (empty verb)
	 syntax: V in [ __ NP]
	 F/A: nil
There is still a slight problem. English has verbs, including the empty verb
be, that are subcategorized for NPs, but none, so far as I can determine, that
are subcategorized for Ns or N′s. Furthermore, English requires an article or
other determiner in order to make an NP out of a singular count noun like
carpenter. Therefore we cannot say *Sally is carpenter, as speakers of even
closely related languages do.5
Again a clever design strategy comes to the fore.
While the articles and determiners of English generally have a semantic func-
tion to perform and need to find representation in F/A structure, we also have
an empty article available for just such an expressive exigency as the need to
describe Sally in terms of her profession. In one usage, then, the indefinite sin-
gular article a(n) counts as a determiner for the purposes of syntax, but is not
represented in F/A structure at all:
(12)	 a(n) (empty article)
	 syntax: Det
	 F/A: nil
The existence of these two purely formal syntactic elements allows us to
express Sally’s carpenterhood as Sally is a carpenter, with (13) as the descrip-
tion of the expression at the syntactic level, and (14) as the simultaneous F/A
description, both of which are completely well formed relative to their own
grammars.
(13) S
NP
Sally
VP
V
is
NP
Det N
a carpenter
30  The interface
2.3	 Insertion and deletion
The structural discrepancies between (13) and (14) are of the kind that would
be handled by insertion processes in some varieties of generative grammar.
McCawley (1988, 141), for example, explicitly recognizes a rule of be inser-
tion. In the present framework, however, there is no need for such a process.
Phenomena that might have been handled by adding a lexical item to trees in
the course of transformational modification can be accommodated just by rec-
ognizing an extreme sort of categorial mismatch in which a lexical item that
represents a certain category in one dimension represents no category at all in
some other dimension. When the dimension in which the category is missing is
a semantic level (either F/A structure introduced in Chapter 1, or the role struc-
ture dimension that will be described in Chapter 3) and the dimension in which
it is found is either syntactic representation or phonological representation, the
phenomenon is usually handled by inserting an element during a derivation,
but here we have reconstructed insertion without the need for that operation.6
Similarly, deletion is not needed. Just as with cases that are handled as inser-
tion in other frameworks, deletion is also a geometrical discrepancy whereby
an element in one dimension is not matched by anything in another. Here,
however, the “deleted” element is present in one of the “deeper” representa-
tions – F/A structure or role structure – and absent at one of the more superfi-
cial levels. (See Chapter 6 for an extended discussion of defective lexical items
that lack a representation with respect to one or more modules.)
The need for what is taken to be inserted be in other frameworks, that is to
say, a verb that performs a syntactic and morphological role, but finds no place
in semantic structure, is attributable to the fact that nouns, which according to
commonplace assumptions are semantic predicates, are often not matched by
verbs expressing more or less the same thing.7
To serve as the main semantic
element in a verb phrase, then, a noun must be supported by a verb, and if there
is no verb whose meaning is to be expressed, the empty verb be is called upon.
There are, of course, pairs such as teach and teacher that allow me to say either
I teach or I am a teacher, with the same truth-conditional properties, though
perhaps with pragmatic differences that depend upon differences of form. But
where the noun exists and no semantically equivalent verb does, the structure
(14) Prop
Arg
SALLY
Fa
CARPENTER
Insertion and deletion  31
of English syntax is such that be must occur whenever the predication is in a
verb phrase.
As mentioned above, if correspondences like (6) and (7) are part of universal
grammar, then they can be used to simplify the lexicon in cases where there
is no discrepancy between syntactic and semantic structure. Take a sentence
such as Ben plays the zither and suppose that the lexical entry for the syntax
of play in this sense is (15) so that the word will occur in syntactic structures
of the form (16):
(15)	 play
	 syntax: V in [VP __ NP]
Now according to the default alignments that are stated in (6) and (7), S cor-
responds to Prop, NP corresponds to Arg, and VP corresponds to Fa. We will
then have the following F/A structure (with some correlations suppressed) cor-
responding to a well-formed clause containing play:
It is apparent that play has a semantic value, so V must be associated with Faa
in F/A structure by (1), the Intermodular Lexical Correspondence Principle. It
is therefore not necessary to specify both the syntactic and semantic category
of a transitive verb whose combinatoric properties are harmonic in these two
(16) S
NP1 VP
V
play
NP2
S
Fa NP1 VP
(17)
Prop
Arg1
Arg2 Faa NP2 V
play
32  The interface
components. Neither is it necessary to stipulate that there is a transitive verb con-
struction in English as is done in the Construction Grammar framework and as
I did earlier. Since at least (6) and (7) express strong universal tendencies,8
syn-
tactically transitive verbs in all languages will strongly tend to be functors from
arguments to predicates, regardless of whether the language has a VP or not.
We have seen that intransitive verbs should count as simple predicates of the
category Fa and transitive verbs should be simple relations, Faa, in F/A struc-
ture. This is, of course, largely true, but there are many examples of verbs that
fail to fall under these generalizations. Empty be, which was discussed above,
is one sort of example: a verb that occurs with an NP complement but repre-
sents no semantic function at all.
Another exception to the smooth categorial matching between syntax and
semantics is provided by verbs that are transitive in syntax but take no com-
plement in F/A structure. The verb beat, for example, is transitive in most of
its uses, taking an NP object obligatorily: *The cook beat for fifteen minutes.9
Thus it conforms to the default and its lexical entry need not mention its F/A
structure category, since it can be filled in with the help of default category cor-
respondences in the manner demonstrated above. But beat is also syntactically
transitive when it is used in the idiomatic expression beat it, where it means
something like “to leave hurriedly,” an intransitive meaning. The syntactic tran-
sitivity, however, is carried over from the other uses of the verb. To correctly
describe the idiomatic sense, then, we must list its semantic category explicitly,
in this way overriding the lexical default and implying the mismatched syntac-
tic and F/A structures shown in (19).
(18)	 beat (it)
	 syntax: V in [ __, NP]
	 F/A: Fa (= LEAVE)
	 morphophonology: /bit/10
Once again, the language faces a problem. Both NP1 and NP2 must be repre-
sented by something in the syntax or the syntactic frame in which the verb must
fit will be incomplete. But if both are represented by something syntactic that
has an F/A value, NP1 by the cook, say, and NP2 by the eggs, there will be more
(19) a. S b. Prop
NP1 VP Arg Fa
LEAVE
V
beat
NP2
Insertion and deletion  33
arguments than the semantic structure allows for. To put it differently, the seman-
tic value of EGGS will not be discharged in (19b) as required by the Intermodular
Lexical Correspondence Principle (1). As before, an empty element in the lexi-
con of English is there to help, this time the pleonastic NP it, homophonous with,
but not lexically identical to the referential pronoun. Since this is the only unre-
stricted, semantics-free NP in the language, the lexical representation of beat as in
(18) will suffice, the appearance of exactly the word it as its only possible object
arising automatically. Pleonastic it has other uses in English, some of which will
be discussed later. Once again, there is no insertion, merely a mismatch between
syntactic and F/A structures such that an element that is required in the syntax
is unmatched by anything in the semantic structural representation. Anticipating
the morphophonemic component that will be presented in Chapter 5, we have
(20) as the representation of this important lexeme.
(20)	 it (pleonastic)
	 syntax: NP
	 F/A: nil
	 morphophonology: /ɪt/
A similar sort of exception to categorial matching is presented by transitive
verbs that are subcategorized for a PP, not an NP, where the preposition makes
no independent contribution to semantic form. In one variety of these the
preposition is part of an idiom. There are a great many such examples in the
English lexicon. Consider the expression look into NP, in the sense of “investi-
gate.” An appropriate lexical entry would be as in (21):11
(21)	 look into
	 syntax: V in [ __ PP[into]]
	 F/A: Faa (= INVESTIGATE)
The “real” preposition into cannot be used here since there is no room for its
semantic combinatorics in the F/A structure. If the phrase headed by into is
taken to be a syntactic and semantic modifier (an adjunct and an MFa in F/A
structure, respectively), it must take an argument in the F/A structure and
the lexical expression in (21) would require three arguments altogether. But
there are only two NPs in the syntax of a sentence like The senate looked into
the matter, so the F/A structure will be incomplete. Here the preposition is
lexically required to occur in the syntax and lexically specified so as not to
include the meaning of the homophonous item in F/A structure, the desired
outcome.
The case of a verb like dispose meaning “discard,” which takes a prepos-
itional phrase headed by of is slightly different. This expression could be han-
dled in exactly the same way as look (into) was, but, for the sake of parsimony,
34  The interface
it might be preferable to identify the of that occurs here with the of that marks
what are understood as arguments of adjectives and nouns, that is to say, yet
another semantically empty syntactic element, another “function word.”
(22)	 of (functional)
	 syntax: P in [PP[of] __ ]
	 F/A: nil
Then the lexical entry for dispose-of could then be simplified to (23).
(23)	 dispose “discard”
	 syntax: V in [ __ PP]
	 F/A: Faa
Here some preposition must be found in the syntactic structure, but it cannot
be any of the ordinary ones, since they all have semantic combinatoric values,
and the F/A structure of the verb phrase would be complete with a simple
argument and therefore offers no slot for an additional meaningful element.
Since no preposition is given in the lexical entry that could enter the tree syn-
categorematically, the only possibility is that the all-purpose functional pre-
position of appears in the syntactic structure. Once again, the effect of insertion
is achieved without the derivational insertion of anything. Note that the syntac-
tic structure and the functional structure that are needed to achieve this result
are both perfectly well formed and obvious.
2.4	 Geometrical correspondence
The second sort of default correspondence that emerges when one compares
syntactic and combinatoric semantic representations has to do with the rela-
tive structural positions of corresponding elements in the two dimensions
that have been considered to this point. The general principle is that hier-
archical relations among elements in one dimension should be reflected in
the hierarchical relations among the corresponding elements in the other
dimensions.12
As an introductory example of the utility of assuming a principle that favors
congruent representations in syntax and semantics, consider the following
question: if syntactic and semantic representations are autonomous, what is
it that ensures that the semantic subject (i.e., the argument that is combined
with a predicate to form a proposition [Dowty 1982]) is ordinarily associated
with the syntactic subject, and the semantic object13
(i.e., the argument that
a relation takes to make a predicate) is usually matched with the syntactic
Propositional modifiers  35
object? In other words, why does the sentence Dogs like cats mean what it
does rather than “Cats like dogs”? Regardless of which semantic structure is
paired with the syntactic structure, the semantic requirements of all lexical
items would be satisfied, the ordinary default correspondences of categories
would be observed, and the representations in both dimensions would be well
formed. What is wrong, of course, is that the positions of dog and cat in syntax
would not match those of the corresponding elements DOG and CAT in F/A
structure.
The basic structural relations that are subject to default geometrical corres-
pondence conditions are dominance and c-command.14
(24)	 Geometrical Correspondence Conditions15
	
Let A and B be nodes in dimension D1 and A′ and B′ be corresponding
nodes in dimension D2. Then:
	 a.  if A dominates B, A′ should dominate B′.
	 b.  if A c-commands B, A′ should c-command B′.
I will refer to (24a) and (24b) as Conservation of Dominance and Conservation
of C-command.16
Assuming the modular grammars that were discussed in
Chapter 1, it is obvious that the pair (S dogs (VP like cats)) and (Prop CATS
(Faa
LIKE DOGS)) involve violations of Conservation of Dominance and
Conservation of C-command that are not found in the pair (S dogs (VP like cats))
and (Prop DOGS (Faa
LIKE CATS)).
2.5	 Geometrical non-correspondence
As with the categorial correspondences, the geometrical correspondence con-
ditions are defaults. In many cases they determine exactly what kinds of com-
plements certain verbs should accept and, conversely, what kinds of functional
categories the verbs should count as, but in special cases they do not. Examples
of both will be discussed in the following sections.
2.6	 Propositional modifiers
Consider the case of a verb whose F/A value is Fp, that is, one whose
semantic value applies to a proposition and returns a proposition. The max-
imum conformity of such a functor with the categorial and geometrical
defaults of (6), (7), and (24) will be achieved if this verb has a clausal NP
as a subject in syntax, in which case the syntactic and F/A structures will
be (25a) and (25b):
36  The interface
Prop1 will be associated with S1, Prop2 with S2, and Fp with V, as shown by
the dotted lines in (25). There are a few verbs in English that project harmonic
structures in syntactic and F/A structures as in (25), including stink, suck, rule,
bite, and perhaps a few others, but the majority of English verbs that count as
propositional modifiers in F/A structure do not achieve this level of congru-
ence between the syntactic and F/A dimensions of representation. The few
verbs that do pattern as in (25) are all factive, in the sense that they can only
be felicitously used when the propositions expressed by their complements are
taken by the speaker as assumed true, that is, as accessible information in the
discourse setting. The majority of verbs whose meaning is such that they com-
bine semantically as in (25b) are non-factive, i.e., verbs that introduce brand
new information, including seem, appear, happen, transpire, turn out, come
about, come out, look (as if), and so on. All of these, without exception, have
to have complement clauses following the verb. That class will be treated in
detail below.
Despite the small number of factive verbs of the type diagrammed in (25),
the frame is enough to let a hearer know that the speaker assumes that S2 is true
and that the hearer shares this belief. The generalization, stipulatively, is (26).
(26)	
A non-factive verb in English with the value Fp in F/A structure must have a
syntactic complement.17
The existence of this generalization has to do with the fact that the semantic
arguments of factive verbs are, almost as a matter of definition, old informa-
tion. Besides the correlations between syntax and function-argument structure
that are being investigated at this point, there are well-known correlations with
other autonomous systems in language as well, one of which is information
structure, some discussion of which will be found in Chapter 7. The align-
ment between informational organization and the order of constituents is well
known. Crudely, it is (27). (See Chapter 7, sections 7.5 and 7.6 for further
discussion.)
(25) a. b.
Prop1
VP Prop2 Fp
V
S1
NP
S′
S2
Propositional modifiers  37
(27)	 Old information precedes new information.
The statement above is a correlation between two independent systems of gram-
mar, the formal linearization of elements (Chapter 4), and indicators of the dis-
course status of the meaningful parts of an utterance. As such, it is a default
alignment of the same nature as principles (24a) and (24b) above and should be
assumed to be a violable constraint. The correlation between intransitive verbs
that take subject clauses and factivity in English seems to be a grammaticalized
example of a violable tendency. This generalization needs to be stated formally
in the description of English, but, restricting our attention to just syntax and
F/A structure for present purposes, we can temporarily state it informally as
(28a) which implies the lexical entries (28b).18
(28)	 a.  If a lexeme has Fp as its F/A value and V in [ __ ] as its syntactic value,
		 then it is factive.
	 b.	 stink, suck, bite, rule, rock …
		 syntax: V in [ __ ]
		 F/A: Fp
Members of the larger class of verbs of the Fp semantic category, however,
must occur with a complement of some kind, in the present instance, an S′. In
other words, they will lack an entry like (28b) that would allow them to occur
with no complement at all. Notice that (28a) applies only to verbs since only
verbs can head VPs. Thus Fp adjectives and nouns regularly do head A′s and
N′s without complements: That many students will show up is unlikely/a fore-
gone conclusion. Now it is also the case that the few factive verbs of the class
Fp all can, optionally, take S′ complements, as in It stinks that so many students
left. In fact, every verbal, nominal, and adjectival predicate that counts as Fp
in functional terms can take a clausal complement. This fact is easy enough to
state in automodular terms as the default (29):
(29)	 Intermodular Default (English):
	 All verbs whose F/A value is Fp have
	 V in [XP __, S′] as one of their syntactic values
This holds for the factives like stink, which now do not need another lexical
entry beside (28b) when they take S′ complements, since that entry will be sup-
plied by the redundancy rule (29). Furthermore, the non-factive verbs like seem
do not need an entry like (30) since (29) makes it sufficient to specify only their
F/A category, as in (31).
(30)	 seem, appear, happen, transpire, turn out, come about, come out …
	 syntax: V in [ __ S′]
	 F/A: Fp
38  The interface
(31)	 seem, appear, happen, transpire, turn out, come about, come out …
	 F/A: Fp
But seem and the other verbs in (31) do not have more specific lexical entries
like (28b) that would allow them to also occur without a complement.
Now the verb seem may occur with other complement types, including
adjective phrases and infinitive verb phrases, a fact that I will examine below,
but let us now consider further ramifications of the lexical specification in (31).
Syntactically seem will form VPs with clausal complements, and the resulting
VP can combine with an NP to form a clause according to the familiar, general
rule of clause structure (14a) of Chapter 1. Semantically, it will be a function
that takes a proposition and yields another proposition. Furthermore, clauses
in English consist of NP and VP, and propositions consist of a functor and an
argument. Thus the following structures in the two dimensions are implied by
the lexical entry (30), abbreviated as (31):
From the geometrical and categorial alignment principles we get the correspond-
ences shown in (32). But this leaves the subject of the main clause, NP1, unassoci-
ated.As before, if NP1 had ordinary lexical content, then its lexemes would have
to find expression in both levels of description. But there is no more room for
the meaning of a semantically contentful noun phrase in (32b), since its sole
argument is necessarily associated with NP2 in order to conserve c-command
relations. NP1 must therefore be a noun phrase without semantic content, and,
handily enough, we have one, namely it, whose lexical entry has already been
given in (20). We have thus derived the effect of the rule in derivational theories
sometimes analyzed as extraposition and sometimes as interposition (Emonds
1972), depending on what is taken as the input and what as the output. But we
have not needed to postulate either rightward or leftward movement of any kind
so we do not need to address the question of directionality at all.
b. Prop1
(32) a. S1
NP1 VP Fp
SEEM
Prop2
V
seem
S′ Arg Fa
2
S
NP2 VP
Propositional modifiers  39
Readers can easily convince themselves that the spare assumptions I have
made imply that when seem occurs with an S′, the effect of so-called extrapos-
ition will always be observed. Such a verb was classically handled by listing
it as obligatorily undergoing the otherwise optional rule of extraposition, but
here it is a verb whose meaning is what it is, namely a one-place, non-factive
propositional operator whose syntactic subcategorization frame is unspecified
thereby automatically taking a sentential complement because of the very gen-
eral feature of English embodied in (29). Note that the automodular analysis
makes the wider class of non-factive verbs the default class lexically, since the
syntax of such items need not be stipulated at all.19
According to the classical
theory of extraposition, however, the non-factive verbs are odd and have to
be marked as obligatorily undergoing an otherwise optional rule. The unusual
class of factives that had few exponents fifty years ago would not need such
special marking according to the transformational treatment, whereas the non-
transformational theory requires that they be made a special case with the com-
plex lexical entry in (28b).
Returning to members of Fp that are not verbs, we notice that they will regu-
larly occur with complement subjects and hence with no complement object.
All of them, so far as I can tell, will belong on the lists in (33) or (34).
(33)	 odd, likely, apparent, unpleasant …
	 syntax: A in [ __ ]
	 F/A: Fp
(34)	 disaster, foregone conclusion, likelihood, pain in the neck …
	 syntax: N in [ __ ]
	 F/A: Fp
Another intermodular default would handle these, the formal statement of
which should be obvious.20
But since all such non-verb predicators (as well as the factive verbs stink,
suck, bite, rule, etc.) are listed as Fp, they will all automatically also have
derived entries of the following form:
(35)	 odd, likely, apparent, unpleasant …
	 syntax: A in [ __ S′]
	 F/A: Fp
(36)	 stink, suck, bite, rule …
	 syntax: A in [ __ S′]
	 F/A: Fp
When they do take a complement by (29), they may only have asemantic it
as a syntactic subject, for the now familiar reasons. When they do not take a
40  The interface
complement, their subject can be a clausal NP. Thus they appear in alternat-
ing syntactic frames but with the same semantic combinatorics, a set of facts
handled by an optional movement rule in the transformational literature, but
following from simple and direct assumptions in the present framework.
2.6.1	 “Raising” to subject
A number of predicators that function as intransitive operators (that is to say,
propositional modifiers of the F/A category Fp) can occur with syntactic com-
plements other than subordinate clauses, including VPs and adjective phrases.
These include verbs such as seem, appear, and happen, adjectives such as likely,
certain, and sure, and nominals such as strong likelihood, certainty, and good
bet. The verbs seem and appear occur with either a VP complement: appears to
be absent; an adjective complement: seems sick; or (chiefly in British English) a
nominal: seems a nice enough bloke. None of the adjectives or nominals can take
an adjective phrase or a nominal as a complement, but most do occur with VPs:
(37)	 a.	 is certain to be absent
	 	 *is certain very sick
	 	 *is certain a nice enough bloke
	 b.	 is a good bet to be absent
		 *is a good bet very sick
		 *is a good bet a nice enough bloke
I make the unusual, but from my point of view obvious claim that those predi-
cators that can be followed by an infinitive phrase have infinitive phrases as
complements. The more common assumption − that they take clauses − is
based solely on the fact that they are understood as propositions, a matter of
autonomous semantic structure, so far as I can see. The lexical entries for these
items will therefore be as follows:
(38)	 seem, appear, look
	 syntax:	 a.	 V in [ __ VP[to]]21
		 b.	 [ __ AP]
		 c.	 %
[ __ NP]22
	 F/A: Fp
(39)	 likely, certain, sure
	 syntax:	 a.	 A in [ __ VP[to]]
		 b.	 [ __ ]
	 F/A: Fp
(40)	 certainty, good bet
	 syntax:	 a.	 N in [ __ VP[to]]
		 b.	 [ __ ]
	 F/A: Fp
Propositional modifiers  41
Such verbs, adjectives, and nominals will also appear with S′ complements
according to the redundancy rule (29), and when they do, their subject must
once again be pleonastic it. The generalizations regarding complement type
can easily be extracted in the form of redundancy rules, too, but, again, I will
continue to write the expanded lexical entries for clarity’s sake.
(41)	 It/*He seems/is likely/is a good bet that Tracy will be absent.
Let us consider the syntax–F/A interface for those predicators that operate
on propositions to create modified propositions and are syntactically subcate-
gorized for infinitival VPs. The two-dimensional analysis of a sentence such as
Melanie appears to limp is this:
Geometrical and categorial default correspondences will straightforwardly
give us certain matches across the syntax–F/A structure divide. In particular,
S1 will align with Prop1, and VP2 with the Fa LIMP. Furthermore, the verb
appear and its semantic counterpart, the Fp APPEAR will have to be associated
to satisfy the Intermodular Lexical Correspondence Principle. This arrange-
ment also maintains the c-command relations between corresponding elements
in the two dimensions.
Now we know that in the syntax of the expression Melanie appears to limp
the proper noun Melanie must be the NP subject (because clauses in English
need NP subjects) and we know that the meaning MELANIE must be Arg in
Prop2 (because LIMP is a functor that demands an argument to form a propos-
ition). Such a cross-modular identification is in line with the categorial expec-
tations that NPs will be Args and Args will be NPs. However, the syntactic NP
and the semantic Arg are not in the same relative positions in their respective
structures; there is a failure of Conservation of C-command. Nevertheless, the
NP subject and the lower proposition’s Arg can discharge the syntactic and
semantic values of the lexical content of the proper name Melanie, so that
both structures are well formed in their respective syntactic and F/A dimen-
sions, thus satisfying the Lexical Correspondence Principle (1). The mismatch
is clearly tolerable in this case since the sentence is grammatical and means
(42) a. b.
S1 Prop1
NP
Melanie
VP1 Prop2 Fp
APPEAR
VP[to]2
V
appear
Arg Fa
to limp MELANIE LIMP
42  The interface
what it does. The misalignment is forced here by the peculiar lexical fact that
appear has just the combination of syntactic and semantic properties given in
(38a).
What we see, then, is that the effect of the older transformational rule of
Raising-to-Subject, or its newer, more general formulation in Government
and Binding terms as NP movement, is taken care of in the automodular
view as a simple configurational mismatch between syntactic phrase struc-
ture and semantic F/A structure without the need for movement rules, their
attendant machinery, and the great variety of notions that have been put
forward as to the motivation for the movement. The lexical properties of
raising verbs like appear are such that the mismatch cannot be avoided.
Any predicator that belongs to the semantic category Fp and has as a syn-
tactic complement a phrase type whose meaning is that of a predicate, in
other words, one that requires an additional referential argument to form
a proposition, will be a Raising predicate. This holds not just for VPs, but
also adjectives such as likely in Melanie is likely to limp, and nominals such
as a sure thing in Melanie is a sure thing to be limping. Having just this par-
ticular combination of syntactic and semantic values, both of which can be
immediately discerned, is, in fact, what it means to be a Raising predicate
in automodular terms.
Note that if a Raising predicate (that is, an {F/A: Fp; syntax: V in [ __ VP]})
contains another Raising predicate in its complement, the considerations above
correctly and automatically produce the effect of cyclic raising with no more
stipulation. Consider the analysis of the sentence Errol seems likely to suc-
ceed in the two autonomous dimensions under discussion here. According to
the simple grammars given in Chapter 1 (3), (6), and (8) for F/A structure and
Chapter 1 (14) for syntax, as well as the lexical requirements of seem and likely
found in (38a) and (39), the skeletal structures at the two levels will be (43)
and (44):
(43) S
NP VP
seem VP[to]
be AP
A
likely
VP[to]
to succeed
Propositional modifiers  43
The identification of most constituents across the interface is straight-
forward according to the interface principles that have been introduced;
in the case of Raising predicates, the relative scope of the syntactic and
semantic corresponding nodes of the predicators seem and likely is assured
by Conservation of C-command. The one problematic case is the cross-
­
identification of the NP subject in the syntax and the Arg in the semantics.
But there is no other possibility that would allow the lexical content of
the NP to be discharged in semantic structure, or, looked at the other way
around, for the meanings of these lexical items to find their way into syn-
tax. The combined, two-level analysis in (43) and (44) can thus character-
ize a well-formed expression.
It can easily be seen that there is no limit in principle to the depth of embed-
ding of lexical items specified as {F/A: Fp; syntax: V in [ __ VP]} within other
elements of the same category, obviously the correct result since examples like
those diagrammed in (43) and (44) are quite acceptable.
The description offered so far also provides a disarmingly simple treat-
ment of certain facts that are somewhat difficult in other frameworks. Recall
that non-factive raising-to-subject verbs in English cannot ordinarily have
clausal subjects: *That we will be rescued tomorrow seems. Yet the sentence
That we will be rescued tomorrow seems likely is well formed. Why? A
glance at the lexical specification of seem in (38b) reveals the answer. This
verb must take a complement of some kind in syntax, either a VP, an AP, or
in some dialects an NP, as shown directly in the lexical entry, or else an S′,
as implied by the redundancy rule (29). But in the syntactic structure *That
we will be rescued tomorrow seems, the verb seem has no complement, so
the form is syntactically deviant, the subcategorization requirements of the
verb not having been met. In the grammatical sentence That we will be res-
cued tomorrow seems likely, on the other hand, seem does have a comple-
ment, namely the AP [likely]. Since likely, an adjective, can occur with no
complement in syntax according to its lexical entry (39b), the example is
syntactically beyond reproach.
(44) Prop1
Fp
SEEM
Prop2
Fp
LIKELY
Prop3
Arg Fa
SUCCEED
44  The interface
2.7	 Functors belonging to the category Fpa
A verb such as claim combines semantically with a proposition, such as the
meaning of a clause, to form a predicate, and this predicate combines seman-
tically with an argument to form a proposition. In other words, claim on this
usage belongs to the semantic class Fpa according to the notation described in
Chapter 1. When applied to a propositional category as in the meaning of claim
that traces exist, the result is a predicate of individuals that is true of those who
so claim. The lexical entry for such a verb in this usage is (45), inducing syn-
tactic and semantic structures of the form (46) and (47):
(45)	 claim
	 syntax: V in [__ S′]
	 F/A: Fpa
Here the alignment between semantic and syntactic nodes, both in terms of
category and constituency, is as close as it can be. It should not be surprising,
then, that most, perhaps all, verbs that belong to the semantic category Fpa can
occur with clausal complements. If this observation is always true, then we can
expand the generalization in (29) above to include both intransitive and transi-
tive operators as follows:
(48) 	 Intermodular Default (English):
	
If a lexeme is Fpψ in F/A and is V, N, or A in syntax, then it can occur
in [ __ S′, …] in syntax.
(46) S
NP VP
V
claim
S′
Comp S
NP VP
(47) Prop
Arg Fa
Fpa
CLAIM
Prop
Arg Fa
Functors belonging to the category Fpa  45
Here “ψ” is any string of a’s and p’s, including the empty string, and “…” is
any set of syntactic constituent types, including the empty set. The generaliza-
tion expressed in (48) therefore extends to lexical items such as strike in strike
me that S, seem in seem to me that S, convince in convince me that S, explain
in explain to me that S, and so on.
Verbs of the combinatoric class Fpa belong to a variety of different cognitive
classes including:
(49)	 Verbs of saying:
	
affirm, allege, announce, assert, assure, aver, avow, certify, claim, contend,
declare, inform, insist, maintain, pretend, profess, pronounce, propose,
propound, protest, reaffirm, reassert, relate, repeat, say, state, swear, tell,
vouch, warrant
(50) 	 Verbs of thinking:
think, believe, assume, presume, imagine, dream, postulate, hypothesize,
­
theorize, think, reflect, cogitate, consider, deliberate, speculate, contemplate,
meditate, ponder, muse, dream, ruminate, brood over, study, discuss, realize,
appreciate, fancy, reconsider, strike
(51)	 Verbs of perceiving:
	 perceive, notice, see, find, observe, hear, sense, discover, detect
(52)	 Verbs of intending:
	
intend, want, desire, crave, wish, intend, purpose, design, mean, have, as-
pire, endeavor, aim, dream, premeditate, propose
(53)	 Verbs of trying:
	 try, endeavor, strive, assay
For each of these classes there are clear tendencies toward certain sorts of
syntactic behaviors, especially concerning what sorts of phrases they take as
complements. Therefore these cognitive classes cannot be dealt with just in
terms of F/A structure, since at that level of purely combinatoric analysis,
all predicators of the same F/A category are semantically identical. A finer-
grained treatment in terms of the actual content of the verbs will have to await
the development of a level in which linguistically relevant aspects of cognitive
structure can be distinguished. This level will be introduced and discussed in
the next chapter.
For some verbs in these meaning classes an infinitive complement is possible
or required, and that correlates to some extent with their cognitive class. At the
same time, it is important to notice that at least some of the time this property
46  The interface
is not predictable on the basis of meaning. All of the verbs of perception listed
in (51), for example, do not allow an infinitive complement (*I noticed to be
getting sick), some verbs of saying and thinking do, and apparently all verbs of
intending and trying do. An NP complement in addition to the VP complement
is also possible with some of these predicates when they occur with an infini-
tive and is sometimes necessary.
(54)	 The doctor perceived/observed (the patient)/*Ø to have a rash.
While there is a good deal of predictability based on semantic content, as
Dixon (1991) and Levin (1993), to name just two, have demonstrated, it is
important to recognize, however, that at least some of the time the kind of syn-
tactic complement the verb allows is not predictable. There is, in other words,
such a thing as grammar.
The following pairs of near synonyms, for example, do not have identically
the same privileges of occurrence within VPs:
(55)	 a.	 claim/*assert to be a Libertarian
	 b.	 %
claim/*assert Fred to be a Libertarian
	 c.	 assume/*postulate Nancy to be popular
	 d.	 *intend/desire Fred to vote Libertarian
	 e.	 like/enjoy swimming
	 f. 	like/*enjoy to swim
The verb claim, then, will have the following lexical entry, allowing it to
occur in syntactic and F/A structures like (58a) and (58b), with a stipulated VP
complement. The similar verb assert, on the other hand, is only found with S′
complements, derivable via the redundancy rule (48) so that the frame [ __ S′]
need not be mentioned in the lexicon for either. Assert cannot therefore occur
with the syntax shown in (58a).
(56)	 claim
	 syntax:	 a.	 V in [__ S′]
		 b.	 [__ VP[to]]
		 c.	 %
[ __ NP VP[to]]
	 F/A: Fpa
(57)	 assert
	 syntax: V in [__ S′]
	 F/A: Fpa
Functors belonging to the category Fpa  47
2.7.1	 The syntactically null argument RHO
When a verb such as claim is used with a VP, as in, say, Frieda claimed to
be Napoleon, there is an important discrepancy between its syntactic and
semantic combinatoric properties. The semantic form of this example has
two predicates (Fa) in it: the meaning of CLAIM(Arg2, NAPOLEON) and
the meaning of NAPOLEON. To construct a well-formed semantic struc-
ture, then, both of these predicates will have to combine with the correct
sorts of arguments, which in both cases are entity arguments. The meaning
of CLAIM(Arg2, NAPOLEON) is not a problem, since its semantic subject
(i.e., the argument that combines with the predicate to form a proposition)
is obviously the meaning of Frieda, which is in a corresponding position
in syntax and F/A structure. But what of the predicate NAPOLEON? It
clearly does have a semantic subject; we understand there to be a refer-
ence to someone’s being Napoleon. There must therefore be an argument
expression in the F/A structure that does not have a representation in syn-
tactic structure, the mirror-image of pleonastic it. I will call this element
RHO:
(59)	 RHO
	 syntax: nil
	 F/A: Arg
This purely combinatoric pair of properties says nothing, of course, about
the reference of RHO, which in a case like that above corefers with whoever
is referred to by the semantic subject of claim. This is an example of what is
(58) a. S
NP
Frieda
VP1
V
claim
VP2
to be Napoleon
b. Prop1
Arg1
FRIEDA
Fa
Prop2 Fpa
CLAIM
Arg2 Fa
NAPOLEON
48  The interface
variously called coreferent complement subject deletion (Postal 1970), Equi
NP deletion, or obligatory control in the transformational literature. Here
RHO is a semantic long-distance reflexive, a kind of automodular version of
the derivational theory’s PRO. But there is an important difference between
RHO and PRO: PRO is a syntactic item with reflexive semantics, while RHO
is a semantic reflexive with no correspondent in syntax at all. In particular, it
is not an NP, as I argued already in Sadock (1994, 2003a), an idea that was
also proposed by Culicover and Jackendoff (2006).
The fuller F/A form of Frieda claimed to be Napoleon is (60a) and its syn-
tactic structure is (60b), where the complement of claim is just what it appears
to be, namely a VP, since there is no NP correspondent to RHO in the syntactic
representation.
The condition on the antecedence of RHO might be stated as (61), which will
have to be revised, but will do for the time being.
(61)	 Reference of RHO (provisional)
	
RHO has the same reference as the nearest c-commanding argument in F/A
structure.
The condition in (61) is stated in terms of the semantic F/A structure,
since at this point in the development of the framework, arguments (and
(60) a. Prop
Arg Fa
FRIEDA Fpa Prop
CLAIM Arg Fa
RHO NAPOLEON
b. S
NP VP[to]
Frieda V VP
claimed to VP
be Napoleon
Functors belonging to the category Fpa  49
indeed RHO itself) only appear in that level of representation, a sensible
approach in view of the fact that reference is, by its very nature, a semantic
notion. In the next chapter, however, certain coreference requirements will
be attributed to the cognitive level of role structure in recognition of the fact
that it is the truth-conditional meaning, that is, the entailments of certain
predicates, not just their semantic combinatoric properties, that plays a role
in determining the reference of RHO. The statement in (61), however, does
cover a great majority of standard cases and can, I think, be taken as the
default case.
The analysis also extends to members of the category Fpa comprised of
verbs such as try and attempt that allow only VP complements and are never
found with clausal complements (*Fran attempted that she/Ricky scored a
touchdown). If such verbs are described in such a way as to escape the redun-
dancy rule (48), a mechanism for which is suggested in Chapter 3, section 3
below, their only allowable complements will be VPs, and RHO will always
appear as the semantic subject of the proposition they operate on semantically,
since RHO is the only element that can satisfy the semantic requirement for a
referential argument in F/A structure without being represented in the syntax.
As such, its appearance in semantic structure would parallel the appearance
of pleonastic it in the syntax without the need for insertion or deletion and
without the assumption that the complement of these verbs is a clause with
an abstract NP subject. The assumption that RHO has a semantic value is
motivated by the fact that we understand there to be a propositional argument
with a semantic subject in the meaning of expressions containing RHO. But
there is no clearly syntactic motivation that I am aware of for the existence of
an abstract NP in syntax.
2.7.2	 Cyclic interactions
In many cases the effects of the cycle that were automatically accounted
for in the case of Raising-to-Subject predicates now extend both to nested
occurrences of control predicates as well as examples of Raising and con-
trol predicates combined. Consider examples with nested subject control
verbs like They claimed to have tried to escape. The syntactic and F/A
structures of this example are (62a) and (62b), with some details sup-
pressed for clarity:
50  The interface
There are three arguments in (62b) but only one NP in (62a). Conservation
of C-command requires that the NP be associated with Arg1 or else the NP
will c-command claim, but its correspondent will not c-command CLAIM.
That leaves Arg2 and Arg3 without anything to be associated with in syntax and
therefore both must be RHO, the only semantic argument with no representation
in syntax. (61) specifies that RHO shares reference with the first c-commanding
Arg in the F/A structure. Therefore Arg3 has the same reference as Arg2 and
Arg2 has the same reference as Arg1, which is associated with the only NP in
the syntax, so all three arguments corefer, accurately modeling the meaning.
Next, consider the possibility of a control predicate in the complement of a
Raising predicate.
(63) 	 They seem to have tried to escape.
The syntactic structure of this example is exactly the same as that for NP
claimed to have tried to VP, but the F/A structure is different, namely (65):
(64) S
NP
they
VP
V
seem
VP[to]
V
to try
VP[to]
to escape
(62) a. S
NP
they
VP[to]
V
claim
VP[to]
V
to try
VP
to escape
b. Prop
Arg1
THEY
Fa
Fpa
CLAIM
Prop
Arg2 Fa
Fpa
TRY
Prop
Arg3 Fa
Functors belonging to the category Fpa  51
Here there are two arguments in F/A structure but there is once again only one
in syntactic structure. The association of the NP with Arg1 fails to conserve
c-command since the NP commands the verb seem while its F/A avatar does
not c-command SEEM, but associating the NP with Arg2 is even worse since
there would then be two c-command reversals between the two representa-
tions. So Arg2 must be RHO and the NP must be associated with Arg1, which
is then the referential antecedent for RHO, again as desired.
In both of these cases, then, cycle-like effects are obtained without having
to assume movement or any attendant external cyclic principle. The apparent
cyclicity is implied by the phrase structure rules for syntactic and F/A structure
and the interface principles favoring harmonic association of lexical content in
the two modules that have been introduced to this point.
Consider next examples like (66) with a raising-type verb in the complement
of a control verb.
(66)	 Dick tried to seem to be a friendly person.
Many speakers reject this example but many accept it as well. For those who
accept examples like (66) seem takes on a new meaning, an agentive sense
meaning roughly “do something so as to make it seem; pretend to.” The prob-
lem is that even for such speakers that meaning is unavailable in simpler
examples like Dick seemed to be a friendly person. Rather than assume an
otherwise unattested meaning, I suggest that the communicated proposition,
for those who accept (66), is coerced in the sense of Pustejovsky (1996), which
explains why the apparent meaning is found only in examples like (66) where
it is required for coherence. Some support for this idea comes from the fact
that in examples where the coerced meaning is nonsensical, such as *Dick
tried to happen to be a friendly person, the examples remain unacceptable. The
coerced meaning of seem is a transitive operator, an Fpa. I leave it to the reader
to sketch the implied semantic structure and see that the example is accounted
for without further assumptions.
(65) Prop
Fp
SEEM
Prop
Arg1
THEY
Prop
Fpa
TRY
Prop
Arg2
RHO
Fa
ESCAPE
52  The interface
2.7.3	 Raising-to-object verbs
A number of verbs that otherwise occur with clausal complements and/or VP
complements can occur with both an NP and a VP, as in Nobody believes those
politicians to be trustworthy. Such predicates are necessarily verbs in English,
including those listed in (69) (below), because nouns and adjectives are never
subcategorized for an NP object. The items in (69) were treated as trigger-
ing the raising of the complement subject to their own object position (Postal
1974) or as assigning case in an exceptional way across a clause boundary
(Chomsky 1981). Here they will be handled just by assigning to them their
obvious syntactic and independent F/A structure combinatorics.
As for the syntax of such verbs, it is once again clear to everybody, despite
twenty years of consistent denial, that in such examples as Nobody believes those
politicians to be trustworthy, the NP following the verb is the verb’s syntactic
direct object and does not form a syntactic constituent with the following VP. The
NP is objective in case, it passivizes, and the supposed complement clause that
was postulated in the Government and Binding literature cannot be a clause-initial
focus or the focus of a pseudo-cleft: *Those politicians to be trustworthy, I firmly
believe; *What I believe is those politicians to be trustworthy. I therefore take it as
established that such verbs occur in syntactic structures along the lines of (67):
At the same time, clauses containing verbs such as believe and expect in (69)
are understood in much the same way as sentences with clausal complements,
a matter of semantic structure. While NP2 is the object of V, it is not a semantic
argument of the matrix verb but rather is understood only as the semantic sub-
ject of the proposition that corresponds to VP2. In other words, the F/A struc-
ture into which such verbs fit is as indicated in (68). Consequently, their lexical
specifications in syntax and F/A structure will take the form shown in (69).
(67) S
NP1 VP1
V NP2 VP2
(68) Prop
Arg1 Fa
Fpa Prop
Arg2 Fa
Functors belonging to the category Fpa  53
(69)	 believe, expect, find, suppose, think, presume, assume, consider, understand
	 syntax: V in [__, NP, VP[to]]
	 F/A: Fpa
The interface principles in (6), (7), and (24) dictate that Arg1 in (68) should
correspond to NP1 in (67). The argument of the subordinate proposition, Arg2,
then has to be associated with NP2 and that is basically all there is to it. The
effect of Raising-to-Object is thus reinterpreted as a simple mismatch between
syntax and F/A structure without movement and without the highly question-
able and now largely abandoned notion that verbs such as believe “excep-
tionally” assign case across a clause boundary into the subject position of a
subordinate clause, and without the heavy-handed assumption of a raising-to-
object transformation of the earlier theories.
2.7.4	 Hope for NP to VP; yearn for NP to VP
Certain of the verbs listed in (49)–(53), and several others as well, occur with
the preposition for (meaningless in this context) after the verb, followed by
NP and VP[to]. There are two subtypes, depending on the syntactic constitu-
ent structure of the string that follows the verb, as shown by their differential
behavior in pseudo-clefts:
(70)	 a.	 hope, want, desire	 b.	 yearn (for), wait (for)
		 What I want is for NP to VP		 *What I yearn is for NP to VP
		 *What I want for is NP to VP		 What I yearn for is NP to VP
What this shows is that (for NP to VP) is a constituent with the predicates in
(70a) but not (70b) and that there is a constituent (NP to VP) in (70b), but not
in (70a). (73b) and (73c) are arrangements that would conform to these two
conclusions, appropriate lexical representations for which are given in (71) and
(72), which anticipate the morphological component that will be described in
Chapter 5.23, 24
(71)	 expect, hope, look, want
	 syntax: V in [ __ S′ [for-to]]
	 F/A: Fpa
(72)	 yearn, wait, long, hanker
	 syntax: V in [ __ [for, (S′ [to])]]
	 F/A: Fpa
	 Morphology: [yearn] [for]
54  The interface
Despite their differing syntax, both the classes (71) and (72) belong to the
same semantic category, Fpa, and fit into F/A structures like (73a). The same
considerations as have been discussed above dictate that NP2 in either
(73b) or (73c) will be associated with Arg2, the subject of the subordinate
proposition.
2.7.5	 Object-controlled Equi verbs
A number of verbs of facilitation including persuade, permit, perceive, and
help also take NP, VP[to] complements but differ from the raising-to-object
class in an important, much studied semantic fashion. With this class, the ref-
erent of the NP complement of the verb is both the semantic subject of the
subordinate proposition and a semantic object of the meaning of the verb of
facilitation. While the syntax of such verbs is the same as that in (69) for the
believe class, the F/A structure is (74). Since there are more arguments in F/A
structure than there are NPs in the syntactic form, the subject of the lowest
proposition must be RHO for the F/A structure to be complete. The demon-
stration of this is just the same as what we saw for subject-controlled Equi in
section 2.7.1 above. The F/A category of the verb is Fpaa, giving these verbs
lexical entries like (75).
(73) a. Prop
Arg1 Fa
Fpa Prop
Arg2 Fa
b. S
NP1 VP
V
want
S′[for-to]
Comp[for] S[to]
NP2 VP[to]
S
c.
NP1 VP
V
yearn for
S[to]
NP2 VP[to]
Functors belonging to the category Fpa  55
(75)	 influence
	 syntax: V in [__, NP, VP[to]]
	 F/A: Fpaa
Included in the class of items that have lexical entries like (75) are a few seman-
tic subtypes:
(76)	 a.	 Verbs of influence: persuade, influence, cajole, exhort, convince, force,
		 tell, ask, order, get, command, require, entice, compel, instruct,
		 enjoin, teach, train, direct, urge, beg, beseech, lead, sentence, estimate
	 b.	 Verbs of permission: permit, allow, authorize, forbid
	 c.	 Verbs of perception: perceive, observe, hear
	 d.	Verbs of assistance: help, assist 
25
Given the meaning of sentences with verbs in (76) and lexical entries like those
shown for influence in (75), it is clear that RHO must fill the position of Arg3,
else it would be coreferent with the referent of the subject of the sentence
rather than the object. At this point it is not clear why this is the only correct
assignment according to the various interface association principles that have
been introduced. In the next chapter, though, a more complex view of the ref-
erence of RHO will be introduced that forces RHO to be found where it is in
(74b).
Not every verb of the semantic types above belongs to the lexical class
described by the combination of syntactic and F/A fields in (75). Make, for
example, is a verb of influence, but it is unusual in taking an NP and a base-
form VP that lacks the introductory to, whereas its near synonyms in (76a) all
take infinitive phrase complements headed by to.
(74) a. S
NP1 VP1
V
influence
NP2 VP[to]2
b. Prop1
Arg1 Fa1 [=VP1]
Faa Arg2
Fpaa
INFLUENCE
Prop2
Arg3
RHO
Fa2
56  The interface
(77)	 make
	 syntax: V in [ __, NP, VP[INFIN26
]]
	 F/A: Fpaa
Many verbs of perception fall into the same lexical class as make and also
regularly allow a gerundive complement as an alternative to a base-form com-
plement: We saw it move/moving. Some of the perception verbs, such as those
in (78), are arguably also raising-to-object verbs of the semantic class Fpa, as in
I heard the shit hit the fan, but I will not pursue that idea further here.
(78)	 see, notice, witness, watch, hear, overhear, feel, glimpse
There are other small classes, some with only one member:
(79)	 Miscellaneous predicates of the F/A category Fpaa
	 a.  make out
		 syntax: V in [ __, NP out VP[to]]
	 b.	 listen
		 syntax:	 a.	 V in [ __, PP[to], VP[INFIN]]
			 b.	 V in [ __, PP[to], VP[PRS-P]]
Aware does not, of course, allow a plain NP object in syntax because it is an
adjective, which in English never has such complements. Likewise, any nomi-
nalizations of verbs in these lists will require a prepositional phrase in the place
of the verb’s object, and if none is specified in the lexical entry itself, it will,
as before, have to be functional of, (22) above. It also seems to be a regularity
that the nominalizations only allow gerundive complements even if the verb
allows base-form VPs, e.g., see it move/moving but sight of it *move/moving.
This seems to be a thoroughgoing generalization, but in any case, nominaliza-
tion is not a regular process in English and it might therefore be more honest
just to list those nominalizations that occur along with their lexical values in
each dimension as in (80).
(80)	 sight
	 syntax: N in [ __ PP[of] VP[PRS-P]]
	 F/A: Fpaa
If the only complement type a verb of the F/A class Fpaa allows is NP, VP, then
it is almost always a verb of “obligatory control”; the coreference of the cor-
respondent of the syntactic object with the semantic subject of the complement
proposition is an entailment that follows from (61), but see also Chapter 3,
section 3.3. Many of the verbs listed in (76) allow an NP plus a clausal com-
plement, and in this case they are also semantically Fpaa and therefore combine
with propositions whose subject has independent reference (e.g., We persuaded
them that ducks can’t fly.) Such verbs will have two lexical entries, one for
Properties of Raising versus Equi predicates  57
each of the complement types that they can be found with. It is often the case
that such verbs are palpably ambiguous, which bolsters the lexical analysis
and weakens any derivational analysis. The two verbs persuade, for example,
mean something like “cause NP to intend to VP” and “cause NP to believe
that S.” Often, however, the difference between the two syntactic frames is
subtle. There are near paraphrases such as The dean persuaded me to take the
job and The dean persuaded me that I should take the job. The modal is obvi-
ously crucial to the synonymy, suggesting a modal analysis of certain infinitive
constructions, as has been discussed extensively in the literature. (See Rajesh
Bhatt 1999 and the references there.)
2.8	 Properties of Raising versus Equi predicates
Many of the classically observed differences in behavior between Raising and
Equi predicates follow in a formal, yet intuitively natural way without stipu-
lation in a multi-modular framework.27
Lexical items such as try to VP and
convince NP to VP have RHO as the semantic subject of the subordinate prop-
osition, and predicates such as seem to VP and believe NP to VP have ordinary
referential arguments in the subordinate proposition and display a mismatch
with respect to the position of the syntactic and semantic subjects of that prop-
osition. Those functors that demand a RHO argument in their complement
place two semantic restrictions on the referent of RHO, one from the matrix
proposition in which the antecedent is an argument, and one from the embed-
ded proposition in which RHO is the subject. Those functors for which the NP
is merely displaced with respect to its syntactic position and the position of the
corresponding argument in F/A structure impose semantic requirements on an
argument that come only from the embedded proposition. The varying gram-
matical properties of these two types follow from the separation of syntactic
combinatorics and semantic combinatorics.
Consider the old observation that examples with passive infinitive VPs and
corresponding active VPs are roughly synonymous for the displacement class,
as shown in (81) and (82), but have distinct truth conditions for the RHO-
selecting class, as we see in (83) and (84):
(81)	 a.	 The doctor seems to have examined the patient.
	 b.	 The patient seems to have been examined by the doctor.
(82)	 a.	 They believed the doctor to have examined the patient.
	 b.	 They believed the patient to have been examined by the doctor.
(83)	 a.	 The doctor tried to examine the patient.
	 b.	 The patient tried to be examined by the doctor.
58  The interface
(84)	 a.	 They persuaded the doctor to examine the patient.
	 b.	 They persuaded the patient to be examined by the doctor.
Since passive propositions are roughly synonymous with active propositions (a
treatment will be offered in Chapter 3) the pairs (81a,b) and (82a,b) will also
be roughly synonymous, since the only semantic function of the argument that
is mismatched is in the lower proposition. But since in the active pairs (83a)
and (84a), the doctor is also the semantic subject of TRY (i.e., the one doing
the trying) and the semantic object of PERSUADE (the one who is persuaded),
the pairs have different truth conditions. Whereas the patient is the semantic
subject of TRY in (83b), in (84a) the doctor is the one persuaded, and in (84b)
it is the patient.
Next, consider the quantifier scope possibilities of the argument-displacing
forms versus the RHO-selecting forms:
(85)	 a.	 Three elephants seem to have escaped.
	 b.	 I believe three elephants to have escaped.
(86)	 a.	 Three elephants attempted to escape.
	 b.	 I trained three elephants to escape.
Quantifiers, which will be taken up in the next section, must originate above
the proposition containing the highest occurrence of the variables that they
bind (McCawley 1988). Therefore in (87), which is part of the F/A structure of
(85a), the quantifier could be above Prop2 or Prop1 and still bind the variable
(x), but in (88), which corresponds to (85b), the quantifier can only bind the
variable if it occurs above Prop1.
(87) Prop1
Fp
SEEM
Prop2
Arg
(x)
Fa
(88) Prop1
Arg1
(x)
Fa
Prop2 Fpa
ATTEMPT
Arg2
RHO
Fa
Properties of Raising versus Equi predicates  59
In (87) the quantifier can appear either above Prop2 or Prop1, since the only
occurrence of the variable is in Prop2. Therefore a sentence such as Three
elephants seem to have escaped is ambiguous between a non-specific reading
“It seems that there were three elephants that escaped” and a specific reading
“There are three elephants that seem to have escaped.” In (88), on the other
hand, the quantifier must bind the highest variable (with which RHO will be
coreferent) and so must occur above Prop1, giving only a specific reading
“There are three elephants that attempted to escape.”
As a last example of the difference in behavior between displacement and
RHO-selecting predicates, let us take up the well-known fact that the former,
but not the latter can involve “funny NPs” such as idiom chunks and existen-
tial there. Consider the difference between (89a), which can have an idiomatic
reading, and (89b), which cannot, sentences that must have representations in
the F/A dimension along the lines of (87) and (88), respectively. The meaning
of all hell would then have to be the semantic subject of ATTEMPT, which it
can’t be, because whatever else it is, all hell is not a possible agent, which the
subject of ATTEMPT must be.
As Stephen Wechsler (p.c.) pointed out to me, it is not immediately clear
how the distinction between F/A structure and syntactic form could account for
the fact that the proverbial pandemonium encoded as all hell can be displaced,
or, in old-fashioned terminology, “raised.”
(89)	 a.	 All hell seems to have broken loose.
	 b.	 *All hell attempted to break loose.
We could analyze idioms the way Nunberg et al. (1994) did. What they
proposed is that some idioms, which they call “idiomatically combining
expressions” are fully or partially compositional, but the lexical items they
contain have meanings that are restricted to their occurrence within the idiom.
They provide clear and convincing arguments that these facts do not argue for
the necessity of transformations and further arguments to the effect that “the
dependency among the parts of idiomatically combining expressions is thus
fundamentally semantic in nature” (Nunberg et al. 1994, 505).
Their account is not formal, but the idea of it can easily be formalized in the
present view of things. (90) and (91) provide the lexical entries for the syntac-
tically and F/A structurally compositional pieces of the idiom all hell break
loose, and their environments in the F/A component require that the F/A pieces
need to be together in the combinatoric semantic structure.
(90)	 all hell (“pandemonium”)
	 syntax: NP
	 F/A: Arg in [Prop __, (BREAK LOOSE)]
60  The interface
(91)	 break loose (“arise suddenly”)
	 syntax: VP
	 F/A: Fa in [Prop [Arg ALL HELL], __ ]
Their syntactic congeners, [NP all hell] and [VP break loose], however, are not
required to comprise a constituent in syntactic structure, so displacement of the
raising-to-subject type, that is to say, the pairing of the trees in (92), is perfectly
allowable.
In the control cases, however, the pieces would not occur together as a sin-
gle semantic unit, and for this reason (as well as others), such idioms will be
incompatible with control predicates.
These accounts, it will be noticed, function in something like the same intui-
tive way that the explanation of these facts did in the old-fashioned Raising and
Equi analyses, but without movement or deletion and all of the grammatical
technology that movement requires. In the modern context, questions arise as
to the position to which verbs move (to C, Spec of CP, recursive CP, or Infl, and
if so whether Infl is exploded, and if so into what pieces it fragments), as well
as questions concerning what requires movement, for example, the “strength”
of inflection, and how strong versus weak inflection is to be determined, or
perhaps EPP features, and so on.28
Such questions simply don’t come up in the
present view of things – because there is no movement.
2.9	 Quantification
Since quantificational phenomena provide some of the best evidence for F/A
structure, an outline of how this important semantic subsystem can be incorpo-
rated is called for. I will have little new to offer in the way of analysis and will
rely instead on what others have contributed in formal semantics and general-
ized quantifier theory, ideas that can be easily imported into the autonomous
F/A component, a grammar of semantic structure. The ideas that McCawley
(1981) and other logically minded linguists developed starting in the 1960s
will form the basis of my sketch.
(92) S Prop
NP
all hell
VP Fp
SEEM
Prop
V
seem
VP
break loose
Arg
ALL HELL
Fa
BREAK LOOSE
Quantification  61
First of all, it is necessary to assume that there are variable arguments (x, y, etc.)
in the F/A component29
and that these variables must be bound in any fully speci-
fied proposition. The binding of a variable is done by a quantifier phrase that turns
an unsaturated proposition into a proposition that is one degree more saturated.
The following rule for the binding of a variable will therefore be added to the F/A
component. A quantifier phrase (QP[x]) applies to a proposition Prop[…x…],
where “[x]” is a semantic feature that is inherited up the semantic tree from any
daughter category that bears it.30
When an F/A expression bearing such a feature
is combined with a quantifier phrase that has the same feature, the phrase’s vari-
able feature is eliminated in much the same way as “slash features” are eliminated
in the syntax in GPSG (Gazdar et al. 1985) and HPSG (Pollard and Sag 1994).
Quantifiers are logical functions that have open propositions as arguments and
return quantifier phrases.
The word every is a quantifier with the lexical entry (95a) allowing it to
occur in F/A trees such as (95b), the F/A representation of Every linguist
doodles.
a. Prop[…] → QP[x], Prop[…x…]
(93)
b. Prop
QP[x] Prop[x]
a. QP[x] → Q, Prop[x]
(94)
b. QP[x]
Q Prop[x]
(95) a. every
syntax: Det in [NP __ N�[SING]]
F/A: Q
b. Prop
QP[x] Prop[x]
Q
EVERY
Prop[x] Arg[x] Fa
DOODLE
x
Arg[x] Fa
LINGUIST
x
62  The interface
This system allows for the successive binding of different variables and will
automatically account for the quantifier scope ambiguity found in sentences
such as Every student admires two professors. (96) represents the structure of
one of these understandings:
In (96) the existential quantifier “TWO” that expresses the F/A value of the
numeral has scope over the universal quantifier expressed by the word EVERY
and therefore (96) is the F/A structure of the “specific” reading of the sentence,
roughly “There are two professors such that every student admires them.” A
tree with QP[y] and QP[x] exchanged would also be well formed, giving the
reading “Every student is such that for him/her there are two professors that
he/she admires.”
Note that this method of accounting for quantifier scope ambiguity con-
trasts sharply with traditional movement-based grammatical methods such
as quantifier lowering in the fashion of generative semantics, quantifier rais-
ing in the GB, P&P, and Minimalist literature, or Cooper storage (Cooper
1983) in a system that derives syntactic and semantic representations in
tandem rather than in parallel. Here two or more independent semantic rep-
resentations that differ in the scoping of the quantifiers are generated quite
independently of the syntactic phrase structure. Whether two or more scope
relations in F/A structure can be matched with a single syntactic structure
is influenced by interface principles that will be discussed in more detail in
Chapter 7.
Notice that the category of a noun in function-argument structure can remain
as it was in the earlier discussion. A noun like dog will be a function of one
(96) Prop
QP[y]
Q
TWO
Prop[y]
Fa
PROFESSOR Arg[y] Prop[y]
y
QP[x] Prop[x,y]
Q
EVERY
Prop[x] Arg Fa[y]
x
Arg[x] Fa
STUDENT
Faa
ADMIRE
Arg
x y
Existential there  63
variable – an Fa, and a noun like bride will be a function of two variables – an
Faa. In a sentence like Every dog barks, DOG will have to be the predicate of
the quantifier phrase if c-command relations between F/A structure and syntax
are to be preserved.
2.10	 Existential there
So-called There-insertion is a complex matter subject to highly variable judg-
ments, but the central facts can be handled by means of lexical specifications
that indicate the function of lexical items in the autonomous dimensions of
representation, in particular, syntax and F/A structure. Existential there can be
found with a variety of verbs (Lakoff 1984), all having something to do with
existence, but here I will only deal with a single verb, the verb be, the only verb
that the construction colloquially occurs with in my speech. Even the best of
the other uses that are mentioned in the literature, e.g., there exist … or there
appeared … are restricted to particular genres, for example, discussions of logic
or recitations of fairy tales. For these other speech levels, a lexical rule like that
required by the passive, which will be presented in Chapter 3, might be invoked.
For my day-to-day dialect, however, a special lexical entry for be is all that is
needed.
In formulating this lexical entry it will be necessary to consider be in much
more detail than was done in connection with (11) above. That rule only
provided for a semantically empty use with a noun-phrase complement, but
be occurs with a variety of phrasal complements – adjective phrases, prep-
ositional phrases, verb phrases, and idiomatically with certain particles like
back, away and through. When be has an adjective phrase or prepositional
phrase complement, it can easily be treated as being meaningless, its pres-
ence necessitated by the requirement in English that verb phrases be just
that: phrases headed by verbs. There are two uses of be with participial verb
phrase complements. When the head verb is in the present participial mor-
phological form we often speak of “progressive be,” and with the past par-
ticiple we speak of “passive be.” This usage suggests that the progressive
sense and the passive sense are carried by be, making it (at least) three ways
ambiguous. In Chapter 3 the passive will be treated in such a way as to make
the passive participle the bearer of the passive meaning and argument struc-
ture, so that use of be can also be taken to instantiate the semantically empty
verb. The same thing can be done with the progressive, treating the participle
as the bearer of the progressive operator in the same way as the past-tense
inflection will be handled in Chapter 5 (38)–(40). Then all of these uses can
64  The interface
be subsumed under the same lexical entry, the expanded version of which
would be (97):
(97)	 be
	 syntax: V in [VP__, XP]
	 F/A: id in [Fa
__, Fa] 31
The F/A field here indicates that the word is an identity function from predi-
cates to the identical predicate. In the syntax, however, the category of the
complement is an unspecified maximal projection and therefore it may be used
with any phrasal syntactic category whose F/A counterpart is a semantic predi-
cate. For this reason as well, various syntactic categories may be conjoined in
the complement of be, as pointed out in Sag et al. (1985). Examples like My
paper is in your mailbox and ready to be copied are good because both con-
juncts are syntactic XPs, the category of the complement specified in (97), and
both are matched with F/A structure predicates.
When it occurs in the existential construction, be takes an NP comple-
ment in addition to the XP that is given in (97). There is one syntactic
phrase type that cannot occur as XP in the existential construction, how-
ever, namely NPs, even if they are predicative in the F/A structure.32
From a
semantic point of view, it should be fine to say There were some provisions
bargains meaning “Some provisions were bargains,” but we can’t, and I
assume that is due to a syntactic restriction on the complement of existential
be. In its existential use, be is a semantic identity function from propositions
to propositions.
Existential be will therefore have the lexical content provided by (98a) and
enter into syntactic and F/A structure trees as in (98b), where the dotted lines
indicate the associations that are most in keeping with the categorial and geo-
metrical correspondence principles that were introduced in sections 2.2 and
2.4 above:
(98) a. be (existential)
syntax: V in [VP __ , NP, XP] where XP is not NP
F/A: id in [Fa __, Fa]
S
b.
NP VP Prop
be NP XP Fa Prop
BE
Arg Fa
Existential there  65
English requires subjects in clauses, and subcategorized NPs cannot be dis-
placed the way unsubcategorized subjects can, so there is an unassociated NP
in (98b), but since there is no room for an additional argument in the F/A struc-
ture, the subject NP must not have any semantic value. There is such an NP, of
course, the empty it whose lexical entry is formalized in (20) above, and there
are varieties of English in which pleonastic it is the subject of existential sen-
tences, as has been frequently remarked in the literature on African American
Vernacular English (e.g., Rickford 1999). German has two different existential
constructions and both have pleonastic es as subject. But in Standard English,
only there can occupy the syntactic subject position in existential clauses.
Now the semantic subject of the proposition in the existential construction
must be indefinite, a property that can be attributed to an existential quantifier
in function-argument structure. The fact that this is a quantificational restriction
rather than a syntactic or morphological one is well known. Ordinarily syntac-
tic NPs formed with the definite article or with demonstratives are semantically
definite, but there are certain constructions in which they have an indefinite
sense and in that sense they participate in the existential construction; There
were the usual people at the party (i.e., people whom one might expect to find),
or There’s this funny-looking guy at the door (i.e., some funny-looking guy to
whom I now shift the topic). This suggests a way of restricting the subject of
the existential construction to there, namely by identifying it with the existen-
tial quantifier. The lexical entry (99) would then find its way into syntactic and
F/A trees as in (100).33
(99)	 there (existential)
	 syntax: NP in [ __ … [be … ]]34
	 F/A: [Q ∃]
Since according to (99) the NP there is not a semantic argument, it can
count as a syntactic subject without introducing an additional argument in
F/A structure that has no structural position to occupy in that dimension. It
(100) S Prop
QP
NP VP Prop[x]
there Q[x] Prop
be NP XP Fa
∃ x BE Prop
Arg
x Fa
66  The interface
does not matter, then, where the extra NP position is in the syntactic expres-
sion and it can therefore be matched with the “raised” subject of a verb like
seem, or the “raised” object in the case of a verb like believe (NP to VP).
The accounts extends to apparently cyclic phenomena found in examples like
There is believed to be a mouse in the house, phenomena which will be further
adumbrated in the discussion of the passive of verbs like believe surrounding
example (18) in Chapter 3.
2.11	 Reflexive and non-reflexive pronouns
Pronouns are lexemes with form and content and therefore, in a theory without
rules that alter one form to produce another, they are distributed in the same
way as any other lexemes: they have distinct properties in various autonomous
components and these properties must be simultaneously satisfied in each
module in order for the expressions in which they are found to be completely
well formed. The definite pronouns include reflexives, possessives, and non-
reflexives. As to syntax, the reflexive pronouns of English are NPs in the non-
subjective case, like me, her, him, us, and them. The details of the distribution
of these case forms in English are complex matters that go beyond grammat-
ical description per se, and will therefore not be taken up in great detail here.
Suffice it to say that reflexive pronouns are syntactically excluded from any
positions where subjective (nominative) case pronouns are required.35
As to the semantics, pronouns ordinarily count as arguments, though the
possessives can also be restrictors of quantifiers or predicates.36
Sample lexical
entries are provided in (101)–(104).
(101)	 themselves
	 syntax: NP[OBJ, 3pl]
	 F/A: Arg [+PRON, +REFL]
(102)	 them
	 syntax: NP[OBJ, 3pl]
	 F/A: Arg [+PRON, −REFL]
(103)	 myself
	 syntax: NP[OBJ, 1sg]
	 F/A: Arg [+PRON, +REFL]
(104)	 I
	 syntax: NP[SBJ, 1sg]
	 F/A: Arg [+PRON, –REFL]
Note that these entries do not distinguish them and themselves in the syntax.
The features [PRON] and [REFL] will be formally introduced in Chapter 6,
Derivational and automodular approaches compared  67
section 6.3.1 where their functional role as anaphoric devices will be clarified.
Here it will be sufficient to point out that pronouns have no independent refer-
ential power but borrow reference from some antecedent. The conditions under
which they find their antecedents serve to further differentiate pronouns, and
that is why the traditionally named features distinguishing the reflexive and
non-reflexive pronouns are found only in their F/A specifications.37
2.12	 Deep similarities between derivational
and automodular approaches
Though it may not be obvious because of the great architectural difference
between the multi-modular and derivational perspectives, the two views in fact
agree at a deep level on a number of important points. Some of the principles
that are the source of what linguists are fond of calling explanations are quite
similar in the two frameworks, even if they are stated in very different terms. In
transformational grammar, these explanatory postulates are put very abstractly,
but they tend to have definitions that make more intuitive sense in the frame-
work presented here. For instance, both Theta Theory and Case Theory, con-
structs that do a great deal of work in mainstream syntax, have direct analogues
in autolexical terms, but unlike the movement theory, they require little in the
way of independent stipulation outside of the basic architecture of the system,
as I will explain immediately below. Numerous other arcane-seeming concepts
in mainstream generative grammar also have much more realistic and more
easily graspable, formalizable, and falsifiable counterparts in automodular
grammar.
2.12.1	 Theta Criterion
The Theta Criterion states that each referential noun phrase must be assigned
one and only one Theta Role and that each Theta Role that is assigned by a
Theta Role assigner must be assigned to one and only one referential noun
phrase. It should be obvious that Theta Roles (“agent,” “patient,” and various
ancillary roles) are contentful semantic notions. They will be taken up in more
detail in the next chapter, but for now it is enough to note that such participant
characteristics are usually associated with arguments in the function-argument
representation, which were described in this chapter.
For purely structural reasons, an argument in a well-formed functional
structure must occur in an argument position and every argument position in
a well-formed functional structure must be filled. That is simply the definition
of well-formedness in the F/A component, since F/A structure has its own
68  The interface
grammar in which functors and predicates must combine with exactly the right
number of arguments and all arguments must be arguments of some argument-
taking functor. Any putative F/A structure in which there are too many or too
few arguments for the semantic type of the functors it contains will either not
be generated, or not be a proposition.
What it means for something to be an argument in F/A structure is that it is
a referring expression. Since arguments in the present framework correspond
on the one hand to noun phrases in the syntax, as set forth in this chapter,
and on the other hand to proto-roles in role structure, as will be explained in
Chapter 3, the Theta Criterion follows just from the nature of the F/A level
that is built into the architecture of the grammar that is employed here, and
from the correspondences between elements of that level in the independent
levels of syntactic phrase structure and cognitive role structure. An example
like *The class seems that the teacher sneezed, while syntactically grammat-
ical (compare It seems that the teacher sneezed) contains two referential NPs
whose meanings must find a place in F/A structure. But there is only one func-
tion that applies to entity arguments in the meaning representation, namely
SNEEZE, so the expression is not ungrammatical; it is unsemantical, so to
speak. The opposite semantic flaw is found in *There seemed to appear (cf. A
cloud seemed to appear); here there are no NPs with referential semantics but
there is one functor, APPEAR, that requires such an argument, so this form is
likewise unsemantical.
2.12.2	 Case Filter
Let us next take up the Case Filter, the requirement that every pronounced noun
phrase be assigned Case. This principle, it turns out, is also a consequence of
the architecture of grammar assumed here, this time a reflex of the nature of the
syntactic phrase structure grammar.
Although the Case Filter as stated in GB terms is abstract, involving a notion
of Case that is quite distinct from the morphosyntactic notion of case, its effect-
iveness stems from its ability to assure that the actual noun phrases that are
found in the syntax of an expression have appropriate syntactic roles to play
as subjects of clauses, or as objects of verbs that take objects, or as objects of
prepositions. In automodular terms, the Case Filter is the syntactic counterpart
of the Theta Criterion and as such, it follows directly from the adoption of a
phrase structure grammar of syntactic constituency such as is assumed here.
According to the rules in Chapter 1 (14), noun phrases only get into syntax as
subjects of clauses, as complements of transitive verbs, or as objects of prepo-
sitions. All grammatical occurrences of noun phrases are in essence sanctioned
Derivational and automodular approaches compared  69
in the same fashion that they are “assigned Case,” but without the need for
any auxiliary principle such as the Case Filter, indeed without the need for
an abstract notion of Case altogether. Furthermore, syntactic well-formedness
requires that the subcategorization requirements of verbs and prepositions be
satisfied and, for English, at any rate, that all clauses have subjects. Therefore
an expression with more or fewer noun phrases than are needed to fulfill these
requirements will be ill formed.
Consider, for example, why the string of words The dog was being devoured
the steak is ungrammatical. On the GB analysis passive verbs “fail to assign
Case” to their objects. The noun phrase in object position therefore does not
get Case and has no place to move to acquire it, so the sentence is ruled out.
On the non-derivational theory, passive participles are intransitive, which is to
say, they do not take objects.38
Therefore a VP headed by the passive participle
devoured and containing an object will not be generable any more than this
VP headed by the intransitive verb disappear would be. Intransitive verbs are
found in the language anyway, whereas the idea that there are transitive verbs
that do not sanction an object is something new. The core facts covered by Case
Theory thus follow directly from the architecture of multi-modular grammar
and do so in a way that is conceptually simple.
2.12.3	 Raising
Let us take up next the phenomena that come under the heading of Raising.
Both classical GB and the automodular views share the desirable property of
not requiring a construction-specific rule that is written in an ad hoc fashion
so as to raise the subject of a subordinate clause to subject position in a higher
clause, as was the case in earlier generative treatments. (See, for example,
Postal 1974.) In classical GB theory, the phenomenon of Raising is seen as
an instance of a completely general rule of movement that happens to apply in
this case in such a way as to effect the structural alteration that the derivational
theory assumes. Just as with passives, the standard GB account takes the move-
ment to be required by considerations of Case. The infinitive complement is
(despite appearances) taken to be a kind of clause, and it so happens that it does
not assign Case to its subject. Therefore it must abandon its birthplace and seek
asylum in a more welcoming clause where it can get Case. In Minimalist work,
as well, Raising results from the interaction of various deeper principles, though
these still seem to be subject to dispute. (See, for example, Lasnik 2003.)
In the present theory there is likewise no special rule of Raising, but there
are lexical items whose specifications in syntax and combinatoric semantics
are such as to produce the structural discrepancy we call Raising. One use
70  The interface
of seem, for example, takes a complement of the form [to VP]. That comple-
ment is just what it appears to be: a VP. It lacks a subject because, well, VPs
are subjectless. At the same time, this use of seem is semantically a modifier
of propositions. Propositions consist of a predicate and an argument. VPs are
by default predicates, and English requires sentences to have subjects, so the
argument of what SEEM modifies gets associated with the syntactic subject of
seem. No inscrutable postulations are needed.
The movement theory assumes that Raising verbs take clausal comple-
ments despite the fact that all we see is an infinitival VP. According to the the-
ory espoused here, VPs do not, by definition, have subjects. They are parts of
clauses, not clauses, and that is why no lexical subject can appear within them.
This is not so much an assumption as a null hypothesis based on appearances.
In the transformational theory verbs like seem do not assign Theta Roles to their
subjects. This is plainly a semantic fact and is handled here at the level of func-
tion-argument semantic structure where SEEM is an operator that takes a prop-
osition as an argument, again a fact that is pretheoretically motivated, involving
no stipulation beyond what is needed to capture the obvious meaning relations.
On the derivational theory the subject of the subordinate clause must move
to a position where Case is assigned (or equivalently, checked) in order to sat-
isfy the Case Filter. Such a position is the subject position of a finite clause.
The necessity for clausal subjects in English has been attributed to yet another
abstract principle with an impressive appellation: the Extended Projection
Principle.
2.12.4	 The Extended Projection Principle (EPP)39
The requirement that is expressed as “S → NP, VP” is stated grandiloquently in
transformational grammar as the EPP – The Extended Projection Principle:
(105)	 The Extended Projection Principle (EPP)
	 IP must have a specifier.
It is no less stipulative, though much farther from observable fact than the
straightforward phrase structure rule. A consequence of the divorce between
the superficiality of the notion and its formal statement in generative grammar
is that it becomes much more susceptible to tampering than what, in automod-
ular terms, I will semi-seriously call the Clausal Subject Principle:
(106)	 Clausal Subject Principle (CSP)
	 Clauses in English require a subject.
But even this is unnecessary given the phrase structure rule that formalizes
it, namely (14a) of Chapter 1.
Derivational and automodular approaches compared  71
2.12.5	 RHO v. PRO
RHO in the present parallel architecture model is the syntactically null, func-
tionally relevant version of PRO in GB and subsequent transformational treat-
ments. Within the GB family of theories, the restrictions on the occurrence of
PRO mainly flow from the principle that PRO is ungoverned, the conclusion
of the famous PRO Theorem of Chomsky (1981, 191). As originally sketched,
this “proof” goes something like as follows:
(107)	 The PRO Theorem
	 a. 
Binding Theory specifies that anaphors are bound in their governing
category.
	 b.	
Binding Theory specifies that pronominals are free in their governing
category.
	 c.	 PRO is a category that is both an anaphor and a pronominal.
	 d.	
Oops! PRO must therefore be both bound and free in its governing
category – a contradiction.
	 e.	 Therefore there is no governing category for PRO.
	 f.	 Therefore PRO is ungoverned.
About this conclusion Haegeman (1991, 253) writes: “The proposition that
PRO is ungoverned is … not a self-evident truth, but it is deduced by a chain
of reasoning on the basis of other accepted propositions.” The problem with
her characterization is that this is not the only conclusion that can follow
from (107a–f). The conclusion that PRO is ungoverned might be suggested
by the reasoning above, but it certainly is not a deduction in the strict and only
defensible sense of the word. All the argument really shows is that at least one
assumption concerning PRO is wrong and I think that the incorrect assumption
is a deeper one, namely that there is, in fact, such a thing as PRO.
The basic distribution of the element RHO is accounted for by the inter-
modular versions of the Theta Criterion and the Case Filter in something like
the same way that the distribution of PRO is accounted for in transformational
theory, but without much of the questionable technical apparatus of that the-
ory. The assumption made here to the effect that RHO is a semantic referential
argument with no syntactic correspondent means that it cannot correspond to
any position in syntactic structure where a noun phrase is required. It will not
be able to correspond to a syntactic subject of any clause, let alone a tensed S,
nor can it be the object of a syntactically transitive verb or a preposition, since
all of those positions’ functions must be fulfilled by a syntactic noun phrase.
But RHO is not a syntactic noun phrase, indeed, not a syntactic anything. RHO
will be a possible semantic subject of a proposition that is represented in syn-
tax only by an infinitive VP (e.g., to retire young), a gerundive (e.g., retiring
72  The interface
young), a secondary predicate (e.g., He retired young), and so forth. These
propositions clearly require semantic subjects but no syntactic subjects. How
do we know this? We know they have semantic subjects because we under-
stand them that way, and we know they do not have syntactic subjects since we
don’t find any. Given that RHO counts as an argument but not a noun phrase,
its distribution in the present theory follows from the structure of the grammar
of surface form, and the structure of the grammar of semantic form.
The point of this chapter has not been just that automodular grammar han-
dles the same facts as the transformational theory deals with, or even that
it does so without unwarranted abstractions, but that it does those things in
something like the same intuitive fashion. Chomsky had a brilliant, transforma-
tive insight: natural languages use two levels of representation, one oriented
toward external form and the other toward cognitive content. Grammatical
descriptions based on this insight were far more elegant and empirically suc-
cessful than were possible in theories with only one level of structure. The
F/A structure in automodular grammar corresponds closely to deep structure
in the classical theory of generative grammar and syntactic phrase structure
is the counterpart of surface structure. From the middle 1960s to the pre-
sent, the dual-structure theory has been implemented in mainstream studies
by rules of deformation that sequentially alter one of these representations
to produce the other. I believe that the fondness for derivationality has been
responsible for the welter of recurrent analyses, the complexity, and the lax
empirical grounding of grammatical theory that have characterized linguistics
for more than forty years. My aim here has been to show that we can imple-
ment the idea of Saussurian form–meaning duality of linguistic expressions
in a non-derivational way with greatly increased elegance, empirical content,
and empirical spread than we find in derivational theories.
73
3	 Role structure
The accounts of grammatical behavior that have emerged to this point rely only
on possible discrepancies between the position and category of parts of expres-
sions in two combinatoric dimensions: syntactic phrase structure and semantic
function-argument structure. The latter, being entirely combinatoric, does not
differentiate among meaningful parts of expressions on the basis of their con-
tent, that is to say, the way the pieces of language connect with the world and
with notions such as truth, entailment, and synonymy. But it seems clear that
the grammars of natural languages are sensitive to certain aspects of cognitive
content and that there are significant generalizations that play out in the realm
of grammar that cannot be captured without reference to at least some aspects
of the actual meaning of expressions.
One particular area where reference to entailments is crucial to the capture of
important grammatical generalizations is what can broadly be termed “voice,”
the system of language that determines the choice of semantic and syntactic
subjects and objects. A moment’s reflection reveals that in events in which a
volitionary act is performed that results in some change in the state or position
of another entity, the actor is almost always the subject of a simple sentence in
English. But English has a productive passive that allows something other than
the default subject to appear in subject position. The phrase structure syntax
of actives differs from that of passives, of course, and furthermore (as I shall
argue) the two differ in F/A structure as well. The system that was outlined in
Chapter 2, then, cannot display their approximate synonymy and must be sup-
plemented so that entailment and other truth-conditional properties of natural
language expressions can be referred to.
In this chapter I introduce a third autonomous module, which I call role
structure, though Event Structure or Cognitive Structure would be appropriate
names as well. I will formulate role structure as a phrase structure grammar
and assume that, all other things being equal, there will be the same pressure
toward harmony with the two levels of analysis that were introduced in the
previous chapters. Both hierarchical and categorial features of role structure
74  Role structure
will tend toward conformity with syntactic and function-argument structure,
and those two levels will tend to harmonize with role structure as well. It is my
contention that it is at the level of cognitive content that actives and passives
are alike. It is also at this level that the entailments involved in determining
proto-roles are available and at which proto-roles can be used to speak about
case-marking strategies and alternations. For example, entailments regarding
responsibility and benefit have been implicated in the phenomena of controller
determination and controller switch and, indeed, the identification of the con-
troller of RHO (or PRO in syntactocentric theory).
3.1	 Case-marking strategies
Consider the fact that there are three common language types with respect to
case marking (Dixon 1994). There is one in which intransitive sentences mark
their sole syntactic term morphosyntactically in the same way as the subject
of a transitive clause, one in which it is marked like the object of a transitive,
and one in which intransitive subjects are sometimes marked like transitive
subjects and sometimes like objects. One of the clearest examples of the last
class, to which Dixon applies the term “fluid case marking,” is Batsbi, or Tsova
Tush, as described by Holisky (1987). In that language there are two nominal
cases that are relevant to the discussion, the ergative, which marks what is usu-
ally called the agent of transitive clauses, and the absolutive, which marks the
patient of a transitive clause. The sole term of certain syntactically intransitive
predicates, such as “be hungry,” “freeze,” and “be afraid” takes only absolutive
marking, while for others, such as “come,” “walk,” and “play,” only the erga-
tive is possible. In a third group, either sort of marking can be found with dif-
ferent degrees of naturalness. This group includes such meanings as “drown,”
“roll,” and “begin.”
The situation could be analyzed in a brute force way just by listing all
the intransitive verbs in the language and giving an indication for each as to
whether it assigns only one of the two cases to its subject or whether it may
assign either. There are several things wrong with such a description, includ-
ing and especially the fact that it misses an important semantic generalization,
namely that the obligatory ergative types all belong intuitively to a certain cog-
nitive class and the obligatory absolutive types belong to another. Predicates
whose sole argument necessarily represents a voluntary actor take only the
ergative, while those for which the absolutive is the only possibility have a
meaning such that their subject is not in control of the action. Furthermore,
for the fluid type, using the ergative case indicates that the action is volitional,
Case-marking strategies  75
while using absolutive marking indicates that the action is uncontrolled. Tsova
Tush would not be the language it is if we placed all of its verbs in a hat and
assigned predicates randomly to one of the three classes in something like
the way gender is assigned to inanimates in, say, French or Nama Hottentot
(Hagman 1977). Clearly, we need to be able to say that a certain aspect of
meaning determines whether an intransitive predicate belongs to the ergative
class, the absolutive class, or the fluid class. Since the F/A level of organization
is merely combinatoric, the important generalization concerning case assign-
ment in Tsova Tush cannot be captured there. Rather, there needs to be some
way of allowing semantic content, the sort of thing upon which judgments of
truth and falsity depend, to enter the picture.
Many kinds of cognitive distinctions seem to play a role in grammar, but
since I find it better to err on the side of caution, I will adopt a highly restrict-
ive system for dealing with conceptual aspects of linguistic organization, one
that will certainly turn out to be too narrowly drawn to allow us to capture
all of the sorts of interpenetrations of grammar and cognitive content that are
actually found in natural languages, but one that will allow us to say something
about some of the most important interactions of this kind. In keeping with the
general plan of automodular grammar, the cognitive organization of natural
languages will be modeled in terms of a simple grammar of iterative categor-
ies. The categories and their combinations will all be distinct from those in any
other component but will be constrained to align to a certain extent with the
other components by the interface principles of Chapter 2. Just as is the case
at the syntax–F/A interface, there also exist standard correlations between the
categories of role structure and the categories of the two components that have
already been introduced, and a general expectation that geometrical properties
at the level of role structure correspond as much as possible to similar proper-
ties in the other autonomous dimensions. Mismatches arise when requirements
of the various modules or particularities of lexical items get in the way of strict
matching.
The predicate elements of natural languages refer to event types, includ-
ing states and activities, in which one or more participants play distinct roles.
I will assume that the grammar of the RS level characterizes expressions in
terms of the event and the cognitive status of the participants in the event. The
idea is an old one, dating back to the work of Gruber (1965), Fillmore (1968),
and Jackendoff (1972). The inclusion here of a dimension of role structure
was stimulated by the use to which such a level is put in Jackendoff’s (1997)
and Culicover and Jackendoff’s (2006) recent work in an autonomous modular
grammatical architecture.
76  Role structure
The events expressed by morphologically simple lexical items in natural
languages do not ordinarily involve more than three, and perhaps never more
than four evoked participants, though the scene they set may involve many
more. The twin bugaboos of most versions of participant role theory have al-
ways been first, the apparently unstoppable tendency for the number of roles
to proliferate from a favorite few, such as agent, patient, and instrument, to
much finer-grained distinctions, and second, the concomitant difficulty of de-
termining the criteria for classifying the arguments of a particular proposition
into one or another of these roles. The common practice of giving these roles
Latinate names has no particular justification, since the roles described by
each predicator are in fact unique. Thus we would eventually need, besides
the more familiar terms, such lexically particular terms as factor, destructor,
victor, ambulator, crepitator, and so on, for the subjects of make, break, win,
walk, fart, and so on.
Dowty (1991) provided a solution to the difficult problem of characteriz-
ing the most central participant roles. Participant roles, he said, were cluster
concepts with a prototype involving a number of separate characteristics.
The various roles in an event can be compared to each other in terms of
lists of properties that characterize prototypes of various roles. Proto-agents,
for example, are typically sentient, act volitionally, bring about a physical
change, and so on; proto-patients change locations, are affected, do not act
volitionally, and so on. A participant in an event type that ranks sufficiently
high in terms of the list of properties of proto-agents and outranks the other
participants with respect to these properties will count as an agent, and simi-
larly for the patient role.
The system that I will describe here also allows us to assume that only a
small number of distinctions might suffice to capture the basic features of RS
in natural languages. Dowty assumed only two: proto-agent and proto-patient.
Jan Terje Faarlund (1995) suggested that it is sufficient to recognize a three-
way distinction between what he called agents, themes, and loci. I will adopt
Dowty’s general idea of proto-roles and accept Faarlund’s idea that three roles
are sufficient for the description of most event types. Faarlund’s third role is
defined not in terms of a prototypical set of properties, but negatively as nei-
ther a proto-agent nor a proto-patient. It can be a recipient, a beneficiary, an
instrument, a location, a path, and so on. I will call the three macro-roles in role
structure agent (AGT), patient (PAT), and ancillary participant (ANC).
A grammar of events will specify the event type and an associated list of
the macro-roles that the participants play in the event, the roles assigned on
the basis of a Dowtian contest. The system is iterative in that in addition to
Case-marking strategies  77
the participant roles, a subordinate event (EVENT) may also be evoked.
Accordingly, (1) is a simple grammar of role structure :
(1)	 a.	 EVENT → TYPE, ROLE, (ROLE), (ROLE), (EVENT)1
	 b.	 ROLE → AGT/PAT/ANC
Basic predicates can be specified for their value in role structure just as they
are for phrasal syntax and combinatoric semantics. I will indicate the RS prop-
erties of a predicate element as a list, the first element of which is the truth-
conditional meaning of the predicator, following which is a set of the roles
that are inherent to this meaning. Thus a fuller representation for a few of the
predicators we have already encountered is as follows:
(2)	 sneeze
	 syntax: V in [ __ ]
	 F/A: Fa
	 RS: “sneeze”, PAT
(3)	 take
	 syntax: V in [ __ NP]
	 F/A: Faa
	 RS: “take”, AGT, PAT
(4)	 stink
	 syntax: V in [ __ ]
	 F/A: Fp
	 RS: “stink”, EVENT
(5)	 claim
	 syntax: V in [ __ S′]
	 F/A: Fpa
	 RS: “claim”, AGT, EVENT
(6)	 put
	 syntax: V in [ __ NP, ADV]
	 F/A: Faaa
	 RS: “put”, AGT, PAT, ANC
Other aspects of meaning may also influence grammatical form. For example,
the generalization concerning the kinds of complements that a predicate may
take and its factivity expressed in (26) of Chapter 2 requires access to entail-
ments, and role structure makes such information available. For instance, the
ancillary participant in an event of putting expresses a goal, something that can-
not be defined in syntax, where it might be realized as a prepositional phrase
(on the shelf), an adverb (there), or a particle (away). It is obvious that goals
do not have combinatoric properties that define them in F/A structure, where
78  Role structure
they have the same combinatorics as, say, source locatives. But goals can be
defined in terms of entailments. If the sentence We put the book there is true,
then it follows that there was a time t at which the book was not located there
(at the place demonstrated or referred to), and a later time t+n when the book
was there. The expression there is therefore a goal in role structure, a definable
type of ANC role.
Default associations between role structure categories and both syntactic
and F/A structures are also apparent. EVENTs correspond to clauses and prop-
ositions, and ROLEs to NPs and Args. We may therefore expand (6) in Chapter
2 to include the following normal correlations:
(7)	 Syntax		 F/A		 RS
	 S	 ⇔	 Prop	 ⇔	 EVENT
	 NP	 ⇔	 Arg	 ⇔	 ROLE
Since role structure (as in Fillmore’s original conception of Case Grammar)
is essentially “flat,” all participants are equally visible and prominent within a
single event frame.2
Thus there is no RS correspondent to VP in syntax and Fa in
F/A structure, making the complete tri-modular table of correspondences (8).
(8)	 Categorial correspondences in three dimensions
	 Syntax	 F/A	 RS
	 S	 Prop	 EVENT
	 NP	 Arg	 ROLE
	 VP	 Fa	 —
In all languages, then, role structure is flat and in all languages F/A structure
branches in a binary fashion. Languages differ much more in syntax than they
do in the two semantic dimensions; some harmonize with RS, thus lacking a
VP, and some model their syntax on F/A structure, composing a verb with an
object NP into a VP.
3.2	 Passives
It seems clear that an account of the properties of passive predicates in multi-
modular terms requires reference to role structure. In languages that present
the right kind of evidence, it is usually the case that the syntactic subject of
a passive behaves just like the syntactic subject of an intransitive both with
respect to morphosyntactic characteristics such as case, agreement, and phrase
structure, and such combinatoric semantic properties as scope and anaphoric
reference. In Japanese, for example, the subjects of passives are in the nom-
inative case, just like subject of transitive sentences, or, more to the point,
intransitive sentences. The subject of the passive can be the antecedent of the
Passives  79
reference of the reflexive element zibun, but the object of the corresponding
active cannot:
(9)	 a.  Taroo-ga	 Ichiro-o	 zibun-no	 uchi-de	 mi-ta
		 T-NOM	 H-ACC	 self-GEN	 house-ANC	 see-PAST
		 “Taroo saw Ichiro in his (Taroo’s, not Ichiro’s) house.”
	 b.	 Ichiro-ga	 zibun-no	 uchi-de	 mi-rare-ta
		 I-NOM	 self-GEN	 house-LOC	 see-PASSIVE-PAST
		 “Ichiro was seen in his (Ichiro’s) house.”
In Kalaallisut, the ergative language of West Greenland, the subject of a tran-
sitive clause is in the ergative case and the verb agrees with it and with the
absolutive case object. In an intransitive clause the subject is in the absolutive
case and is the sole element with which the verb agrees. The subject of the
passive behaves just like an intransitive subject in syntax in these two respects.
Despite the substantial morphosyntactic dissimilarities between Japanese and
West Greenlandic, the F/A properties are the same. Only the subject (ergative
or absolutive) can antecede reflexives, and this holds for passive subjects as
well, as in the following examples from Sadock (2003b).
(10)	 a.	 Ataatama	 Kaali	 qinngutiminik	 takuaa
		 father-1s/ERG	 Karl-ABS/sg	 binoculars-INST/3R	 see-IND/3s/3sg
		 “My father saw Karl with his (my father’s, not Karl’s) binoculars.”
	 b.	 Kaali	 qinngutiminik	 qinerpoq.
		 Karl-ABS/sg	 binoculars-INST/3R	 look-around-IND/3sg
		 “Karl looked around with his (Karl’s) binoculars.”
	 c.	 Kaali	 qinngutiminik	 taku-neqar-poq
		 Karl-ABS/sg	 binoculars-INST/3R	 see-PASSIVE-IND/3sg
		 “Karl was seen with his (Karl’s) binoculars.”
On the assumptions about F/A structure made here, then, actives and pas-
sives will have to have different combinatoric semantic representations. The
reflexive zibun in Japanese and the 3R inflection in West Greenlandic require
reference to an F/A structure subject. It follows that the F/A structure subject
of an active sentence and that of the corresponding passive are different in both
Japanese and West Greenlandic. The vaunted (and somewhat exaggerated)
synonymy of active/passive pairs cannot, then, be accounted for by assigning
both the same F/A structure and setting up a mismatch in passive sentences
between the syntactic and F/A structure levels that more or less corresponds
to the mismatch between surface structure and deep structure in the classical
standard theory of transformational grammar. Rather, the synonymy must be
represented at the level of content, that is to say, role structure. There is, after
all, an understood agent in all true passives, even if it is unexpressed or lacks
80  Role structure
genuine semantic reference. I thus conclude that the resemblance between
active and passive sentences is to be attributed to their similarity at the RS
level, not F/A structure. An active/passive pair would then receive descriptions
in the three levels as sketched in (11) and (12).
F/A structure is the level where quantifier scope is represented, so if the F/A
structure of the goose was stolen was assumed to be similar to that of Someone
stole the goose, then a sentence such as Every goose was stolen should display
the same scope ambiguity as Someone stole every goose or Every goose was
stolen by someone. But the passive sentence is unambiguous and this adds
weight to the argument that passive sentences cannot have the same F/A ana-
lysis as the corresponding active sentence, even in English where reflexive
reference is not restricted to antecedents that are F/A structure subjects. The
conclusion is thus the same for Japanese or Eskimo or English: there is only
one argument in the F/A structure of an agentless English passive. Yet the pas-
sive does resemble the transitive proposition with regard to cognitive content
and that resemblance can and should be represented in role structure.
There are some phenomena of a cognitive nature that fairly directly demon-
strate the resemblance of passives to transitives. Intentional adverbials such as
purposely have a meaning such that they must refer to agents. We can say I was
purposely disrespectful, but not I was purposely old.3
The distinction is not a
matter of combinatorics but of content. Agents that are merely “in the air,” so
to speak, are not sufficient to sanction the use of such adverbials. For example,
in a narrative of a woodcutter hacking away at a tree, the sentence The tree fell,
will be understood as an event that resulted from an agentive act, but we never-
theless cannot say The tree purposely fell, meaning that that was the intention
(12) Syntax F/A RS
S Prop EVENT
NP VP Arg Fa TYPE AGT PAT
the goose was stolen GOOSE STOLEN “steal” “goose”
(11) Syntax F/A RS
S Prop EVENT
NP
thieves
VP Arg
THIEVES
Fa TYPE AGT PAT
“steal” “thieves” “goose”
V NP Faa Arg
stole the goose STOLE THE GOOSE
Passives  81
behind the woodcutter’s chopping. In passives, however, even where there is no
scene setting, an agent is cognitively salient and adverbs such as purposely are
allowed: the sentence The tree was purposely felled is sensible with the adverb
understood as being predicated of an unstated agent. There is similarly a con-
trast between passives and “middles” such that in the passive the agent is part
of the invoked event, but it is not in the middle construction, even though an
agent is entailed in both cases. The books were sold in large numbers in order
to raise money for charity is fine, whereas the very similar The books sold in
large numbers in order to raise money for charity is not nearly as acceptable.
To describe what is going on, we need to say something like this: intentional
adverbials such as purposely and in order to … must refer to the RS agent of
the event encoded by the verb they modify. The books were sold quickly has an
RS agent; The books sold quickly does not, even though for books to sell, there
must be an agent who puts them up for sale.
As has been extensively demonstrated in the linguistic literature over the last
thirty-five or more years, agents outrank patients, and patients outrank ancillary
participants in the competition for the status of semantic subject. Furthermore,
semantic subjects are higher in the F/A tree than objects, so in a language such
as English that has a VP, the NP dominated by S outranks all other NPs in a
clause and therefore will be preferentially aligned with the semantic subject by
geometrical correspondence. Where there is no agent, the patient will usually
be next in line in terms of subject succession. Given the hierarchy in (13), then,
the default alignments of (14) follow from general alignment principles very
much along the lines of early Case Grammar (Fillmore 1968).
(13)	 Role Hierarchy
	 Agent > Patient > Ancillary
In active sentences default associations obtain among participant types, seman-
tic arguments, and syntactic relations: if there is an agent, it will be the pre-
ferred subject both syntactically and semantically, and if, in addition, there is
a patient, it will be the default object in both dimensions, and if there is also a
third, ancillary role, it will be neither subject nor object, but occur in an oblique
(14) RS F/A Syntax
AG Prop S
PAT Arg Fa NP VP
ANC Arg Faa NP …
82  Role structure
case or as the object of a meaningful adposition, for example. But (14) gets the
facts wrong for passives so a device must be introduced to suppress the agent
role in syntactic and F/A structure. I will make the assumption that just as there
is a semantically null NP it that is not represented in F/A structure (or RS), and
a referential item RHO in F/A structure that has no counterpart in syntax, there
is a third, defective lexical item – perhaps an RS universal – that counts as a
role but is represented neither in F/A structure nor in syntax, an unspecified
entity playing only a cognitive ROLE. I will represent a semantically and syn-
tactically null role in RS as the role name enclosed in double angled brackets.
The lexical entry for the unspecified agent is:
(15)	 << AGT>>
	 syntax: nil
	 F/A: nil
	 RS: AGT
The Role Hierarchy still works, but the agent of the agentless passive is
<< AGT>> and therefore cannot be matched with anything in F/A structure
or syntax. The patient is then the highest available role that could find a
representation in function-argument structure and in syntax, so, the patient
in a passive wins the contest for semantic and syntactic subjecthood.
An active verb stem and the corresponding passive participle will have lex-
ical representations like the following:
(16)	 a.  buy	 b.	 bought
		 syntax: V in [ __ NP]		 syntax: V[PSV-P] in [ __ ]
		 F/A: Faa		 F/A: Fa
		 RS: “buy”, AGT, PAT		 RS: “buy”, <<AGT>>, PAT
It will not do, of course, simply to list all active verb forms and all passive
verb forms in the lexicon, since the existence of one more or less implies the
existence of the other. A mechanism that can handle regular relations between
words without deriving one from the other syntactically is the lexical rule, a
rule that specifies that if a lexical entry of a certain kind exists, then another
lexical entry with a formalizable relation to it will also exist.4
In automodular
theory, with its autonomous modules and independent specifications of lexical
properties for each of these modules, such a rule specifies that given a lexical
item with a certain syntactic value, a certain combinatoric semantic value, and
a certain set of properties in RS, there is another lexical item related to it whose
syntax is related to the syntax of the first, whose F/A status has a statable
­
relation to the F/A status of the first, and whose role structure properties can
be described as a function of the RS structure of the first. This is basically the
Passives  83
same format that is used in all grammatical formalisms that invoke lexical rules
but fits more naturally into the present architecture of grammar than it does in
many others that recognize the existence of such rules.
For the agentless passive, a reasonable statement of this kind is the
following:
(17)	 Passive Lexical Rule
	 Active		 Passive
	 syntax: V in [ __ NP, ψ]	 →	 syntax: V[PSV-P] in [ __ψ]
	 F/A: Fφa	 →	 F/A: Fφ
	 RS: “v”, AGT, χ	 →	 RS: “v”, <<AGT>>, χ
Here ψ, φ, and χ are variables over strings of syntactic categories (NP, VP,
PP, etc.), strings of argument types (a, p), and role strings (AGT, PAT, ANC,
EVENT), respectively. The rule alters all three fields in producing a new lexical
entry from an existing one. It removes an NP from a list of syntactic comple-
ments, removes the rightmost item – the semantic subject – from the list of
the arguments that the lexical functor applies to, and requires the agent in role
structure to be the functionally and syntactically empty entity << AGT>>, mak-
ing it no longer directly codable in syntactic and F/A structure, while preserv-
ing its cognitive significance. In addition, it adds the morphosyntactic feature
[PSV-P] to the verb thus ensuring that the verb will always have the form of a
passive participle. The result is to turn the entry for a verb like (16a) into one
for its passive participle, which will head verb phrases that are selected as the
complements of verbs like be and get. The past and passive syntactic parti-
ciples are not distinguished morphophonologically. (See Chapter 5 (14) and
(37).) They are, however, distinguished syntactically in that they form VPs that
are selected by different verbs. Auxiliary have takes past participial syntactic
complements that themselves have full complements: had put the book on the
shelf, whereas one non-auxiliary use of have selects an NP and a VP headed by
a passive participle, which necessarily lacks an object NP according to (17):
had (the book) (put on the shelf).
To see the effect of this rule, let us examine a number of the verb classes that
have already been discussed. For a simple transitive such as buy, the rule gives
as output a verb form that takes no syntactic complement and combines with a
single argument to form a proposition, but retains the cognitive significance of
the transitive verb “buy.” Setting aside role structure, notice that the resulting
verb is exactly like a lexical intransitive. Similarly, a verb such as put, which
is subcategorized for an NP and another category,5
and which semantically
combines with the meaning of three entity expressions to form a proposition,
will yield a passive that takes only the complement of the unspecified category
84  Role structure
and combines semantically with the meaning of the two arguments to form a
proposition, in something like the same fashion as the (non-passive) adjective
found: Is lithium found in Bolivia?Yes, it is found *(there). Was the book put on
the shelf? Yes, it was put *(there).
Raising-to-Subject and subject-controlled Equi verbs are not inputs to the
passive lexical rule because they do not take an NP among their complements,
both taking VP[to] complements only. But for a verb such as believe in the dis-
placement (i.e., Raising-to-Object) usage, we get lexical entries for the active
and passive verb forms as shown in (18). As far as syntax and F/A structure
are concerned, the passive of such a verb has just the sort of lexical properties
that Raising-to-Subject verbs have, as discussed in Chapter 2, section 2.6.1,
and indeed, their behavior is the same (There is believed to have been a fire,
There seems to have been a fire; The shit is believed to have hit the fan, The shit
seems to have hit the fan, etc.). Note that the redundancy rule (29) of Chapter
2 also predicts that the passivized lexeme, which counts as an Fp and takes an
infinitive VP complement, will also occur with a clausal complement, in which
case it will have to have semantically empty it as its subject. This prediction is
correct, accounting for examples like It is believed that there was a fire without
further assumptions.6
(18)	 Active	 Passive
	 believe	 believed
	 syntax: V in [ __ NP, VP[to]]	 syntax: V[PSV-P] in [ __VP[to]]
	 F/A: Fpa	 F/A: Fp
	 RS: “believe”, AGT, EVENT	 RS: “believe”, <<AGT>>, EVENT
Consider next an object-controlled Equi verb such as persuade. In terms of
phrase structure syntax and function-argument structure, the output in this case
is just like that of a subject-controlled Equi verb. The suppressed agent in role
structure makes it different from a verb such as try, however.
(19)	 Active	 Passive
	 persuade	 persuaded
	 syntax: V in [ __ NP, VP[to]]	 syntax: V[PSV-P] in [ __VP[to]]
	 F/A: Fpaa	 F/A: Fpa
	
RS: “persuade”, AGT, PAT, EVENT	 RS: “persuade”, << AGT>>, PAT, 	
		  EVENT
3.3	 The argument for the cycle
The interaction of passive and other presumed movement rules was widely
considered not just a knock-down, drag-out argument for transformational
The argument for the cycle  85
operations, but more specifically for the cyclic, sequential application of such
rules. Examples such as (20), in which some transformational rule (here Raising-
to-Object) appears to be “sandwiched” between applications of the passive, were
often taken to be especially convincing (in Soames and Perlmutter 1979, 146,
for example).
(20) 	 The child is believed to have been found.
In early generative grammar the deep structure was assumed to have at least the
structure in (21) and to undergo at least the following alterations in the order
given: first the passive transformation operated in S2, making the child the cyc-
lic subject of be found. Raising-to-Object then made the child the direct object
of S1, and finally, passive applied again, this time to S1, making the child the
subject of be believed.
As convincing as this argument might have seemed in the 1960s and early
1970s, this example and others like it are straightforwardly accounted for by
the autonomous descriptions that have been introduced to this point without
resorting to movement rules of any kind or the auxiliary assumption of the cyc-
lic application of rules. Items (22) and (23) show the underlying verb entries
and the passive participles that are induced from them by the lexical rule (17).
(22)	 believe		 believed
	 syntax: V in [ __ NP, VP[to]]	 →	 syntax: V[PSV-P] in [ __ VP[to]]
	 F/A: Fpa	 →	 F/A: Fp
	 RS: “believe”, AGT, EVENT	 →	 RS: “believe”, <<AGT>>, EVENT
(23) 	 find		 found
	 syntax: V in [ __ NP]	 →	 syntax: V[PSV-P] in [ __ ]
	 F/A: Faa	 →	 F/A: Fa
	 RS: “find”, AGT, PAT	 →	 RS: “find”, <<AGT>>, PAT
Given the derived lexical properties of the passive participles in the right-
hand columns of (22) and (23), the tri-modular representations in (24) are the
(21) S1
NP
someone
VP
V
believe
S2
NP
someone
VP
V
find
NP
the child
86  Role structure
only ones possible, and the associations indicated by the dotted lines, the best
available. They do present certain geometrical mismatches, but discrepancies
of structure just like we see here have been encountered already.
There is only one noun phrase in syntax and one argument in F/A struc-
ture, so these must be associated. There are three participants in the scene
diagrammed in role structure, but two of these are fixed as the unassociable
agent role, <<AGT>>, because of the properties of the two passive participles.
Therefore only the patient of the finding event can be associated with the sin-
gle available argument position in F/A structure and the sole NP that occurs in
the syntactic structure, the required subject of the highest verb. Thus the form,
combinatoric meaning, and cognitive content are automatically and correctly
associated without assuming anything like movement, ordered rules, or a cycle
of transformations.
3.4	 Problems with RHO
I return now to RHO, the element that functions as an argument in semantic
F/A structure, but is not found in phrase structure syntax at all. The discussion
from Chapter 2 suggested that its appearance and its reference were automatic.
However, there are a few serious problems with those ideas that make them
impossible to maintain generally. Here I will show how those problems can be
circumvented with the help of role structure.
The condition that RHO’s antecedent is the first c-commanding argument
in F/A structure (Chapter 2 (61)) will handle certain aspects of control, but
there is ample evidence that this simple treatment is inadequate. In languages
as diverse as Irish (McCloskey and Sells 1988) and Igbo (Ura 1998), what
correspond intuitively to control structures in English are expressed with finite
(24) Syntax F/A RS
S Prop EVENT1
NP
the child
VP Fp Prop TYPE <<AGT>> EVENT2
BELIEVE “believe”
find”<<AGT>> PAT
V VP[PSV-P] Arg Fa
was CHILD FOUND
V[PSV-P] VP
believed
be VP[PSV-P]
found
Problems with RHO  87
clause complements that enforce the same coreference requirements as do cor-
responding English verbs with infinitive complements. In Greek, for example,
a finite subjunctive clause is used in many cases where English would have an
infinitive VP (examples from Alexiadou and Anagnostopoulou 2002):
(25)	 O	 Petros	 kseri	 na	 koliba-i
	 the	 Peter	 knows	 SUBJ	 swim-3sg
	 “Peter knows how to swim.” lit., “Peter knows that he might swim.”
Here there is necessary coreference between the main-clause subject and the
inflectionally indicated subject of the finite subordinate clause. Therefore if
the inflection of the verb of the subordinate clause cannot be coreferent with
the main-clause subject the sentence is ungrammatical, as shown in (26a).
Likewise, the presence of an NP subject that cannot be coreferent with the
main-clause subject, as in (26b), produces ungrammaticality. RHO cannot
be responsible for the coreference in (25), since RHO is not a pronoun or an
inflection that counts as one in the syntax and therefore can’t be the subject of
the subordinate proposition in F/A structure.
(26)	 a.  *O	 Petros	 kseri	 na	 kolimbao
		 the	 Peter	 knows	 SUBJ	 swim-1sg
	 b.	 *O Petros	 kseri	 na	 kolimbai	 i	 Maria
		 the Peter-NOM	 knows	 SUBJ	 swim-3sg	 the-NOM	 Maria
A similar problem arises in connection with some instances of “copy rais-
ing,” or “Richard,” as Andy Rogers (1974) originally called it. In examples
such as (27a), the referent of he in the meaning of the subordinate proposition
is the same as that of John (Potsdam and Runner 2001). Here, as in the case
of Greek subjunctives, there is necessary coreference between the referent of
the main-clause subject and the referent of a role in the event expressed by
the complement clause. In English the coreferent participant is expressed as
a pronoun.
(27)	 a.  John looks like he’s/*I’m ill.
	 b.	 Julia looks like someone threw a cake at her/*me.
What we see, then, is that certain verbs, in particular many of those that induce
obligatory control, demand coreference between something in the matrix
clause and an overt item in the subordinate clause.
A different problem, brought to my attention by Jason Merchant (p.c.),
concerns the account of the ungrammaticality of the following example in
English:
(28)	 *John tried to seem that the earth is flat.
88  Role structure
The analyses of verbs such as seem as intransitive semantic operators and verbs
such as try as transitive operators interact correctly when both have infinitive
VPs as syntactic complements (Dick tried to seem to be a friendly person =
Chapter 2 (65)), as we have seen. But in the case of (28) there is a problem. The
syntactic and semantic structures for the sentence above would come out as (29)
and (30), both of which are well formed within their own modules. The syntax
of the expression is all right, since try has its required VP complement, and seem
can take an S′[that] complement. Furthermore, the semantic functors TRY and
SEEM meet all of the interface constraints of Chapter 2 when matched with their
syntactic correspondents.
The analytical error here is the same as the one that was found in Greek and in
the case of copy raising: there is a requirement in effect that demands corefer-
ence between the subject of a matrix proposition and the subject of the imme-
diately subordinate proposition that is independent of the distribution of RHO,
a syntactically empty pronominal argument that does not even figure in the F/A
structure of (28).
Yet another empirical failing is that there are verbs that allow infinitive com-
plements, and hence ought to have RHO but fail to require coreference even
when there is a c-commanding argument that is a possible antecedent.
(31)	 a.  Mom said to come home.
	 b.	 Every alderman voted to fund the new stadium.
(29) S1
NP
John
VP
V VP
try
V S′
seem
Comp S2
earth.be.flat
(30) Prop1
Arg
JOHN
Fa
Fpa
TRY
Prop2
Fp
SEEM
Prop3
FLAT(EARTH)
Problems with RHO  89
If RHO always had as its referent an available c-commanding antecedent, as
(61) of Chapter 2 proposes, then (31a) would mean that Mom said that she,
Mom, would come home, and (31b) would mean that each alderman would
fund a new stadium, clearly the wrong results.
So what can be done to handle these facts? If the coreference cannot be attrib-
uted to RHO alone, to what should we attribute it? It is intuitively clear that the
coreference requirements (and non-requirements) that have just been presented
are not random but have to do with the meaning of particular predicates and
for that reason, near synonyms such as try, strive, attempt, and endeavor all
require coreference between their subject and the notional subject of the sub-
ordinate proposition.7
But the F/A level of representation distinguishes among
predicates solely on the basis of their semantic combinatorics and not on the
basis of their content. In this chapter another semantically oriented level has
been introduced that does include truth-conditional meaning, so the corefer-
ence facts that cannot be handled combinatorically can be dealt with here.
Consider verbs such as try, and its near synonyms. All of these take only
infinitive VP complements and are predicates of obligatory control, clearly a
function of what they mean. Any successful attempt, endeavor, or act of trying
by an agent to bring about some state of affairs entails that the hoped-for state of
affairs is itself facilitated by an agent and that agent is the same as the attempter,
endeavorer or trier. I will therefore simply stipulate the coreference requirement
in the role structure field of the lexical entries of predicates such as these, in-
dicating it with a line connecting the coreferring elements (32). Redundantly
in this case, I will indicate the fact that verbs such as try must have semantic
complements with RHO as their subject with a subscript “R” in the F/A com-
plement list, where R means a proposition with the feature “RHO.” The two
requirements are separate in some cases, however. In Greek, as we have seen,
the role structure requirement is in effect for verbs of the same semantic class
as English try, but for which there is no RHO in F/A structure. In English one
use of the verb say as in (31a) takes an infinitive complement with RHO as the
semantic subject but does not impose the coreference requirement.
It can easily be seen that the problems that were outlined above are solved,
or at least avoided, by means of this additional mechanism. In a language such
(32) try, attempt, endeavor, make an effort …
syntax: V in [ __, VP[to]]
F/A: FRa
RS: “try”, AGTi, EVENT[AGTi, …]
90  Role structure
as Greek, the meaning of certain predicates will be such as to require corefer-
ence even though the syntactic complement is a finite clause. Here are lexical
representations for Greek kseri in the sense of “know how to” (33a) and for
English look in the “copy raising” usage (33b):
Assuming that in Greek the only possible representative of a coreferent sub-
ject in a finite subordinate clause is an inflection and in English it is a per-
sonal pronoun, the ungrammaticality of (26a,b) and (27b) follows. Example
(28) is ungrammatical because the subject of the EVENT immediately sub-
ordinate to “try” has to have an agent that is coreferent with an agent of
“try,” and redundantly, it must have a subordinate proposition whose subject
is RHO.8
3.5	 The problematic verb promise
There is a small class of predicates in English that also occur with a fol-
lowing NP and VP[to] but which can be understood by some speakers with
the subject of the verb coreferent with the subject of the subordinate prop-
osition despite the intervening direct object. For some speakers (including
the writer) there is only one such verb, promise, and some speakers have
none. The possibility of coreference of the subordinate proposition’s subject
with the referent of the syntactic subject of promise shows up clearly in the
distribution of reflexive pronouns for those speakers who allow promise to
occur in this usage.
(34)	 a.	 I persuaded my brother to take better care of *myself/himself.
	 b.	 I promised my brother to take better care of myself/*himself.
One thing that could be done to handle these facts is to make promise a member
of a new F/A category, namely Fapa so that it combines first with the argument
representing the promisee and only then with the proposition representing
(33) a. kser- (Greek, “know how to”)
syntax: V in [ __, S[SUBJ]]
F/A: Fpa
RS: “know how to”, AGTi, EVENT [AGTi, …]
b. look
V in [ __ S�[like] ]
RS: “look.like”, AGTi, EVENT[ … ROLE …]
The problematic verb promise  91
what is promised. This would make the subject of promise correspond to the
first argument in F/A structure that c-commands RHO and therefore a natural
candidate for controller of RHO’s reference.
The dimension of role structure that has been introduced in this chap-
ter provides access to semantic content, rather than simple combinatorics.
Considerations of meaning and the coreference relations they entail make the
assumption of an otherwise unattested type of F/A function, Fapa, unnecessary.
Since the coreference of the promisor and the agent of the promising event
are attributible to meaning, an analysis in terms of semantic combinatorics
becomes superfluous and we may assume that promise instantiates the well-
attested functional category Fpaa.
The lexical entry for promise, including its description in role structure is, then,
(36a), and its position in function-argument structure will be (36b), not (35b).
It has been amply documented in the voluminous literature on the as-yet-
unresolved question of what is responsible for controller assignment, that the
(35) a. promise (provisional)
syntax: V in [__ NP, VP[to]]
F/A: Fapa
b. Prop
Arg1 Fa
Prop Fpa
Arg2 Fa Arg3 Fapa
RHO PROMISE
(36) a. promise
syntax: V in [__ NP, VP[to]]
F/A: FRaa
RS: “promise”, AGTi, PAT, EVENT[TYPE, AGTi,… ]
b. Prop
Arg1 Fa
Arg2 Faa
Prop Fpaa
PROMISE
Arg3 Fa
RHO
92  Role structure
judgments of grammaticality and coreference in such examples as we are dis-
cussing are quite variable. In some examples it would seem that structure alone
determines coreference, as in (37) and (38), where our knowledge of sports
makes the only available reading pragmatically odd:
(37)	 The doctor tried to be healthy by game time.
(38)	 The quarterback persuaded the doctor to be healthy by game time.
There are, however, many kinds of examples in the literature where pragmatic
considerations are pretty clearly implicated. Each of the following examples
is in principle ambiguous, but there is a preferred interpretation for each that
depends upon knowledge of the world and guesses based on knowledge about
responsibility for an event (Farkas 1986).
(39)	 a.	 The quarterback promised the coach to be healthy by game time.
	 b.	 The doctor promised the quarterback to be healthy by game time.
(40)	 a.	 The quarterback begged the doctor to be healthy by game time.
	 b.	 The coach begged the quarterback to be healthy by game time.
A similar case of pragmatic intrusion on the interpretation of control relations
is (41). For many speakers who accept Fred promised Nancy to behave himself
with subject control, (41), which displays object control, is also acceptable.
(41)	 Fred promised Nancy to be allowed to vote for herself.
On the basis of what we know about the ordinary relation between quarter-
backs, doctors, and coaches and about acts of promising and acts of allowing,
it should eventually be possible to say some substantive things about the extra-
grammatical factors that contribute to or inhibit various coreference relations.
For the time being, however, the matter is still not entirely settled, so a treat-
ment of the semantic and pragmatic factors that override the default corefer-
ence principle (61) in Chapter 2 will not be attempted here. Where the facts are
clear and rather general, they can be stipulated in the role structure represen-
tation, as was done in (36). (For an extended discussion and treatment of the
factors that produce coercion of semantic interpretation, see Sag and Pollard
[1991].)
3.5.1	 Visser’s generalization
Regardless of how controller–controllee relations are semantically and prag-
matically determined, one fairly robust fact that characterizes control examples
is this: if the referent of the syntactic subject is the controller and the verb
occurs in the frame [ __ NP, VP[to]], the verb cannot comfortably occur in a
The problematic verb promise  93
passive. This fact is known as Visser’s generalization (Bresnan 1982) and its
principal exemplar is the verb promise, though the generalization also applies
to certain other cases for some speakers. Let us then consider the derived entry
for the passive participle of promise. The lexical entry of the base verb is given
in (36a) above. Applying the passive lexical rule (17) will then yield (42) as the
lexical specification for the derived lexeme.
Example (43) will then be assigned the RS and F/A structure representations
(44) and (45).
(43)	 *Nancy was promised to vote.
In the F/A structure RHO has only one natural antecedent, NANCY, the im-
mediately c-commanding argument, and indeed, the only c-commanding argu-
ment. But as (44) shows, “Nancy” is the patient of the promising situation not
the agent. If RHO has an antecedent at all, then it must be the general “arbitrary
referent” familiar from the literature on PRO. The antecedent of RHO, how-
ever, is not arbitrary: (44) requires it to be coreferent with the promisor and this
automatic tension produces the dramatically diminished acceptability of (43).
(42) passive participle of promise
syntax: V[PSV-P] in [ __, VP[to]]
F/A: FRa
RS: “promise”, <<AGT1 >>, PAT, EVENT[TYPE, AGT2, …]
(44) EVENT1
“promise” <<AGT1>> PAT EVENT2
“Nancy”
“vote” AGT1
(45) Prop
Arg
NANCY
Fa
Fpa Prop
BE.PROMISED
Arg Fa
RHO VOTE
94  Role structure
It is clear that it is the presence of RHO in the function-argument structure
of example (43) that is partially to be blamed for Visser’s generalization, since
examples with essentially the same cognitive structure as (43), but a syntax and
semantics that does not include RHO strike me as perfectly acceptable. (46) is
such an example.
(46)	 Nancy was promised a vote.
The point of this discussion has been that the account of Visser’s generaliza-
tion just presented, an account that makes use only of ideas that have already
been justified, crucially depends upon the separation of two distinct and some-
times incongruent dimensions of semantic representation, one reflecting only
structural semantic relations (F/A structure) and the other based upon connec-
tions between meaning and truth (RS structure).
3.6	 Agentive passives
Passives that present an explicit agent as the object of by could be handled in
several ways, for example, by adopting the rather traditional stance that the
object of by in a passive sentence occupies the same functional position as the
subject of the active sentence, as in Marantz (1984). But a considerable mass
of evidence is assembled in Napoli (1989) showing that the semantic agent-
hood of the object of by is not the same as the role assigned to the subject of
the active verb.
Two notions are bound up in the traditional notion of Theta Role: (1) a struc-
tural notion that is embodied in the Theta Criterion in transformational theories
(Chapter 2, section 2.12.1), and (2) a cognitive notion that defines the kind
of role that the various participants in an event play, as discussed in terms of
proto-roles in Dowty (1991). The former are represented in F/A structure in the
present theory, and the latter in role structure. This separation makes it possible
to say at the same time that the object of by in passive sentences is a (proto-)
agent and yet is not an argument of the passive verb in F/A structure. These
ideas can be formalized quite easily in a modular framework of grammatical
description by formulating an appropriate lexical entry for agentive by:
(47)	 by (agentive)
	 syntax: P in [ __ NP]
	 F/A: MFa → BY, Arg
	 RS: EVENT → “act”, AGT, EVENT
Lexical entry (47) assigns by to its evident syntactic class: it is a preposition,
a function from NPs to PPs. Its semantic combinatorics are such as to form a
Agentive passives  95
modifier of predicates – MFa – by combining with an argument, which must
be the referent of the syntactic object of by. The category that by forms in F/A
structure is the same as a predicate “adverb” that restricts the meaning of a
predicate to certain subcases. In a phrase such as sing softly, the unmodified
predicate is the set of all those who sing, whereas the modified predicate refers
only to those who sing softly. Similarly, the word built refers to everything that
is built, but built by Wren in (48) restricts the predicates to those things that are
built with Wren as an agent. Turning next to role structure, “by” counts as a
very general event type that involves an agentive participant and a subordinate
event. If we crudely paraphrase this as “act” (after Ross 1971), then a passive
sentence like (48) would be something like “The cathedral is among the things
such that Wren acted as an agent in their building.”9
(48)	 The cathedral was built by Wren.
For clarity, the tri-modular representation of (48) is presented in (49), (50),
and (51).
(49) S
NP VP
the cathedral
V
was
VP[PSV-P]
PP VP[PSV-P]
P NP V[PSV-P]
by Wren built
(50) Prop
Arg Fa
CATHEDRAL
MFa Fa
BUILT
BY Arg
WREN
(51) EVENT
“act” AGT EVENT
“Wren”
“build” <<AGT>> PAT
“cathedral”
96  Role structure
This modular treatment has the distinct advantage of making otiose any
independent agentive rule or subrule for the passive. The same rule that was
written for the agentless passive still applies and if the agentive by is used as
in (48), the result is an agentive passive with the three independent representa-
tions (49)–(51).
Though the agent is not an F/A argument of the verb according to (47), it
does have a function in that dimension of representation. Therefore it can give
rise to scope ambiguities, whereas the notional agent in the agentless passive
cannot. (52) is ambiguous in a way that (53) is not.
(52)	 Every problem was solved by some student.
(53)	 Every problem was solved.
An automodular account of the agentive passive construction also holds out
the possibility of yielding accurate, principled accounts of other uses of by that
have been cited in the literature as supporting a meaning-based, rather than a
constructional theory of agentive by. For example, there are syntactic intransi-
tives that are understood as involving an agent and accept agentive by-phrases,
e.g., The package arrived by bicycle courier. And then there is the oft-cited
case of crypto-activity nouns as in a portrait by Whistler or the cathedral by
Wren, where again, giving by the right sort meaning might be all that is needed
to explain such facts, though I will not refine those descriptions here.
3.7	 Pseudo-passives
Passivization can sometimes affect the object of a prepositional phrase in the
verb phrase, a phenomenon generally known as pseudo-passivization:
(54)	 This bed has been slept in (by somebody).
(55)	 This lock has been tinkered with (by an amateur).
(56)	 The police were spat on (by the crowd).
But, as is well known, many syntactically similar examples do not have pseudo-
passive alternatives that are as acceptable as those in (54)–(56):
(57)	 ??
The ice was slipped on.
(58)	 ??
The movie was appeared in by John Travolta.
(59)	 ??
The crowd was vanished into by the thief.
As written, the lexical passive rule (17) will not apply to produce any such
examples because the syntactic part of the rule requires a subcategorized NP
Pseudo-passives  97
object, and it is impossible to analyze the syntax of (54)–(56) as not containing
a prepositional phrase. What looks like a prepositional phrase in those sentences
behaves in the syntax just like other subcategorized prepositional phrases; it can
be “pied piped” as in (60a) or be the focus of a cleft sentence as in (61a), and
cannot be separated from the verb by an adverb as shown by the ungrammat-
icality of (62),10
regardless of whether the structure alternates with a pseudo-
passive, as do the a. examples in (60)–(62), or not, as is in the b. examples:
(60)	 a.	 the bed on which I slept …
	 b.	 the ice on which I slipped …
(61)	 a.	 It was not on this bed that I slept, but on that one.
	 b.	 It was not on the ice that I slipped, but on a banana peel.
(62)	 a.	 *I slept on comfortably the bed.
	 b.	 *I slipped on inadvertently the ice.
I conclude that the syntax (in the sense in which that term is used here) has the
same phrase structure regardless of pseudo-passivizability (63), and for this
reason, the passive lexical rule (17) cannot simply be modified so as to neglect
any preposition that follows the verb.
Furthermore, adjuncts of the verb phrase are never associated with pseudo-
passives:
(64)	 a.  Ben sang in Japan.
	 b.	 *Japan was sung in by Ben.
(65)	 a.	 Harry vanished with the loot.
	 b.	 *The loot was vanished with by Harry.
(66)	 a.	 Laura dances for a living.
	 b.	 *A living is danced for by Laura.
Modifiers, however, have a different position from subcategorized prepos-
itional phrases both in F/A structure and syntactic structure. The passive rule
will not apply in such cases because there is no NP whatsoever in the comple-
ment of intransitive sing (67b).
(63) S
NP
I
VP
V
slept/
slipped
PP
P
on
NP
the bed/ice
98  Role structure
The reason for this is that English, unlike other languages, does not allow
passives of F/A structure intransitives even where there is an understood role
structure patient. We have no impersonal passives like German Es wird in
Irland viel gesungen “There is much singing in Ireland.” The same point is
illustrated by VP idioms both with non-referential NP complements and with
prepositional phrase complements with non-referential objects. Such examples
generally have intransitive semantics and therefore represent the F/A category
Fa, for which reason idioms like kick the bucket meaning roughly “die” and
not play with a full deck meaning “be stupid” do not have passive versions:
*The bucket was kicked by Billy’s turtle; *A full deck isn’t being played with
by her cousin. VP idioms that are construed as transitive and can plausibly be
assigned to the category Faa often do have reasonable passive alternatives as
with spill the beans meaning “divulge the secret”: The beans were spilled to
the KGB. (See Newmeyer 1972 for the source of this idea.)
An important consideration in reformulating the passive rule so as to allow
for pseudo-passives is their dependence on semantic content, something that
was observed early on in the study of this sort of construction. In addition
to the combinatoric factors that have already been taken into account, two
others are at play, namely (1) whether the subject is a strong candidate for
proto-agency, and (2) whether the object of the preposition is a strong can-
didate for the role of proto-patient. The more agent-like the properties of
the subject and the more patient-like the properties of the object, the better
a pseudo-passive sounds. Though the literature seems regularly to assume
either full grammaticality or full ungrammaticality for any given example of
a pseudo-passive, intermediate judgments seem to me to be what we actu-
ally find. For instance, the following three examples are like standard ones
in the literature that are treated as equally good, but to my ears they decrease
(67) a. Prop
Arg Fa
BEN
Fa MFa
SANG IN.JAPAN
b. S
NP VP
Ben
VP PP
in Japan
V
sang
Pseudo-passives  99
in acceptability in the order given, apparently because tampering, as in (68)
is a fully intentional act that physically alters the item that is tampered with,
while an act of sitting on something, such as what is described in (69), does
not necessarily produce any noticeable change in what has been sat on and in
addition, that item is a locus and hence not the best sort of patient. In (70) the
object of the preposition is also a non-affected locus and additionally, sliding
can be either purposeful or – more ordinarily – accidental. Thus the degree
of agency of the subject NPs is low. In all these respects, (68) is close to the
prototypical transitive verb situation, (70) is pretty far from it, and (69) is
somewhere in between.
(68)	 The safe has been tampered with. >
(69)	 The table has been sat on. >
(70)	 The closet has been slid into.
Examples that take prepositional phrase complements and are quite amenable
to pseudo-passivization can sometimes be paraphrased with syntactically tran-
sitive verbs.
(71)	 a.  They set upon the enemy.
	 b.	 The enemy was set upon.
	 c.	 They beset the enemy.
(72)	 a.	 The congressmen have engaged in illegal activities.
	 b.	 Illegal activities have been engaged in by the congressmen.
	 c.	 The congressmen have practiced illegal activities.
(73)	 a. The Feds looked into Macrotuff’s bookkeeping.
	 b.	 Macrotuff’s bookkeeping was looked into.
	 c.	 The Feds investigated Macrotuff’s bookkeeping.
Examples that lack pseudo-passives rarely allow such paraphrases. There
is no transitive verb corresponding even roughly to slide into, slip on, van-
ish with, appear in (a movie), and so on. (See examples (57)–(59) and the b.
examples in (64)–(66).)11
And it is not just pseudo-passives, but passives in general, that are sensitive
to the degree of agentivity and patientivity of the participants in an event. Even
genuinely transitive syntax does not guarantee the existence of a good passive,
as has long been understood. Where the subject is a marginal agent and/or the
object a dubious patient, passives are often excluded, as with symmetric predi-
cates: *George Washington is resembled (by Martha’s cousin); instrumental-
subject constructions: *The door was opened by the key; and measure verbs:
*Seven pounds is weighed by her dissertation.
100  Role structure
Considerations such as these are referred to the RS level that has been intro-
duced in this chapter. The presence of a proto-agent and a proto-patient in the
RS input is already required in the passive rule (17). If we recognize the scalar
quality of these proto-roles and their influence on the acceptability of passive
versions of active forms, then the only modification needed is to allow for an
optional preposition in the complement of a verb:
(74)	 Revised Passive Rule12
	 Active		 Passive
	 syntax: V in [ __ [<P>13
NP], ψ]	 →	 syntax: V[PSV-P]14
in [ __ <P>, ψ]
	 F/A: Fφa	 →	 F/A: Fφ
	 RS: TYPE, AGT, PAT, χ	 →	 RS: TYPE, <<AGT>>, PAT, χ
3.8	 Role structure and miscellaneous classes of predicates
The connection between semantic roles and grammar has been explored in
detail in a number of frameworks and has proven to be a very fruitful area
of inquiry. (See, for example, Gruber 1965; Fillmore 1968; Jackendoff 1972;
Talmy 1975; Stowell 1981; Langacker 1987; Dixon 1991; Dowty 1991; Krifka
1992; Pustejovsky 1995; Levin and Rappaport-Hovav 2005, to cite just a few
of the many, many contributions to semantically oriented grammar.) Many of
the insights from this literature can be directly incorporated into the present
scheme through the autonomous dimension of role structure. Indeed, most ser-
ious studies of lexical semantics recognize a level in which cognitive content
interfaces with other components, in particular, syntax. For illustrative pur-
poses, I will discuss here only a few further classes of verbs, incorporating
ideas from the existing cognitive semantic literature.
The discussion that follows is merely meant to be suggestive as to how the
very spare notions of cognitive content that have been introduced in this chapter
might be put to use in coming to grips with how the actual role of participants
can be related to the syntactic realization of various elements of a cognitive
scene and how they may interact with such combinatoric semantic facts as
scope and reference. It is very far from an authoritative treatment of such prob-
lems and leaves entirely out of the picture such notions as aspect, telicity, the-
maticity, and various types of discourse information such as definiteness, figure
and ground, and topic and comment. Anyone familiar with the detailed and
cogent work on lexical semantics will recognize that the pared-down system
of role contrasts that has been introduced in this chapter is inadequate to the
task of describing the range of phenomena concerning syntax, combinatoric
semantics, and the structure of events. My aim here is the same as it has been
Role structure and miscellaneous predicate classes   101
throughout this book: to show how a multi-modular framework can describe a
wide range of phenomena in a formalizable, testable, and lucid manner.
3.8.1	 The commercial transaction
Role structure can be employed to capture the common cognitive value of cer-
tain non-synonymous lexical items that should not be located in syntax or struc-
tural semantics. I will take as an example the “commercial transaction frame”
discussed in Charles Fillmore’s early works on frame semantics (Fillmore
1976, 1977, 1982). Fillmore wanted to consider the relation between a set of
verbs including buy, sell, pay, cost, and others. For illustrative purposes, I will
here consider only buy and sell in examples (75) and (76):
(75)	 They bought a vase.
(76)	 They sold a vase.
The verb buy occurs here in a syntactic frame where it is a simple transitive
verb (e.g., They bought a vase) and cannot be used without an object (*They
bought).15
When buy occurs with optional prepositional phrases (They bought
a vase (from Andrew) (for $37.56)), I assume they are modifiers (adjuncts)
of the verb phrase, not constituents that the verb is subcategorized for. In the
function-argument semantics, buy is clearly a function from arguments to pred-
icates, and the event it describes involves an agent and a patient.
(77)	 buy
	 syntax: V in [ __, NP]
	 F/A: Faa
	 RS: “buy”, AGT, PAT
Likewise, sell also occurs with a more or less obligatory direct object, and
with that syntax the verb is a function that produces an F/A structure predicate
in combination with an argument. It is thus indistinguishable from buy in these
two representational levels. Nor is any help forthcoming from the RS represen-
tation by itself, since sell also depicts an event in which there is an agent and a
patient, just as buy does.
(78)	 sell
	 syntax: V in [ __, NP]
	 F/A: Faa
	 RS: “sell”, AGT, PAT
But role structure is derived from actual content – from entailments of the
kinds that Dowty suggested. Because it allows access to entailments of all
sorts, RS does, in fact, provide a way of distinguishing between buy and sell.
102  Role structure
Let us follow Fillmore in recognizing a commercial transaction frame in
which at a minimum, two entities with human sentience and two entities of
value are involved. One of these entities with value is a recognized medium of
exchange, money, for example. Let us designate the sentient participants as the
buyer and seller, and the two valuable entities as the goods and the funds. The
commercial frame is an event type in which the ownership of the goods is trans-
ferred from the seller to the buyer, while ownership of the funds is transferred
from the buyer to the seller. Our understanding of the commercial transaction
frame is part of our knowledge of the world, a world that includes social facts
as well as natural facts. It is not specifically knowledge of language, though
linguistic meaning can, of course, refer to this extra linguistic knowledge.
Because we know the meaning of (75), we know that if the sentence is true,
it follows that they refers to a buyer and a vase refers to a valuable property
in the commercial frame. We also know that the truth of the sentence entails
the existence of funds and of a seller, though neither of these is mentioned in
the sentence and neither is part of any of the sentence’s specifically linguis-
tic representations. From (77), we understand the transaction as one in which
the subject/external argument/agent is the seller, the object/interior argument/
patient is still the goods. By the same token, (76) entails that the RS structure
agent is the seller, the patient is the goods, and the existence of a buyer and
funds is implied.
To make this clear, we might annotate role structure as in (79) and (80),
where “CTF” means that the verb evokes the commercial transaction frame.
(79)	 buy
	 syntax: V in [ __, NP]
	 F/A: Faa
	 RS: “CTF”, AGT (= BUYER), PAT (= GOODS)
(80)	 sell
	 syntax: V in [ __, NP]
	 F/A: Faa
	 RS: “CTF”, AGT (= SELLER), PAT (= GOODS)
Notice that in the case of the two verbs just discussed, harmonic alignment
obtains among the three structural linguistic components, the syntactic subject,
the semantic subject, and the highest role in role structure. This is not the case
for the verbs pay and cost, however, as the reader can easily see.
One more thing about the commercial transaction frame deserves men-
tion, namely the possibility of specifying the required elements of the frame
that are not found in the syntactic or F/A representations. In the commercial
Role structure and miscellaneous predicate classes   103
transaction frame an unselected element of the frame needs to be marked by a
preposition, and that preposition can be predicted on the basis of entailments,
which here can only be referred to role structure. For example, an element of
the commercial transaction frame that is not represented as a subject or object
of the verb will be marked in the syntax with the preposition for if it is either
funds or goods, that is, if it is one of the valuable entities in the frame, e.g., We
paid $400 for a TV, We bought the TV for $400. We can handle this fact with a
lexical entry for for that is specific to the commercial transaction frame:
(81)	 for ( CTF)
	 syntax: P in [ __, NP]
	 F/A: __ [ __, MFa
]
	 RS: ANC (= VALUABLE ELEMENT)
3.8.2	 The hay wagon
With certain verbs there is a well-known syntactic alternation between a usage
where one of the participants surfaces as an object and the other appears in
a prepositional phrase, and a usage in which those syntactic relations are
reversed. The standard example in the literature is the verb load that can have
the vessel that is loaded as object and the loaded material in the prepositional
phrase, or the material as the object with the vessel in a prepositional phrase.
In either case, the prepositional phrase can be left out.
(82)	 a.	 We loaded the wagon (with the hay).
	 b.	 We loaded the hay (onto the wagon).
Despite attempts to handle the contrast by rule, it seems to me that the rela-
tion between (82a) and (82b) is properly a lexical matter. There are close para-
phrases of load, such as fill, that have only the vessel as an object, and others
such as dump that have only the material as an object.
(83)	 a.	 We filled the wagon with the hay.
	 b.	 *We filled the hay into the wagon.
(84)	 a.	 We dumped the hay onto the wagon.
	 b.	 *We dumped the wagon with the hay.
To handle such facts, let us suppose first of all that the verbs in question all
have three-participant role structures:
(85)	 load1, load2, fill, dump …
	 RS: EVENT, AGT, PAT, ANC
Secondly, as with the commercial transaction frame, there is a material move-
ment frame (MMF) involving a MOVER, a MATERIAL, and a VESSEL, and
104  Role structure
these can be associated with the participants in the role structure of the verbs
that we are considering, just as the elements of the commercial transaction
frame are associated with the participants of the relevant verbs.
(86)	 a.  load, fill, pack
		 syntax: V in [ __, NP]
		 F/A: Faa
		 RS: “MMF”, AGT (=MOVER), PAT (= VESSEL), <<ANC>>
		 (= MATERIAL)
	 b.	 load, insert, dump
		 syntax: V in [ __, NP]
		 F/A: Faa
		 RS: “MMF”, AGT (= MOVER), PAT (= MATERIAL), <<ANC>>
		 (= VESSEL)
Note that load appears in both (86a) and (86b), and therefore an example
such as We loaded the trucks is ambiguous between a reading like insert and
another like fill, where the semantic objects bear different relations to the
action. The trucks might be loaded onto a ship or loaded with boxes.
Furthermore, as has been noted (e.g., in Hopper and Thompson 1980), We
loaded the wagon with the hay suggests that the wagon is completely loaded
while some of the hay might be left over, whereas We loaded the hay onto the
wagon suggests that all the hay is loaded and there might still be room on the
wagon for more. This makes sense on the account given here.Affectedness is one
of the properties that determines patientivity. The patient will, ceteris paribus, be
the more affected participant – the vessel in (86a) and the material in (86b).
The preposition that marks an ancillary vessel can be in, into, on, onto, inside,
on top of, and others. These prepositions clearly have their ordinary locative,
allative, or inessive significance in such examples and do not need separate list-
ing in the lexicon. A special listing for the preposition with is perhaps required,
though, since it is the only preposition that marks an ancillary material in the
material movement frame. With is the same preposition that marks ancillary
instruments in general, and perhaps the usage we are considering here can be
collapsed with it, but this with might deserve a separate entry along the lines of
(87), which again, requires reference to role structure:
(87)	 with (MMF)
	 syntax: P in [ __, NP]
	 F/A: MFa
	 RS: NP = (ANC (= MATERIAL))
An independent dimension of role structure makes it possible to account for
the otherwise problematic, obligatory third element found with the verb put. It
Role structure and miscellaneous predicate classes   105
is sometimes said that the word is subcategorized for an NP and a prepositional
phrase, but in place of the prepositional phrase we can also find adverbials
such as back and away that are clearly not prepositional phrases syntactically.
But if we say – correctly – that the verb is subcategorized for an adverbial
besides an NP, the description becomes far too liberal, allowing examples such
as *I put the book carefully/with care/yesterday/on Tuesday to be complete and
grammatical. If we try to distinguish the class of adverbials including prep-
ositional phrases that occur as complements of put we would have to weed
out manner adverbials, temporal adverbials, sentence adverbials, and so on. It
then becomes clear that it is meaning, not syntax that defines the set of oblique
complements of verbs like put.
This intuitive analysis can be straightforwardly formalized in an autono-
mous modular framework of grammar that includes role structure. The syn-
tactic field of the lexical entry for put will indicate that the verb requires an
NP and an adverbial in order to form a verb phrase. Despite the syntax, we
can take the verb to have only two semantic arguments, with the required
adverbial taken as a predicate modifier, which adverbs regularly are. The role
structure, like the syntax, has three participants, an agent, which by the usual
system will be the active participant, a patient, which will be the affected par-
ticipant, and an ancillary participant that signifies the endpoint of a movement
path in the cognitive frame, which I have indicated here with the annotation
“(= GOAL).”
(88)	 put
	 syntax: V in [ __, NP, Adv]
	 F/A: Faa
	 RS: “put”, AGT, PAT, ANC (= GOAL)
3.8.3	 Psych predicates
Verbs like frighten and embarrass signify event types that produce various
emotional states in an experiencer. On the other hand, verbs like fear describe
emotional states of the experiencer as they relate to events or entities. It might
be possible to show that the role assignment differs between the two classes,
especially in languages with rich cases systems where some or all of the
frighten class might take a dative object, which would provide some evidence
that the experiencer is an ancillary participant rather than a patient (Filip 1996).
For English, however, I know of no convincing evidence of this kind and will
therefore assume that the basic lexical entries are the same for both classes
when both the subject and the object are noun phrases.
106  Role structure
(89)	 a. 
frighten, scare, terrify, alarm, startle, upset, worry, amuse, entertain,
		 interest, bore, sadden, charm, embarrass, irritate, please …
		 syntax: V in [ __, NP]
		 F/A: Faa
		 RS: TYPE, AGT, PAT
	 b.	 fear, dread, like, hate, enjoy, appreciate, respect, love, dislike, detest …
		 syntax: V in [ __, NP]
		 F/A: Faa
		 RS: TYPE, AGT, PAT
As many have observed, however, there are important cognitive differences
between the two classes (Dowty 1991; Filip 1996). Even though the lexical
entries for these two classes of verbs are the same in all three dimensions of
representation, the role structure has actual semantic content from which the
relevant entailments can be deduced. Verbs of the frighten class ordinarily
describe events in which a change is produced in the experiencer’s emotional
status, whereas verbs in the fear class describe an emotional state – an attitude
that the experiencer has with respect to the stimulus. As such, the affected
experiencer in the frighten class has more patient-like characteristics than does
the predisposed experiencer in the fear class. Conversely, the stimulus has
more agent-like properties in events of the frighten type than it does in the case
of verbs such as fear, and may even be a conscious instigator of the effect.
Filip (1996) argues quite cogently that no single semantic property, not
telicity, not positive or negative effect, and not permanent effect are the sole
contributors to the assignment of agent and patient roles in the case of psycho-
logical predicates. Nor should one expect there to be one single, overriding
criterion in such cases, since the meanings they express lie some distance from
prototypical agent–patient cases. In English this is reflected in the fact that the
acceptability of passives of psychological predicates depends on the strength
of the proto-agent and proto-patient properties of the two participants. In gen-
eral, the more or less causative type in (90a) has a better passive than the more
or less stative variety in (90b).
(90)	 a.  The child was terrified by the spiders on the boat.16
>>
	 b.	 The spiders on the boat were dreaded by the child.
Perceived or encoded volitionality also plays a role, making (91a) better than
(91b), at least in my judgment. The degree of conscious control of the emotion
can improve passives for the non-causative type, so that (92a) is better to my
ears than (92b).
(91)	 a.	 I was frightened by three intruders. >>
	 b.	 I was frightened by three bacteria.
Role structure and miscellaneous predicate classes   107
(92)	 a.	 The gifts were very much appreciated by the children.>
	 b.	 The gifts were very much liked by the children.
In English such differences in meaning are enough to rank the proto-role status
of the two participants differently with different verbs. Since subject selec-
tion is largely based on alignment between the role hierarchy and the phrase-
­
structural syntactic hierarchy, differences in cognitive content will correlate
with differences in what will show up as the subject. The correspondence prin-
ciples of Chapter 2 can be used to predict such correlations from the level of
role structure that has been introduced in this chapter.
3.8.4	 Unaccusatives
Perlmutter (1978) distinguished between two types of intransitive sentences:
those in which the NP subject behaves similarly to the way the object of a tran-
sitive does, and those in which the sole NP term behaves similarly to the subject
of a transitive. The former he called “unaccusative” and the latter “unergative.”
Typical unaccusative verbs include arrive and fall, while intransitive sing and
eat are examples of typical unergatives. Numerous properties of various kinds
have been adduced over the years to illustrate grammatical differences between
unaccusatives and unergatives in a variety of languages.
Fluid case marking, or active/stative alignment, as in Lakhota (Van Valin
1977; Foley and Van Valin 1984), Tsova Tush (Holisky 1987), and a number
of other languages can be roughly captured by saying that subjects of unac-
cusatives are marked with the nominative (or absolutive) case while subjects
of unergatives are marked with the ergative case. For certain verbs, however,
either case can be used with a difference of meaning. For example, when the
subject of the verb meaning “fall” is in the ergative case, Holisky (1987) says
that it indicates that “It was my fault that I fell down,” but when it is in the nom-
inative, there is “No implication that it was my fault.”
Another commonly cited correlate of the distinction between unaccusatives
and unergatives involves the choice of auxiliaries in a number of European
languages.Yiddish, for example, uses either the auxiliary zayn “to be,” or hobn
“have” with the past participle to express the past tense of a verb.
(93)	 a.  Zi falt/kumt on. “She falls/arrives.”
	 b.	 Zi iz gefaln/ongekumen. “She fell/arrived.”
(94)	 a.	 Er iz/vert krank. “He is/becomes sick.”
	 b.	 Er iz geven/gevorn krank. “He was/became sick.”
(95)	 a.	 Zi zingt. “She sings.”
	 b.	 Zi hot gezungen. “She sang.”
108  Role structure
(96)	 a.	 Er est. “He eats.”
	 b.	 Er hot gegesn. “He ate.”
For all purposes of the combinatoric semantics and phrase structure syntax
the subject of both kinds of verb behaves as the highest argument in the struc-
tural tree. So there seems to be no reason whatsoever to count them as different
at those levels of grammar. There is, however, a clear cognitive generalization
concerning the verbs that take the auxiliary zayn “to be”: they are all verbs of
motion or being. This difference can be nicely represented in role structure as
a difference between verbs whose sole participant is a proto-agent and those
where certain Dowtian criteria make it a proto-patient:
(97)	 faln (Yiddish “fall”)
	 syntax: V in [ __ ]
	 F/A: Fa
	 RS: “faln”, PAT
(98)	 esn (Yiddish “eat”)
	 syntax: V in [ __ ]
	 F/A: Fa
	 RS: “esn”, AGT
InYiddish the distinction can pretty much be read straight off the actual mean-
ing of the predicates, according to the following rules:
(99)	
A sole participant whose movement or existence in a certain state is predi-
cated by a verb is a patient. Otherwise, it is an agent.
(100)	 V[AUX, PAST] → zayn iff its subject corresponds to PAT in RS17
(101)	 V[AUX, PAST] → hobn
We can allow (99) to operate to fill in unspecified roles, thus simplifying the
lexicon and capturing the cognitive generalization. But as a default specifica-
tion, (99) and similar principles in other unaccusative–unergative splits allow
for lexical exceptions. In Yiddish, for example, while the verbs zajn “to be”
and vern “to become” take the auxiliary zayn, as predicted, eksistirn “to exist”
takes hobn.
It is the case that the definition of agenthood and patienthood can depend
on different semantic properties or combinations of properties in different
languages. In Icelandic, auxiliary selection is regulated by something like the
same principle that we have seen in (100) and (101), but the quintessentially
unaccusative verbs vera “to be,” and verða “to become” select the auxiliary
hafa “to have,” rather than the auxiliary vera “to be.”
Summary  109
(102)	 Hann er komin til Reykjavíkur.
	 “He has come (came) to Reykjavik.”
(103)	 Hann hefur orðið góður læknir.
	 “He has become (became) a good doctor.”
(104)	 Eiður hefur verið óheppinn.
	 “Eiður has been (was) unlucky.”
Cross-linguistic comparison has shown that the class of verbs with the spe-
cial behavior typical of unaccusatives is by no means uniform. Furthermore,
even within a single language, grammatical properties that are associated with
unaccusatives do not always isolate exactly the same class of predicates. This
is an embarrassment to theories that allow only a binary choice, say, deep struc-
ture subject for unergatives versus deep structure object for unaccusatives. By
referring role-sensitive grammatical phenomena to entailments, however, dif-
ferent grammatical phenomena can be correlated with different entailments. In
German the selection of auxiliaries depends on agentivity/patientivity scales,
much as it does in Yiddish. German also allows passives of some but not all
intransitives. Those that are more agentive and take the auxiliary haben allow
impersonal passives, while those that are more patientive and take the auxil-
iary sein disallow them. But the two classes are not exactly the same. In (105)
we have an example in which there is a conjunction of verbs in the impersonal
passive, most of which take the auxiliary haben, as is to be expected, but one of
which – sterben, “die” – takes sein. Role structure is a level from which entail-
ments can be calculated. I submit that the entailments that figure in auxiliary
selection are not precisely the same as those that determine whether a verb can
occur in an impersonal passive.
(105)	
Hier wurde gestorben und geliebt, gefeiert und geweint, demonstriert und
getrunken … (Henke and Schwarz 2006)
3.9	 Summary
In this chapter I have introduced a level of role structure that includes real-
world meaning – semantics, in the logician’s sense. It is obvious to me that
linguistic structure must be recognized in describing natural languages and,
at the same time, truth-conditional meaning is important to linguistic descrip-
tion as well. In motivating the need for this new level, I have concentrated
on cases where entailments figure importantly in the determination of what
are ordinarily taken to be clearly grammatical phenomena  – case marking,
passive versus active, the determination of the reference of the syntactically
110  Role structure
empty counterpart to PRO, which I call RHO, alternations having to do with
the choice of subjects and objects in particular cognitive realms, and the phe-
nomena that are dealt with under the rubric of unaccusativity.
In the case of the active–passive alternation, I have argued that the facts can-
not be handled as a mismatch between syntactic and F/A level subjects, since
agentless passives have only one syntactic term and only one F/A argument.
Rather, the resemblance between actives and passives has to do with cognitive
content, and not with structural form. While there is no agent to be found in
either the syntax or F/A structure in agentless passives, there is one in the cog-
nitive scene. There is, in other words, a mismatch between role structure roles
and both syntactic form and logical form.
I have chosen to present role structure in terms of a very simple phrase struc-
ture grammar so that this level can be easily compared to, and in default cases
matched with, the purely structural levels introduced in the previous chap-
ters. The constituents of this level are not determined arbitrarily, but are read
off semantic entailments of the kind Dowty proposed in his important work
on proto-agents and proto-patients. In the later sections of the chapter, how-
ever, it turned out that a simple three-way proto-role distinction that is always
determined according to the same set of entailments within a single language
(let alone universally) is inadequate, and access must be provided to entail-
ments of various kinds as playing a role in various grammatical phenomena.
What I offer here should be taken, then, as merely a demonstration of how
grammatically relevant aspects of meaning can be dealt with formally in an
automodular theory of grammar. It is my hope that the much more thorough
and insightful work of lexical semanticists (e.g., Levin and Rappaport-Hovav
2005) can be imported naturally into the kind of grammar that I am arguing
for in this book.
111
4	 The linear order component
4.1	 The independence of linearization
One absolute universal of human language is that it is temporally segment-
able and the segments are presented and apprehended in linear time, whether
they are intonational (or gestural) peaks and valleys, phonemic signals, words,
phrases, or utterances. Since I have little to say about phonology in this book, it
will suffice to assume that there are such things as words and that they occur in
any actual expression in a particular sequence from earlier to later. The order of
words is commonly regarded as the province of ordinary syntax, but it is also
clearly influenced by rhetorical forces, as the Prague School linguists stressed
(see, for example, Firbas 1992), by processing factors (Hawkins 1994), by the
scope of quantifiers (Aoun and Li 1993)), by considerations of the relative
weight of the ordered elements (Wasow 1997), by iconicity (Haiman 1985),
and by prosodic and other phonological factors (Cooper and Ross 1975), among
other things. All of these systems play a role in determining how to resolve the
problem of presenting the pieces of language in the dimension of time. In the
context of a theory that is founded on the assumption of the autonomy of vari-
ous structural and meaningful components, the inescapable conclusion, then,
is that linear order is the province of a separate dimension of representation,
correlated with all the others, but essentially independent of any of them.
4.2	 The linear order component (LOC)
The principles of this component are not as intricate nor, indeed, as interesting
as those of the others that have been discussed so far. In its simplest form, the
linear order component says nothing more than that the units of language occur
in a sequence. However trivial this sounds, it is an irreducible truth about human
language. Formally, we may state this by assuming a finite state grammar whose
basic function is to place the phonemes, syllables, words, phrases, and utter-
ances in a specific sequence. If we formulate the finite state machine as a one-
way branching grammar, then there are two possibilities – either a uniformly
112  The linear order component
right-branching grammar as in (1), or a uniformly left-branching grammar as
in (2):
(1)	 Σ → w (Σ)
(2)	 Σ → (Σ) w
If w is a variable whose domain is the set of words that comprise the vocabu-
lary of a language, then either of the grammars above will produce all possible
sequences of words. This formalism has the handy property of assigning a hier-
archical (albeit not very exciting) structure to any string of words, making its
representations easy to compare directly with the hierarchical representations
sanctioned by the other components, which we have taken to be order free.
The overarching principle of the componential interface is that representa-
tions in any two modules tend to align. Therefore we should expect that the
hierarchy corresponding to the order given by one or the other of the grammars
(1) and (2) should align to some extent with each of the independent modules
discussed in the previous three chapters. Let us consider syntactic structure
first, where this expectation is clearly not disappointed.
In a great many languages lexical heads tend fairly uniformly to precede
their complements, or fairly uniformly to follow them. The reason for this
under the present conception of grammar is as follows: according to (1),
every word asymmetrically c-commands every word on its right, and accord-
ing to (2), every word asymmetrically c-commands every word on its left. In
the phrase structure syntax, a lexical head, ordinarily a word, asymmetrically
c-commands any word of its complement.1
The syntax imposes only hier-
archical structure on the elements it deals with, not linear order, as indicated
by the commas, a notational device I have adopted from Gazdar et al. (1985).
Given the principle of Conservation of C-command (Chapter 2 (24b)), if A
c-commands B in syntax, then A′ should, ceteris paribus, c-command B′ in
the linear order component, where c-command is directly related to linear
order. Therefore in a language that follows the right-branching linear order
regime a lexical head will precede all other words in the phrase it heads, as
shown in (3a), and it will follow all other words of its phrase in a language
that works according to the left-branching regime, as we see in (3b).
(3) a. Right-branching linear order component
syntax LOC
LP
L YP
Σ
Σ
w1 w1�
w2, w3 … w2�, w3� …
Language-particular ordering facts  113
But the account of linear order in natural languages is rarely this simple. Even
when it comes to syntax, the alignment with linear order is not always calcul-
able according to the above considerations. In phrase types that are not lexic-
ally headed, for example, we cannot attribute constituent order to c-command
alignment between syntax and linear order components because the words of
a non-lexical sister do not generally c-command the words of another non-
lexical sister phrase. The general preference for subjects to precede objects,
for example, does not follow from c-command relations between syntax and
the linear order component in languages with no VP, since the syntactic sub-
ject and the syntactic object c-command each other. Different forces must be
at work here, all of which can be understood as hierarchical in nature and thus
in principle associated with the hierarchy of left-to-right order. Keenan (1976)
takes high position on a number of independent hierarchies as definitional of
subjecthood. These include wide semantic scope, domination by the root node
in the syntactic tree, and – relevantly – leftmost position in linear order.
Once again it is the existence of an independent linearization component
coupled with the tendency for hierarchical relations in various dimensions to
align that can be made to account for the widespread tendency for subjects to
come before objects.
4.3	 Language-particular ordering facts
The general tendencies described above are often supplemented or partly over-
ridden by more parochial sequential requirements in individual languages.2
For
example, modern Romance languages are basically head initial, so that verbs
and adpositions precede their objects, and nouns precede their modifiers. But
pronominal objects have special ordering requirements, occurring in a special
templatic order that varies from language to language within the family and
from dialect to dialect within a language. Pronominal objects occur earlier than
corresponding non-pronominals, as preclitics to the finite verb, for example.
Assuming that the pronouns still fill syntactic positions, that is, that they are
nodes in the syntactic phrase structure tree, special linear order privileges have
to be assigned to them. The place to do that in the model under discussion here
is in the linear order component.
b. Left-branching linear order component
syntax LOC
LP
YP L Σ
Σ
wn+1
wn+1
w1, w2, … wn w1, w2, … wn
114  The linear order component
Forty years ago David Perlmutter (1971) suggested handling the ordering
facts concerning Spanish and French pronominal objects and other clitics by
means of surface structure constraints or filters. His constraint for French stip-
ulated the following order of elements:
(4)	 [NOM] > ne > me/te/nous/vous/se > [3, ACC] > [3, DAT] > y >en > V[FIN]
We may take Perlmutter’s template and restate it as a special rule that connects
the linear order component with morphosyntactic categories. Simplifying his
formula somewhat for the sake of clarity, we can restate his observations as the
intermodular connection below:
(5) =
Σ α β γ δ ε
<< << << << << …
VP = (ne) (PRN) (PRN) (PRN) V …
[1/2/REF] [3, ACC] [3, DAT] [FIN]
(6) =
Σ α β γ δ
< < <
VP = V NP PP VP/S'
The first line in (5) is an equation connecting a string variable Σ with a sequence
of elements, α–ε, in the order given. The symbol “<<” is to be interpreted “imme-
diately precedes.” If both elements are present they must occur in the stated order
with nothing intervening between them. The second line of (5) provides infor-
mation about the elements ordered in the first line, where the information comes
from other modules of grammar, here mostly syntax, but also a lexically defined
element ne. The feature PRN is presumably morphological. The vertical lines in-
dicate connections that hold between these categories and the ordering given in
the first line. Parentheses around a category mean that the category need not be
present within the verb phrase, but if it is, it must bear the indicated ordering re-
lation to any other mentioned categories that are instantiated in the verb phrase.
To take another example, when a verb has two or more subcategorized com-
plements, they usually all occur as sisters at the same rank within the verb
phrase. Nevertheless, there is in English a preferred order of complements
that depends upon their syntactic category, namely, (6). (Here the symbol “<”
means “precedes,” but not necessarily immediately.)
We could leave it at that, saying, in essence, that it is simply a brute fact that
the elements of the verb phrase occur in this order. In the earliest generative
grammar, order was included just that stipulatively in the phrase structure rules
Language-particular ordering facts  115
that developed the verb phrase. In GPSG (Gazdar et al. 1985) a linearization
of the pieces of a verb phrase is stated separately, but in an equally ad hoc way.
In much work of the Principles and Parameters type, the position of the object
NP immediately after the verb is attributed to its need to get Case. The NP in a
prepositional phrase gets Case from the preposition, so it need not follow the
verb directly, even if it is subcategorized. Kayne (1994) offered a hierarchical
connection between X-bar position and word order that says, in essence, that
specifiers precede what they specify and complements follow what they are
complements of, but this is again a stipulation following from no independ-
ently needed assumptions, so far as I can see.
But I think that there is a naturalness to the order of elements we see in (6)
that ought to be captured in an adequate description. The constituents to the
right of the verb follow a natural hierarchy of syntactic complexity, more com-
plex constituents following less complex ones. Given the very simple syntax
embodied in Chapter 1 (14), a clause must have a VP as an immediate daugh-
ter, and while VP may have a clause as a daughter, it doesn’t need to; the verb
phrase can immediately dominate a prepositional phrase, but not vice versa;
and one immediate daughter of a prepositional phrase must be an NP, but on
the theory that the structure of NP is [Det, N′], the reverse is not true. Relative
complexity seems to be determined according to the following definitions:
(7)	 Relative Syntactic Complexity
	 XP is syntactically more complex than YP if either
	 a.	 XP must immediately dominate YP, but YP need not immediately
		 dominate XP, or
	 b.	
XP may immediately dominate YP, but YP cannot immediately
dominate XP.
This definition of syntactic complexity yields the hierarchy in (8), ranking
phrase types from lesser to greater complexity.3
(8)	 Syntactic Complexity Hierarchy
	 NP < PP < VP < S4
Let me now make the following assumption explicit: any linguistic hier-
archy can induce harmonic effects with other hierarchies. This includes the
hierarchies defined by the phrase structure grammars of the various modules,
but also others, such as the Complexity Hierarchy (8).
Due to the general tendency for hierarchies from different modules to align,
then, (9) will be expected to hold, other things being equal.
(9) =
Σ α β
<
Ci Ci+n
116  The linear order component
The alignment of Syntactic Complexity with linear precedence will, other
things being equal, achieve the desired ordering of parts of the verb phrase in
English without the need to say anything more. But it expresses itself in other
ways and in other languages as well, for example, in the likelihood of vari-
ous kinds of constituents being found later or earlier than would otherwise be
expected.
Consider the order of VP constituents in Yiddish and German, two closely
related languages. In Yiddish, direct objects may appear either between the
finite and non-finite verbs of a clause or after the non-finite verbs, as in the
examples in (10), both from a story by Ayzik-Mayer Dik (1993):
(10)	 a.	 Er hot dem ksav untergeshribn …
		 he has the letter signed
		 “He signed the letter …”
	 b.	 Zey hobn opgeshribn dem ksav …
		 they have written the letter
		 “They wrote the letter …”
In German the direct object categorically occurs between the finite and non-
finite parts of the verb.
(11)	 a.	 Adenauer hat den Brief unterschrieben …
		 Adenauer has the letter signed
		 “Adenauer signed the letter …” (Hübsch 2002, 70)
	 b.	 *Adenauer hat unterschrieben den Brief.
In both Yiddish and German a prepositional phrase may be found in either
position, but inYiddish the later position is far more common than the position
between the finite and non-finite verbs, while the reverse is true for German.
(12)	 a.	 Vi Dine iz in shtub arayngekumen …
		 as Dine is in house entered
		 “When Dine came into the house …” (Grözinger 2008, 575)
	 b.	 Moyshele iz arayngekumen in shtub …5
		 Moyshele is entered in house
		 “Moyshele came into the house …”
(13)	 a.	 Ich bin in Berlin geboren.
		 I am in Berlin born
		 “I was born in Berlin.”
	 b.	 Ich bin geboren in Berlin.
		 I am born in Berlin
		 “I was born in Berlin.”
The preference for the prepositional phrase to occur in the earlier position, in
the Mittelfeld, as it is termed in traditional German grammar, is clear from the
fact that an internet search on March 6, 2011 found 31,800 instances of (13a),
Language-particular ordering facts  117
versus only 2,560 of (13b). Statistics forYiddish are much harder to obtain, but
it is my strong feeling that the order of elements in (12a) is quite unusual.
An infinitive phrase in Yiddish may only follow the non-finite verb, but in
German it may also precede it, though it is less commonly found there.
(14)	 a.	 hot er gelozn shteyn dem vogn mitn erdl [sic] oyf droysn,
		 has he let stand the wagon with-the horse on outdoors,
		 “He left the horse and wagon outside,” (Prince 1993)
	 b.	 *hot er dem vogn shteyn golozn oyf droysn
	 c.	 *hot er shteyn gelozn dem vogn oyf droysn
(15)	 a.	 Die Geschichte … hat mir geholfen zu verstehen, was …6
		 The story … has me helped to understand what …
		 “The story … has helped me to understand what …”
	 b.	 … und mir zu verstehen geholfen, was eigentlich passiert.7
		 … and me to understand helped what actually happened.
		 “… and helped me to understand what actually happened.”
In both languages, however, finite clauses must follow the non-finite verb:
(16)	 [er] ken gor nit gloybn az emitser ken zayn aza min idyot …8
	 [he] can absolutely not believe that someone can be such type idiot …
	 “[he] absolutely can’t believe that anyone could be such an idiot …”
	 *[er] ken az emitser ken zayn aza min idyot gor nit gloybn …
(17)	 Ich kann nicht glauben, dass ich so ein Glück habe.9
	 I can not believe that I such a happiness have.
	 “I can’t believe that I have such happiness.”
	 *Ich kann dass ich so ein Glück habe nicht glauben.
On the well-supported analysis that takes German to be a language in which the
verb is final in theVP andYiddish as one in which the verb is initial in theVP, one
would have to say that in German, NPs may not, but clauses must be extraposed.
For Yiddish, however, it would be necessary to say that NPs may, and clauses
may not be interposed. Such a treatment misses an obvious generalization, one
that is found to some extent in most or perhaps even all languages: elements of
greater complexity tend to occur later than elements of lesser complexity.
Furthermore, it is a striking fact that Yiddish is more inclined toward post-
verbal position than German, but the same hierarchy of complexity is opera-
tive in both languages. In German, an object NP must be found medially, but
in Yiddish it may be found finally. In both German and Yiddish, prepositional
phrases may be final, but that position is far less common in German than in
Yiddish. Infinitive phrases usually follow the non-finite verb in German, but
they often occur in the earlier position, whereas in Yiddish they may not occur
earlier. Sentential complements may not be medial in either language. What we
see, then, is that Yiddish is one degree less tolerant of middle-position phrases
than German for every position on the hierarchy in (8).
118  The linear order component
4.4	 Verb second in Germanic
All Germanic languages sometimes position a finite verb immediately after
a single syntactic constituent of a clause under various conditions that differ
from language to language. While not completely unprecedented, the phenom-
enon is only rarely attested in other language families. It has been shown to be
a feature of Kashmiri (Rakesh Bhatt 1999), for example. It therefore seems that
a special statement in the linear order component is required to order some of
the basic sentence elements of Germanic languages and that the peculiar prop-
erty that this small family shares is not derivable from widely attested general
principles of language.
The linear order component includes some version of the following template
in all Germanic languages, restricted in different ways from language to lan-
guage as will be briefly discussed below:10
In German, for example, the clause to which the verb-second template
applies cannot be preceded by an overt complementizer, a fact that can be
included in the statement of the rule.
Generally speaking, the linear order component is a more parochial, more
language-specific component than is syntax, just as syntax is a more particular
component than semantics. For this reason, linear order statements are more
demanding than the more general rules. In cases of direct conflict between
word-order requirements of the linear order component and constituent struc-
ture requirements in syntax, the demands of the linear order component are
normally satisfied rather than those of the syntax (see Chapter 7 (2)) (ref). Thus
if an element other than the syntactic subject is first (often for the reasons that
we will take up in connection with information structure in Chapter 7) then the
next element will be the finite verb. This forces the subject to occur no earlier
in the string than the third position, and forces the finite verb to be in second
position, even in languages such as German and Dutch where it is otherwise
(18) =
Σ α β
<<
S = [XP V[FIN] … ]
(19) V2 rule for German
If w is not [Comp], then:
=
Σ α β γ
<< <<
YP = [ … w [S XP V[FIN] . . .]]
Verb second in Germanic  119
last. We therefore interpret (19) as saying that if the elements governed by the
template are present, then its demands must be met regardless of more general
ordering forces emanating from alignment tendencies with other dimensions
of grammar.
In German, Dutch, Yiddish, and (with important exceptions) Scandinavian,
the element β in (19) is not restricted by the linear order component, so the
finite verb will be second regardless of the nature of the element of S that is
found in first position. The linear order component rule responsible for this
ordering is most widely applicable inYiddish, where it applies to clauses of all
types (Diesing 1990), but it is less productive in other Germanic languages, as
we have already seen in German.
In continental Scandinavian languages the template allows certain excep-
tions when the clause is introduced by an overt complementizer (see Vikner
1995 for a thorough discussion in the Minimalist framework). Thus we find the
following contrast in Danish:
(20)	 a.	 Hans	 siger	 at	 hann	 ikke	 kommer.
		 Hans	 says	 that	 he	 not	 comes.
		 “Hans says that he’s not coming.”
	 b.	 Hans	 siger	 hann	 kommer	 ikke.
		 Hans	 says	 he	 comes	 not.
		 “Hans says he’s not coming.”
One important complication needs mentioning. The finite verb is sometimes
initial in all Germanic languages, for example in polar questions in all the lan-
guages but Yiddish, in imperatives, and in sentences understood as expressing
consequent action in some German dialects and Yiddish.11
A Yiddish sentence
like Geyt er aheym, literally goes-he-home means something like “after that,
he goes home.” In Chapter 6 defective lexical items that lack representation in
one or more components will be taken up. Lexical items that lack phonological
content form an important subset of them. I will somewhat hesitantly propose,
then, that there is a phonologically null12
element in Yiddish with a meaning
very like nokhdem “afterward” that occupies an initial position in the order of
elements in a clause, making the surface-initial verb in fact the second element
in the syntax, just as it is in Nokhdem geyt er aheym.
(21) NSA (Yiddish null sentence adverbial)
syntax: ADV in [ __ S]
F/A: Fp (equivalently, Mp)
LOC: =
Σ α β
< <
S = [ NISA V[TNS] … ]
mphon: nil
120  The linear order component
4.5	 Pronoun position in Germanic
Yiddish generally places the verb at the left periphery of the verb phrase, its
complements following. Thus when there are auxiliary verbs, each auxiliary
verb will have the head verb of its complement immediately to its right, and the
main verb will have its complements to its right, much as in English.
(22)	 Oyb ir volt gekent gefinen andere mentshn …13
	 If you would been.able find other people …
	 “If you would be able to find other people …”
As in French, pronominals in some Germanic languages appear in a tem-
platic order earlier in a clause than the corresponding non-pronominal terms.
When the objects of a verb are non-pronominals, they occur in the order in-
direct object–direct object. But in some of the languages, when the comple-
ments are pronouns, they occur in a stipulated order following the finite verb
and preceding the non-finite verbal elements. For example, Yiddish places the
pronouns in the Mittelfeld – after the finite verb and in the order direct object–
indirect object – whereas full NPs appear at the end of the string of verbs in the
order indirect object–direct object.
(23)	 a.	 Got hot gegebn dem nar hent un fis.14
		 “God has given the fool hands and feet.”
	 b.	 Der daytsh hot zey im nokhgevorfn afn toytn vogn.
		 The German has they him thrown.after on.the corpse wagon
		 “The German threw them after him onto the corpse wagon.”
		 (Halio and Siegel 1997, 62)
The Yiddish template is rather similar to Perlmutter’s template for French
clitics in (4), but whereas an argument can be made that (4) describes morph-
ology, all of the evidence points to the non-morphologized status of theYiddish
pronouns. Unlike French, they may be stressed, conjoined, and even interrupted
by small elements such as dokh “however” and take “indeed,” as in the follow-
ing example from Sholem Aleykhem’s (1925) story “Der daytsh.”
(24)	 Hoybt	 dokh	 mikh	 mistome	 mayne	 on	 tsu	 traybn …
	 Begin	 in fact	 me	 perhaps	 mine	 Prt	 to	 nag …
	 “Then my wife actually starts to nag me, wouldn’t you know …”15
In light of these considerations, we may set up a linear order template for
Yiddish that refers to a combination of morphological and syntactic features:
(25) Σ α ζ
β ε
δ
γ
= << < < < < …
S = XP V PRON PRON PRON PRON
[FIN] [NOM] [REFL] [ACC] [DAT]
Verb second in English  121
Since (25) is a rule of the linear order component and takes precedence over
considerations of syntactic constituency, the pronouns can fulfill their ordinary
roles as complements in the hierarchical syntactic tree without occurring in a
contiguous sequence with the heads that they are complements of. Consider
a simplified version of (24) without the little words dokh and mistome. In its
analysis at the syntactic level, the (headless) NP mayne can be taken to be the
subject of the sentence and the pronoun mikh can still be the direct object of the
infinitive traybn “nag,” despite their positions in the linear string:
Notice especially that all of the words in this example that are not ordered by
the LOC template (25) occur in the same order as in Mayne hoybt on tsu traybn
dem shokhn “My (wife) began to nag the neighbor,” a sentence to which the
template does not apply and in which more general ordering principles are in
effect. (For more on this treatment of Yiddish word order, see Sadock 1990a,
and Yuasa and Sadock 2002.)
4.6	 Verb second in English
The verb-second template in English is highly restricted compared to the gen-
eral schema in (18). What is unique in English is that there are conditions
on both XP and V[FIN] and upon the domain in which the general template
(18) applies.16
In particular, XP must be a wide-scope negative phrase in F/A
structure, a WH-element, or one of a few other elements with operator-like
(26) S
AdvP NP VP
NSA mayne
V[FIN] VP[tsu] Syntax
V[FIN]
hoybt on tsu VP
V[INF] NP
traybn PRON[ACC]
hoybt mikh
XP V PRON
[FIN] [ACC]
XP V PRON mayne on tsu traybn LOC
[FIN] [ACC]
122  The linear order component
semantics. V[FIN] can be not just any finite verb, but must be a finite aux-
iliary verb, a notion that will be dealt with in detail in Chapter 5, where it
will be shown that for most purposes it is sufficient to refer to the category
V[TNS]. The special statement relating elements of syntax to a particular order
of presentation is, accordingly, (27). What follows the pieces whose order is
specified by (27) are elements that are ordered by more general principles. For
example, since subject NPs are regularly initial in English under the pressure
of their hierarchical position in other modules, they will precede everything in
the domain to which the rule applies except for XP and V. Under inversion, in
other words, subjects will normally follow the finite auxiliary immediately.
Now let us consider polar questions in English that begin with a finite aux-
iliary. Just as I postulated a phonologically null adverbial inYiddish that occu-
pies initial position in a clause and requires inversion, I will postulate a null
interrogative sentence adverbial in English that triggers the same inversion
order as overt WH-elements.
The reason that subject interrogatives like (29) do not have altered word
order, and are well formed without auxiliary verbs will be presented in Chapter
5, where that fact follows without stipulation.
(29)	 Who wants pizza?
4.7	 Long-distance dependencies
In the sections that follow I will present just the briefest outline of a treatment
of unbounded dependencies in an effort to illustrate the utility of an autonomous
dimension of linear order. Long-distance dependencies have been the subject
of an enormous amount of research centering particularly on the constraints
on movement in those theories that use movement. It would be impossible to
address more than a tiny fraction of the results that have been achieved and the
(27) Σ α β
= < <
#S# = [XP[NEG/WH] V[TNS] … ]
(28) Null interrogative sentence adverbial (NISA):
syntax: ADV[WH] in [S[INT] __ , S]
F/A: Fp (equivalently, Mp)
LOC: =
Σ α β
< <
S = [NISA V[TNS] … ]
mphon: nil
Long-distance dependencies  123
problems that remain, so what I will do is show how a multi-modular grammar
can handle some of the most robust of the structural constraints on movement,
including the Coordinate Structure Constraint and the Complex NP Constraint
of Ross (1967a). I assume along with many, that the various kinds of constraints
that have been suggested comprise a heterogeneous class, and I assume along
with a few that some of the factors influencing the acceptability of long-distance
dependencies are not structural in nature. Sag, Hofmeister, and Snider (2009),
for example, present experimental evidence supporting the claim that Ross’s
complex noun phrase constraint can be dispensed with in favor of independently
motivated processing considerations. Even supposing that Sag, Hofmeister, and
Snider are right, I believe that structural features can at least be used to elucidate
what it is that makes Complex NP Constraint violations difficult, and I will offer
an account of their variable unacceptability in terms of mismatches between
various dimensions of representation and linear order.
Sag, Hofmeister, and Snider (2009) do, however, accept the structural nature
of the Coordinate Structure Constraint. To handle it, I will first have to flesh
out the multi-modular treatment of unbounded dependencies and then make
some specific commitments regarding the syntax and semantics of coordinate
structures. I begin with a discussion of interrogative clauses introduced by an
interrogative NP.
4.7.1	 The independence of syntactic constituency and linear order
A clause-initial interrogative phrase that is positioned there by the special lin-
ear order statement in (27) can fulfill a syntactic requirement imposed by a
word or phrase that is separated from the interrogative phrase’s linear position
by any amount of syntactic material, an important fact that helped to motivate
the movement treatment of interrogative clauses early on in the history of gen-
erative grammar. In (30)–(32), the NP what counts as the object of the obliga-
torily transitive verb take (Chapter 2 (5)), but occurs at various removes, both
in terms of string length, and number of intervening nodes:
(30)	 What did Mary take?
(31)	 What did Mary claim that she took?
(32)	 What did Mary claim that I said she took?
Since linear order and syntactic structure are separate matters in the present
model, there is no reason in principle why the sentence-initial NP in examples
(30)–(32) cannot still function in the syntactic module as the complement of
the verb take. In a manner similar to what we saw in connection with the pos-
ition of pronouns in Yiddish, there is a modular mismatch here between the
124  The linear order component
phrase structure position of an NP and its position in the linear string of words.
Diagram (33) shows the mismatch presented by (30).
As in the other cases discussed in this chapter, there is no movement rule,
just a discrepancy between representations in two autonomous dimensions.
The inversion template is stronger than the syntax and can therefore override
it, and when it does, the second element must be a member of the category
V[FIN] and hence an auxiliary, in this case did. These features of English will
be described in detail in Chapter 5.
4.8	 Conjunction
The fundamental facts of conjunction in natural language can be modeled in
the framework of automodular analysis in a now familiar way: conjunction will
receive separate treatment in several modules the representations from which
will be associated by the rules of the interface. In particular, ordinary conjunc-
tions have values in syntactic structure, function-argument structure, and role
structure. They are also subject to linear order requirements that vary from
language to language.17
4.8.1	 The syntax of conjunction18
The most general treatment for conjunction in syntax would allow like syntac-
tic categories to be conjoined, producing a phrase that is of the same category
as the component conjuncts. It seems reasonable to assume that there may be
any number of conjuncts conjoined in a flat structure, though other analyses
might turn out to be better motivated. Neglecting for the moment the all-im-
portant conjunction itself, the general syntactic schema for conjunction would
be (34), inducing trees like (35).
(34)	 X → Xn
, where n ≥ 2
(33) S
NP VP Syntax
Mary
V[TNS] VP
did
V NP
take what
XP < < V … LOC
[NEG/WH] [FIN]
Conjunction  125
Since the conjoined phrases are of the same type as the daughter phrases,
they may themselves be conjoined with other phrases of the same type. Thus
(36) can have different syntactic structures, viz. (37a)–(37c) (neglecting for the
moment the positioning of conjunctions).
(36)	 Tracy and Jamie and Kim
Now let us consider the conjunction itself, part of the lexical entry for which
is given in (38). The rules introducing conjunctions in phrase structure are (39)
and (40).
(38)	 or
	 syntax: Conj
(39)	 X → X1+n
, X[CONJ]
(40)	 X[CONJ] → Conj, X
Rule (39) says that a conjoined phrase X consists of one or more phrases of
category X and exactly one phrase of category X that bears the special feature
[CONJ]. (40) expands the specially marked category X[CONJ] as a conjunc-
tion and a phrase of type X.
Recall that syntactic rules specify hierarchy, but not order. It is a fact of
English and a great many other languages that a conjunction is associated with
the last of a series of coordinated constituents. In English it is also the case
(37) a. NP
NP
Tracy
NP
Jamie
NP
Kim
b. NP
NP NP
Tracy
NP NP
Jamie Kim
c. NP
NP NP
Kim
NP NP
Tracy Jamie
(35) X
X1, X2, … Xn
126  The linear order component
that the conjunction precedes the phrase it is associated with. Rules (41a) and
(41b) accomplish this by relating syntactic structure and linear order. The first
of these says that the special conjunct with the feature [CONJ] is the last of the
conjuncts and the second says that in a phrase of type X[CONJ] containing a
conjunction, the conjunction immediately precedes its sister.
Regardless of how many conjuncts there are in a coordinate phrase, (39),
(40), and (41) together guarantee that there will be only one conjunction and it
will be positioned immediately before the last conjunct.
There are therefore three constituent structures for (36) including conjunc-
tions that are illustrated in (42)–(44).
(42) NP
NP NP NP[CONJ]
Tracy Jamie
and NP
Kim
(43) NP
NP NP[CONJ]
Tracy
and NP3
NP NP[CONJ]
Jamie
and Kim
(44) NP
NP NP[CONJ]
NP NP[CONJ] and NP
Tracy Kim
and NP
Jamie
(41) a. Σ β γ
Σ β γ
= … < <
X = [ … X X[CONJ]]
b. = < <
X[CONJ] = [ Conj X ]
Conjunction  127
These are the only analyses that are consonant with (39), (40), and (41) and
they are all intuitively reasonable on both intonational and semantic grounds.
A fourth structure in which a conjunction is found before each constituent is
possible, a sequence that is often pronounced with an intonation indicating the
bracketing in (45):
(45)	 ((Tracy) (and Jamie) (and Kim))
We therefore require a further rule that includes a conjunction before every
conjunct except the first:
(46)	 X → X, X[CONJ]n
4.8.2	 Bipartite conjunctions
To accommodate the bipartite conjunctions both … and, either … or, and nei-
ther … nor we add rules (47a–c) to our list of rules that expand XPs. These rules
introduce a feature [FRST] that distinguishes the first of the paired, bipartite
conjunctions, viz., both, either, and neither, from Conj without this feature, the
same set of items as in the previous rules, namely and, or, and nor.
(47)	 a.	 X → X[CONJ, FRST, BOTH], X[CONJ, AND]
	 b.	 X → X[CONJ, FRST, EITHER], X[CONJ, OR]
	 c.	 X → X[CONJ, FRST, NEITHER], X[CONJ, NOR]
Since these rule do not order the elements to the right of the arrow, (48) is
needed to ensure the correct order.
Making use of features that are introduced by individual lexical items, we
may now list the various conjunctions by means of the partial entries in (49a,b)
and similar rules for the other pairs of conjunctions.
(49)	 a.	 both
		 syntax: [CONJ, BOTH]
	 b.	 and
		 syntax: [CONJ, AND]
The rules above provide only for an initial and a final conjunct.Thus both Cohen
and Cohan is syntactically well formed, but *both Khan, Cohen, and Cohan is not.
This result is correct for a great majority of speakers, but many speakers accept
similar examples with disjunction: either Cohen, Khan, or Cohan. I will let the
reader consider how the language of such speakers can be formally described.
(48) =
Σ α β
<
X = X [CONJ, FRST] X [CONJ]
128  The linear order component
There are several other peculiarities of the bipartite conjunctions that are not
covered by the rules above. For example, both … and cannot introduce clauses
without overt complementizers: *I know both Smith left and Jones stayed,
though they can introduce clauses introduced by complementizers (I know both
that Smith left and that Jones stayed). These details will also not be formalized
here, but once again, I invite readers to think about how they might be.
4.8.3	 Semantics of conjunction
The older tradition in logic was to treat all conjunctions as elements that took
truth values of propositions as arguments and returned truth values. Thus a sen-
tence such as Three and five are odd numbers would be given a logical analysis
like (50), despite its syntax.
(50)	 ∧ ((ODD(3)), (ODD(5)))
In many cases such an analysis can be upheld, but there are well-known
examples where a conjunction of syntactic constituents smaller than a clause
cannot be formalized as a conjunction of propositions, e.g., Jen’s paper com-
pared Shakespeare’s sonnets and Ludicris’s raps, or Three and five are eight.
The latter, for example, is not equivalent to Three is eight and five is eight.
Furthermore, as Keenan and Faltz (1978), Gazdar (1981), and others have
shown, it is perfectly possible to develop a cross-categorial semantics for coord-
ination such that in certain cases, the truth conditions for a semantic structure
with sub-propositional coordination come out identical to the truth conditions
of a conjunction of propositions. I refer the reader to their work for details that
can readily be imported into the present framework as principles for determin-
ing truth conditions of propositions containing non-propositional conjunction
in F/A structure.
As to the combinatoric semantics, let us begin with the assumption that
semantic conjunction is like syntactic conjunction: F/A structure conjunction
is the composition of logical phrases of the same F/A category to form more
complex phrases of the same category: predicates may be conjoined with pred-
icates to form predicates, arguments may be coupled with arguments to form
arguments, and so on. Logical conjunctions are binary modifiers that apply to
two categories of the same type and return a category of the same type, the
schema for which is (52), where φ is a variable over function-argument types.
The logical properties of the conjunctions will then be lexically specified sim-
ply as (51).
(51)	 AND/OR/NOR
	 F/A: CONJ
Conjunction  129
(52)	 φ3 = CONJ(φ1, φ2)
A more complete lexical entry for or would then be (53):
(53)	 or
	 syntax: Conj[or]
	 F/A: [CONJ, OR]
4.8.4	 The Coordinate Structure Constraint and the
across-the-board exception
The analysis of the position of interrogatives, relative pronouns, topical-
ized phrases, and so forth, creates a mismatch between linear order and
syntactic constituency as presented in section 4.7 above. We now have in
place enough of an analysis of unbounded movement and coordination to
deal with the Coordinate Structure Constraint of Ross (1967a), the fact that
the mismatched item cannot come from just one conjunct. I have argued
that out-of-order elements are not necessarily outside of their hierarchical
syntactic constituents. Therefore it would seem that (54) ought to have the
same well-formed syntactic structure as (55) and be just as acceptable as
(55) is.
(54)	 *What exam has that student bought a term paper or cheated on?
(55)	 That student has bought a term paper or cheated on what exam?
However, there is another dimension of representation involved: the combi-
natoric, function-argument semantics. At that level, the interrogative NP is a
logical binder with scope outside of the coordinate phrase, as shown in the
somewhat simplified diagram (56).19
According to the binding system described in Chapter 2, the expression
BOUGHT (z) is of the category Fa[z] but the expression CHEATED.ON (x)
belongs to the category Fa[x]. But logical conjunction, like syntactic conjunc-
tion, requires the conjuncts to be parallel both notionally and structurally,
as Schachter (1977) argued. The F/A constituent *Fa in (56) is therefore ill
(56) Prop
QP[z]
QP[x] Prop[x]
WHAT.EXAM.(x) TERM.PAPER
Arg *Fa
STUDENT(y)
CONJ Fa[z] Fa[x]
BOUGHT (z) CHEATED.ON (x)
130  The linear order component
formed. This makes the Coordinate Structure Constraint a semantic phenom-
enon, an idea that is also argued for in Culicover and Jackendoff (1997) and
Yuasa and Sadock (2002). Other examples of Coordinate Structure Constraint
violations will turn out similarly.
But as Ross (1967a) observed, something missing from all conjuncts does
not constitute a violation of the Coordinate Structure Constraint.
(57)	 What paper did the student buy and submit?
Here identical F/A structures are conjoined and the example is well formed
at that level, the two coordinated semantic constituents both belonging to the
category Fa[x]:
The example is syntactically well formed as well because the coordinated
elements also belong to the same syntactic category, namely V:
(59)	 [VP(V(V buy) and (Vsubmit)) what]
This treatment is quite similar to the strikingly original one provided by Gazdar
(1981). In that work, however, the categorial incompatibility of the coordinated
constituents in (54) is attributed to the syntax, for which Gazdar introduced the
mechanism of slash categories. Adopting the automodular point of view, we
can dispense with this mechanism in favor of general principles of semantic
quantification, which are motivated quite independently.
4.9	 Relative clauses
In this section I will provide a treatment of the syntax, semantics, and linear
order characteristics of relative clauses in terms of autonomous modules con-
nected by a lexicon and general principles of the interface. I hope to show
that this treatment has some important advantages with respect to motivation
and simplicity, and offers some empirical advantages as well. The treatment
I provide models many of the insights and ideas of researchers working in
(58) Prop
QP[x] Prop[x]
WHAT.PAPER.(x)
Arg Fa[x]
STUDENT.(y)
CONJ Fa[x] Fa[x]
BOUGHT (x) SUBMIT (x)
Relative clauses  131
diverse frameworks, both syntacto- and semanto-centric. It is not meant to be
the whole story, of course, but only to provide suggestions as to how to formal-
ize the properties of the lexemes one finds in English relative clauses, their syn-
tax, semantics, and linear order requirements, and how these lexemes then turn
out to get some of the intricate properties of relative clauses right with relative
ease. Only the most central kinds of relative clauses will be dealt with here.
4.9.1	 The relative pronoun
Relative pronouns are pronouns20
and deserve the same basic syntactic and
F/A analysis as definite pronouns (cf. Chapter 2 (102)). What differentiates
relative pronouns from run-of-the-mill definite pronouns, however, is first, that
they bear the morphosyntactic feature [WH[REL]], which restricts their dis-
tribution, and second, unlike definite pronouns, they cannot have contextually
established antecedents, but must corefer with expressed NPs. The relative
pronoun makes the clause a relative clause (60), and such a clause acts as an
adjunct to N′ (61b).
(60)	 who (relative pronoun)
	 syntax: NP[WH[REL], 3sg]
	 F/A: Arg21
	 RS: ROLE
(61)	 a.	 S′ [RC] → [S … WH[REL] … ]
	 b.	 N′ → N′ S′[RC]
Relative clauses obey the Coordinate Structure Constraint, of course, the rea-
son for which is the same as for main-clause interrogatives: the semantic binder
of a variable in the relative clause must be outside the relative clause, so if it is one
of two conjuncts, the conjuncts will differ, which makes the conjunction illicit.
Finally, (62) is a rule positioning the relative pronoun obligatorily at the begin-
ning of a relative clause. What it says is that the phrase bearing the WH[REL]
feature precedes any other phrase in a relative clause. The rule does not mention
the category V[TNS], so it is not associated with inversion and do-support.
The category that relative XP[WH[REL]] forms – S′[RC], a relative clause –
is a syntactic adjunct and a semantic modifier of N′s, making it hierarchic-
ally similar to an attributive adjective phrase, though it is not headed by an
adjective.
(62) =
Σ α β
<
S�[RC] = [ XP[WH[REL]] … ZP… ]
132  The linear order component
An interesting syntactic motivation for the common analysis of relative
clauses as hierarchically the same as adjective phrases comes from Danish,
a language in which the definite article is enclitic to the head noun, but is an
independent word when the noun is modified by an adjective or by a restrictive
relative clause:
(63)	 hund-en
	 dog-the
(64)	 den søde hund
	 the cute dog
(65)	 den hund jeg købte
	 the dog I bought
(66)	 *den søde hund-en
(67)	 *den hund-en jeg købte
(68)	 *søde hund-en
(69)	 *hund-en jeg købte22
The generalization is that the definite article must cliticize to a noun that is a
sister of the article and is therefore blocked if anything is adjoined to the N′, be
it an adjective or a relative clause. The phrase structure rules introducing rela-
tive clauses and adjective phrases can be stated together as (70), which ensures
that the Danish definite article will not cliticize to the noun hund in (71). The
ordering of the relative clause and the adjective is a separate matter that is to be
handled by rules of the LOC.
(70)	 a.	 N′ → N′, S′[RC]
	 b.	 N′ → N′, AP
4.9.2	 The F/A structure of relative clauses
The semantic analysis of the relative clauses is a bit more challenging than
the syntax. I am fairly confident, however, that the general idea I will advance
here, while technically imperfect, can be made acceptable without too much
(71) NP
Det N'
N' AP/ S'[RC]
hund
Relative clauses  133
effort to specialists in the semantics of natural languages. The F/A structure
status of the relative pronoun, as already given in (60), is that of an argu-
ment whose meaning resembles that of a pronoun, as its traditional name sug-
gests. A simple way of guaranteeing that the relative pronoun and the noun
phrase in which it is found corefer is to say that relative clauses are semantic
appositions forming conjunction-less coordinate structures with a meaningful
constituent.
According to what was said in Chapter 2, section 2.9, a phrase such as every
linguist will be a quantifier phrase with a variable in one argument slot in the
restricting proposition, as shown in (72).
Relative clauses are semantic propositions, of course, so if they are in appos-
ition to something, that something will also have to be a proposition, and by
geometrical correspondence with the syntax and (51), the like-constituent rule
for F/A conjunction, the function-argument representation of every linguist
who speaks Inuktitut must be (73):
Note that the general conformation of the logical and syntactic structures is
basically the same, up to differences that are inherent in the basic categories of
the two components. This fact is quite in keeping with the general tendency for
representations in different dimensions to correspond as much as possible.
4.9.3	 Adjectives
Let me now flesh out the treatment of adjectives alluded to in the F/A rules (6)
and the syntactic rules (14g)–(14i) of Chapter 1. A simple adjective such as
(72) QP[x]
Q
EVERY
Prop[x]
Arg[x]
x
Fa
LINGUIST
(73) QP[x]
Q
EVERY
Prop[x]
Prop[x] Prop[x]
Fa Arg Arg Fa
LINGUIST x x
Faa Arg
SPEAK INUKTITUT
134  The linear order component
red would then count as a predicate and as a modifier of N′. The lexical entry
for be, Chapter 2 (97), also allows an adjective phrase to count as the syntactic
complement of the empty verb be. Ordinary adjectives that don’t take a com-
plement will have lexical entries like (74a), allowing them to occur in either of
the syntactic positions shown in (74b) and (74c).
The F/A value of the adjective phrase in (74b), here just that of the adjec-
tive, is obviously Fa, since be has no value in function-argument structure so
the VP corresponds to a predicate, as desired. The dog is shaggy thus means
SHAGGY(DOG).
For attributive adjectives, however, the case is murkier, though I think ultim-
ately unproblematic. If we continue to maintain that an adjective phrase counts
as a predicate – the simplest assumption – then we must determine how the
predicate corresponding to the N′ and the predicate corresponding to the AP in
(74c) are combined semantically. Since the two syntactic sisters both instan-
tiate the category Fa, there is no particular reason why they couldn’t exist
in a conjunction-like juxtaposition of like categories, much as in traditional
logical analyses of adjectives and the analysis of relative clauses that was just
given.23
Note that relative clauses diagrammed in (71) and attributive adjectives
(74c) both combine syntactically with an N′ to form an N′. But they must have
different semantic combinatorics since they belong to different F/A categor-
ies: relative clauses are propositions and attributive adjectives are predicates.
a. red, shaggy, irrational, vacuous, etc.
(74)
syntax: A
F/A: Fa
b. VP
V
be
AP
A
c. NP
Det N'
AP
A
N'
(75) Fa
Fa
RED
Fa
DOG
Relative clauses  135
Therefore relative clauses occur in semantic structures like (73) and adjectives
occur in structures like (75).
This treatment suffices for simple, intersective adjectives and it can be easily
extended to various kinds of complement-taking adjectives such as identical,
fond, and happy. An adjective like fond, for example, will combine with the
meaning of its complement to form a predicate, which then behaves like a
simple adjective. Gradables like big can be taken to have an unexpressed role
structure argument that represents the standard of comparison. All of these
classes form adjective phrases that also occur as predicates following be.
McCawley (1988, 391–92) formulates a rule that moves adjective phrases
to pronominal position if the head adjective is the last element of the phrase, a
condition that can be stated with the help of the linear order component as the
following compound LOC rule. Here Σ1 is an adjective phrase that ends in the
adjective A and precedes the N′ that it modifies in Σ2.
4.9.3.1	 Intensional adjectives
Adjectives such as former, alleged, and would-be, however, cannot be treated
in this way; a former roommate is not someone who is both a roommate and
former. Intensional adjectives must be seen as belonging to the category of
predicate modifiers, not predicates. Separating syntax and combinatoric seman-
tics makes it unnecessary to assume that adjectives such as this belong to a dif-
ferent syntactic category than extensional adjectives do. A quite unacceptable
example such as *Her roommate is former can be taken as syntactically well
formed, but malformed in F/A structure. Since be contributes nothing to F/A
structure, the example would consist of an argument and a modifier of predi-
cates. Neither can be the semantic complement of the other, so the example
fails to have a well-formed meaning.
I think it is at least as sensible to treat the single syntactic class of prenom-
inal adjectives as corresponding to two distinct semantic classes, predicates
and predicate modifiers, as it is to treat all adjectives as semantic modifiers.
The very designations “intensional adjective” and “extensional adjective”
seem to recognize that they differ fundamentally in meaning.
(76) Σ1
Σ2 γ δ
α β
=
AP = [ … XP … A]
N�= [ AP N� ]
= <<
136  The linear order component
4.9.4	 Non-restrictive relative clauses
The communicative and formal differences between restrictive and non-restric-
tive relative clauses are well documented: restrictive relative clauses contribute
to the delimitation of the class of entities designated by the head noun, whereas
non-restrictive relative clauses add separate information. Non-restrictive rela-
tive clauses must be introduced by a WH relative pronoun and are set off into-
nationally. Examples (77a)–(77b) are understood only as restrictive. Examples
(78a) and (78b) are stringwise ambiguous, but clearly disambiguated by in-
tonation. (77b) cannot be pronounced with the pauses characteristic of non-
­
restrictive relative clauses, and (78a) must be pronounced with non-restrictive
intonation. Since (78b) must contain a non-restrictive relative clause, (79a)
and (79b) are ungrammatical with the complementizers that only characterize
restrictive relatives.
(77)	 a.	 The Smith that I know well lives in Berwyn.
	 b.	 The Smith I know well lives in Berwyn.
(78)	 a.	 The Smith whom I know well lives in Berwyn.
	 b.	 Smith, whom I know well, lives in Berwyn.
(79)	 a.	 *Smith, I know well, lives in Berwyn.24
	 b.	 *Smith, that I know well, lives in Berwyn.
Danish is again instructive as to the syntactic position of the relative clause
because the facts cited in (63)–(69) do not apply to non-restrictive clauses. As
opposed to the ungrammatical (69), (80), with a non-restrictive clause, is per-
fectly acceptable for all or nearly all speakers, indicating that the non-­
restrictive
clause modifies the NP, rather than the N, as in (81), where the determiner is a
sister to the noun and may be cliticized to it.
(80)	 Hund-en, som jeg købte, var en pudel.
	 dog-the which I bought was a poodle.
	 “The dog, which I bought, was a poodle.”
It is therefore clear that the interrogative element in non-restrictive
relatives is a separate lexeme from its homophones in restrictive relative
clauses, with syntax as indicated in (82a–c), as opposed to what we see in
(60a–c).
(81) NP
NP S[REL]
som jeg købte
Det
-en
N
hund
Relative clauses  137
(82)	 a.	 who (non-restrictive)
		 syntax: NP[WH[NREL]]
	 b.	 S′[NRC] → [S … [WH[NREL]] … ]
	 c.	 NP → NP S′[NRC]
As has been firmly established in the literature, non-restrictive relative
clauses constitute separate speech acts. (See Krifka 2004 and the citations
therein.) There are even non-declarative uses such as Symbolic logic, which
who cares about anyway, is awfully tough. Non-restrictive relative clauses are
therefore semantically similar to parentheticals, which can also have inde-
pendent illocutionary force. This suggests analyzing non-restrictives as “non-
­
syntagmatic” elements (Peterson 2004), that is to say, as parentheticals, but
with the difference that the syntax of non-restrictives connects them to NPs,
whereas parentheticals have much greater syntactic freedom:
(83)	 Mr. Smith – and I know him well – is quite honest.
(84)	 Mr. Smith, whom I know well, is quite honest.
(85)	 Mr. Smith is – and I know him well – quite honest.
(86)	 *Mr. Smith is, whom I know well, quite honest.
(87)	 Mr. Smith is quite honest – I know him well.
(88)	 *Mr. Smith is quite honest, whom I know well.
As to the semantic structure of non-restrictive relative clauses, we might prof-
itably resurrect the ideas of Eilfort (1989) in favor of a separate illocutionary
module, as Bagchi (2011) has recently done in order to account for the relation
between illocutionary force and intonation. Many of the communicative prop-
erties of non-restrictive relatives might follow from the association of a non-
restrictive relative clause with an independent speech act. Additionally, placing
illocutionary force on its own tier would circumvent many of the objections that
were leveled at the idea of performative clauses in the 1960s and ’70s. I believe
there is a lot to be said for setting up an independent component in which an
analysis of (78a) and (78b) as (89a) and (89b) could be officially stated:
a.
(89) SPEECH.ACT
I.F. CONTENT
ASSERT The Smith whom I know
lives in Berwyn
b. SPEECH.ACT SPEECH.ACT
I.F. CONTENT I.F. CONTENT
ASSERT Smith lives in Berwyn ASSERT I know Smith
138  The linear order component
4.10	 Disharmony islands
I have already presented a treatment of the kind of island that Ross (1967a) la-
beled the Coordinate Structure Constraint. The automodular treatment of that
constraint was based on the idea that within a module, coordinated elements must
be of similar categories. In the autonomous modular framework this follows from
the general tendency for categories to correspond across dimensions as discussed
in Chapter 2, section 2.2. Thus we expect the like-category requirement for syn-
tactic conjunction to correspond to a like-category requirement in F/A structure,
and vice versa, at least in default cases. The Coordinate Structure Constraint is
explained by showing that the improper examples involve illicit coordinations of
unlike categories in just one component, namely function-argument structure.
Many of the other sources of lowered acceptability of expressions of natural
language that go by the name of island constraints can be traced to failures of
geometrical correspondence between representations in different modules ra-
ther than to forbidden configurations in a single representation. The discrepan-
cies in question differ in nature, number, and degree, and therefore there are in
general not just fully grammatical sentences without island violations and fully
ungrammatical examples with violations, but rather smoothly shaded degrees
of acceptability. I think that most, if not all researchers concerned with the re-
lation between form and meaning recognize the fact of graded acceptability of
island violations, though published pronouncements sometimes gloss over it.
The recognition of separate, independent systems of linguistic representation,
some of which have to do with meaning and some of which have to do with
form, ought to remove all sense of embarrassment over the fact that island con-
straint violations exhibit variable acceptability.
The geometrical mismatches that lead to diminished acceptability can often
be seen from the automodular vantage point as crossing association lines
between alternative dimensional analyses of expressions. The classical con-
straints on unbounded “movement” display a strong tendency toward preserv-
ing harmonic representations between and among representations by inhibiting
crossing association of corresponding units.
4.10.1	 Pronominal reference
As a venerable example, consider the well-known connection between word
order, notions of command, and antecedent–pronoun relations that began with
Ross (1967b) and Langacker (1969). The following examples are typical of the
extensive literature on pronoun coreference:
(90)	 a.	 Although Nancy was sick, she took the exam.
	 b.	 Although she was sick, Nancy took the exam.
Disharmony islands  139
	 c.	 Nancy took the exam, although she was sick.
	 d.	 *She took the exam, although Nancy was sick.
In (90a) the potential antecedent precedes but is commanded by the pronoun,
whereas in (90b), the opposite is true. In (90c) the potential antecedent both
precedes and commands the pronoun. In all three of these cases, coreference is
possible. But in (90d), the pronoun both precedes and commands the potential
antecedent and coreference is not possible.
The condition on the antecedent–pronoun relation, commonly stated as for-
bidding an anaphor to both precede and command its antecedent, has received
a variety of alternative, nearly equivalent formulations, for example:
(91)	 NP1 cannot be interpreted as coreferential with NP2 iff NP1 precedes
	 and commands NP2 and NP2 is not a pronoun. (Reinhart 1981, 606)
(92)	 An AD [anaphoric device] may not c-command its antecedent if it (i)
	 is a clausemate of the antecedent … or (ii) precedes the antecedent.
	 (McCawley 1988, 347)
In any case, there is fair agreement that a natural relationship exists between
antecedents and precedence on the one hand, and between antecedents and
asymmetric command on the other.25
These relationships for the four cases
in (90) are displayed in (93), which makes it clear that it is the dissonance
between associations in two dimensions simultaneously that mar a potential
antecedent–pronoun relation to the extent that the relationship cannot obtain.
The relationship between anaphoric devices and their antecedents is clearly
a great deal more intricate than this, but the example should serve to indicate
(93) a. commands antecedes precedes
commanded anteceded preceded
b. commands antecedes precedes
commanded anteceded preceded
c. commands antecedes precedes
commanded anteceded preceded
d. commands antecedes precedes
commanded anteceded preceded
140  The linear order component
that the existing literature in effect recognizes the independence of hierarchical
syntax and linear order.
4.10.2	 Scope of logical elements
Another kind of example that can be, and in fact traditionally has been, eluci-
dated in terms of disharmony between different kinds of linguistic information
concerns the relation between quantifier scope interpretation and word order,
a topic that came up in a famous give-and-take between Barbara Partee (1970)
and George Lakoff (1970). The question was first one of fact: do (94) and (95)
differ in the semantic scope of the quantifier many and the negation in such a
way that (94) would be true if many arrows went astray but a sizable number
were accurate while (95) would be false in that situation? Or are both am-
biguous? Or are there different dialects/idiolects with regard to the allowable
interpretations?
(94)	 Many arrows didn’t hit the target.
(95)	 The target wasn’t hit by many arrows.
In a number of empirical studies, Guy Carden demonstrated a very com-
plex state of affairs. (See Carden 1973 and the references that are cited there.)
Whatever else can be said, it is at least clear that there is a tendency to inter-
pret the scope of quantifiers as harmonic with the earlier to later order of the
morphosyntactic pieces that correspond to the logical elements. But such in-
terpretations are not obligatory. Viewed from the perspective of automodular
representations, the distinction between the favored and disfavored interpret-
ations is a matter of the geometrical correspondence or lack of correspondence
between the dimension of F/A structure and the dimension of linear order.
The harmonic interpretation – “many arrows are such that they did not hit the
target” – of (94) is schematically (96), and the dissonant interpretation – “It is
not the case that the arrows that hit the target were many” – is (97).
(96) F/A: Prop
QP[x]
MANY (ARROWS (x)) Prop[x]
NOT
Prop[x]
x HIT TARGET
LOC: many arrows did n’t hit the target
Disharmony islands  141
Derivational grammars look at such discrepancies between representations
as produced by movement rules, either “overt” if the direction of the movement
is taken to be toward a more superficial level (e.g., DS to SS) or “covert” if the
movement is taken to be from a more superficial level to a more abstract level
(e.g., SS to LF). Interestingly, Lakoff’s (1969) take on the problem was similar
to the one adopted in principle here, despite its adherence to a derivational the-
ory in which deep structure, equivalent for him at that point in time to semantic
representation, was sequentially deformed on its way to surface structure. In
this case, Lakoff used data from quantifier scope to argue for “global deriv-
ational constraints,” most of which involve direct relationships between a level
that closely approximates the logical level that I call F/A structure, and some
level whose connection to audible form is tighter. The idea was that transform-
ational rules could derive either sentence from either logical structure, but a
derivational constraint filtered out those derivations in which surface order dif-
fered from semantic scope.
At the same time, Jackendoff (1969), representing the opposition to
Lakoff’s generative semantics, presented an interpretive theory of the same
putative facts. Jackendoff’s deep structures were not logical structures and
did not specify semantic scope. Instead, an interpretive rule moved the neg-
ation from its surface position to the intuitively correct logical position:
An interpretive rule of scope essentially has to do Klima’s rules of neg-
placement in reverse. Instead of making neg move to the right and attaching
to lower nodes in the tree, we have to generate neg in its surface structure
position … then move the neg up the tree by the scope rule.   (Jackendoff
1969, 235)
I hope it is by now obvious to the reader that a dispute about directionality
cannot arise in an automodular framework. Jackendoff and Lakoff in fact
agree that there is a rather direct, though imperfect connection between the
(97) F/A: Prop
NOT Prop[x]
QP[x]
MANY
(ARROWS (x))
Prop[x]
x HIT TARGET
LOC: many arrows did -n’t hit the target
142  The linear order component
position of words with logical meanings in linear order and the scope of
the corresponding elements in logical representations. Automodular gram-
mar eschews movement rules of any kind. There are constraints relating to
levels of representation, but these are very circumscribed; they can only in-
volve levels that are independently justified and follow general, intuitively
plausible principles such as the geometrical correspondence principles that
favor similar hierarchies of corresponding elements in different dimensions
of grammar. At the time that Lakoff wrote, there was no reason to prefer
alignment between these distinguished levels over alignment between, say,
even-numbered stages in syntactic derivations. Only the former is a possi-
bility in a theory that generates distinguished levels independently of one
another.
4.10.3	 The Complex NP Constraint
Let us turn our attention next to one of the classical examples of an island con-
straint where I think it is easy enough to see the same kind of alignment forces
at work. Consider those effects that Ross (1967a) placed under the heading of
the Complex NP Constraint:
(98)	 The Complex NP Constraint
No element contained in an S dominated by an NP with a lexical head noun
may be moved out of that NP by a transformation. (Ross 1967a, 70)
The examples below contrast a verbal complement (99), a complemented
indefinite noun with a “light” verb (100), and a complemented possessed noun
that is the complement of a contentful verb (101):
(99)	 He dreamt that he met Gina Lollobrigida.
(100)	 He had a dream that he met Gina Lollobrigida.
(101)	 He mentioned his dream that he met Gina Lollobrigida.
When an interrogative NP is displaced in linear order in accordance with (27)
above we find a high degree of acceptability in the case of the verbal com-
plement, degraded acceptability with the complemented noun supported by
a dummy verb and quite low acceptability where the displaced NP is part
of the complement of a noun that represents an actual argument of a verb.
(See Kluender 1992 for a discussion of variable acceptability of Complex NP
Constraint violations.)
(102)	 Who did he dream that he met? >
(103)	 Who did he have a dream that he met? >>
Disharmony islands  143
(104)	 Who did he mention a dream that he met?
Speakers have increasing difficulty processing (102), (103), and (104).
(See Sag, Hofmeister, and Snider 2009.) Automodular techniques, I believe,
are particularly illuminating as to the nature of the Complex NP Constraint
violation and provide a clear model of the graded reactions to examples like
(102)–(104). The double tree in (105) (in which some irrelevant details are
suppressed) shows the syntactic and linear order representations of (102). The
F/A and role structure representations are congruent with the syntax to the ex-
tent they can be. In (105), then, we see the discrepancy between all three levels
and the linear order of elements that follows from (27), the special ordering
template that is characteristic of English questions. I have shown only the as-
sociations of NPs and their homologues in the linear order component. The
displaced NP crosses two other NPs and the same would be true between the
other modular correspondents of NPs, which are arguments in F/A structure
and Role Structure. At all three levels, then, the interrogative element crosses
two other similar elements, giving a total of six crossed association lines.
Skipping ahead to (104), the least acceptable example, we find (1) a complex
NP, a dream that he met who, as the object of the verb mention in the syntax,
(2) an argument A DREAM (Prop), the semantic object of MENTION, and
(3) a role, A DREAM [EVENT], that is the patient in an event of mentioning.
The syntactic structure with its correlation to linear order is presented in (106)
and the function-argument and role structure are similarly correlated to linear
order. What this means is that the string-initial position of the interrogative
element is three positions out of alignment with its corresponding constituent
(105)
LOC:
S
NP VP
he
V S′
dream
Comp S
that
NP VP
he
V NP
meet who
who he he
144  The linear order component
in each of the three major structural dimensions, for a total mismatch of nine
crossing associations. This does not explain the deviance of (104), but it does
give us a model of what it is about that expression that depresses its acceptabil-
ity for speakers of English.26
Finally, let us consider (103), an example of intermediate acceptability. Its
syntactic structure is (107), which similar to that of (104). As indicated, the ini-
tial position of the interrogative crosses three syntactically superior NPs. The
syntax and linear order are thus mismatched by three in the case of (103) and
(104), versus two in (102).
It is not entirely clear how to analyze (103) in terms of functions and argu-
ments. Either dream provides descriptive content to an argument, in which
case the F/A structure is similar combinatorically to the logical structure of
(107) S
NP VP
have NP
N S
dream
he VP
met who
who
LOC: he dream he
(106) S
NP VP
mention NP
N S
dream
he VP
met who
who
LOC: he dream he
Summary  145
He mentioned a dream that he met Gina Lollobrigida, thus presenting three
crossed associations with linear order, or HAVE.A.DREAM is a functionally
indivisible Fpa, in which case (103) is logically the same as He dreamt he met
Gina Lollobrigida with the F/A structure that is two degrees discrepant with
the linear order.
Regardless of the F/A structure, it is intuitively reasonable to assume that the
verb have has no cognitive significance, making it identical in role structure to
(102), Who did he dream he met? Therefore it presents only two crossing lines
when associated with the linear order of elements as in (108).
Under a tri-modular analysis, then, the scale of acceptability that we see in
(102)–(104) is modeled, if not explained, on the basis of the number of cross-
ing association lines between the structural representations and the linear order:
(102) has six, (103) has seven or eight, and (104) has nine. What Ross discov-
ered, then, seems to be not just a complex NP constraint, but simultaneously
a complex argument constraint and a complex individual concept constraint,
a result that is in keeping with the idea of independent, but related analyses in
various informational dimensions. It remains to be seen whether other clas-
sical island constraints – the sentential subject constraint and the WH-island
constraint, for example – can be usefully elucidated if attention is paid to their
representation in several planes of analysis simultaneously.
4.11	 Summary
The purpose of this chapter has been to argue for the existence and utility of
an autonomous linear order component. The independence of an information-
ally encapsulated grammatical component is best demonstrated by showing
that it interfaces with other informationally encapsulated components, which
to this point are the syntax, the function-argument module, and role structure.
Though the fact that linear order interfaces with syntax hardly needs demon-
stration, several aspects of this interface have been investigated here, including
(108) EVENT
TYPE AGT EVENT
DREAM HE
TYPE AGT PAT
MEET HE WHO
who
LOC: he he
146  The linear order component
the preference for syntactic heads either to begin or to end their phrases, pa-
rochial constituent ordering in individual languages, and the ordering of the
pieces of coordinate phrases. Linear order interfaces with structural semantics
at least insofar as logical scope tends to be reflected in word order, and it inter-
faces with role structure in that agents tend to precede patients without regard
to other grammatical considerations across a wide range of languages. The
morphological component will be introduced in the next chapter. Linear order
considerations will play a large role in that chapter as well.
An important point that this chapter makes is that automodular grammar
makes available an account of the limitations on long-distance dependencies
that is not entirely stipulative. Such limitations are related to the expectation
of geometrical congruence among alternative representations of the same
expression, an expectation that was motivated independently of long-distance
dependencies. In other grammatical frameworks such limitations are cast as
constraints on movement. There is no movement in automodular grammar, and
the constraints on long-distance dependencies are viewed here as reflecting the
natural forces that disprefer discrepancies between linear order and the com-
mand relations that are found at any other level of representation.
147
5	 Morphology and
morphophonology
5.1	 Pure morphology
Morphology concerns the makeup of those segments of language that we call
words. The word word, however, is multiply ambiguous, having been applied
also to the atoms of syntax, phonological stretches defined in terms of allowable
initial and final sequences of segments or intonational properties, the smallest
elements that can be pronounced as whole utterances, and contiguous stretches
of utterances with meanings that cannot be derived from shorter components.
But these are not morphological features per se. We might call elements of lan-
guage defined according to these various criteria syntactic words, phonological
words, discourse words, and lexical words, respectively. While these conceptu-
ally distinct notions often align, they also sometimes don’t, and that makes the
identification of the word a matter of some controversy.
In this chapter we are interested in morphological words whose defin-
ition cannot be reduced to a combination of properties in other components.
Morphologically complex words are structured in a way that often corresponds
to properties in other components, but they are essentially independent of any
of them. That is to say, morphology is an autonomous component with its
own categories and its own rules of combination, just as is the case with the
other autonomous components of grammar.1
Its categories are connected most
closely with phonology and with syntax, but it must be sharply distinguished
from both morphophonology (Woodbury 1995) and morphosyntax, two sub-
jects with which pure morphology is frequently confused.
As is the case with other major components of grammar, the morphological
component of a natural language can be formalized in terms of an order-free,
context-free phrase structure grammar. The structure of morphologically com-
plex entities is frequently not manifested morphophonologically as the simple
concatenation of strings of phonological segments, but as far as the morpho-
logical information itself is concerned, there is nothing at all wrong with the
phrase structure formalism, and there are several things to recommend it in
148  Morphology and morphophonology
the present framework. Morphology is the grammar of word structure and
therefore deals only with productive morphological facts. Lexicalized morph-
ology properly belongs in the lexicon where it can be dealt with as generaliza-
tions over sets of distinct lexical items. The boundary between productive and
unproductive morphology is notoriously difficult to draw, but there are clear
cases of both.
So what are the elements of morphology and what sorts of rules govern their
combination? The minimal assumption that can be made is that there are two
basic categories, the morphological word, and a sub-word category that I will
call a stem. The fundamental morphological operations will then be functions
from morphological categories to morphological categories, giving four fun-
damental operations: (1) operations that produce stems when applied to stems,
(2) operations that produce words when applied to stems, (3) operations that
produce stems when applied to words, and (4) operations that produce words
when applied to words. Conceptually, these operations are functions from
one category to another and could be represented as, for example, M(Stem)
= Stem, where M is a morphological function, but for the sake of parallelism
with the other components, the symbolic system I will use is that of a phrase
structure grammar. The four fundamental operations will then be represented
as (1)–(4):
(1)	 Stem → Stem, M 	 (morphological derivation)
(2)	 Stem → Word, M	 (morphological inflection)
(3)	 Word → Word, M	 (morphological cliticization)
(4)	 Word → Stem, M	 (morphological derivational cliticization)
Operations of the type in (1) capture the idea of derivational morphology from
a purely morphological point of view. The stem that is the output of the oper-
ation is different from the input stem, a new lexeme, or lemma, if you will, that
is capable of undergoing further derivational or inflectional processes.
Type (2) operations can be identified with morphological inflection in that
they are needed (in a language with such operations) to form full-fledged mor-
phological words. A language with no inflectional morphology whatsoever, of
which there are many, will either have in its lexicon only words, or will con-
tain a default operation of type (2) that has no morphophonological, semantic,
or syntactic consequences associated with it. If the language has derivational
morphology but no inflection, that might be the preferable treatment. If a lan-
guage lacks both morphological inflection and morphological derivation, it
might be best to say that the lexicon contains only words.
Pure morphology  149
Word-to-word operations of type (3) are examples of morphological cliti-
cization. It is not necessary for an operation of this type to be associated with
other characteristics that are taken to be typical of cliticization: concatenative
phonology, distribution with respect to syntactic phrases, and robust semantic
content, for example.2
Other features belonging to independent components
of grammar do often accompany word-to-word operations in the morphology,
but they obviously warrant description only in those other components: phon-
ology, syntax, and semantics, respectively.
There is no standard name for operations of the fourth type above, but they
do occur,3
though less frequently perhaps, than any of the preceding three types.
They loom large in the grammars of Inuit languages such as West Greenlandic
Inuttut, where the suffix –kar-, for example, derives a verb stem from a noun
with allative case inflection: illussinnut “to your(pl) house,” illussinnu-kar-poq
“He/she is going to your(pl) house.” (See Rischel 1974; Fortescue 1984.) In
Sadock (2003b), I termed this kind of operation derivational cliticization. Such
morphology is not relevant to the phenomena discussed in this work and will
not be considered further.
Finer morphological categories than the two fundamental ones are also gen-
erally found in languages with either derivational or inflectional morphology.
The class of stems might divide, for example, into two morphologically defined
classes, according to whether a certain subset of derivational and inflectional
processes applies to members of the class. In English, for example, there is
a class of stems roughly corresponding to syntactically defined verbs, which
undergo the derivational process that suffixes /ər/ to the stem, creating a mor-
phological noun, and can take the inflectional affix whose morphophonology
is suffixal /ɪŋ/ producing an inflected word.
Members of the morphologically defined class to which observe belongs are
ordinarily also syntactic verbs, i.e., heads of verb phrases. I say mostly, since
the morphological and syntactic classes are not in perfect alignment; modal
(5)
-/ər/ -/iŋ/
observe OK OK
rodent *
crimson *
*
*
150  Morphology and morphophonology
auxiliaries, for example, head verb phrases but do not undergo either derivation
or inflection typical of other syntactic verbs. It is important to keep the dis-
tinction between a morphological category and a largely overlapping syntactic
category in mind, so I will indicate morphological categories in a script font to
remind us that this is morphology, and not syntax. The first two lexemes in (5),
then, will have lexical entries including the fields shown in (6) and (7).
(6)	 observe
	 syntax: V in [ __, NP] or [ __, S]
	 morph: Stem [V]
(7)	 rodent
	 Syntax: N
	 morph: Stem [N]
The word fun provides an example of the independence of syntactic and mor-
phological categories that can be handled as Francis (1999) handles deviations
from prototypical correspondences in lexical classes. Fun has much of the syn-
tax of an adjective for many speakers: it is a prenominal modifier in a fun game,
can be modified with very, and can be conjoined with adjectives as in a fun and
educational game. But it lacks adjectival morphology. It does not accept com-
parative or superlative suffixes (for most adults), does not form an adverb with
–ly, or even occur with the productive de-adjectival nominalizing suffix –ness. It
also has some of the syntax of a noun, but fails to accept most nominal morph-
ology as well: *fun-like, *funs (which would presumably mean “types of fun”).
The best treatment, then, might be to treat fun as a Word in the morphology,
incapable of inflection or derivation, but as a noun or adjective in the syntax.
(8)	 fun
	 syntax: A or N
	 morph: Word
5.2	 Morphophonology
Morphophonology deals with the phonological realization of productive mor-
phological alternations and must be kept clearly separate from pure morph-
ology. For one thing, there is productive morphology that is not associated
with any morphophonological alternation at all, so-called zero derivation and
inflection. The English present tense, non-third person inflectional forms are
(except for the verb be) the same as the infinitive, and not different from the
morphological Stem. For another thing, it is commonly the case that the very
same morphological effect can be achieved in a variety of morphophonological
Morphophonology  151
ways. In morphologically rich languages, for example, there are many examples
of classes of stems that require very different morphophonological processes
to effect the same morphological result. Latin has several morphophonological
classes of nouns that are subject to the same morphological processes but
with different morphophonological results. Nouns belonging to two different
declensions can be listed with an arbitrary feature specifying the declensional
class to which morphophonological rules are sensitive, as in the following
examples from Latin:
(9)	 agricol-
	 syntax: N[MASC]
	 F/A: Fa
	 morph: Stem [N, DEC-1]
	 mphon: /agrikol/
(10)	 serv-
	 syntax: N[MASC]
	 F/A: Fa
	 morph: Stem [N, DEC-2]
	 mphon: /serv/
(11)	 a.	 nominative singular
		 syntax: [NOM, SG]
		 morph: Stem [N]→ Word[N, NOM, SG]
		 mphon: 1.  /… / → 	 / … a/ in [[DEC-1], __ ]
			 2.	/… / → 	 / … ʊs/ in [[DEC-2], __ ]
	 b.	 nominative plural
		 syntax: [NOM, PL]
		 morph: Stem [N]→ Word[N, NOM, PL]
		 mphon: 1.	/… / → 	 / … aɪ/ in [[DEC-1], __ ]
			 2.	/… / → 	 / … i/ in [[DEC-2], __ ].
These specifications handle the fact that agricola and servus are both mascu-
line singular syntactic nouns (agricola bonus, “(a) good farmer,” servus bonus,
“(a) good servant”) and that agricolae and servi are both masculine nominative
plurals as far as syntactic behavior is concerned.
English has quite a few irregular verbs for which the morphophonology that
registers morphological past tense either involves a vowel change (ran), the
regular suffix and a vowel change (swept), suppletion (went), or nothing at all
(put). But since each of these classes is restricted to a few examples or even a
single example, it is perhaps best to handle each irregular example lexically. A
regular verb can be treated simply as a stem, as in (12a). Regular inflectional
rules with productive morphophonology like the partial entry for the regular
past-tense inflection (12b) will apply to regular verb stems.
152  Morphology and morphophonology
(12)	 a.	 trade
		 syntax: V in [ __ NP, PP[for]]
		 F/A: Faaa
		 morph: Stem [V]
		 mphon: /treɪd/
	 b.	 Past (English inflectional past tense)
		 morph:	 Stem [V ]	 →	 Word [V, PAST]
		 mphon:	 /X/	 →	 /X + D/
An irregular verb like sing, on the other hand, needs to have all of its irregular
forms listed, the more particular statement in (13.2) blocking the more general
rule (12b), as is normal (Kiparsky 1973). The following lexical entry illustrates
a simple way that irregular inflection can be accommodated.
(13)	 sing
	 syntax: V in [ __, NP]
	 F/A: Faa
	 morph: 1.  Stem [V]
			 mphon: /sɪŋ/
		 2.	[ __, PAST]
			 mphon: /sæŋ/
		 3.	[ __, PST-P]
			 mphon: /sʌŋ/
Morphological processes such as we see in (12b) are operations very much
akin to lexical rules like the passive rule (Chapter 3 (17)) that make simultan-
eous alterations in more than one field of a class of lexical entries to yield other
lexical entries. The passive rule has a direct morphological function to perform
that was not considered earlier. It is now possible to reformulate it along the
lines of other morphological operations.
(14)	 Agentless Passive (English)
	 syntax: V in [ __ NP, ψ]	 →	 syntax: V[PSV-P] in [ __ψ]
	 F/A: Fφ a	 →	 F/A: Fφ
	 RS: TYPE, AGT, χ	 →	 RS: TYPE, <<AGT>>, χ
	 morph: Stem[V]	 →	 Word[V, PST-P]
Note that the syntactic feature in the inflected form here is different from the
morphological feature. The syntax of the past participle and the passive parti-
ciple are clearly different, the former lacking an NP complement that the latter
must have, so they must be distinguished in the syntactic component. At the
same time, the morphology (and based upon it, the morphophonology) of the
past and passive participles is always the same, a fact that is easily captured in
the morphological and morphophonological components by recognizing only
one feature there. Syntax, in other words, is not morphology.
Morphophonology  153
As we see in (14), morphological processes can have semantic effects,
both in terms of combinatoric function-argument structure and cognitive role
structure. As another example, consider a productive causative such as the
one that is found in West Greenlandic Inuttut, which is realized as a ver-
bal suffix /tiC/. The full lexical entry as it applies to intransitive verb stems
would be (15).4
(15)	 causative
	 syntax:  V[–TR] 	 → 	 V[+TR]5
	 F/A:	 Fa 	 → 	 Faa
	 RS:	 TYPE1, AGT 	 → 	 CAUSE AGT, [TYPE1, AGT]
	 morph:	 Stem [V, –TR]	 →	 Stem [V, +TR]
	 mphon:	 /X/ 	 →	 /X + tiC/
As yet another example of a lexical rule, consider the more or less product-
ive agentive nominalization rule in English. For simplicity’s sake, I will con-
sider here only intransitive verbs as the input:
(16)	 Agentive Nominalization (English)
	 syntax: V in [ __ ]	 →	 syntax: N
	 F/A: Fa	 →	 F/A: Fa
6
	 RS: TYPEn, AGT, χ  →	 RS: AGT in [TYPEn, __, χ]
	 morph: Stem[V]	 →	 Stem[N]
	 mphon: /X/	 →	 /X + ər/
As these examples should make clear, morphology in the automodular frame-
work is much closer to the item and process way of looking at things than it is
to the item and arrangement metaphor.7
Morphemes are usually taken to be the
smallest units of phonology with a constant semantic value. But processes such
as those in (1)–(4) are functions from morphological categories to morpho-
logical categories with a variety of effects in the various dimensions of gram-
mar. On the other hand, the process in any single module can be as “thing”-like
as any element in that component.
Non-concatenative morphology, however, presents no particular difficulties
in the present framework. For example, one of the strongest arguments against
the concept of morphemes as substantive, phonological content regards trun-
cating morphophonemics like the following example from Martin (1988, cited
in Anderson 1992).
(17) 	 Alabama
	 sg	 pl/habitual
	 balaa-ka “lie down (sg)”	 bal-ka “lie down (pl)”
	 batat-li “hit”	 bat-li “hit repeatedly”
	 kolof-li “cut”	 kol-li “cut repeatedly”
154  Morphology and morphophonology
Since the stem in the singular form contains various final syllables that are
not present in the plural or habitual, it is clear that the latter are phonologically
based upon the former and not vice versa. If the derivation involves the add-
ition of material, it must be phonological antimatter. But if the operation is a
simultaneous operation on the value of the lexemes in various dimensions, it
could look like (18) without producing conceptual headaches:
(18)	 plural/habitual (Alabama)
	 morphology: morph: Stem[V]	 →	 Stem[V, PL/HAB]
	 mphon: /X V(V)(C)/	 →	 /X/
5.3	 Feature osmosis
An important principle of modular grammar is that categories tend to match
across different dimensions of grammar (Sadock and Schiller 1993). Thus we
expect the morphological category of nouns (those elements that in a given
language might be inflected, say, for gender and case) to correspond to the
syntactic category of nouns (those atoms of syntax that serve as the heads of
NPs). The same matching principle is the default for finer categories as well.
If a language presents two categories of nouns in the morphology (masculine
and feminine, say,) and if there is agreement in the syntax, then we expect
the agreeing categories to correspond, for the most part, to the morphological
categories. To put this differently, in the unmarked situation, there will be a
correspondence between categories of the morphology and categories of the
syntax and vice versa. Formally, category-defining features that arise in one
component are typically matched by features in other components, at least in
the unmarked cases. We have already seen examples of this in connection with
syntax, F/A structure, and role structure. This default can be formalized for
morphology and syntax as in (19), which can easily be generalized to apply to
all pairs of components.
(19)	 Let F be the set of morphological features and F be the set of syntactic
`	 features. Then for all f ∈ F and all f ∈ F,
	 If a lexical item is [f], that lexical item is [f] and vice versa.
Examples of this cross-modular featural correspondence are manifold. In
Italian, for example, there is a subclass of nouns in the morphology that are
formed morphophonologically with a suffix /a/ in the singular and /e/ in the
plural (bicicletta “bicycle,” biciclette “bicycles”), and another morphological
subclass that are formed with /o/ and /i/ (treno “train,” treni “trains”). These
subdivisions generally correspond to a syntactic bifurcation, with feminines
Clitics  155
requiring one sort of agreement and masculines another (la bicicletta “the bi-
cycle,” il treno “the train”). If a noun is formed with {/a/, /e/} or {/o/, /i/}, then
a single feature in the morphology [FEM] and a corresponding feature in the
syntax [FEM], correlated by (19), provide the default associations. The nu-
merous exceptions, such as nouns that end neither in /a/ nor /o/ in the singular,
as well as genuine exceptions such as la mano “the hand,” will have overriding
features in their lexical entries.
In Latin, however, the declension of nouns and the syntactic agreement
patterns are much more loosely related. Nouns in nominative singular /a/,
accusative singular /am/, nominative plural /aɪ/, and so on, do not necessar-
ily correspond to nouns that agree syntactically with adjectives with the same
desinences. For this reason the morphological class is not traditionally called
feminine, but first declension, the term “feminine” being reserved for the syn-
tactic agreement class. If we follow traditional practice and distinguish two
separate features, the default rule (19) will give (20a) and (20b), among other
correspondences.
(20)	 a.	 DEC-1	 ←→	 DEC-1
	 b.	 MASC	 ←→	 MASC
A noun like agricola “farmer” will be lexically listed as [DEC-1] in its mor-
phological field and [MASC] in the syntactic field, as in (9) above. It will
therefore also be [DEC-1] in the syntax and [MASC] in the morphology by
rule feature osmosis. There is no harm in this, since the feature DEC-1 is never
referred to in the syntax and MASC plays no role in morphology. Since they
serve no function in these components, they may be neglected there.
5.4	 Clitics
To reiterate, morphological clitics are functions from morphological words to
morphological words. Some of the elements of speech that have been labeled cli-
tics in the linguistic literature are therefore not clitics from a morphological point
of view, in particular, those that are merely phonologically attached to some other
phonological entity forming phonological words from phonological words. An
example in English is the destressed second person pronoun, [jə]. It must “lean”
on another phonological constituent, since it is intonationally too weak to stand
on its own. As such, morphological category, constituency, and syntax seem to
play no role in its phonological phrasing, as examples such as Did you ([dɪʤə])
laugh?, The letter I wrote you ([rəʊtʃə]), I know what you ([wʌtʃə]) want, show.
An unstressed first syllable in a word such as united will not palatalize preceding
156  Morphology and morphophonology
dentals because it is already supported phonetically within the word of which it
is a part. Thus the sequence (he) had united (the kingdom) is [hædjənaɪtəd], but
(he) had you knighted (by the queen) can be [hæʤənaɪtəd].
There are innumerable post-inflectional parts of phonetic words that cannot
be described entirely in terms of phonetic reduction, however, since they are
sensitive in some degree to morphological features of their host words, or to the
syntactic position of the host, or they occur in a finite set of lexical forms, or do
not correspond phonetically to any free form. In such cases, we are ­
entitled to
assume that there is actually a morphological unit of the form [Word [Word X] M],
where the operation M derives a word when applied to a word, and meets the
definition of a morphological clitic given above.
Restricting our attention to morphological operations that can be consid-
ered cliticization, we find that one of the most common extra-morphological
requirements is that the clitic is attached to a word that is linearly adjacent to
it. A very nice example is the English possessive clitic. In the syntax it has
very similar properties to those of syncategorematic elements like functional
of (Chapter 2 (22)), except that it is not the head of a prepositional phrase, or at
least there is no evidence that it is. Therefore it will provide a syntactic feature
that is required in certain configurations such as that of the genitive determiner
in a possessor–possessed phrase. The possessive clitic cannot be considered to
be a phonologically reduced version of an independent word, since there is no
candidate in the English lexicon. Morphologically, the clitic takes a word and
returns a word and has the morphophonological consequence of appending
morphophonological /S/, with predictable allomorphs /əz/, /z/, or /s/.8
There
is also a linear order rule associated with the possessive clitic that requires the
additional phonological material to follow its morphological host and to fol-
low the noun phrase that is its syntactic complement.9
In the syntax, the clitic
counts as a category-free element that combines with an NP to form an NP
with an additional syntactic feature that I will call POSS. Neglecting the effects
of the clitic in the two semantic dimensions as not relevant to the point at hand,
its properties are specified in the following lexical entry.
(21) ’s (English possessive clitic)
syntax: ’s in [NP[POSS] NP, __ ]
morph: Word Word
mphon: /X/ /X + S/
LOC: NP[POSS]
Σ α β
= NP ’s
= <<
Word = [ …Word] M
Clitics  157
Unlike the derivational processes (14), (15), (16), and (18), which are func-
tions at all levels at which they have an effect, the possessive clitic is an actual
item, at least in the syntax, though not one that can ever appear as a free form.
Returning to the autonomous syntactic component, we find that there is a
requirement that a noun phrase serving as a determiner bear the possessive fea-
ture and a separate rule that allows (or for many requires) a human noun phrase
following possessive of to bear that feature. Possessive of, as in a portrait of
John’s by Peale, is not the empty of (Chapter 2 (22)) that is found in a portrait
of Washington by Peale. The element of does not clearly form a prepositional
phrase with the following genitive, as it does with a non-possessive NP object:
Of whom/*whose is this a picture, Whom/*whose is this a picture of. Neither
does it clearly make an independent contribution to semantic structure, but in-
stead restricts the cognitive relation between the referent of the possessive NP
and the possessed item.
(22)	 NP → NP[POSS], N′
(23)	 of (possessive)
	 syntax: __ in [ N, __, NP[POSS]]
	 F/A: nil
	 RS: ROLE = __ in [“belong”, __, ANC]
Besides acquiring the feature [POSS] through combination with the posses-
sive clitic, an NP can have the feature in its lexical entry. The attributive pos-
sessive pronouns (my, your, etc.) and the absolute possessive pronouns (mine,
yours, etc.) both bear this feature lexically. The attributive form of the posses-
sive pronoun must combine with an N′ to form an NP, while the absolute form
makes a non-possessive NP all by itself.
Both (24a) and (24b) are obviously less general than the formation of an
NP[POSS] by combining a possessive clitic and an arbitrary NP. Therefore,
forms such as *me’s are preempted.10
A second clitic that I wish to consider here is the auxiliary clitic ’ll. It is per-
haps just phonologically reduced in most uses, but in combination with pronouns
(24) a. my, your, his, her, its, our, their
syntax: NP[POSS] in [NP__, N']
F/A: __ in [Arg __, Fa]
LOC: α β
<<
___ N'
b. mine, yours, his, hers, its, ours, theirs
syntax: NP[POSS] in [NP__ ]
F/A: __ in [Arg __, Fa]
158  Morphology and morphophonology
it is clearly a morphologically sensitive item that combines with the pronoun to
form a word. Morphophonologically it makes a monosyllable when added to
vowel-final pronouns that may have a shortened version of the vowel that occurs
in the full form of the pronoun: I’ll is [aɪl] or [al], she’ll is [ʃiːl] or [ʃɪl], etc.
In syntax, combinatoric semantics, and role structure it has exactly the same
functions as the auxiliary will. Finally, the element is restricted to cases where
the syntactic pronoun (whose feature is spread from the morphology, where it is
independently needed) occurs immediately before the syntactic atom: will.
Let us call a terminal element of the syntax a syntactic word, whether or
not there is a free form that can instantiate it. The possessive clitic (21) and
the future auxiliary clitic (25) both count as terminal elements of the syntax as
well as word-to-word morphological operations. Both clitics are also governed
by an adjacency condition. Let us call this sort of behavior morphosyntactic
cliticization, which is described in (26a). The dual tree in (26b) depicts the situ-
ation for the English possessive operation.
There are many other examples of morphosyntactic cliticization that are not
described here, including the infinitive marker in wanna and hafta, and, with
some complications, the negative clitic on auxiliary verbs, as well as examples
in other languages, such as the NP-final definite clitic in Haitian Creole, the
(25) ’ll
syntax: [V[TNS] will] in [ __ VP[INF]]
F/A: Fp
RS: “will”, EVENT
morph: N[PRO] � Word
mphon: /… V:/ � / … V(:)l/
LOC: only if α << β
N[PRO] will
(26) a. Morphosyntactic Cliticization
The joining of a syntactic word and an adjacent syntactic word
that produces a morphological word from a morphological word.
b. NP[POSS]
NP Possessive syntax
… W
W M(’s) morphology
W
Incorporation  159
definite clitic suffixed to the first word of an NP in South Slavic, the conjunc-
tive clitic –que in Latin that is suffixed to the first word of a conjunct phrase,
and the similarly distributed clitic conjunction –lu in Inuit languages.
5.5	 Incorporation
Another important kind of morphology–syntax mismatch goes by the name
of incorporation, a classical example of which is Southern Tiwa noun incorp-
oration (Allen, Gardiner, and Frantz 1984). In that language the more patient-
like the argument, the easier it is to incorporate it. For the most patient-like
arguments – direct objects that contain an inanimate head noun or consist of
an unmodified, animate, common noun – the incorporation is obligatory. With
modified animates the incorporation is optional and with proper names, it is
impossible. (See Sadock 1985b.)
(27)	 a.	 *Diru-de 	 a-k′ar-hi.
		 chicken-cl	 AGR-eat-future
		 “You will eat the chicken.”
	 b.	 A-diru-k′ar-hi.
		 AGR-chicken-eat-future
		 “You will eat the chicken.”
(28)	 a.	 Yede	 diru-de 	 a-k′ar-hi.
		 that 	 chicken-cl	 AGR-eat-future
		 “You will eat that chicken.”
	 b.	 Yede 	 a-diru-k′ar-hi.
		 that 	 AGR-chicken-eat-future
		 “You will eat that chicken.”
In (28b) we see that the incorporated noun is the head of an NP and is incorpo-
rated with the syntactic head of the verb phrase, stranding a possible modifier. In
the morphology, the stem of the verb and the stem of the noun are compounded
to form a new verb stem making the process derivational as defined by (2). These
two features – syntactic heads combining with syntactic heads and morphological
stems being modified to form stems – are very typical of incorporation, though
deviations from this pattern do occur, sometimes blurring the line between cliti-
cization and incorporation. Incorporative processes play little role in English
with the very important exception of the behavior of the tense element that will
be taken up in detail below, but they are widely attested in other languages. Baker
(1988a) gives detailed treatments of a variety of different incorporative phenom-
ena in several languages, and others can be found in Sadock (1991).
Let us define a notion of morphosyntactic incorporation along the same lines
as morphosyntactic cliticization as (29). The Southern Tiwa example of noun
incorporation, (28b), is diagrammed in (30).
160  Morphology and morphophonology
(29)	 Morphosyntactic Incorporation
	 The joining of a syntactic head word and an adjacent syntactic head word
	 reflected in a morphological operation that produces a morphological
	 stem from a morphological stem.
5.6	 Tense and auxiliaries in English
The basic insight behind the analysis of the verb system of English that I
will present is that tense is a syntactic head, as assumed by most investiga-
tors working in the transformational paradigm from its inception. But tense
is ordinarily realized as an inflection on verbs in English and when it is, it
presents a discrepancy between its syntactic and morphological constituen-
cies, a discrepancy that is subject to interface constraints like those governing
cliticization and incorporation. In particular, the parts of the morphological
word must correspond to heads in syntax, as in incorporation, and these must
be adjacent in linear order, as in cliticization. Adjacency of the syntactic tense
element to main verbs is interrupted by negation, inversion, tagging, and so
on, and therefore main verbs cannot be directly negated, inverted, or appear
in tags. Auxiliary verbs must be treated differently since they can be negated,
inverted, and appear in tags. As in a number of works in different frameworks,
English auxiliaries will be treated as listed in the lexicon already associated
with tense and will therefore not present discrepancies between syntactic
structure and morphological structure. They are therefore not affected by the
interface constraints.
5.6.1	 Tense
Viewed from the perspective of multi-modular grammar, the term “tense” (like
many other basic grammatical terms) is multiply ambiguous. Tense may refer to
(30)
VP
NP V syntax
Dem N
yede a diru k’ar hi
AGR [ ]
[ ]
[ R ]
morphology
Tense and auxiliaries in English  161
(1) the semantic category of tense that relates the time of a described event to some
reference point, (2) the syntactic category, a head in syntax, (3) the morphological
category that is required in order to form a finite verb, a morphological word as
set out in rule (1) above, or (4) the morphophonological substance that indicates a
category of verbal morphology as in the usage “the tense affix.”
Various combinations of these distinct notions are often – perhaps usually –
confounded, but the framework advocated here demands that they be kept separ-
ate. In the next several sections I will consider each of these component-specific
notions of tense and then say something about how they are interrelated.
5.6.1.1	 The semantic category of tense
Semantic tense is a meaningful operator that locates one event temporally with
respect to a reference event (Reichenbach 1947; McCawley 1981; Heim and
Kratzer 1998, etc.). Some of the relations commonly expressed by semantic
tense are precedes, coincides with, and follows. Where the reference event is
the act of uttering the sentence itself, these relations correspond to main-clause
past, present, and future semantic tense.
Tenses are combinatoric functions in the F/A component, just as predicates,
quantifiers, and arguments are. They are obviously propositional modifiers, or
equivalently, predicates that take propositions as arguments. We can represent
the meaning of a past-tense sentence such as René cogitated as (31), where
“PAST” can be read: “is true at a time preceding the moment of speech.”
Similarly, René cogitates would contain a present tense operator and would
correspond to a proposition that is true if René is among the set of cogitators at
the moment the sentence is uttered. There are other categories of tense such as
a recent past versus a remote past, near future versus remote future, and so on,
but the three relations just mentioned seem to be the most common ones that
are reflected by simple operators in the semantics of natural languages.
Since an operator like PAST is a function from propositions to propositions,
it can be iterated. This allows for well-formed semantic structures such as (32),
which McCawley (1988) cleverly demonstrated to be the right semantics for a
present perfect such as René has cogitated.
(31) Prop
Prop
Fp
PAST Arg
RENÉ
Fa
COGITATE
162  Morphology and morphophonology
5.6.1.2	 The syntactic category of tense
Let us accept an idea that was already anticipated in Chomsky (1957, elabo-
rated in Chomsky 1965 and Chomsky 1981), and is generally accepted now-
adays by adherents to virtually all kinds of transformational grammar, namely
the idea that the tense element in English is a phrasal head in syntax and has a
verb phrase as its complement. Diverse syntacticians at various times – from
Chomsky (1957), to McCawley (1981), to Radford (1997) – include structures
like (33) as a common syntactic denominator. There are a variety of alphabetic
variants and more structure may interrupt the constituents in (33), but (33)
lurks somewhere in what is accepted as basic clause structure in a great deal of
research into English grammar over the last fifty years.
The elaborated structure of a finite clause that I will now assume is (34), which
is implied by the phrase structure grammar in (14) of Chapter 1 in conjunction with
the system of feature geometry of the syntactic verb family as summarized in (35).
S
NP
T
T'
VP
(33)
S[TNS]
NP VP[TNS]
V[TNS]
(34)
VP[-TNS]
(35) V
TNS -TNS
PAST PRES PART INFIN
PRS-P PSV-P PST-P
(32)
Prop
Prop
Prop
Fp
PRES
Fp
PAST
Arg
RENÉ
Fa
COGITATE
Tense and auxiliaries in English  163
5.6.1.3	 The morphological category of tense
In many languages, verb-words appear in a paradigm of contrasting forms called
tenses. In English there is only a two-way morphological contrast between mor-
phological PAST (e.g., was, had, walked, rode, went) and morphological PRES
(e.g., am, has, walks, rides, goes).The reason for using the semantically grounded
terms “past” and “present” to refer to this and similar morphological contrasts
is, of course, that these morphological distinctions often correlate with semantic
past and present tense. But morphology is not semantics and the morphological
forms are often at odds with the similarly named semantic distinctions, e.g., in If
the dog was here right now she’d be barking, or I leave for Peoria next week.
Any meaning-bearing element can in principle be represented by a morpho-
logical stem, by a word, or by a morphological process. If tense is represented
as an inflectional category of verbs, as it frequently is, it will be introduced in
the position of PAST in (36), a special case of (2).
(36)	 PAST in [Word [PAST] Stem[verb], __ ]
5.6.1.4	 The semantics, syntax, and morphology of tense
Syntactic tense is usually represented in English as verbal inflection in the
morphology of the language. The partial lexical entry for the past-tense inflec-
tion, including an indication of the semantics of tense as a function from prop-
ositions to propositions, is accordingly the morphological rule in (37) that
makes a finite verb of a stem and adds the phonological material that is associ-
ated with the additional morphology.
(37)	 Past, Pres (English inflectional tense)
	 syntax: V[TNS] in [ __ VP]
	 F/A: Fp 	
	 morph: Stem [V] → Word [V, PAST]
	 mphon: / … / → / … + D/
This lexical item occurs in the sentence Mendel sang, whose F/A struc-
ture is diagrammed in (38), whose simple syntax is shown in (39), and whose
morphological structure is (40).11
The present tense will have a similar lexical
entry, but with the morphological feature PRES in place of PAST, and the
semantic feature PRES in place of PAST.
(38) Prop
Fp
PAST
Prop
Fa
SING
Arg
MENDEL
164  Morphology and morphophonology
The discrepancy between the position of the semantic subject in (38) and
the syntactic subject in (39) is exactly the same as what is found in the case of
a raising-to-subject verb like seem and will follow without the need for move-
ment, as discussed in 2.6.1 for raising verbs.
But the lexical entry Past is not a morphological verb; it is a verbal inflection
that has productive morphophonological realization as the suffixes /əd/, /d/, /t/,
and various other effects that have to be listed in the lexicon under the entries for
specific verbs. What it means for PAST in English to be an inflectional process
is that it applies to morphological stems to produce words, and for that reason,
only one level of morphological tense is allowable in a word. Thus in a context
where a non-finite inflectional form such as the present participle is called for,
say the complement of a verb like keep, inflectional tense is impossible because
the inflected form singing, for example, is a word, not a stem. Because inflec-
tional tense is excluded in such a position, the syntactic ­
homologue of morpho-
logical tense, [V[TNS] Past], is impossible in non-finite context.
Conversely, since all surface words must be morphologically complete, all
verbs must have some inflection. If no non-finite inflection is required by the
syntax, then the clause must contain a tense element V[TNS] to provide the
verb with inflection through lexical entries such as (37) above. A clause of
the form NP VP where VP is neither [TNS] nor [-TNS] will fail to be gram-
matical for an essentially morphological reason: its verb will remain a mor-
phologically incomplete bare stem.
5.6.1.5	 Tense association
English inflectional tense has morphosyntactic properties combining those of
the typical of stem-to-stem incorporation and word-to-word cliticization: the
input is a stem, as in incorporation, and the output is a word, as in cliticization;
the tense element is the head ofVP[TNS] and it combines morphologically with
(39) S
NP
Mendel
VP[TNS]
V[TNS]
Past
VP
sing
(40) Word [V, PAST]
Stem [V]
sing
PAST
Tense and auxiliaries in English  165
the head V of its syntactic verb phrase complement, as in incorporation; and
those two elements must be adjacent in the string of words as is the case with
cliticization. I propose to identify this set of behaviors as a third fairly stable
and frequently encountered type of mismatch between morphology and syn-
tax. For lack of a preexisting term, I will call it Morphosyntactic Association.
(41)	 a.	 Morphosyntactic Incorporation
		 Syntax: head to head	
		 LOC: no restriction
		 Morphology: Stem → Stem
	 b.	 Morphosyntactic Cliticization
		 Syntax: no restriction	
		 LOC: word << word
		 Morphology: Word → Word
	 c.	 Morphosyntactic Association
		 Syntax: head to head	
		 LOC: word << word
		 Morphology: Stem → Word
It is, in fact, quite common for the morphological joining of two independent
elements of syntax to be restricted by the combination of the head adjacency
condition in syntax and the string adjacency condition in linear order. Local
rules in the sense of Emonds (1976) have just this property. Pullum (1979)
argued that rules that in his framework had to be post-cyclic were local in the
same sense and had to involve linearly adjacent items that were either sis-
ters or aunt and niece, and van Riemsdijk (1998) has argued that all head-
to-head adjunction (which would cover the phenomenon we are interested in
here) requires linear adjacency of the source and target heads. I believe that the
reason for the existence of conditions like those in (41a)–(41c) is that incorpor-
ation, cliticization, and association produce modular mismatches. For the syn-
tactic structure and semantic structure to be easily determinable, it appears that
there need to be additional clues as to how the mismatches are to be resolved,
clues that include head adjacency and string adjacency.
Let me return to the special behavior of English finite verb phrases and
the idea that morphosyntactic association accounts for much of it. It was
Chomsky’s (1957) insight that under inversion, negation, tagging, and so on,
something intervenes between the tense element and the main verb. My (41c)
is a version of the same adjacency constraint, now embedded in a theory where
this constraint makes sense. In my version, as in early transformational theory,
when a main verb is not adjacent to the tense element in syntax, the association
of the tense element with a verb will not be possible, and since the tense elem-
ent is not a morphologically independent element, no grammatical result will
166  Morphology and morphophonology
be possible. But English has negation, inversion, and tagging, and it is the short
list of special verbs we call auxiliaries that makes these important expressive
devices possible.
5.6.2	 English auxiliary verbs
While main verbs and tense are separate elements in the syntax and can there-
fore be reordered in the LOC, preventing their morphological association,
tense and auxiliary verbs are never separate in syntax. Traditional transform-
ational analysis handled this with one or more movement rules that joined
tense and auxiliaries earlier than tense and main verbs. Since the present
theory lacks movement altogether, there is no analysis available other than
one that treats auxiliaries as having different syntax from ordinary verbs. I
will treat English auxiliaries as syntactic adjuncts to V[TNS].12
As such, they
produce another V[TNS] that takes a verb phrase as a complement and adds
a specific feature to that complement that determines the non-finite form of
the complement that the auxiliary takes. Whereas main verbs will occur in
the configuration in (42), auxiliaries will be found in structures like (43). In
the latter case the introduction of something between V[TNS] and the other
constituents of the verb phrase means there is no mismatch between syntax
and morphology and the expression is well formed regardless of the position
of the main verb V. (It is the fact that a verb is listed in the lexicon as a modi-
fier of the category V[TNS] that determines its special behavior, so there is
no need for the ad hoc feature [AUX] that was used in Chapter 4 as a tem-
porary expedient.)
(42) VP[TNS]
V[TNS]
Pres
VP
V
sing
...
(43) VP[TNS]
V[TNS] VP[F]
V[TNS] V ...
Pres can sing
be
have
etc.
Tense and auxiliaries in English  167
The auxiliary verbs of English thus have different syntactic combinatorics
than other verbs in the language. Main verbs are syntactic heads of verb phrases,
which may be complements of V[TNS], whereas auxiliaries are subconstitu-
ents of V[TNS]. A lexical entry such as the following for the modal auxiliaries
formalizes the idea.
(44)	 can, could, may, might, shall, should, will, would, must
	 syntax: V in [ [V[TNS]V[TNS], __ ], VP[INFIN]]13
	 F/A: Fp
	 morphology: Stem in [ __, PRES]14
	 mphon: /kæn/, /kʊd/, /meɪ/, /maɪt/, /ʃæl/, /ʃʊd/, /wɪl/, /wʊd/, /mʌst/
Main verbs with irregular morphophonology are not modifiers of tense
in the way that auxiliary verbs are. Their oddity is at the morphology–­
morphophonology interface; their syntax is that of an ordinary lexical item, a
head that selects a particular type of complement. The verb phrase that main
verbs head can occur wherever verb phrases can, including as complements
of V[TNS], as shown in (37). The lexical entry for sing in (13), for example,
would allow it to occur in the syntactic, morphological, and morphophono-
logical structures (45). As the diagram shows, the syntax and morphology
require morphosyntactic association of the tense and therefore the adjacency
requirement is in effect.
Can, have, be, and the remaining auxiliaries, on the other hand, are adjuncts
to tense that remain adjacent to tense and will therefore always be pre-­
associated
with it in the morphological component (46).
(45) VP
V[TNS]
Past
VP Syntax
V
sing
…
[PAST, Stem [V]]
Morphology
Word
/sæη/ Morphophonology
168  Morphology and morphophonology
Let us now consider inversion, one of the factors that distinguishes main
and auxiliary verbs. The linear order component rule for inversion, (27) in
Chapter 4, is repeated here as (47):
Now if XP is anything other than the subject, the subject will appear as close
to first position as possible because of its high position in the syntactic tree and
the pressure that creates for harmony with the LOC. It should therefore imme-
diately follow the highest V[TNS].15
If V[TNS] dominates an auxiliary verb
like can, have, or be, which modifies the category V[TNS], the subject simply
follows the auxiliary. But if there is no auxiliary, the subject (γ) will intervene
in linear order between the tense element (β) and the main verb (δ), as shown
in (48), and that would block association.16
(46) VP
V[TNS] VP[INFIN] Syntax
VP V[TNS] V[INFIN] …
can Pres
[Stem[V], PRES]
Morphology
Word
/kæn/ Morphophonology
(48) S
VP
NP V[TNS]
Past
VP
V
sing
NP
what
Mendel
Σ = α β γ δ
< <
(47) = < <
#S# =
Σ α β
[XP[NEG/WH ] V[TNS] … ]
Tense and auxiliaries in English  169
Thus *What sang Mendel? and *Sang Mendel?17
are ungrammatical because
they contain an improper association of tense and the main verb.
On the other hand, if XP[WH] is the subject, then that is what will be found
in initial position as in (47), where it would be anyway, since it is the high-
est element in the syntactic and F/A trees. There will therefore be no mis-
match of any kind, the subject will not intervene between V[TNS] and the
following V, morphosyntactic association will be possible, and no auxiliary
verb will be needed to support the tense element morphologically. Thus the
grammaticality of Who sang America the Beautiful? is explained without fur-
ther assumptions.
5.6.2.1	 Do “support”
When the tense element fails to be adjacent to the head verb of its complement
and cannot be associated morphologically with the verb stem, its morphological
requirements will be unmet, and furthermore, the stem of the verb will not be
inflected and will fail to constitute a full morphological word. The expression
will thus be ungrammatical or un-morphological, we might say. One use of do
behaves like a modal auxiliary and can be used to satisfy these requirements
in the absence of any other verb that is lexically combined with V[TNS]. Like
the modals, it is subcategorized for infinitive verb phrase complements and has
only finite forms. Therefore, like the modals, it cannot occur in the scope of
another auxiliary or in any context that requires a non-finite form of the verb
(e.g., *I object to John’s doing sing the Internationale, *John has done sing
the Internationale, *For me to do sing the Internationale would be a mistake.)
Unlike the modals, however, supportive do has special morphophonemic pre-
sent and past tense forms and therefore allows the expression of the meaning
of morphological tense. The really special characteristic of auxiliary do is, of
course, that it has no semantic representation and can therefore serve morpho-
logical and syntactic functions without contributing any meaning of its own. Its
lexical representation is (49), allowing one to say What did Mendel sing?, Did
Mendel sing?, and Nowhere did Mendel sing that better, in order to express
what we cannot express with the simpler forms *What Sang Mendel?, *Sang
Mendel? and *Nowhere sang Mendel that better.18, 19
(49)	 do (auxiliary)
	 syntax: V in [VP [VV[TNS], __ ], VP[INFIN]]
	 F/A: nil
	 RS: nil
	 morphology:
	 1.	 Stem in [ __, PAST]
170  Morphology and morphophonology
		 mphon: /dɪd/
	 2.	 Stem in [ __, PRES, 3s]
		 mphon: /dʌz/
	 3.	 Stem in [ __, PRES]
		 mphon: /duː/
Because of its syntactic status as a modifier of V[TNS], meaningless do
allows for inversion when no other auxiliary is present. In cases where nothing
blocks the association of tense and a main verb, supportive do will not be used
since a less effortful, simpler form is available for expressing exactly the same
meaning.20
5.6.2.2	 The verb have
English perfective have behaves like an auxiliary, taking a VP complement,
inverting, supporting negation, and so on. For some speakers, non-auxiliary
uses of have will also have lexical entries allowing them to appear as modifiers
of V[TNS]. For those dialects that can treat possessive have as an auxiliary
(e.g., Have you a match? I haven’t a car) the verb will receive the lexical de-
scription (50) where it differs from other modifiers of V[TNS] insofar as it has
an entirely different kind of complement, an NP. The behavior of possessive
have can be specified as in (50) indicating that the verb occurs with a noun-
phrase object, counts as a semantic relation of the category Faa, expresses the
HAVE relation between a patient and (following Fillmore 1968) an ancillary
participant, and that it is a morphological stem with unusual morpho­
phonology
in the finite forms. That much is constant, but there are two kinds of syntax that
the verb displays.
(50)	 have (of possession)
	 F/A: Faa
	 RS: “have”, ANC, PAT
	 syntax:
	 a.	 V in [ __, NP]
	 b.	 %
V[TNS] __ in [VP [V[TNS], __ ], NP]
	 morphology: Stem[V]
	 i.	 Stem in [ __, PAST]
		 mphon: /hæd/
	 ii.	 Stem in [ __, PRES, 3s]
		 mphon: /hæz/
	 iii.	 Stem in [ __, PRES]
		 mphon: /hæv/
The syntactic subentry (50a) makes have an ordinary transitive verb, for all
speakers, while the alternative (50b) allows possessive have to invert, support
Tense and auxiliaries in English  171
negation, and so on, an alternative that is not productively available for many
speakers.
Most uses of be will also count as V[TNS], the major exception being the
imperative: Do be quiet, Don’t be silly. I will leave it as an exercise for the reader
to formulate the appropriate lexical entries for the various uses of be in English.
The semantic face of tense, i.e., TENSE, is an operator – a function from
propositions to propositions. TENSE finds expression in English as inflection,
as we have seen, but it is possible for the proposition expressed in non-finite
structures to have TENSE as well. McCawley (1971) argued that non-finite
verb phrases can display a contrast between present and past semantic tense,
the argument proceeding from the observation that the adverbials right now
and at 11:00 last night are diagnostic of simple present tense and simple past
tense in finite clauses.
(51)	 I am at Jimmy’s right now/*at 11:00 last night.
(52)	 I was at Jimmy’s *right now/at 11:00 last night.
(53)	 I have been at Jimmy’s *right now/*at 11:00 last night.
These adverbs also occur with non-finite verbs, as the following examples
show. We can conclude, then, along with McCawley, that the adverbs diagnose
semantic present and past tense.
(54)	 a.	 I believe Leslie to be at Jimmy’s right now/*at 11:00 last night.
	 b.	 I believe Leslie to have been at Jimmy’s *right now/at 11:00 last night.
Notice that the subordinate proposition in (54b) corresponds to a main
clause with a simple past tense, and not to a present perfective main clause: I
believe that Leslie was/*has been at Jimmy’s at 11:00 last night. McCawley
(1971, 1981) concluded that auxiliary have encodes a semantic past tense and
its absence in non-finite forms encodes semantic present tense.21
A slight complication arises in connection with the following examples:
(55)	 a.	 I believed Leslie to be at Jimmy’s at 11:00 last night.
	 b.	 *I believed that Leslie is at Jimmy’s at 11:00 last night.
If the absence of have in (55a) reflected semantic present tense, then that sen-
tence ought to be just as unacceptable as (55b). I would surmise that the notion
“sequence of tense,” as discussed, for example, in Hornstein (1990), supplies
the subordinate proposition with a semantic past tense, though I will not pursue
the idea formally.
Having established that have counts as semantic past tense, McCawley rea-
soned that the present tense of the auxiliary counts as the present of a past
172  Morphology and morphophonology
semantically, and the past tense of the auxiliary as the semantic past of a past.
The contrast between the reasonable (56a) and the unreasonable (56b) is partly
explicable given these assumptions.
(56)	 a.	 Stoppard has written 22 plays.
	 b.	 ?
Shakespeare has written 38 plays.
(57)	 a.	 Stoppard had written 15 plays by the time he was 35.
	 b.	 Shakespeare had written 25 plays by the time he was 35.
If tenses are relations between the times of two events, the event time and
the reference time, then the present perfect will be a statement about the past
whose relevance continues to the present but may change in the future, whereas
a simple past represents an event that was true at some earlier time and is neu-
tral with regard to present relevance. The past perfect represents an event that
was true at a time anterior to a past event but whose relevance continued to
the time of the reference event and may have ceased to be true at times later
than the reference event, which in both (57a) and (57b) happens to be appro-
priate since both authors continued to write plays after the reference time that
is mentioned.
Matters of tense are much more intricate than this, of course,22
but the point
is that McCawley’s basic insight – that a present perfect is the semantic present
tense of a past tense and the past perfect is the semantic past tense of a past
tense are automatically modeled by the mechanisms that have been developed
here without the transformational machinery that McCawley relied on in his
framework. The required lexical entry for perfective have is (58), where the
syntactic frame a. is the use as finite auxiliary and the syntactic frame b. allows
non-finite uses as in might have left, having left, and so on.
(58)	 have (perfect auxiliary)
	 F/A: Fp (=PAST)
	 syntax:  a.  V in [V [VV[TNS], __ ], VP[PST-P]]
		 b.	 V in [ __, VP[PST-P]]
	 morphology:
		 1.	 Stem in [ __, PAST]
			 mphon: /hæd/
		 2.	 Stem in [ __, PRES, 3s]
			 mphon: /hæz/
		 3.	 Stem in [ __, PRES]
			 mphon: /hæv/
		 4.	 Stem in [ __, INFIN]
			 mphon: /hæv/
Let us examine the quadri-modular representation of (56a) above:
Tense and auxiliaries in English  173
The syntax, morphology, and morphophonology given in (59)–(60) are the only
well-formed structures compatible with the lexical items found in the expres-
sion. Now PAST and PRES must both occur in the combinatoric semantics
because of the presence of inflectional tense, here associated with PRES and
/hæz/, which is associated with PAST. There is no particular structural account
of the scope we find, since in none of the other structures does the componen-
tial representation of present tense asymmetrically c-command the past-tense
operator. But I think there is another explanation for the fact that the past tense
must be in the semantic scope of the present tense. When two tense operators
occur in sequence, the higher one establishes the relevance time for the second:
a present of a past is a past event that is relevant to the present; a past of a past
is a past event that is relevant to a subsequent past event. The relevance time
apparently must follow the event time, but that would not be the case for pre-
sent events that are relevant to the past, until the time machine is perfected.
(59) S
NP
Stoppard
VP[TNS]
V[TNS]
V[TNS]
Pres
VP[PST-P] Syntax
have written 22 plays
(60) Prop
Fp
PRES
Fp
PAST
Prop
Prop F/A
Arg Fa
STOPPARD WRITE 22 PLAYS
(61) STEM, PRES, 3s
Morphology
WORD
/hæz/ Mphon
174  Morphology and morphophonology
Finally, one more fact from McCawley’s work: non-finite have can be found
where either simple past (62a), present participle (63a), or past participle (64a)
is required in a finite clause:
(62)	 a.	 I remember that he was at Jimmy’s at 11:00 last night.
	 b.	 I remember him as having been at Jimmy’s at 11:00 last night.
(63)	 a.	 I believe that he has been studying for two hours by now.
	 b.	 I believe him to have been studying for two hours by now.
(64)	 a.	 I remember that he had already left by the time I got there.
	 b.	 I remember him as having already left by the time I got there.
To account for this McCawley postulated a rule of have deletion whereby all
instances of have are deleted except one. Here all that needs to be said has
already been said. The lexical entry for perfective have lacks a specification
for a past participle, and because have requires a past participial comple-
ment, nested have is impossible. The best that can be done in non-finite verb
phrases of English is to indicate all manner of pastness with a single semantic
operator.
5.6.3	 Negation
The distribution of not also differentiates the small class of auxiliaries from all
other verbs in English. In the present framework it is possible to say that the
negative element not is simply a modifier of verb phrases, just like its relatives
in other Germanic languages and its ancestor in Old English. Where there is no
V[TNS] in a verb phrase, not simply precedes the verb phrase: your not having
been there, her not being certain, (we request) that you not say a word, They
asked you not to smoke, and so on. The peculiarity of the present-day word is
that it is subject to a special linear order component requirement that demands
that it follow a V[TNS] rather than precede it as a modifier would be expected
to do in English (65).
(65) not
syntax: Adv in [VP __VP]
F/A:Fp (= NOT)
morph: WORD
mphon: /nat/
LOC: Σ α β
= <
VP = [not, [V [TNS] … ]]
Tense and auxiliaries in English  175
If there is no auxiliary modifying V[TNS] in the verb phrase that not
modifies, there will be no grammatical result, since the syntactic tense
element, which needs to be expressed as a verbal inflection for reasons
that have already been discussed, will be too far away from the head of the
non-tensed V in terms of string proximity to associate with it, as we can
see from (66).
In order to express the meaning that a semantic structure such as
(NOT(SANG(MENDEL))) represents, the semantically empty auxiliary do is
pressed into duty, as discussed in connection with inversion. This word allows
the same content to be expressed without violation of the association constraint
on morphological tense. Mendel didn’t sing is described in several dimensions
as (67)–(69), where it can be seen that nothing interrupts the contiguity of
the stem of do and the past-tense morphological process, so association is not
blocked. Furthermore, the F/A structure is exactly the same as it would be
for Mendel not sang or Mendel sang not, were they grammatical in modern
English.
(66) VP
not VP Syntax
V[TNS] VP
V[TNS] not sing LOC
Past
PAST Word STEM
Morphology
*Word
(67) Prop
Prop
NOT
Fp
Fp
PAST
Fa
SING
F/A
Prop
Arg
MENDEL
176  Morphology and morphophonology
Since not may not precede V[TNS] and since it may modify any verb phrase,
the linear order component stipulation governing its position will often lead to
scope ambiguity. For example, the sentence Students may not participate in the
convocation, is ambiguous between a reading in which permission to participate is
denied and a reading in which permission to refrain from participation is granted.
On the former reading it is reasonable to assume that the negation is a modifier of
the entire verb phrase may participate in the convocation, but on the latter read-
ing it is a modifier of the lower verb phrase participate in the convocation. All
other things being equal, the maximization of congruent c-command relationships
between F/A structure and syntax coupled with the stipulation that not must not
precede V[TNS] should make this so. There are well-known restrictions on scope
interactions (Horn 1989), some of which will be dealt with below, but the possi-
bility of ambiguity is perfectly natural given the separation of levels.
Consider next the interaction of inversion with the constraint preventing not
from preceding V[TNS]. In a WH-question the V[TNS] appears immediately
after the clause-initial interrogative phrase followed by the other constituents
in their natural order. If the initial phrase is something other than the subject,
the subject therefore immediately follows V[TNS], so V[TNS] must contain
an auxiliary to keep from blocking tense association. The negative element
(68) S
VP
Mendel
V[TNS] V
sing
Syntax
V[TNS]
V[TNS]
α β
do
not
< LOC
(69)
/dɪd/
Mphon
WORD
STEM(=/du:/) PAST Morphology
Tense and auxiliaries in English  177
may not precede V[TNS], but in this case it will not anyway, since the elem-
ent V[TNS] is in second position in the clause. Other constituents will follow
V[TNS] in their natural order: subject, not, and the rest of the verb phrase, as
desired. Diagram (72) illustrates the analysis.
(70)	 What problem do the students not have to do?
(71)	 *What problem do not the students have to do?
5.6.3.1	 The negative contraction
It will be immediately obvious to any speaker of English that there is a sen-
tence that is very similar to the ungrammatical (71) but is perfectly grammat-
ical. Example (73), with the negative element contracted, is a very natural
alternative to the ungrammatical (71).
(73)	 What problem don’t the students have to do?
We must therefore consider how to treat negative contraction in the automodu-
lar framework. Zwicky and Pullum (1983), arguing that negative contractions
are inflections, document all of the idiosyncrasies that auxiliary-negative com-
binations are heir to. For the common auxiliaries there are only twenty conceiv-
able contracted forms, of which four either don’t exist or are not particularly
colloquial, three have unpredictable phonological shapes, two have fixed wide
negative scope, four have fixed narrow negative scope, and three have no scope
with respect to the meaning of the auxiliary since the auxiliary is do and is not
represented in F/A structure. While some generalizations exist regarding both
morphophonology and scope (for the latter, see Horn 1989), it hardly seems
worthwhile to extract these generalizations rather than simply listing all sixteen
(72)
NP
S
VP
not VP
V[TNS]
V[TNS]
do
VP
have to do what
= XP[WH]
α V[TNS] (NP) (not) (have) (to do)
178  Morphology and morphophonology
colloquial forms in the lexicon. Table (74) indicates the relevant grammaticality,
phonological, and scopal particulars of all the possible forms.
(74)	 Auxiliaries with the contracted negation
			 mphon	 scope
1.	 can’t 	 /kænt/	 NOT(A)
2.	 couldn’t		 NOT(A)
3.	 %
shan’t	 /ʃænt/	 ?
4.	 shouldn’t		 A(NOT)
5.	 won’t	 /wəʊnt/	 ?
6.	 wouldn’t		 A(NOT)
7.	 *mayn’t	 —	 —
8.	 %
mightn’t		 A(NOT)
9.	 mustn’t	 /mʌsnt/	 A(NOT)
10.	 doesn’t		 NOT
11.	 don’t	 /dəʊnt/	 NOT
12.	 didn’t		 NOT
13.	 hasn’t		 NOT(A)
14.	 haven’t		 NOT(A)
15.	 hadn’t		 NOT(A)
16.	 *amn’t		 —
17.	 isn’t		 NOT(A)
18.	 aren’t		 NOT(A)
19.	 wasn’t		 NOT(A)
20.	 weren’t		 NOT(A)
It is apparently necessary to list each of the contracted auxiliaries separately
in the lexicon in order to provide their unpredictable properties. At the same
time it will be desirable, though not absolutely necessary, to provide a separate
entry for the contracted negative itself in order to factor out the commonalities
among its various uses. The following description indicates that, like the aux-
iliaries themselves, the contracted negative produces a modified V[TNS] and
therefore will not be separated from V[TNS] by inversion, tagging, and so on.
Thus the contrast between tags like do they not? and don’t they?
The contraction is clitic-like in its morphology, producing a word by apply-
ing to a word. The word it combines with should be a V[TNS] in the syntax, but
that cannot, of course, be the tense inflection, since the inflection is not a mor-
phological word, and therefore the V[TNS] must be the morphological com-
bination of the inflection and the stem of an auxiliary verb. The clitic counts
semantically as the same propositional negation as does the independent neg-
ator not described in (65). The morphophonemic fields list forms other than
those that involve the addition of the syllabified sequence /nt/ to verb forms
ending in a consonant and non-syllabic /nt/ to verb forms that don’t end in a
consonant. The regular forms are described by (75), a separate entry for the
Tense and auxiliaries in English  179
negative contraction, which are, as usual, overridden by the more specific lex-
ical entries, such as those we find in (76) and (77).
(75)	 n’t
	 syntax: __ in [V[TNS] __ [V[TNS]]
	 F/A: Fp (= NOT)
	 morph: [WORD __, [WORD]
	 mphon/ … / → / … + nt/
(76)	 can’t
	 F/A: NOT(CAN in [ __ (Prop)])23
	 mphon: /kænt/
(77)	 mustn’t
	 F/A: MUST(NOT in [ __ (Prop)])
	 mphon: /mʌsnt/
It is worth considering one of these examples in more detail. Mustn’t in
simple examples such as Mendel mustn’t sing has the syntactic representa-
tions (78).
Despite the position of –n’t in the syntax, (75), its lexical description, makes
it a propositional function and this, coupled with the lexical entry for mustn’t,
forces it to be in the scope of MUST. The F/A structure for Mendel mustn’t
sing is therefore (79), which correctly models the fact that that sentence cannot
mean that he is not required to sing.
(78) S
V[TNS] n’t
V[TNS] must
NP
Mendel
VP[TNS]
V[TNS] VP
sing
(79) Prop
Prop
Prop
Fp
MUST
Fp
NOT
Fa
SING
Arg
MENDEL
180  Morphology and morphophonology
Because of the associated syntax in which it is the topmost V[TNS] that is
followed by something other than the verb, the association of tense and the
modal will still be possible (80).
What if there is an additional not in a sentence with mustn’t, e.g., Mendel
mustn’t not sing Home on the Range? This can certainly mean that he is for-
bidden from refraining to sing it, where the second negative element is associ-
ated with the verb phrase sing Home on the Range. Diagram (81) illustrates the
association of the logical elements with linear order, mediated by the syntax
(here melded into the linear order component representation for clarity of
exposition).
(81)
LOC:
Prop
Prop
Prop
Prop
MUST
NOT
NOT
MENDEL SING HR
Σ = V[TNS]
must not …
n’t
V[TNS]
V[TNS]
(80)
LOC:
S
NP
Mendel
VP[TNS]
V[TNS]
V[TNS] V
sing
NP
what
VP
V[TNS] must
n’t
<< Mendel sing
=
Σ α β
Summary  181
It is impossible to construe Mendel mustn’t not sing Home on the Range to
mean that he is permitted to sing it, i.e., it’s not the case that he must not sing it.
The reason for the unavailability of this reading is illustrated in the graph (82).
It is the crossing of negations between the hierarchy in F/A structure and lin-
ear order that impedes this interpretation, while the correct scope of the nega-
tive elements has only harmonic correspondences, as we see in (81).
5.7	 Summary
The purpose of this chapter has been to flesh out a free-standing morpho-
logical component and its coordinated morphophonological component in suf-
ficient detail to illustrate their advantages within the automodular framework
of grammar. One of the immediate benefits was that the “lexical rules,” such
as the passive rule in Chapter 3 (17) could be assimilated to the independently
needed morphological rules that must be recognized in almost any grammat-
ical theory.
Much of what is traditionally called morphology in languages like English is
restricted to a finite list of relations in the lexicon, but the morphological mod-
ule developed in this chapter is a grammar, and like all of the other modules,
generates new forms. The “real morphology” is productive. Several important
phenomena in English meet this criterion and have been analyzed here, includ-
ing cliticization and verbal inflection. The independence of morphological
concerns allows for a very spare treatment of one of the most characteristic
features of English grammar, the special behavior of a small class of auxiliary
(82) Prop
Prop
Prop
NOT
MUST
NOT Prop
MENDEL SING HR
Σ = V[TNS] must not …
V[TNS] n’t
V[TNS]
182  Morphology and morphophonology
verbs in syntax, semantics, and morphology. I hope to have shown that simply
spelling out the functions of the various lexical elements in the various compo-
nents where they play a role is sufficient to predict the basic facts. The lexical
entries are complex, to be sure, but what is said about a given lexeme’s value in
any one module is more or less what has to be stipulated anyway.
What has been presented in Chapter 5 is hardly a complete treatment of
morphology, needless to say, and in fact it is not even a very complete treat-
ment of the productive morphology of English. Among the topics not found
here is the very remarkable facility with which English speakers form and
comprehend novel compound nouns, not even noticing, perhaps, that they are
doing so. Compounding morphology in English deserves a book-length auto-
modular exposition all by itself.
183
6	 Gaps and other defective elements
Most lexical items are complete in the sense that they are represented with
appropriate content in each of the major structural dimensions: phrase struc-
ture syntax, functional (F/A) and cognitive (RS) semantics, morphology, and
morphophonology. This is the case for the great majority of open-class lex-
emes – nouns, verbs, and adjectives, in particular – which generally have par-
allel representations in all of the major dimensions of analysis. A transitive
syntactic verb such as extinguish, for example, is also a transitive relation (Faa)
in function-argument structure, determines a two-participant type of event in
RS, is a morphological verb stem, and carries the morphophonological value
/ekstɪŋgwɪʃ/. The lexeme saganaki is a syntactic noun, an F/A structure predi-
cate (Fa), helps determine the referent of one of the participants in RS EVENT,
counts as a morphological noun stem, and contributes the morphophonological
content /saganaki/ to the phonological string it is part of. Numerous examples
of such non-defective lexical elements have been amply discussed in the pre-
ceding chapters and will not concern us further in this chapter.
One of the important kinds of mismatches between representations in one
component and those in another that we have already seen several examples of
is induced by lexical items that have a positive value at one or more levels of
description but are unmatched by anything at some other level or levels. There
are, for example, lexical items that are distinct elements of syntactic structure
and most other dimensions of representation, but have no value in F/A struc-
ture at all. In Chapter 2, we saw empty be (11), the indefinite article used with
predicate nominals (12), pleonastic it (20), infinitival to (n. 21), and functional
of (22). In Chapter 5 there was the do of traditional do-support (49). It should
also be noted that in all these cases, the lexeme does not play any part in filling
out the scene that is represented by the expression and the item is therefore also
unrepresented in role structure as well as F/A structure.
While defective lexical items that are semantically empty both combinatori-
cally and cognitively are a frequent type in English, there are other sorts of
lexemes that lack representations in one or more dimensions. The unspecified
184  Gaps and other defective elements
agent in the “agentless” passive, for example, whose lexical entry is (15) in
Chapter 3, has a function in role structure as explained there, but plays no role
in the combinatoric semantics, a conclusion that is clear from the fact that the
agent it introduces has no semantic scope properties with respect to other com-
binatoric units of the F/A structure. It also lacks morphological status and mor-
phophonological content, as seems natural for items with no syntactic value.
A major example of another type is the very important element RHO (Chapter
2 (59), (61)). It is a lexical element that has a distinct position in both kinds
of semantic representations, but which is not found at all in the phrase struc-
ture syntax or the morphological representation of expressions, and contributes
nothing to the phonological string. I think it is likely that these three classes of
defective lexemes are found in a great many of the world’s languages.
6.1	 Gaps
Another prominent family of partly empty elements that has not yet been
touched on is comprised of lexical items that have no pronunciation, that is
to say, those that have null morphology and morphophonology, yet play a role
in the syntax. These I will call gaps. While they all lack morphophonological
content, gaps do have representations in various combinations of the non-pho-
nological descriptive levels.
It is clear enough that zero morphology exists. In other words, there are clear
examples of genuine morphological operations that have no morphophono-
logical consequences. Consider in this regard the accusative singular formation
of one class of masculine nouns in Icelandic. The paradigm of a noun such as
fiskur “fish” is given in (1) (Einarsson 1949).
(1)		 Sg	 Pl
	 Nominative:	 fiskur	 fiskar
	 Accusative: 	 fisk	 fiska
	 Dative: 	 fiski	 fiskum
	 Genitive: 	 fisks	 fiska
Assuming that the morphophonological content of the stem of the noun for
fish is /fɪsk/, the nominative and accusative inflections can be treated as lexical
items with the following properties in various modules:
(2)	 Strong Declension Masculine Nominative Singular (Icelandic)
	 syntax: nil
	 F/A: nil
	 morphology: N[Stem] → N[Word, NOM,1
SG]
	 mphon: / … / → / … + ʏr/
Verb stem ellipsis in Inuktitut  185
(3)	 Strong Declension Masculine Accusative Singular (Icelandic)
	 syntax: nil
	 F/A: nil
	 morphology: N[Stem] → N[Word, ACC, SG]
	 mphon: nil
The accusative singular form of Icelandic noun fisk has properties parallel to
fiskur and fiski with overt case endings, but it is not associated with a phono-
logical effect on the stem.
6.2	 Verb stem ellipsis in Inuktitut2
While it is very rare, there are also examples of phonologically null stems in
morphology. Mary Swift and Shanley Allen (2002) have reported a remarkable
case of this in the Tarramiut dialect of Inuktitut, spoken in Arctic Quebec. In
that dialect, a verb stem may have no morphophonological content under cir-
cumstances very like those that allow VP ellipsis in European languages. But
verb stems are always word initial in Eskimo-Aleut and are followed immedi-
ately either by an inflectional or a derivational suffix. Therefore, when the stem
is a gap, a naked suffix, stripped of its supportive stem, begins a word and in
fact often begins an utterance.
For example, in answer to a child’s request for some soup, Swift and Allen
documented the following exchange:
(4)	 Child:	 Anaana	 qajur-tur-uma-junga.
		 mother	 soup-consume-want-INDIC/1s
		 “Mother, I want to have soup.”
(5)	 Mother:	 -nialir-qutit 	 siaru.
		 -will-INDIC/2s	 later
		 “You will (have some soup) later.”
Except under pragmatic circumstances such as this, the affix -nialir- is always
a bound derivational suffix. In this case, the uttered form is at least phonologic-
ally well formed, since Inuktitut words may begin with /n/, but the truncation
also produces forms that are not otherwise phonotactically legal. Swift and
Allen report such examples as:
(6)	 -gumanngi-
	 -guma-nngit-
	 -want-NEG-3
	 “I don’t want to.”
(7)	 -nngimmat
	 -nngit-mmat
186  Gaps and other defective elements
	 NEG-CTG4
/3sg
	 “It’s not”
No native Inuktitut word can begin with a voiced consonant other than a nasal,
and no native word can begin with a geminate or a velar nasal, let alone a
geminate velar nasal.
Truncated forms such as we find in Tarramiut are completely lacking in other
Inuit languages, so far as I know. To produce the same discourse reference that
is more or less the equivalent of our VP ellipsis, one needs to employ the stem
pi- “to do something,” which in this usage has an anaphoric function, referring
back to the meaning of a predicate that had been mentioned previously in the
discourse. Instead of (6), a Greenlander would have to say (8), respecting both
the morphotactics of the language and its phonotactics:5
(8)	 Pijumanngilanga
	 pi-juma-nngit-langa
	 do-want-NEG-(NEG)IND/1s
	 “I don’t want to do so.”
The phonologically defective verb stem inTarramiut can be reasonably assigned
a lexical entry with the following specifications for its value in morphology
and morphophonology. I will guess that it is syntactically and logically like the
VP-gap described in (31) below, but without knowing the details of its behav-
ior, it is a guess I make without a great deal of confidence.
(9)	 Defective anaphoric verb stem (Tarramiut Inuktitut)
	 morphology: V[Stem]
	 mphon: nil
With the idea of phonologically empty lexemes made at least plausible,
I return to the matter of gaps in English. Under the heading of gaps I will
include only phenomena where it appears to be the case that at least a word of
the syntax, and as much as an entire syntactic category, has no phonic expo-
nent. The major phenomena where gaps have been implicated include:
(10)	 a.	 
Sluicing: Scott spoke with a friend yesterday but I don’t know who
[gap].
	 b.	 Stripping: Smith will be promoted to full professor, but not Lewis [gap].
	 c.	 Gapping: Tracy writes romances and Sarah [gap] mysteries.
	 d.	 Fragments: [gap] Made in Germany.
	 e.	 N′ (aka NP) ellipsis; Nancy’s pictures of herself won first prize and Bill’s
		 [gap] won second prize.
	 f.	 Telegraphic omission: Keep [gap] out of the reach of children.
	 g.	 VP ellipsis: Edna didn’t play, but Ed did [gap].
VP ellipsis  187
	 h.	 Comparative deletion (Kennedy 1998) : I ate more canapés than you
		 did [gap].
	 i.	 Tough movement: Papers on tough movement are not hard to find [gap].
One thing that is clear from the general framework that is being employed in
this work is that gaps are not to be understood as deletion. Deletion per se can-
not be modeled in the present framework since it lacks derivations involving
two distinct representations of an expression in any one dimension. Moreover,
expressions containing gaps cannot have ordinary lexical items within the gap
because such lexical items include phonological material and gaps, by defin-
ition, do not. But that does not mean that the gap does not contain lexically spe-
cific structure in any other dimension. Indeed, the evidence is that gaps usually
have ordinary structural properties in other modules, as forcefully argued in
Merchant (2001) was the case with sluicing.
I will look at a few of the kinds of gaps in the catalog in (10), with an eye to
determining what the properties of the gap in various dimensions of grammar
must be. In particular, I will present moderately detailed analyses of the last
three kinds of gaps listed above.
6.3	 VP ellipsis
Example (11) is a typical case of VP ellipsis.
(11)	 Edna didn’t play, but Ed did [gap].
We know, of course, that the lexical entry for the VP-gap will have no mor-
phophonological representation, but it must be given a distinct role to play in
the syntax since otherwise the subcategorization requirements of the verb in
whose immediate scope it occurs will not be satisfied.
While the process of deriving examples like (11) is referred to as “VP dele-
tion” or “VP elision” (both inappropriate metaphors for the automodular the-
ory of linguistic structure) it cannot be the case that the category of the VP-gap
is, say, VP[-TNS], though that specification does get a lot right.6
First of all, non-VPs can be elided:
(12)	 a.	 Barbara is a genius, but I’m not.
	 b.	 Lincoln was president before Grant was.
	 c.	 They are up to no good, just as I suspected they would be.
On the basis of examples like these it is sometimes suggested that the phe-
nomenon involves the elision of predicates, sometimes taken to be a syntac-
tic constituent type. In this work, however, that category exists independently
of syntactic constituency as an indispensable functional type in logical
188  Gaps and other defective elements
representations. This was made clear in the discussion of supportive be, (97)
in Chapter 2, and in footnote 31 in the same chapter. But it is clear that not all
VP gaps are semantic predicates. This is particularly clear in the case of those
variants of the English language in which the have of possession, Chapter 5
(50), displays some of the properties of auxiliary verbs. While not common,
examples like (13a), from the story “Winter Dreams” by F. Scott Fitzgerald
(Bruccoli 1989, 250), are well attested. In my speech there are only a few
common examples of the auxiliary use of have, haven’t a clue, for example.
Remarkably, this one example seems fairly comfortable with the object elided
as in (13b).
(13)	 a.	 “Have you a car here? If you haven’t, I have.”
	 	 “I have a coupé.”
	 b.	 I haven’t a clue and my wife hasn’t either.7
I conclude, then, that whatever can count as the syntactic complement of the
right sort of element can be elided. The question is what sort of element it is
that leaves a “VP” gap in its wake. In Chapter 5 it was demonstrated that it was
sufficient to refer to the category V[TNS] in picking out the class of verbs that
behave as auxiliaries for the purposes of negation, inversion, and so on. But
that will not work to delineate the class of Vs that sanction the VP-gap for the
simple reason that non-finite (i.e., V[-TNS]) forms of those inversion auxiliar-
ies that have non-finite forms also sanction it:
(14)	 a.	 Mary might have been writing and her room mate might have, too.
	 b.	 Mary might have been writing and her room mate might have been, too.
As if this weren’t enough, there is a clear example of a non-verb that takes a
VP-gap, namely the infinitive marker to:
(15)	 a.  I wanted to take the train, but they didn’t want to.
It seems that there is little choice but to assume, as was done traditionally,
that there is a feature that marks the small, partly idiosyncratic set of English
lexemes that take the VP-gap as a complement. So as not to disguise the ad
hoc nature of this feature, I will call it by its traditional name: [AUX]. The
syntactic field in (16) ensures that the phonologically empty constituent will
occur only as the complement of a lexical item that happens to bear the fea-
ture AUX.
(16)	 VP-gap
	 syntax: VP in [[AUX], __ ]
	 mphon: nil
VP ellipsis  189
There is one firm generalization connecting those lexical items that are com-
bined in the lexicon with V[TNS] and the items that allow the VP-gap as a
complement: the former class all belong to the latter. Thus, if we want, we can
write a lexical redundancy rule to capture this generalization:
(17)	 If the syntax of a lexical item includes the specification “in [V[TNS], __ ],”
	 then the lexical entry bears the syntactic feature [V[AUX]].
As (13b) above shows, this generalization carries over to a few aberrant forms.
It likewise applies to idiosyncratic phenomena such as the optional combin-
ation of V[TNS] with need and ought. Since needn’t indicates lexical com-
bination with V[TNS], I’ll take care of it, so you needn’t, is grammatical, but
since don’t need indicates the lack of pre-combination, *I’ll take care of it, so
you don’t need is ungrammatical. But … you don’t need to is fine because to
allows VP deletion.
6.3.1	 The reference of the VP-gap
Now with regard to semantics, it is necessary to model the fact that the gap is
interpreted as synonymous with another verb phrase. The F/A structure of the
gap must therefore be a semantic pro-element that has an antecedent elsewhere
in the same expression or in prior discourse, which is to say, it is anaphoric.
Anaphora was briefly dealt with in Chapter 2, but now that other components
of the grammar have been fleshed out, some refinement in its treatment is
called for.
Semantic arguments sometimes refer to real or hypothetical individuals and
sometimes to real or hypothetical multi-member sets. An important distinction
among arguments has to do with whether they are sufficient in and of themselves
to determine reference by means of their meanings (intensions) or whether they
draw all or part of their referential properties from the linguistic or extralin-
guistic context in which they are used. All languages have some grammatical
mechanisms for using context to establish reference. The traditional term for a
mechanism that does this is “anaphoric device.” In English the major examples
of anaphoric devices are pronouns, and among the pronouns there is, as in most
languages, an important distinction between reflexives (as well as reciprocals)
on the one hand, and non-reflexives on the other. Since these differences among
argument types have to do with reference, they should be located in the F/A
­
dimension. That will be done here in terms of two binary features similar to syn-
tactic features that have been assumed in other frameworks, but which here are
features at the F/A level. The features [+/–PRON] and [+/–REFL] characterize
only three categories, since every reflexive is also pronominal.
190  Gaps and other defective elements
The personal pronouns are clearly syntactic noun phrases, arguments in
terms of their semantic combinatorics, and fill participant roles in cognitive
semantics. The feature values given in (18) differentiate them from each other
and are determinative of their anaphoric properties in a manner that will be
made clearer in the next section. The definite reflexive and non-reflexive pro-
nouns can be given lexical specifications like those in (19) and (20), which
refine and expand on those provided in Chapter 2 (101) and (102).
(19)	 themselves
	 syntax: NP[OBJ, 3pl]
	 F/A: Arg[+PRON, +REFL]
	 RS: ROLE (a set with cardinality > 1)
(20)	 them
	 syntax: NP[OBJ, 3pl]
	 F/A: Arg[+PRON, –REFL]
	 RS: ROLE (a set with cardinality > 1)
6.4	 Referential properties of anaphoric devices
In the generative tradition the three types of arguments shown in (18) are
somewhat misleadingly called, in order: anaphors, pronominals, and referring
expressions,8
and are defined in almost purely syntactic terms, as befits the
syntactocentric orientation of standard generative grammar. The usual sort of
account in such a theory is to explain the distribution of referring expressions by
thinking up various mechanisms for co-subscripting and/or co-­
superscripting
NPs on the basis of their syntactic relationships. (See, for example, the clas-
sic treatment in Chomsky 1981.) In the present system of grammar, however,
with its emphasis on the independence of semantic representations, it would
seem reasonable to assume that reference, clearly a semantic-pragmatic con-
cept, should be attributable in large measure to semantic structure, and that is
just what I will explore here in the treatment of gaps.
While much of the effort in the syntactic description of pronominal ref-
erence has been toward identifying the syntactic conditions under which
(18) Referring expressions
[PRON] [REFL]
reflexives +
+
+ –
–
–
non-reflexive
pronominals
non-pronouns
Referential properties of anaphoric devices  191
coindexing is allowed or required, the idea of counterindexing, that is, the
conditions under which coreference is impossible is also important in main-
stream generative grammar and other frameworks as well. Condition B of
the Binding Theory of Chomsky (1981), for example, excludes certain NPs
as ­
antecedents of pronominals and Condition C does the same for non-
­
pronominals. Lappin and McCord (1990), concentrating on pronouns, use the
impossibility of coreference as part of a computational model for anaphora
resolution. The result is a mechanism that in and of itself is simpler by far than
those that have arisen in the derivational grammar camp, and furthermore,
it “handles control and unbounded dependency constructions without empty
categories or binding chains,” a very happy result, as far as I am concerned.
I will extend the use of non-coreference, relying mostly on properties of F/A
structure. What I will offer is by no stretch of the imagination the last word
on the subject of anaphora, and knowledgeable readers will immediately note
kinds of examples that this highly simplified presentation will not account for.
My aim, though, as throughout this work, is not so much to create completely
adequate analyses of all aspects of grammar – hardly an achievable goal – as
it is to demonstrate that the recognition of autonomous modularity offers sig-
nificant advantages in terms of elegance, explicitness, and plausibility over
interpretive, derivational models.
6.4.1	 Coreference and non-coreference principles
I offer here three automodular principles that correspond to a certain extent to
the three principles of the Binding Theory of Chomsky (1981). These principles
are for English, but similar rules are undoubtedly at work in most languages.9
(21)	
A reflexive ([+REFL, +PRON]) must corefer with a proposition-mate that
c-commands it in F/A structure.
(22)	
A non-reflexive ([–REFL]), A, may not be coreferent with B, a non-pronom-
inal ([–PRON]), if A precedes B in linear order and the first S node domin-
ating A in syntactic structure also dominates B.10
(23)	 A non-reflexive, non-pronominal ([–REFL, –PRON]) may not corefer with a
	 c-commanding argument in F/A structure.
Individual languages may make further antecedence requirements in various
components including F/A structure, and indeed that is true for English pro-
nouns. Besides the modular restrictions that apply in syntax and role structure
that are imposed by the lexical properties of pronouns through lexical entries
such as (19) and (20), there are further referential requirements that apply gen-
erally in English, several of which will be discussed below.
192  Gaps and other defective elements
The less formalized discussion in Chapter 2 demonstrated how basic facts
concerning the antecedence of reflexives in English make sense even in control
and raising environments. No movement rule, reconstruction, cyclic principle,
or anything of the kind was needed to handle such facts in automodular terms.
But there are still problems with the simple formulation in (21), and (22) and
(23) as well. To take just one, consider the following example, brought to my
attention by an anonymous reviewer:
(24)	 Mary seems to herself to know the answer.
The F/A structure of this example must be (25), in which, it may be noticed,
there is no argument that c-commands HERSELF.
To handle such an example one might perhaps assume that if there is no
c-commanding argument in the logical structure of a sentence, then reference
to the referent of a c-commanding NP in the syntactic structure is allowable.
I don’t suggest this with much confidence, though, because there are many
apparently different sorts of cases where reflexives are acceptable that would be
ruled out by (21). There are, for example, many relatively acceptable examples
of “untriggered” reflexives in English, cases where there is no coreferent elem-
ent in the sentence at all. These are potentiated by a variety of factors from
different realms of grammar, e.g., reference to participants in the act of speech,
reference to discourse prominent entities, use in syntactic positions where mor-
phological case-marking principles are weak, and others. (See in this regard
Parker, Riley, and Meyer 1990.) Owing to these complicating factors, I am
forced to leave a formal treatment of examples like (24) as yet another matter
for further research.
6.4.2	 The VP-gap continued
Let us return to the question of the multi-modular content of the VP-gap. Note
first that it clearly displays properties of a non-reflexive pronominal. McCawley
(1988) noted that VP gaps are subject to the same requirements as are definite
pronouns; they may not both precede and c-command their antecedents:
(25)
Prop
Arg
MARY
Arg
HERSELF
Prop
Fp
Fa Fap
SEEM
KNOW.ANSWER
Referential properties of anaphoric devices  193
(26)	 Although he didn’t want to [gap], Hal got Sal a beer.
(27)	 Although he didn’t want to get Sal a beer, Hal did [gap].
(28)	 Hal got Sal a beer although he didn’t want to [gap].
(29)	 *Hal did [gap] although he didn’t want to get Sal a beer.
Furthermore, as with definite pronouns, the VP-gap may share meaning with
an antecedent in an earlier portion of a discourse:
(30)	 Sal: “Get me a beer.”	
	 Hal: “I don’t want to [gap].”
With this in place, theVP-gap’s lexical entry can be expanded as (31), where the
function-argument structure indicates that the gap is a non-reflexive pronoun:
(31) 	 VP-gap (version 2)
	 syntax: VP in [[AUX], __ ]
	 morphology: nil
	 mphon: nil
	 F/A: Fa [–REFL, +PRON]
The gap therefore counts as a predicate whose reference is the same as that of
an antecedent determined in the same way as for non-reflexive pronouns. But
since the VP-gap is a predicate, an Fa in F/A structure, its antecedent must also
be a predicate. Nominal pronouns, on the other hand, ordinarily have argu-
ments as their antecedents.
This treatment rests on four more or less directly determinable facts: that the
gap is a verb phrase in syntax, that it is selected by an [AUX], that its meaning
is that of a predicate, and that it has no pronunciation. The lexical specification
(31) also accounts without any new assumptions for the strict/sloppy identity
ambiguities that are found in cases of VP ellipsis (Sag 1980). Example (32)
can be interpreted such that the argument within the reference of the gap refers
either to Nancy or to Susan.
(32)	 Nancy thinks that she will win, but Susan doesn’t.
Remember that ordinary pronouns are lexical items with the properties
of arguments in F/A structure. The antecedent of the VP-gap is therefore
THINK(SHE (WILL.WIN)), and SHE, a non-reflexive pronominal, can take
its reference in the VP-gap from the preceding NP “Nancy,” or the c-command-
ing NP “Susan,” as allowed by (22), the automodular counterpart to Condition
B of the Binding Theory in transformational grammar.
There are cases where the strict/sloppy ambiguity does not arise, such as the
following examples:
194  Gaps and other defective elements
(33)	 Tracy claimed to be Napoleon and Scott did, too.
(34)	 Every candidate for class president voted herself but not every candidate 	
	 for vice president did.
In (33) the verb claim has a propositional complement, the subject of which
must be RHO for the reasons detailed in Chapter 2, section 2.7.1. The gap
sanctioned by the [AUX] did is therefore CLAIM [BE.NAPOLEON(RHO)]
and the antecedent of RHO in the VP-gap will unambiguously be Scott, as we
see in (35).
In (34) there is no RHO, but as F/A structure (36) shows, there is a reflexive
anaphoric device that will corefer with the variable x, which is unambiguously
bound by EVERY CANDIDATE FOR VICE PRESIDENT, again the correct
result.
6.5	 The Kennedy–Merchant comparative gap
The structure and meaning of comparative constructions is a fascinating and
challenging area of linguistic research. There are so many still unresolved
problems regarding the analysis of comparatives that it would be foolish to
attempt an exhaustive treatment of them here, but in any case, a gap – an
element that makes its presence known at some level of structure but has no
(35)
Prop
Arg
SCOTT
VP-gap = Fa
Fpa
CLAIM
Prop
Arg
RHO
Fa
BE.NAPOLEON
(36) Prop
QP[x]
EVERY.CANDIDATE
FOR VICE PRES.(x)
Prop[x]
Arg
x
Fa
VP-gap = Fa
Faa
VOTE.FOR
Arg
SELF
The Kennedy–Merchant comparative gap  195
pronounced form – figures prominently in most treatments of comparatives.
I will consider here only one subcase of the comparative gap that was stud-
ied by my colleagues Christopher Kennedy and Jason Merchant (2000). They
provided an elegant and cleverly justified treatment of sentences like (37) that,
quite independently of the work done here, sharply distinguishes syntax and
semantics.
(37)	 Jones published more papers than Smith expected [gap].
First of all, I will assume that in one of its uses, more combines with a com-
plement clause introduced by than to form a syntactic determiner, and that the
word than is a subordinating conjunction, that is, a head of S′ (or CP, if you
prefer.)
(38)	 more
	 syntax: in [Det ___, S′ [than]]
(39)	 than
	 syntax: __ in [S′[than] __, S]
The syntactic structures that these lexical specifications determine will be
along the lines of (40).
Regardless of the syntax, however, the semantic value of more is a quantifier
whose value is relative to some other value. It seems to me that such notions
as “degree phrase” that are often included in the syntax of phrases like more
massive than Saturn, fewer than three, and so on, need independent description
in the semantic components and do not require separate description in syntax,
where – semantics aside – they can be handled as examples of well-known
syntactic categories.
The comparative clause is obligatorily positioned beyond N′ within an
NP in keeping with the general tendency for clauses to occur later in lin-
ear order than other constituents that could fulfill the same syntactic func-
tion, as was discussed in connection with Syntactic Complexity, (6)–(8)
of Chapter 4, a topic that will be further explored in Chapter 7. We can
(40) NP
Det
more
than S
N�
S�
196  Gaps and other defective elements
formulate a grammaticized version of that tendency as (41), accounting for
the paradigm in (42).
(42)	 a.	 More papers than Smith expected were published by Jones.11
	 b.	 *More than Smith expected papers were published by Jones.
(43)	 a.	 Jupiter is a more massive planet than Saturn.
	 b.	 *Jupiter is a more than Saturn massive planet.
	 c.	 *Jupiter is a more massive than Saturn planet.
The bad examples (42b), (43b), and (43c) are independently ruled out by
McCawley’s principle concerning prenominal modifiers that was recast as the
LOC rule (76) in Chapter 4. But that principle does not account for the obliga-
tory position of more as a pronominal attributive adjective and would allow
very dubious sentences such as Papers more than Smith expected were pub-
lished by Jones. I suspect that a reworking of McCawley’s idea could produce
the paradigm in (42) all by itself, but at this time, I don’t see how to do that.
Semantically, more designates a relation between degrees: A(MORE P (B))
is true of something if the degree to which something A is P exceeds the de-
gree to which B is P. In the simplest case the standard, B, is an explicit degree,
e.g., more than three, but in the case of (37), which is what we are considering
here, the standard is implicitly given by reference to the meaning of another
part of the F/A structure. So Jones published more papers than Smith expected
would be interpreted along the lines of “The number of papers n such that
Jones published n papers is more than the number of papers m such that Smith
expected that Jones published m papers,” or perhaps “Jones published n papers
and Smith expected that Jones published m papers and n is more than m,” de-
pending on one’s theory of the meaning of comparatives. I have no detailed
theory of the semantics of comparatives and will happily leave that to more
skilled semanticists than me. The important point is that the semantic value of
the gap in cases like (37) is that of a pro-element that seeks a proposition as
an antecedent.
Kennedy and Merchant (2000) argue that despite its referential properties,
the gap in the syntax is not a clausal gap, as we might expect, but an NP gap.
This is an essentially automodular analysis that was developed quite independ-
ently of the present view, though their treatment marries sophisticated seman-
tics to a syntactic view that allows movement rules. In favor of the idea that
the syntactic value of the gap is an NP rather than a clause, they offer four
(41) Σ α β γ δ
= < < <
NP = [more … ( ) … (N') … S' [than] … ]
A
The Kennedy–Merchant comparative gap  197
arguments: (1) the class of verbs that allows the comparative gap we find in
(46), e.g., know, say, think, predict, admit, expect, want, be aware, be certain
(of), is much larger than the class of verbs that otherwise allow clausal ellipsis,
e.g., know, understand, be aware (compare *I predict and I understand); (2)
there is no general rule allowing null clausal complements in English, even for
a very narrowly defined semantic class; (3) the verbs that do occur with null
comparative complement gaps are all verbs that can select an NP complement;
and finally, the really telling argument, (4) when the verb is passive, and there-
fore unable to take an object noun phrase, there cannot be an expletive it in
subject position, though with a clausal complement there can be.
(44)	 Jones published more papers than was expected.
(45)	 *Jones published more papers than it was expected.
(46)	 Jones published more papers than it was expected that he would.
Now the inaudible NP object of expect cannot be the object of the passive
participle for well-known reasons, in the present view of things simply because
the passive participle has an intransitive subcategorization frame (Chapter 3
(17)). Since it is also the case that the role structure agent phrase cannot be
associated with an NP position in syntax, the only available NP is the syntactic
subject of a passive sentence and must be associated with the only remain-
ing argument, the correspondent of the patient in role structure, which is a
gap. Therefore, Kennedy and Merchant argue, the inaudible NP – the syntactic
value of the gap – occupies the subject position in syntax and leaves no room
for a non-referential NP, explaining the pattern in (44)–(46).
Finally, they take the position that the inaudible NP in these examples is in
fact a WH-nominal, quite similar, indeed, to one use of the word what, with
which the gap alternates:
(47)	 Jones published more papers than (what) Smith expected.
(48)	 Jones published more papers than what/*it was expected.
(49)	 Jones published more papers than *what/it was expected that he would.
The Kennedy–Merchant proposal can be recast in automodular terms by de-
fining a lexical item with the properties of the gap that they described. An
approximate statement of the Kennedy–Merchant gap in several independent
dimensions is (50).
(50)	 The Kennedy–Merchant comparative gap
	 syntax: NP[WH]
	 mphon: nil
	 F/A: Prop[–REFL, +PRON]
198  Gaps and other defective elements
The syntactic field requires the gap to appear in syntax where an NP can,
while the F/A structure category requires the gap to have a proposition as a
semantic antecedent in a position where a non-reflexive pronominal can have
an antecedent, as specified in the antecedence principles (21)–(23) above.
6.6	 Tough “movement”
Sentences like John is easy to please were used as one of the principal advertise-
ments for generative grammar almost since its inception (Lees 1960b), yet they
haveremainedanalyticallyrecalcitrantdespiteattemptstoaccount fortheirprop-
erties within each succeeding version of transformational grammar and within
non-orthodox views of formal grammar as well. The phenomenon is dubbed
tough movement and not easy movement even though the original examples
contained the adjective easy. That is because tough movement isn’t easy. It is
worthwhile examining this important construction from the automodular point
of view since certain apparently contradictory features of it can be accommo-
dated by partitioning its description into several modules. Not all of the intricate
features of this construction can be handled under the analysis I will propose,
but some of the most notable contradictions that have plagued syntactocentric
analyses from early on can be avoided. Properties that would be incompatible in
any single level of representation are seen as mismatches at different levels of
representation in the present theory. It is not necessary to try to reconcile them
within a single level. The plan of the analysis here is straightforward and not
terribly original. A crucial assumption is that there is a tough-movement gap, a
lexical item of the kind introduced in this chapter that has easily statable prop-
erties in several modules, but not in morphophonology.
One of the thorniest problems that tough movement presents is that it has
both properties of A-movement, e.g., raising (Postal and Ross 1971), and prop-
erties of Ā-movement, e.g.,WH-movement (Jones 1983; Jacobson 2000). From
an automodular point of view the A-movement properties of tough movement
can be handled as the same kind of mismatch between syntax and F/A structure
that was discussed in connection with Raising-to-Subject in Chapter 2, section
2.6, and the Ā-movement properties, such as sensitivity to island constraints,
can be handled in the way the Complex Noun Phrase Constraint was handled in
Chapter 4, section 4.10, as a discrepancy between linear order and other levels
of representation.
Let us see how the raising analysis works first. It is obvious that the initial
NP in a tough-movement construction is the syntactic subject. In addition to its
position in the clause, there is the fact that the verb agrees with it and, if it is a
Tough “movement”  199
pronoun it is in the nominative case. Therefore, the phrase structure syntax of
John is easy to please (neglecting tense as irrelevant) is straightforwardly (51).
In function-argument structure, tough-movement construction adjectives are
pretty clearly propositional modifiers, functions from propositions to propos-
itions. Here are two quick arguments for this claim: firstly, the meaning of the
syntactic subject NP functions as a semantic argument somewhere within the
proposition that is the semantic complement of the tough-movement construc-
tion predicate. My toothbrush is hard to answer is anomalous in just the same
way as is I cannot answer my toothbrush. Secondly, there is good evidence that
the meaning of the syntactic subject of easy is not the F/A structure subject of
EASY in the F/A structure of easy.12
We can see this in that (52a) and (52b)
are truth-conditionally equivalent, whereas adjectives like enough in (53a) and
(53b), which have syntactic privileges similar to those of tough-movement con-
struction adjectives, do not show even rough truth-conditional equivalence. For
these predicates, the syntactic subject does, in fact, correspond to the semantic
subject of the adjective’s meaning.
(52)	 a.	 One day will not be hard for us to read these abstracts in. =
	 b.	 These abstracts will not be hard for us to read in one day.
(53) 	 a.	 One day will not be enough for us to read these abstracts in. ≠
	 b.	 These abstracts will not be enough for us to read in one day.
The F/A structure of John is easy to please is (54):
(54) Prop
Prop[R]
FR
EASY
Fa
Faa
PLEASE
Arg
JOHN
RHO
S
NP
John
(51)
V
be
VP
AP
VP[to]
to VP[INFIN]
A
easy
200  Gaps and other defective elements
The subject of the propositional complement of EASY must be RHO, since
that element has no syntactic counterpart. That ensures that only some argu-
ment in the predicate, Fa, can be matched with the syntactic subject in a tough-
movement construction, and it also correctly predicts that the semantic subject
of the complement proposition of EASY is referentially arbitrary in examples
like John is easy to please and controlled (perhaps) in John finds this violin easy
to play.
The syntactic and F/A structure treatments above handle the basic
A-movement properties of tough movement well,13
so it is time to turn our
attention to Ā-movement. For a long time, the most popular approach has made
use of the idea introduced by Chomsky (1977) that there is a “null operator”
in tough-movement constructions that “moves,” giving rise to properties of
Ā-movement, in particular, sensitivity to syntactic islands. Chomsky’s pro-
posal can be easily modeled in the automodular framework, and indeed, the
basic mechanisms that are needed to do so are already in place. A mismatch
between syntactic phrase structure and linear order, as discussed in Chapter 4,
section 4.9, will account for the WH-island phenomenon in (55) and the super-
ior acceptability of “extraction” from complements of verbs over complements
of nouns that we see in (56a) and (56b).
(55)	 *That cello is tough to meet the Dutch woman who plays.
(56)	 a.	 The violin is easy to dream that you play beautifully.>
	 b.	 The violin is easy to have the dream that you play beautifully.
I will assume that there exists an inaudible element in syntactic structure
that must be found out of place in linear order vis-à-vis its syntactic con-
stituency. That would happen if, say, the gap counted as a WH-element that
is specifically mentioned in a linear order rule. We have a lexical item with
these properties already: the Kennedy–Merchant inaudible WH-element (50).
The tough-movement gap will differ, however, in that it will lack an F/A
specification.
Another motivation for the tough-movement gap is that the VP in the tough-
movement construction is superficially incomplete, so the question arises as to
whether there might actually be a syntactic NP in that VP, a gap of some kind,
or whether the subject NP is actually still part of the VP and is merely dis-
placed in linear order. But this is not a possible analysis for tough-movement
constructions since the initial NP is clearly the syntactic subject and, accord-
ing to the Certainty Principle (Chapter 1 (17)), one element cannot be in two
places in a single dimension. Thus, independent of considerations of island
constraints, we must assume a gap in tough-movement constructions. The dir-
ect object of the obligatorily transitive verb take in (57), for example, must be
Tough “movement”  201
an example of this gap, since otherwise the subcategorization requirements of
take would not be satisfied.
(57)	 These pills are easy to take [gap].
This, then, is the outline of a treatment of the tough-movement construction
that is constructed entirely out of existing assumptions about other construc-
tions. What remains is to write the lexical entries of the relevant items, the
tough-movement predicates and the tough-movement gap.
For simplicity let’s restrict our focus to tough-movement adjectives. With
regard to syntax and F/A structure, the entry for a tough-class adjective will be
exactly like that of a raising-to-subject adjective (cf. Chapter 2 (39)), except
that the proposition that is the semantic argument of the adjective can only
have RHO as its subject. The morphological and morphophonological values
are obvious and need not be stated. These adjectives have no special linear
order requirements that are not given by more general rules for the language.
The category FR is the combinatoric semantic category of a proposition whose
semantic subject is the syntactically null pronominal RHO, as described above
example (32) in Chapter 3.
(58)	 tough, hard, easy, impossible …
	 syntax: A in [ __, VP[to]]
	 F/A: FR
Now the lexical entry of the tough-movement gap needs to be written. First
off, it is clear that the gap has no morphophonological form. Secondly, it is
an NP and can therefore fulfill the syntactic subcategorization requirements
of an NP, and next, the gap bears a WH-feature so that it necessarily respects
syntactic islands. Does the tough-movement gap have a representation in F/A
structure? Apparently not, since if it did, that meaning would have to count as
the semantic object of TAKE in the F/A structure corresponding to (57) and
there would be no room there for the meaning of these pills. Similar consider-
ations show that the tough-movement gap has no place in role structure, either.
Its lexical entry will therefore be (59):
(59)	 TMG (English tough-movement gap)
	 syntax: NP[WH]
	 mphon: nil
	 F/A: nil
	 RS: nil
Here is how it works so far. Suppose that the tough-movement gap is chosen
over another NP in the syntactic scope of the tough adjective. The syntactic
structure of (57) is (60a) and its F/A structure is (60b).
202  Gaps and other defective elements
It can readily be seen that the syntactic value of THESE PILLS cannot be
discharged as the object of take, since that position is occupied by TMG, and it
cannot be discharged as the subject of (to take TMG), because there is no such
position in syntactic structure. Therefore it can only be found as the subject of
be easy to take TMG.
Now suppose that the TMG is not chosen. Then, instead of (60a) we will
have (61) and the only subject possible for the sentence as a whole will be ple-
onastic it, (20) in Chapter 2.
(61) S
NP
V
be
VP
AP
A
easy
V
take
NP
these pills
VP[to]
VP[INFIN]
to
(60) a.
to VP[INFIN]
V
take
NP
TMG
b. Prop
FR
EASY
Prop[R]
Arg1
RHO
Fa
Faa
TAKE
Arg2
THESE PILLS
S
NP
these pills
VP
V
be
A
easy
AP
VP[to]
Tough “movement”  203
A linear order rule should also be written ensuring that the TMG comes
earlier than its hierarchical position would determine, something like, if not
precisely, the rule that requires the null WH-element to move in infinitival
relatives, making them subject to island constraints: This is the poem for you
to (*find someone who can) memorize. I will not attempt to write the rule,
though, because I would then have to say something substantive about infini-
tival relatives.
To close this discussion of tough movement, let me turn to the well-known
fact that “funny NPs” are at best funny as subjects of tough-movement construc-
tions (Berman 1973). Idiom chunks, for example, vary from slightly marginal
to unacceptable, which Hicks (2009) observes is parallel to the acceptability
of corresponding passives. In my notation, and with some of his examples and
one of mine, I find the following judgments clear:
(62)	 a.	 Headway was made on the problem. >
	 b.	 The beans were spilled to the cops. >>
	 c.	 His hat was eaten by him.
(63)	 a.	 Headway was easy to make on the problem. >
	 b.	 The beans were hard not to spill to the cops. >>
	 c.	 His hat was hard for him to eat.
Following an idea of Newmeyer’s (1972), I suggested in Chapter 3 that the
acceptability cline we see in (62) has to do with the ease of constructing a cog-
nitive referent for the idiom chunk. In (62a), this is quite easy because head-
way is referential and therefore modifiable (cf. much headway, the headway
we made); it just happens to be a noun that is very restricted in its distribution.
In (62b) the beans can be construed as the untold secret that is divulged but in
(62c) it is very hard to give any sensible, referential interpretation to his hat.
There is no doubt that the noun phrases headway, the beans, and his hat are
part of the syntactic structures in (62) and (63). I think that it is quite clear that
headway is also represented in function-argument structure, the level where
reference is determined, since headway can be referred to: Headway was
made, but it was hard to achieve. And if it can be referred to, it is certainly part
of the cognitive scene that a sentence like (62a) presents. The ol’ proverbial
beans admit few modifiers and for me are poor antecedents of pronouns. ?
She
spilled the beans and the state’s attorney used them at trial. Nevertheless, it
seems not unreasonable to assume that the metaphorical value of the beans,
namely some concealed information, is part of the idea of (62b), and hence is
represented in role structure. In (62c), however, the NP his hat cannot figure in
either semantic dimension.
204  Gaps and other defective elements
What suggests itself as an account of the variable acceptability of funny NPs
as subjects in tough-movement constructions, then, is that the tough-movement
gap be given some referential power. If we require it to have a cognitive ante-
cedent, the unacceptability of (63c) follows. That fails to account for the diffe-
rence between (63a) and (63b), and though it is intuitively clear that there
is a connection between the acceptability of (63a)–(63c) and the number of
dimensions in which the subject NP has a representation, I have no idea how to
capture that formally and will have to leave it as a very obvious loose end.
6.7	 Summary
Neither deletion nor insertion is possible in the framework of grammar pro-
posed here. In earlier chapters, phenomena that have been treated in trans-
formational grammar as insertion or deletion were analyzed in terms of lexical
items that have no representation in at least one component of the grammar but
play a structural role in others. Auxiliary do, for example, has the properties of
an auxiliary verb in the syntax, but is not represented in either of the two kinds
of semantic structure. On the other hand, RHO, the referential argument that
corresponds in some ways to PRO in mainstream syntax, has demonstrable
semantic functions, but does not figure in syntactic structure at all.
The idea that there are lexical items that have no representation in one or
another representational dimension has been extended in this chapter to include
the important category of gaps, in order to account for phenomena that were
handled by deletion under identity in the early transformational literature and
in some subsequent traditions. The main innovation introduced here is the con-
cept of elements that are positively represented in syntactic structure and/or
morphological structure, but lack a phonological form. Since defective lexical
items that are without a function in one or another module are motivated inde-
pendently of gapping, there seems to be no reason to ban artificially lexical
items with no status in the morphophonological module.
205
7	 Conflict resolution
7.1	 The Great Chain of Speaking
In the ideal case, the demands of each component are met without conflict
with any of the others. A sentence such as The cat caught a mouse is about
as harmonic across the several dimensions of representation as we can hope
to find. The schematic modular representations (neglecting tense, for ex-
ample) that are displayed in (1a–d) illustrate the following facts: the verb
is transitive in syntax, combines semantically with two arguments to form
a proposition, and represents an event with two participants in which the
one corresponding to the subject is highly agentive and the one representing
the object is highly patientive. The noun phrases contain one-place stative
descriptions. The mismatches between syntax and F/A structure presented
by the generalized quantifiers the cat and a mouse are unavoidable given the
syntactic makeup of NPs and the logical nature of quantifiers. Even here,
though, the definite quantifier phrase is preferentially interpreted as having
wide scope over the existential quantifier, its hierarchical position in the
combinatoric logical representation thus corresponding as much as possible
to the hierarchical position of the syntactic subject in the syntactic represen-
tation and the cognitive agent in the role structure representation. The match
with linear order is also as conflict free as it could be. The definite subject
noun phrase occupies the highest position in all the major dimensions of
grammar and additionally, represents more accessible information (see (30)
below) than the indefinite second object noun phrase, accounting for the
fact that statistically, this sort of sentence is much more common than, for
example, A cat caught the mouse (Givon 1978). Neglecting tense and its un-
avoidable mismatches (Chapter 5, section 5.6), the harmonic structures for
The cat caught a mouse are (1a–d).
206  Conflict resolution
Once we go beyond the simplest cases, though, not all of the demands of the
individual modules and the lexical specifications of the words and morphemes
can be simultaneously satisfied. In agentless passive sentences, for example, the
VP is intransitive and there is only one quantifier in F/A structure, but the cog-
nized event involves two participants. Since the active sentence exists as an easy
alternative, other forces must be at work to support the incongruences that pas-
sives present, and this is, of course, generally true. Passives are resorted to, for
the most part, where the simple active with an indefinite subject would be longer
without a compensating gain in information, or would be otherwise discourse
inappropriate, as in this sentence, or where the active displays internal non-align-
ment with F/A structure, quantifier scope in particular, which can be avoided
by employing a passive. Most people in Malta speak two languages suggests a
situation of variable bilingualism, whereas Two languages are spoken by most
people in Malta suggests (as happens to be the case) that there are two national
languages. Other reasons for using passive sentences instead of the correspond-
ing actives include the placement of a topical patient in subject position and the
avoidance of mention of an unknown or unmentionable agent. There is no single
reason for employing passives, but there usually is some communicative utility
that passives serve. It is for this reason that attempts by self-appointed grammat-
ical authorities to drive them out of the English language have failed.
(1) a. S
NP VP
the cat V
catch
a mouse
b. Prop
QP[x]
THE CAT
Prop[x]
QP[y]
A MOUSE
Prop[x,y]
Arg[x]
x
Fa[y]
Faa Arg[y]
y
CATCH
c. EVENT
TYPE AGT PAT (where AGT > PAT)
“catch” “cat” “mouse”
d. (the cat) < catch < (a mouse)
The Great Chain of Speaking  207
In other cases of modular conflict, however, there is no readily available
and equally idiomatic competitor to an expression that involves cross-modular
mismatches. This is the case for simple negation with not in English, for ex-
ample, which is at least sometimes a propositional operator in F/A structure but
is never a syntactic sentence adverbial. (See Chapter 5, section 5.6.3.) Consider
This offer is not valid in all states, which on its intended reading means roughly
“It is not the case that this offer is available in all states.” The obvious alterna-
tive would be to put it this way: It is not the case that this offer is valid in all
states, but the prolixity of this alternative formulation is militated against by
increased processing difficulty, the possibility that conversational implicatures
will be attached to the more complex form, and also the fact that advertising
time costs money. An equally simple and unambiguous example would be This
offer is not available in some states. Why it is not put this way I do not know,
but I’m pretty certain that there is some reason, maybe a legal one.
It is a striking fact that the contest between the competing demands of par-
allel dimensions of representation is not equal. For the most part there is a
hierarchy of strength of componential demands, a great chain of speaking, you
might say:
(2)	 The Great Chain of Speaking
	 phonology1
> linear order > morphology > syntax > semantics
Where there is a conflict between (automatic) phonology and linear order, the
phonology almost always triumphs; where linear order demands conflict with
orderings that reflect syntactic constituency, linear order prevails; where mor-
phological demands and syntax disagree, morphology usually wins; and where
syntactic demands are at odds with semantic organization, the semantics is
generally trumped by the syntax. Examples will be presented presently.
The hierarchy of strength of modular demands expressed in (2) is familiar
and can be discerned in various theoretical contexts. This order corresponds,
for example, to the methods of the American structuralists, who insisted that
“scientific” linguistics begins with phonetics, then proceeds to phonology,
then to morphology, and only then to syntax. (See Harris 1951.) The hierarchy
was turned on its head during the linguistic revolution launched by Noam
Chomsky, who properly rejected the discovery procedures of the structuralists
and replaced them with a derivational model that proceeded in the opposite
direction – from deep structure (equated by the generative semanticists with
logical representation), to surface syntax, to morphology (at least in some con-
ceptions), and then to phonology.2
From an automodular perspective, there is
no procedural hierarchy, of course, but some of the spirit of the Great Chain
208  Conflict resolution
of Speaking remains in the strength of the demands imposed by the various
autonomous components, as expressed in (2).
Nor is the hierarchy in (2) an accident; for one thing, it reflects the degree
of cross-linguistic generality of the several informationally distinct represen-
tational systems. It is an antique principle of linguistics that more particular
rules take precedence over more general rules, and since phonological rules
are more language particular than morphological rules, morphological rules
more particular than syntactic rules, and syntactic rules more particular than
semantic rules, the hierarchy of componential strength in (2) can be traced in
part to a universal principle of human language. The differential universality
of the various informational dimensions of language is clear. Up to the point
of anatomical limitations, phonetic facts are highly variable across languages
(Ladefoged and Maddieson 1996). Languages vary considerably with regard
to morphological details: there are isolating languages that have little signifi-
cant sub-word structure, and, at the other end of the spectrum, polysynthetic
languages that use morphological resources to encode a great deal of what is
encoded in complex phrases in less synthetic languages. Syntax is much less
flexible. No language lacks it, the set of possible syntactic phrase types seems
to be highly constrained, and syntactic form hews closely to certain clear prin-
ciples of internal structure. The idea is put differently in various frameworks,
but it seems clear enough that semantic organization is highly consistent from
language to language. Of the two dimensions of semantic structure assumed
here, F/A structure is more flexible since it more closely reflects the some-
times accidental facts of the grammar and vocabulary of a language. No two
languages have just the same inventory of bundles of meaning. Role structure,
on the other hand, is closer to being a cognitive common denominator.
In Sapir’s (1921) Language we find the following often-quoted assertion:
Language and our thought-grooves are inextricably interwoven, are, in a
sense, one and the same. As there is nothing to show that there are sig-
nificant racial differences in the fundamental conformation of thought, it
follows that the infinite variability of linguistic form, another name for the
infinite variability of the actual process of thought, cannot be an index of
such significant racial differences. This is only apparently a paradox. The
latent content of all languages is the same – the intuitive science of experi-
ence. It is the manifest form that is never twice the same, for this form,
which we call linguistic morphology, is nothing more nor less than a col-
lective art of thought, an art denuded of the irrelevancies of individual sen-
timent.   (Sapir 1921, 11)
Perhaps this famous remark can be interpreted as making a distinction similar
to my recognition of two levels of semantics, F/A structure and role structure.
The competition for linear order  209
The actual processes of thought of which he speaks, this collective art of think-
ing, would correspond to F/A structure, reflecting as it does the learned vo-
cabulary of a society. And perhaps the more abstract understanding of events,
the “latent content of all languages,” the “intuitive science of experience,”
which Sapir asserted was the same for all mankind, can be likened to what
I have been calling role structure. If this is the case, then where the semantic
combinatorics of a lexical item disagree with its real-world content, as is the
case with agentless passives (see the discussion following (12) in Chapter 3),
it is the logical organization, the F/A structure, that is closer to overt form than
the role structure, so the demands of F/A will be fulfilled.
These considerations suggest a general principle, one that follows almost as
a corollary from the hierarchy of modular strength in (2), namely:
(3)	 Modular Affinity
	
Adjacent modules in the Great Chain of Speaking exert more influence on
one another than non-adjacent modules.3
There are clearly some direct influences between non-adjacent levels. Special
stress in phonological structure, for example, can directly reflect high seman-
tic scope, and vice versa. And it seems to be the case that ancillary roles in
function-argument structure are closely associated with oblique, that is to say,
non-subject and non-object status in syntax. Strikingly, linear order can be
directly affected by factors from any of the major dimensions, but the strength
of the effect declines as one proceeds to the right along the Great Chain of
Speaking; morphology exerts an almost insurmountable force on linear order,
but role structure influences it only weakly.
7.2	 The competition for linear order
Every expression is presented with its parts arranged in a particular order. The
competition for this unavoidably scarce linguistic resource is fierce, since all
components and all minor forces can express themselves in terms of linear
order. As before, the general hierarchy of modular strength is easy enough
to discern here. If the phonology of a language forbids a sequence of a nasal
consonant followed by a non-nasal consonant and the morphology demands a
sequence of morphemes the first of which ends in a nasal while the next begins
with a non-nasal consonant, the phonology wins; something will happen such
that phonological requirements are met at the expense of morphological trans-
parency – assimilation, loss of the nasal, or vowel epenthesis, for example.
In some cases the morphological order of segments gives way to a different
order that is compatible with the phonotactics. In Hebrew the binyan called the
210  Conflict resolution
hitpa′el, a verb form that often has a reflexive or reciprocal meaning, consists
of a prefix /hit/ followed by a consonantal verb root with intercalated vowels
/a/ and /e/. But if the root begins with a sibilant, the formation would yield a
disallowed sequence of consonants. The resolution in this case is a metath-
esis that produces a phonologically allowable sequence. From the root /ʃ-m-r/
“to guard,” for example, the hitpa′el is not the sequence /hitʃamer/, which the
morphology would suggest, but /hiʃtamer/ “to be on one’s guard,” which is in
keeping with the phonotactics of the language but is untrue to the morphotac-
tics, in which dimension /hit/ is a prefix.
Similarly, if a bound morpheme corresponds to a phrase-initial syntactic
element but is morphologically suffixal, it will, in deference to the morphology,
appear as a suffix either to a preceding word that is not part of its complement
or as a suffix to the first word or phrase of the complement. In Macedonian,
demonstratives precede the nominals that they definitize. The definite article,
however, is a suffix and it appears after the first word of its complement. From
the syntactic order (DEF (sudija)) “(the (judge))” the result is sudijata “the
judge,” and from the constituent structure (DEF (dobar sudija)) “the good
judge,” the result is dobr-iot sudija. (See Sadock 1991, 117–20.) The syntax
here yields to the morphology.
Additional examples of the unlevel modular playing field can be found
in analyses that have already been given: semantic tense is a modifier
with scope over a proposition, but its syntactic role is a function of verb
phrases. When past tense is realized as the verb have in non-finite con-
texts, it appears in its syntactically determined position. But tense in finite
contexts is a verbal inflection. It appears as close to its syntactic position
as it can, namely on the head verb of its complement, but it appears, of
course, as morphology there, rather than as an independent head preced-
ing its complement. A very similar story could be told about the negative
element, not, but in addition, it is subject to a special linear order rule
and therefore appears neither as a proposition-external adverb, where it
would be found if semantics alone was responsible for its position, nor as
a VP-external adverb, which is what we would expect from its syntax and
where it appears in non-finite contexts. Rather, it follows a finite verb, thus
respecting the linear order requirement, and disagreeing with both syntax
and function-argument semantics.
There are many cases, however, where alternative orders are more nearly bal-
anced in terms of the tensions that arise over competing modular demands on
linear order. In such cases minor forces may override the general chain of modu-
lar strength and turn out to be instrumental in fixing the linear order of elements.
Heavy NP “Shift”  211
I will consider below several important examples of this type in the grammar of
English.
7.3	 Heavy NP “Shift”
Noun phrases are ordinarily the first complements in a verb phrase because
they occupy the highest position in the Syntactic Complexity Hierarchy
(Chapter 4, (8)). But, as is well known, great length and internal elaboration
of a noun phrase can allow it to come after an immediately following prep-
ositional phrase, that is to say, one position later in the string of constituents
than Complexity alone would place it. This effect is part of a much more gen-
eral tendency that orders heavy constituents after lighter constituents, ceteris
paribus. Behagel (1909) named this phenomenon das Gesetz der wachsenden
Glieder, but I will call it the Principle of Linguistic Gravity. It is quite likely
that processing considerations are implicated here (Hawkins 1994), but it can
be stated separately from the psychological considerations that motivate it:
(4)	 Principle of Linguistic Gravity
	 Heavy constituents tend to occur later than light constituents.
Most, if not all, phenomena where Linguistic Gravity plays a role display
graded acceptability according to the weights of the constituents involved. This
is clearly the case with NP placement; the heavier the NP and the lighter the PP,
the better they sound with the noun phrase following the prepositional phrase.
We can formulate Gravity in terms of an independent hierarchy that ranks con-
stituents according to their actual length rather than their formal complexity.
As a reasonable approximation we can take it to be a simple ranking according
to number of syllables. (See Wasow 1997; Wasow and Arnold 2003.)
The alignment or misalignment of the hierarchy of Complexity and the
hierarchy of Weight together can account for familiar data such as we see in
(6a–d).
(5) Weight Hierarchy
Let n
be a syntactic constituent with n syllables and n+j
be a syntactic
constituent with n+j syllables. The following alignment will hold, other
things being equal.
= <
n n+j
σ
σ σ
σ
α β
∑
212  Conflict resolution
(6)	 a.	
I related to my brother the story about the narwhal that I had heard in
Greenland. >
	 b.	 I related to my brother the story about the narwhal. >
	 c.	 I related to my brother the story. >
	 d.	 I related to my brother that.
Where the noun phrase is very much heavier than the prepositional phrase,
as in (6a), the force of Complexity is counteracted to such an extent that we
would ordinarily label this example fully grammatical. In (6d), on the other
hand, both hierarchies would place the noun phrase before the prepositional
phrase, and because both hierarchies are violated in (6d), such examples are
so unacceptable as to be labeled straightforwardly ungrammatical. But nei-
ther absolute belonging to nor complete exclusion from the language is par-
ticularly strongly motivated on the view that is being explored here. Whereas
semi-grammaticality is an artificial afterthought in traditional generative gram-
matical frameworks, the present theory inclines us toward the belief that full
grammaticality and full ungrammaticality are merely extremes on an infinitely
variable scale.
“Heavy NP Shift,” the rule in some movement theories of grammar that
accounts for the ordering of parts of theVP in (6a), is a misnomer: first, the phe-
nomenon in question can be better explained without shifting things from one
order to another, and second, it is not restricted to NPs. Heavy subcategorized
prepositional phrases can also gravitate beyond adjunct prepositional phrases
for exactly the same reasons as heavy NPs gravitate toward the right. Thus in
(7a–c) we notice the same sort of decreasing acceptability as the weight of the
subcategorized prepositional phrase decreases.
(7)	 a.	 I spoke by telephone to someone in the Reference Department of the
		 Bayonne Public Library. >
	 b.	 I spoke by telephone to someone in the Department. >
	 c.	 I spoke by telephone to someone.4
When prepositional phrases get heavy enough, they can even be found to the
right of subcategorized Ss, despite the force exerted by Syntactic Complexity
(Chapter 4 (8)).
(8)	 Nancy mentions that she is a doctor to almost everyone that she meets.
Once again, the actual weight of constituents with respect to one another can
overcome other forces that would tend to impose the opposite order, syntactic
phrase structure and F/A structure in particular. It is difficult, however, to get a
simple noun-phrase object to exist comfortably to the right of a subcategorized
clause no matter how heavy it is. (8) (repeated as (9a)) is much better than a
Dative “movement”  213
similar example with a verb that is subcategorized for a noun phrase and a
clause rather than a prepositional phrase and a clause.
(9)	 a. 	
Nancy mentions that she is a doctor to almost everyone that
she meets. >>
	 b.	 Nancy tells that she is a doctor almost everyone she meets.
The reason that a prepositional phrase can more easily be found to the right
of a clause than a noun phrase is that PP and S are closer together on the
Complexity Hierarchy than are NP and S. By appropriately weighting the force
generated by Complexity and that generated by the Weight Hierarchy, these
facts can be modeled.5
7.4	 Dative “movement”
The alternation exemplified in (10) is traditionally handled by means of a
movement rule, usually one that turns a structure like (10a), with a preposition,
into one like (10b), without the preposition. Since two different prepositions,
to and for, participate in alternations of this kind, the natural transformational
treatment is to delete, rather than insert the preposition.
(10)	 a.	 Mother Hubbard gave a bone to the dog.
	 b.	 Mother Hubbard gave the dog a bone.
However, the lexically limited nature of this alternation (Green 1974) sug-
gests a treatment along the lines of GPSG (Gazdar et al. 1985), where cer-
tain verbs, give and tell, for example, occur in two different subcategorization
frames – either with a noun phrase and a prepositional phrase or with two NPs,
but other verbs with similar meanings, donate and relate, for example, occur
only with a noun phrase and a prepositional phrase, and some idiomatic forms
occur only with two NPs, e.g., give someone a piece of one’s mind versus give
a piece of one’s mind to someone, the second of which has only a literal – and
rather frightening – interpretation.
For a verb like give, then, let us assume two different syntactic subcategor-
ization frames and one meaning, something along the lines of (11) in the nota-
tion for lexical entries that has been introduced:
(11)	 give
	 syntax: V in [VP __ NP, PP[to]] or [VP __ NP, NP]
	 F/A: [Faaa]
	 RS: “give”, EVENT, AGT, PAT, ANC
	 morphology: V[STEM]
	 mphon: /gɪv/
214  Conflict resolution
With the NP, PP frame, the order of syntactic constituents is correctly given
by the considerations of Syntactic Complexity and Weight discussed above, in
this case NP before PP. But when the Weight of the noun phrase is sufficient,
the opposite order becomes more acceptable:
(12)	 a.	
I gave to my brother a subscription to a magazine that he was already
subscribing to. >
	 b.	I gave to my brother a subscription to a magazine. >
	 c.	I gave to my brother a magazine. >
	 d.	I gave to my brother one.
When the verb occurs with two NPs, however, the effect of Syntactic
Complexity vanishes, since both constituents occupy the same position on the
hierarchy. In this case we might expect Weight alone to determine the order
of constituents, but that is not what we find. Instead a nearly ineluctable force
takes effect, ordering the noun phrase that encodes the recipient or benefi-
ciary before the noun phrase that encodes the patient or theme. There might
be a principled reason for this ordering, but it is not obvious to me what it is,
so I will treat it as an unmotivated rule of the LOC.6
The arbitrariness of the
ordering is bolstered by the fact that in most Germanic languages the recipi-
ent is regularly ordered before the patient for full NPs, but in some, reverse
order prevails when both are pronouns, as in German Die Mutter hat dem
Hund ein Bein gegeben, “Mother gave the dog a bone,” versus Die Mutter hat
es ihm gegeben, “Mother gave it him.”7
The rule of the linear order compo-
nent in English refers in this case both to syntactic structure and role structure
properties:
Summing up, a verb like give that allows alternative syntactic frames provides
a speaker with a choice of which argument to put first.8
The choice, as it turns
out, is influenced by the very same consideration that comes into play in the
case of Heavy NP Shift phenomena, namely the hierarchy of Weight. A rela-
tively light recipient should, ceteris paribus, precede a relatively heavy patient,
and this can tip the scales in favor of the double-NP construction in which the
recipient will, according to (13), precede the patient anyway. Thus (14a) is
better than (14b).
(13) VP = [ V … NP NP … ]
= <
E = TYPE, ANC, PAT
α
Σ β
Particle “Shift”  215
(14)	 a. 	Andrew gave me a model rocket that he had built
		 himself.>
	 b.	 Andrew gave a model rocket that he had built
		 himself to me.
A relatively light patient and a relatively heavy recipient, on the other hand,
will result in a preference for the NP, PP frame, since in that case the order of
arguments is reversed and will allow word order to align with Weight:
(15)	 a. 	Andrew gave some to the children who live down the street. >
	 b.	 Andrew gave the children who live down the street some.
When there is no great difference in weight between the two arguments, the
two constructions are about equally acceptable.
(16)	 a. 	Andrew gave a quarter to a panhandler. ≈
	 b.	 Andrew gave a panhandler a quarter.
The availability of a choice with certain verbs means that for them, there
is always a way to avoid disharmony between the Syntactic Complexity and
Weight hierarchies. That is to say, an appropriate choice of syntactic frame for
Dative Shift verbs will always allow the linear order of elements to respond to
Weight. With verbs like donate, on the other hand, only the order NP, PP fits
the Complexity Hierarchy, but Weight may tip the scales in favor of the PP, NP
order:
(17)	 a.	 She returned to me the book that I loaned her several years ago. >
	 b.	 She returned the book that I loaned her several years ago to me.9
7.5	 Particle “Shift”
I turn next to the alternation in (18), a phenomenon often treated as the move-
ment of a particle from a position immediately following the verb to a position
after the direct object.
(18)	 a. 	Howard looked up the answer.
	 b.	 Howard looked the answer up.
That many distinct factors influence the acceptability of the order of the par-
ticle and the direct object has been recognized for some time. Recently Gries
(2003) profitably investigated twenty different properties that play a role in
the positioning of particles. Since automodular grammar is specifically set up
to incorporate competing, autonomous grammatical forces, such studies can
easily be recast in terms of this framework. I will discuss only a few of the
forces in evidence in Particle Shift in order to illustrate the idea.
216  Conflict resolution
As before, one such factor is Syntactic Complexity. Particles, though function-
ally similar to prepositional phrases, seem to occupy a position on the Complexity
scale intermediate between noun phrases and prepositional phrases.10
(19)	 Syntactic Complexity Hierarchy (revised)
	 <NP, Prt, PP, VP/S>
The Complexity Hierarchy that orders a particle after a noun phrase is
approximately balanced by the Weight of a medium-sized noun phrase and, if
no other factors are taken into consideration, the alternation displayed in (18)
will appear to be free.
By assuming the position of the particle on the Complexity scale (19) we
also explain some well-known features of Particle Shift without the need for
any extra assumptions or ad hoc provisions. First, there is the fact that pro-
nouns tend strongly to occur before particles. The second example below is
usually blighted with an asterisk (Bolinger 1971; Fraser 1976), but in any case,
it is much worse than the first:
(20)	 a.	 Howard threw me out. >>
	 b.	 Howard threw out me.
Since pronouns are lighter than full NPs, as we have assumed, and all NPs are
already less Complex than particles, the judgment above follows.
Particles that are modified and are thus both more Complex and Heavier
than unmodified particles occur later than simple particles:
(21)	 a. 	Howard looked the answer right up. >
	 b.	 Howard looked right up the answer.
Note also that particles are much less acceptable after subcategorized clauses
than before them because particles are two positions to the left of clauses on
the Syntactic Complexity scale.
(22)	 a.	 She blurted out that she had solved the problem. >>
	 b.	 She blurted that she had solved the problem out.
Even modified particles are better before clauses, though they are perhaps
better after clauses than simple particles are:
(23)	 a.	 She blurted right out that she had solved the problem. >
	 b.	 She blurted that she had solved the problem right out. >>
	 c.	 She blurted that she had solved the problem out.
As we have seen, medium-weight full NPs can occur on either side of a par-
ticle. Quite heavy NPs sound better after the particle, though, just as we should
expect:
Particle “Shift”  217
(24)	 a.	 I pointed out the man that I had seen reading a book by Eco.>
	 b.	 I pointed the man that I had seen reading a book by Eco out.
Because of the balance between particles and medium-weight NPs, Particle
Shift provides a very sensitive probe for more minor forces that are at work in
ordering constituents. For example, another influence on the relative position
of the particle and the object (and according to Erades 1961, the only influ-
ence) is “the news value which the object denoted by the object has” (cited in
Bolinger 1971, 51). Elements that are less accessible from previous discourse
or general knowledge have more news value than those that can be accessed
from context. Bolinger illustrates this with the following contrast between rela-
tively general nouns such as things, and subject, and more specific nouns such
as baggage and divorce.11
(25)	 a.	 He’s bringing in the baggage.>
	 b.	 He’s bringing in the things.
(26)	 a.	 He brought up the divorce. >
	 b.	 He brought up the subject.
For the same reason, a direct object that is used to introduce a brand new
element into the discourse will tend to sound better when it follows the particle
(Bolinger 1971, 52):
(27)	 a.	 It opens up unlimited opportunities. >
	 b.	 It opens unlimited opportunities up.
And contrariwise, definites, being identifiable and therefore accessible, will
be happier before the particle than indefinites:
(28)	 a.	 Then he opened the box up. >
	 b.	 Then he opened a box up.
(29)	 a.	 He opened up a box. >
	 b.	 He opened up the box.12
What we are dealing with here is yet another hierarchy, which we can call
Accessibility. Let us recognize, following Prince (1981), three positions on this
hierarchy: evoked (EV) by the text or the situation, inferable (IN), and new (NW).
The scale of Accessibility from highest to lowest is then (30).13, 14
Other things
being equal, a more accessible referent will precede a less accessible one.
(30)	 Accessibility
	 EV > IN > NW
Now let us turn to the lexical representation of verb–particle combinations.
There are two kinds of these, the idiomatic and the productive, the latter
218  Conflict resolution
of which add a consistent, usually deictic meaning to motion and caused-
­
motion verbs in much the same way as productive derivational morphology
can. Regardless of whether the verb–particle combination is lexical or pro-
ductive, the result is a semantic unit that can often be paraphrased by a single
verb. Thus throw up is equivalent to vomit and take out (on one reading) is
nearly synonymous with remove. There are a great many such examples in
the English lexicon, including look up, throw up, make up, hand up, look out,
throw out, make out, hand out, and so on. I will consider here only one idiom-
atic example, fritter away, more or less the equivalent of waste, the lexical
entry for which is (31):
(31)	 fritter away
	 syntax: [V fritter], [Prt away], in [ __, NP]
	 F/A: Faa
	 RS: “waste”, EVENT, AGT, PAT
	 mphon: /frɪtɹ/, /əweɪ/
The particle and the object are sisters and unordered by the syntax. But
the considerations that were taken up here as well as others that have been
discussed in the extensive literature on verb–particle constructions will be
instrumental in determining the relative acceptability of various constituent
orders, just as they were in the case of heavy constituent “shift” and dative
“movement.” In particular, as the Weight, Complexity, and in-Accessibility of
the NP complement increase, the more acceptable the particle–NP order will
become and the less acceptable the NP–particle order will be, as we saw in
examples (20)–(29).
7.6	 Factivity
Statement (26) in Chapter 2 amounts to stipulating that non-factive verbs can-
not occur with clausal subjects and no complement, whereas factive verbs
can.
(32)	 *That Freida isn’t here seems.
(33)	 That Freida isn’t here stinks.
A partial account of these facts emerges from the hierarchy of Accessibility
and its relation to the left-to-right hierarchy of linear order. Since factive verbs
have complements that contain old information, either accessible but not men-
tioned or already mentioned, while the complements of non-factive verbs
introduce new discourse entities, it makes sense that complements of factives
Factivity  219
can appear early – as subjects – whereas the complements of non-factive verbs
cannot. Combined with the Weight principle, the Accessibility hierarchy like-
wise provides some understanding of why it is that non-factive adjectives can
have complement subjects:
(34)	 That Frieda isn’t here is likely.
Verb phrases in which the content is entirely invested in an adjective phrase
must be supported by a verb, the copula in the default case. A verb can com-
prise a verb phrase by itself, but an adjectival verb phrase must contain at least
two words, a verb and an adjective. Therefore non-factive adjectives occur in
Weightier constituents than non-factive verbs, and would therefore be more
comfortable after informationally light clauses than lighter-Weight verbs
would. These factors are presumably grammaticalized in English, but the con-
siderations above give us a hint as to why they are what they are rather than the
other way around.
Larry Horn (1981) has called attention to the following striking and easily
apprehended facts. Consider example (35):
(35)	 I thought you’d be here.
This admits of two distinct intonation patterns correlated with differential
acceptability in different contexts.
(36)	 a.	
Context A: Speaker is talking by phone with the referent of you, who is
in a remote location.
	 b.	 Context B: Speaker is speaking face-to-face with the referent of you.
(37)	 a. 	I thought you’d BE here.
	 b.	 I THOUGHT you’d be here.
In context A, (37a) is unremarkable and (37b) is anomalous, but in context B
exactly the reverse is true. The reason is that there is a clear difference in the
informational status of the complement clause, and that correlates directly with
the intonational difference. In context A, the fact that the addressee is not here
is readily accessible and may even have been mentioned (“You’re not here yet.
I thought you’d BE here.”). In context B, however, the accessible information
is that the addressee is present (“Here you are! I THOUGHT you’d be here.”).
Since the content of the complement clause in (37b) is accessible informa-
tion, i.e., informationally light, the production of the clause must be intona-
tionally light as well. Conversely, the greater accentual weight on the verb of
the complement clause in (37a) makes that clause informationally weightier.
The accented complement clause in context A contrasts with the mentioned
220  Conflict resolution
or unmentioned accessible information “You’re not here”; the accentual effort
expended on the main clause in (37b) de-stresses the subordinate clause, mak-
ing it more likely to be interpreted as accessible information and suitable for
use in context B.
The same considerations provide an understanding of the role of informa-
tional status on word order, as Horn (1981) stressed. Among other things,
Horn pointed out (terminology aside) that a complement clause that conveys
accessible information facilitates early occurrence. For example, clauses that
are subjects of passives are interpreted as containing accessible information,
whereas the active verb as well as a passive with an expletive subject and an
“extraposed” clause is informationally ambiguous.
(38)	
The conspirators suspected that their phones were tapped (and they were
right/wrong).
(39)	
It was suspected by the conspirators that their phones were tapped (and they
were right/wrong).
(40)	
That their phones were tapped was suspected by the conspirators (and they
were right/*wrong).
7.7	 Ineffability
Componential discord is often resolved on the basis of a hierarchy of modular
strength, the Great Chain of Speaking, that was presented at the outset of
this chapter. If the syntax of a language places certain parts of the expression
together as a constituent, and F/A structure puts the corresponding parts to-
gether differently, the syntax usually wins because it outranks F/A structure
according to the hierarchy in (2). At other times, forces outside of the mod-
ules proper can tip the balance in one direction or another, a situation that is
especially easy to recognize when it comes to linearizing the elements of an
expression. But sometimes the modular conflicts we have seen lead to there
being two ways of expressing approximately the same thing where the pull
of forces in opposite directions produces such tension in the system that none
of the alternatives is particularly acceptable. In such cases speakers might
simply avoid the problem altogether and seek some other way to express the
thought or even say something that is nonsensical that will get the point across
by relying on the hearer’s pragmatic editor to do some extra work. There are
many cases where “we just can’t say it that way.” The most-studied examples
of this kind come under the heading of island constraints, where conformity
Ineffability  221
with the ordinary requirements of the several modules produces unduly com-
plex associations between modular representations.
A different kind of example in English has to do with the possessive form of
conjoined noun phrases. A conjoined noun phrase such as O’Hara and Levin
can be made possessive by combining the whole noun phrase with the posses-
sive clitic, giving (O’Hara and Levin)’s or by making each conjunct possessive
(O’Hara)’s and (Levin)’s, in which case the conjoined phrase is possessive
because both daughter phrases are. Both are completely well formed syntactic-
ally and presumably truth-conditionally equivalent, but the difference is quite
naturally exploited pragmatically so that the syntactically wide-scope posses-
sive, (O’Hara and Levin)’s books suggests that the books were jointly written
and the narrow-scope possessives (O’Hara)’s and (Levin)’s books suggests
that they were individual works.
If one or both of the conjuncts is a pronoun, however, tension is introduced
into the system. While (him and O’Hara)’s books ought to be fully grammat-
ical, ((him) and (O’Hara’s)) books should be ungrammatical as a conjunction
of NPs, since one would bear the feature [POSS] and the other would not. The
fact that on one bracketing the example is syntactically ill formed makes the
example less than fully acceptable for many speakers. There are several alter-
natives, however. One is to conjoin possessive NPs: his and O’Hara’s books,
but this suggests that the books were individually written and if that is not the
intended understanding, that option is also dispreferred.
With a first-person pronoun, the problem is even more pronounced due to
the marketplace success of the originally prescriptive rule that requires first-
person reference to come last in a conjunction of noun phrases, coupled with
the hypercorrection that favors NP and I in all positions (Sadock 2005; Grano
2006). There are several possible alternate versions, including NP and I’s, NP
and me’s, NP and my, and NP’s and my, all of which are attested. Each option
is fraught with tension of one kind or another and therefore some speakers, in-
cluding this writer, would rather avoid them altogether and phrase the thought
completely differently, saying, for example, the article that Etsuyo and I wrote,
thus sidestepping the problem entirely. Georgia Green (1971a, 1971b) docu-
mented several cases where the conflict is between syntax and interpretation,
some of it probably pragmatic. Many further cases of virtual ineffability are
attested in the phonological literature that stem from various clashes between
phonology and morphology (Richards 1998), but I will leave it here. The point
is that the competition between the competing forces I have described in this
book sometimes leads to the demise of both combatants.
222  Conflict resolution
7.8	 Summary
The very idea of automodular grammar implies that there will be conflicts
between modules. If there weren’t there would not be any autonomous mod-
ules. This chapter was devoted to investigating the various things that can hap-
pen when distinct grammatical forces work in opposite directions.
The conflict may be resolved in such a way that the requirements of one
components prevail over the another, its requirements being expressed while
the conflicting requirements of another are suppressed. The result is a toler-
able mismatch between the expressed structure and a conflicting structure that
is found in a different autonomous module. Cases of this kind are generally
resolved according to the Great Chain of Speaking: the stronger component
will express itself over the demands of any weaker component. A syntactic
requirement that is at odds with a semantic requirement will be expressed –
unless, of course, there is a morphological requirement that is at odds with the
syntactic requirement.
The most sought-after territory in the grammatical conflict is linear order.
The Great Chain of Speaking plays a role here, too, we know. If a lexeme
is a syntactic word but a grammatical affix, and affixes in a particular lan-
guage are suffixes, then that lexeme will occur as a suffix regardless of the
language’s word-order regime. But, as Sapir taught us, all grammars leak; there
are examples in all languages that are not firmly decided by any component,
and in such cases there may be free variation with regard to the modules, but
other natural but non-modular forces may come into play. When that happens,
we often find tolerance of both options, with the acceptability of one or the
other order improving and the other degrading in a scalar fashion depending
on the degree of strength of one or another of the forces. This combined with
varying degrees of mismatch between modules provides an automatic account
of the graded acceptability of expressions that is an undeniable fact of natural
language.
The last sort of outcome of modular conflict is the opposite of the tolerance
just mentioned. In some cases, the demands of two or more modules are indi-
vidually strong enough that none can be comfortably neglected. In such cases
there is no adjudication of the dispute that is acceptable to all parties, and a dif-
ferent speech strategy has to be found. Such phenomena are well attested and
an adequate theory of grammar ought to make room for them.
223
8	 Some final observations
My goal in this book has been to persuade those with an interest in the structure
of language that the derivational metaphor intrinsic to transformational gram-
mar is unnecessary and, indeed, pernicious. I argue for a model with no rules
that lead from one representation to another, a model that operates instead with
a number of self-standing modules, each generating a set of structures that we
may look upon as specifying the language of an independent representational
dimension. These separate components are associated not by derivational rules,
but through a lexicon that provides the value of lexical items in each module,
and by principles that prefer any two alternative modular representations of the
same expression to be as similar as they can be. The attractions of such a sys-
tem of description are that it allows each module to be kept reasonably simple,
computationally tractable (Higgins 1998), and intellectually intelligible. The
power of the system resides in its ability to describe complex phenomena as the
result of competition among individually simple components.
I have tried to persuade not so much by argument as by demonstration. In
a relatively short work I have presented quite detailed analyses – quite for-
mal analyses – of a wide range of grammatical phenomena, principally from
English. The grammar I have provided covers a great deal of the basic structure
of English, leaves little to the imagination, engages in little abstract specula-
tion, and produces clear and testable predications. I invite readers to compare
the treatments that emerge from adopting a multi-modular perspective with
what counts as description in the modern transformational literature in terms
of formality, clarity, empirical coverage, and especially, elegance.
For more than a quarter century, much of my research has been devoted to
investigating the autonomous modular architecture for grammar, and during
that time I have benefited greatly from the work of a number of students and
a smaller number of converts from the wider academic community. A more
or less independent version of the autonomous modular approach entered the
theoretical scene with Jackendoff (1997) and continued through Jackendoff
(2002) and Culicover and Jackendoff (2005). Their work addresses a number
224  Some final observations
of issues not covered here: neuroscience, evolution, computation, and lan-
guage learning, to name a few, and is much more thorough in comparing
modular architecture with various versions of transformational grammar. The
Jackendoff–Culicover program is, however, generally less analytically explicit
and integrated than the present work. The two projects, theirs and mine, com-
plement each other nicely.
Culicover and Jackendoff’s excellent book, Simpler Syntax (2005), describes
itself as “a contemporary version of Interpretive Semantics” (p. xiv). I would
describe my very similar philosophy of grammar as “a contemporary ver-
sion of Generative Semantics.” Both claims are absolutely true: neither their
view nor mine countenances any calculation that takes one representation into
another. The view we share neither interprets a level of syntactic representa-
tions as some sort of logical structure, nor takes some sort of logical structure
and calculates from it a level of syntactic form. Jackendoff and Culicover came
to their view from the Interpretive Semantics camp and I arrived at mine from
Generative Semantics. I produced a contemporary version of what I had been
doing by jettisoning transformations and they did the same thing. I would go
so far as to claim that the non-derivational model retains what is common to
all forms of generative grammar, doing away with many of the differences that
define the various theoretical camps within generative grammar, differences
that have been the subject of a great deal of discourse that has covered and
­
re-covered the same ground and produced very little compensatory progress.
Ray Jackendoff and I didn’t share much in the way of linguistic philosophy,
having served in opposing militias during the linguistic wars. Since the 1960s
Ray has been developing and refining notions of cognitive structure that were
quite independent in principle from rules of syntax. My epiphany came much
later with the sudden realization that the obvious morphological system for
West Greenlandic Inuttut combined with an equally obvious and simple syntax
could directly account for the surprising properties of noun incorporation in
that language without derivation, provided a certain degree of mismatch was
allowed between the representations of the one component and those of the
other. (See Sadock 1985a.) At the Annual Meeting of the Linguistic Society of
America in Boston in January 1994, Ray and I both attended a workshop deal-
ing with a recent development in the transformational model. We were both
struck by the arbitrariness of the framework, its tenuous relation to facts, and
especially by the very loose formalism that, if it had any consequences at all,
seemed to have absurd consequences. Out in the hall after the question session,
we discovered that from opposite ends of the theoretical spectrum, our views
had converged on the idea of non-derivational grammar.
Some final observations  225
That convergence includes our rejection of the oddly popular notion that
human language is in some sense perfect. Not so long ago Steven Pinker and
Ray Jackendoff took Chomsky to task for suggesting (among other things)
that the design of language, while beautiful, optimal, and in its way perfect,
is not particularly suited to the purposes to which language is put. Among
other things, Chomsky has been committed for quite some time to the idea that
the system of language is (again, in some sense) non-redundant. Pinker and
Jackendoff level pointed criticism at Chomsky for writing,
[T]he [human language] system is elegant, but badly designed for use.
Typically, biological systems are not like that at all. They are highly
­
redundant, for reasons that have a plausible functional account … Why
language should be so different from other biological systems is a prob-
lem, possibly even a mystery.   (Chomsky 1991, quoted in Pinker and
Jackendoff 2005, 227)
Numerous other claims that Chomsky has made about the relation of linguistic
structure to biological structure are at least puzzling. Here’s one:
Biological systems – and the faculty of language is surely one – often exhibit
redundancy and other forms of complexity for quite intelligible reasons, relat-
ing both to functional utility and evolutionary accident. To the extent that this
proves true of the faculty of language, then the correct theory of U[niversal]
G[rammar] is not in itself an intellectually interesting theory, however empir-
ically successful it may be.   (Chomsky 1981, 14)
I have trouble seeing how an empirically successful theory of a natural phe-
nomenon can be intellectually uninteresting. Chomsky is surely right about
one thing: biological systems do not display the kinds of properties that he
attributes to the system of human language, in particular, non-redundancy. The
idea that redundancy is in fact a fundamental feature of the design of lan-
guage occurred to me in the middle 1980s. That reorientation of my thinking
was instrumental in precipitating the idea of autonomous modular grammar. In
Sadock (1983), I argued that there was wide-scale redundancy of function be-
tween components of the grammar, and in Sadock (1984), I tried to show that
lexical items were often redundantly specified for various properties.
There is plenty of redundancy in the organic world: we have two function-
ally identical kidneys, we produce vastly more gametes than could ever be
used, and so on. But that is not the sort of duplication of function that is most
widespread in biological organisms or, for that matter, in natural language.
Rather, biological systems – and the faculty of language is surely one – often
provide two or more distinct mechanisms for accomplishing the same end.
Technically, biologists prefer the term degeneracy, borrowed from quantum
226  Some final observations
mechanics,1
for speaking of separate, overlapping, paths to the same end in
biological systems:
Degeneracy is the ability of elements that are structurally different to perform
the same function or yield the same output. Unlike redundancy, which occurs
when the same function is performed by identical elements, degeneracy,
which involves structurally different elements, may yield the same or differ-
ent functions depending on the context in which it is expressed.   (Edelman
and Gally 2001, 13764)
Edelman and Gally say that what they do in their paper is “point out that degen-
eracy is a ubiquitous biological property” and they argue that it is “a feature of
complexity at genetic, cellular, system, and population levels.” The quest for
simplicity – Occam’s Razor – is a powerful heuristic in the physical sciences,
but Occam’s Scalpel needs be used sparingly in biology.
Degeneracy, as Edelman and Gally describe it, is exactly the kind of func-
tional duplication that automodular analysis imputes to the system of natural
languages. There are not two identical rules of syntactic agreement, for ex-
ample, which are applied randomly, now one, now another. But there are sev-
eral distinct, and sometimes conflicting mechanisms that are involved in the
expression of number. At times, then, number is redundantly represented; in
the sentence These lambs are similar the idea that a group is involved is rep-
resented four ways: by the quantificational function of the demonstrative, the
plural form of the noun, the plural form of the verb, and the meaning of the
adjective. In the form of grammar that I advocate, four different grammatical
systems are individually capable of producing the same result, the signaling of
plurality: role structure, lexicon, morphology, and syntax.At times, only one of
these is functional, as we see in the following set of sentences:
(1)	 The sheep became similar.
(2)	 These sheep became sick.
(3)	 The lambs became sick.
(4)	 The sheep are sick.
At other times, there is disagreement among the forces competing to display,
say, number marking of the verb, something I have brought up many times in
arguing for a model of grammar with partly overlapping principles. (See, for
example, Sadock 1998a.) In examples where there is tension between compet-
ing principles, there is often vacillation, as in (5) and (6).
(5)	 a.	 My family is/are tall.
	 b.	 My family is/are Irish.
Some final observations  227
	 c.	 My family is/are at each other’s throats.
	 d.	 My family is/are all doctors.
(6)	 a.	 My parents is/are what I want to talk about.
	 b.	 What I want to talk about is/are my parents.
Functional duplication is a good thing in biological systems, so it is a good
thing in linguistic systems, too. It allows for language to work under less
than ideal circumstances, enabling communication between second-language
speakers and native speakers, whose syntax and morphology very likely differ;
it allows us to understand lexical items we have never heard before, makes it
possible to understand our seatmates on an airplane, and sometimes even the
pilot on the intercom.
Edelman and Gally’s observation that the independent mechanisms do not
always yield the same result is significant in a second way as well. In organic
systems the incomplete overlap of functions explains the existence and the
frequency of degeneracy. The same is obviously true of a linguistic system
consisting of incompletely overlapping independent modules. Syntax, function-
argument semantics, and role structure will often provide a single expression
with similar constituent structures, ordered similarly by the LOC component.
In such cases one could essentially choose any one of these descriptions as
the grammatical representation of the expression. But that is only so in those
special, though admittedly rather central examples where there is little tension
among the demands of the various modules. In many cases, the independence
of the modules is perfectly obvious, since the representations they provide are
not congruent; they are mismatched and present the user of the grammar with
a choice. If for every expression in a language, two components always pro-
duced homomorphic descriptions, they could be collapsed into a single com-
ponent. Discrepancies that must be apprehended by language learners thus
reinforce in the minds of speakers the idea that language is multifaceted, with
different, parallel dimensions of structure and different, parallel dimensions of
significance.
Consider as a simple example the particle modifier right, mentioned briefly
in section 7.5 of Chapter 7. Right as it appears with particles is unusual in being
a modifier of modifiers, specifically, a modifier of (or adjunct to) adverbs.
(7)	 right (adverbial modifier)
	 syntax: __ in [ADVP ___, ADVP]
Right in this use has a few different meanings, for example, “without detours”
with path adverbials: We went right home; “precisely” with locative adverbials:
They’re standing right in the middle; and something like “immediately” with
228  Some final observations
time adverbials, as in Right then the lights went out, or The guests arrived right
after we left. What is of interest here is that this last, temporal sense occurs
even when there is no temporal adverbial: The child spoke right up, She blurted
right out that she had solved the problem (= Chapter 7 (23a)). For this reason,
the word is ambiguous with path adverbials, since all events that include a path
also involve a time. Thus I’ll come right home can mean either “I will leave
immediately for home” or “when I leave I will come home without detours.”
A more complete lexical entry for this element is (8), which indicates, as
above, that it must modify an adverb, that it is a propositional modifier, with
the meaning “immediately,” and is a morphological word of indeterminate
category.
(8)	 right (temporal modifier)
	 syntax: __ in [ ___, ADV]
	 F/A: Fp
	 RS: “immediately”, TYPE, EVENT
	 morphology: Word
Now someone who has learned that right is a syntactic modifier of adverbs
will know that it cannot be used by itself as a particle meaning “immediately”:
*I will leave right. But there is an empty adverb away that syntactically sup-
ports the temporal meaning of right: I will leave right away, *I will leave away,
I’ll be there right away, *I’ll be there away. Its lexical entry will be (9), as the
reader might well have guessed.
(9)	 away (empty adverb)
	 syntax: ADV
	 F/A: nil  RS: nil
	 morphology: Word
These two lexical entries, whose syntactic and semantic fields can be deter-
mined directly from introspection, provide a simple account of properties that
would be difficult to describe if meaning is calculated from form or vice versa.
The point is that the account is crucially dependent on the autonomy of syntax
and the other informational dimensions. In (8), modular independence allows
for a geometric mismatch between the position of the lexical item in syntax
and its position in the semantic dimensions. In (9), that same feature of gram-
matical architecture permits an element to have a representation of an ordin-
ary kind in syntax and morphology, and to fail to have a representation in the
semantic tiers. Furthermore, the apprehension of these independent features of
the lexical item reinforces the independence of the dimensions and facilitates
other analyses that simplify descriptions of a large range of grammatical phe-
nomena, as I have attempted to show in this book.
Some final observations  229
Let me turn now to the topic of explicitness, a desirable quality in any view
of language that is to be taken seriously. One of the great virtues of a model
of grammar comprised of several free-standing generative components is that
each of these components is simple enough to imagine formulating quite expli-
citly. Explicit rules can rather easily be formulated, as I have done throughout.
It is not my intention to expend much energy criticizing views I find lacking
in merit, but I am struck by the breadth of the chasm that separates the discus-
sions of grammatical facts from explicit statements that describe the facts in
the modern literature. One finds pages and pages of prose littered with un-
defined technical terms, and punctuated once in a while with trees whose ori-
gins are a matter of habit rather than rule. These trees ordinarily contain nodes
that differ from investigator to investigator, and supplementary arrows showing
how various pieces of the trees have moved around, without making explicit
the reasons they have moved beyond saying something like “for EPP reasons.”
(See Chapter 2, n. 39.) Rather than continue this diatribe, let me just invite the
reader to pick up any recent number of one of the top theoretical journals in lin-
guistics and ask what it would take to make the analysis formal. What assump-
tions need to be stated carefully enough to be made into rules? What principles
need to be defined in terms of concepts that themselves are formally defined?
And then, you should ask yourself, “Why hasn’t this been done?”
There is a downside to assuming simple components whose rules can be
formulated without great difficulty: that property behooves you to be explicit.
You get – and deserve – a guilty conscience if you evade formalization. Simply
drawing trees that are not generated by an explicitly stated rule system is not
formalization, nor is the statement of principles that include terms that have
only vague definitions. Hand waving cannot be outlawed, of course, but it can
be made to hurt. In extreme cases, explicitness can make it pretty clear that an
analysis is not just insufficient, but wrong. I say “pretty clear” because there
is no grammatical theory that I am aware of that can actually be shown to be
wrong. A particular assemblage of rules and principles is falsifiable if it is
formulated with sufficient precision, but none of the rules or principles in any
view I am cognizant of is so firmly established that it cannot be adjusted or
scrapped without the “theory” in which it was embedded being shown wrong.
It is all the more clear that the inability of a time- and investigator-dependent
version of linguistic theory to deal with some particular phenomenon is usually
considered an annoyance, rather than a challenge to the school of thought to
which that investigator adheres at particular time.
I blush to admit that the one-room school of thought that I have had a hand
in building is not really any different in principle. I find it hard to believe that
any new grammatical fact could persuade me tomorrow to abandon entirely the
230  Some final observations
idea of autonomous grammatical modules. But when it comes to the analysis
of individual phenomena, I think that the model I have exemplified here has
some distinct advantages, both in the degree of precision of its descriptions and
the degree of entrenchment of its principles.
There are several instances where the breeze from my waving hand was
discernable. I am certain that there are serious flaws in the some of the ana-
lyses I have presented, but it is my hope that I have at least formalized them
well enough to be definitively proven wrong. The big question is whether it
is merely a matter of bad analysis or whether theoretical assumptions of one
kind or another must be abandoned. I would be unhappy to have to drop the
assumption that the modules are to be formulated as context-free grammars.
There are two core assumptions that I could only give up by repudiating the en-
tire program I have taken such trouble to promote: (1) the existence of separate,
generative components of grammar, and (2) the absence of rules that lead from
one representation of an expression to another representation of that expres-
sion, either within a module or between modules. But if these ideas have been
made clear enough to be disconfirmed, that in itself will be a triumph.2
231
Notes
	 Introduction
1	 Construction Grammar (Goldberg 1995) also recognizes the trans-modular nature of
certain grammatical phenomena.
1	 Autonomous modularity: syntax and semantics
1	 ABS = absolutive case, INS = instrumental case, ERG = ergative case, LOC = loc-
ative case, IND = indicative mood, 3 = third person, 3R = reflexive third person,
s = singular, p = plural.
2	 This idea is essentially the same as the transitive construction in Construction Gram-
mar (e.g., Goldberg 1995, 117) and is also found in Jackendoff’s (1997, 2002)
recent framework. The architecture of autonomous grammatical modules lends itself
extremely well to the formalization of the notion of construction.
3	 By choosing names that allude to principles of physics here and elsewhere in this
book I am attempting to lend an aura of scientific rigor to the present enterprise. The
reader is cautioned against thinking that the terminology is anything more than pro-
paganda.
2	 The interface
1	 Perfect correspondence between representations in all modules is not even a logical
possibility within automodular grammar, since if it existed, there would be only one
module with various alphabetic homomorphisms. If logical representations and syn-
tactic representations are merely notational variants of one another, as some strict
compositionalists seem to believe, it wouldn’t matter whether you called a level syn-
tax or semantics. That is precisely the kind of view that the theory presented here is
opposed to.
2	 See also Jackendoff (1997, 2002), where a very similar conception of the role of
lexical items has been adopted apparently independently of work in the autolexical
framework. Marantz (1984) employs a similar conception of lexical items.
3	 The parallel with the techniques of Construction Grammar will become even more
precise when role structure (Chapter 3) is included.
4	 Predicate nominals are another construction in English, but for the sake of clarity I
will in general write out the syntactic and F/A structure fields in full, no matter how
much interpredictability there is.
232  Notes to pages 29–34
  5	 Cf. John F. Kennedy’s famous mistranslation of English I am a Berliner as Ich bin
ein Berliner. He should have said Ich bin Berliner, where the noun is determiner-
less as is appropriate for a predicate rather than an argument.
  6	 The reason for the asymmetry is that deep structure (or DS) is, in a real sense,
closer to being a representation of conceptual structure than either surface syntax
or morphological structure. Since the derivations are ordinarily conceived of as
proceeding upward toward surface structure (or SS), elements that are not found
in deep structure but are found in any of the more “superficial” levels must be
inserted.
  7	 There are important regularities here. Whether a predicate is realized as a syntactic
noun or verb is not a completely arbitrary matter; and in fact, has something to do
with the cognitive content of the predicates. Such regularities need to be captured,
and when cognitive content is brought into the picture, as it will be in Chapter 3,
something concrete can be said about the difference between nominal and verbal
predicates. Functional/cognitive grammarians have sometimes claimed that there
are few accidents in this realm, nouns and verbs always expressing different mental
takes on the world, a point of view expressed in Langacker (1990) and Hopper and
Thompson (1984). But while this is largely true, I think there are some oddities that
must be attributed to lexical happenstance. Whorf (1956) claimed that the Hopi find
lightning to be too evanescent to be categorized as a thing and therefore the Hopi
(and, I might add, also the Germans) say “It lightens,” but English has no verb for
such an event and we must say, circumlocutorily, “There is lightening.” Do we con-
ceive things differently from our Hopi brethren? I think not, the proof being that
we, or at least I, often want to say *It’s lightninging or something like that, but can-
not do so while remaining within our shared lexicon according to which lightning
is only a noun.
  8	 (7) is not a universal since some languages lack VPs. But no language lacks seman-
tic predicates, or at least that is what I am assuming.
  9	 What about the use of beat without an overt complement in, say, recipes: Beat with
a wire whisk? I take this to be a transitive use with a pragmatically anteceded zero-
pronominal object whose occurrence is restricted to certain genres. See Chapter 6
and Sadock (1975).
10	 I have included the morphophonological field here in anticipation of what is to
come in order to reinforce the idea that despite the descriptive and theoretically
unnecessary name that I have given this lexical entry, the phonology (and indeed
the morphology, though this is not explicit here) are the same as that of the verb
beat. The truth-conditional meaning LEAVE is shown here in F/A structure, but the
dimension of role structure that will be introduced in the next chapter is where its
truth-conditional meaning is properly located.
11	 This theory of the idiom is the traditional one and stands in contrast with that of
Nunberg et al. (1994), according to which both look and into have meanings, just
not their usual ones. Their view could just as easily be accommodated in this frame-
work and in fact will be in section 2.10 in connection with existential there.
12	 This and the correlation of categories discussed above were both included under the
generalized interface principle of Sadock and Schiller (1993).
Notes to pages 34–39  233
13	 Alternatively, we might say that the semantic subject is the Arg(ument) immedi-
ately dominated by Prop(osition). The semantic object is the Arg that is immedi-
ately dominated by the predicate node, Fa. In a parallel fashion, we may follow
generative tradition (Chomsky 1965) and define the syntactic subject as the NP
immediately dominated by S and the syntactic object as the NP immediately domi-
nated by VP. Now since S corresponds to Prop and VP to Fa, the correspondence
will follow without assuming an independent condition. Such a definition works
fine for a language such as English with an easily recognized VP but will not do
for languages that lack a VP. In such languages we may have to say that there is
no syntactic subject per se, but perhaps instead a morphosyntactic subject, which
occurs in the least marked case, or controls verb agreement, or the like. In any
case, geometrical correspondence is needed to ensure that Mary left and John
cried doesn’t mean “John left and Mary cried.”
14	 Because of the simplicity of the various modules, a very straightforward definition
of c-command can be assumed, namely: A c-commands B if the first non-lexical
category dominating A also dominates B.
15	 These are more refined versions of the Structural Integrity and Linearity Constraints
of Sadock (1985a).
16	 In earlier work I postulated a third geometrical correspondence condition, Conser-
vation of Linear Order, but in this book linear order is the province of an indepen-
dent component that is described in Chapter 4. There the work of the linear order
condition will be done by treating it as a hierarchical correspondence with the dom-
inance and c-command hierarchies that are projected from the other components.
17	 This principle is obvious once it is seen, but I would not have seen it if Larry Horn
(p.c.) had not pointed it out to me.
18	 When role structure is introduced in Chapter 3 and the notion of factivity can be
captured formally, the generalization that factive verbs in English do not form VPs
without a complement will be stated formally. For a propositional modifier, factiv-
ity is the property that Fp(P) → P. Role structure represents cognitive content and
allows entailments to be calculated.
19	 For another view that does this with somewhat similar assumptions, see Seppänen
and Herriman (2002).
20	 A possible reason non-factive adjectives and nouns (such as likely and foregone
conclusion) might fail to be included in the group of “positive absolutive excep-
tions to extraposition” is that there is another force that shapes English, and, I
believe, all other natural languages as well, a principle of gravity that can result
in heavy things sinking closer to the end of expressions than lighter things, which
tend to float upward, toward the beginning. The principle of Linguistic Gravity
will be formulated as (4) in Chapter 7. Verb phrases built from adjective phrases
or noun phrases are necessarily heavier than verb phrases built from verbs, since
the adjective or noun will require an additional verb to make a VP, whereas a verb
can form a VP all by itself. I take it as obvious that in some sense the phrases is
apparent or is a foregone conclusion are formally heavier than the word seems. In
any case, stink has the lexical specification given in (28b) and odd, likely, appar-
ent, unpleasant, disaster, foregone conclusion, and so on, all have analogous
234  Notes to pages 39–64
lexical specifications, except, of course, that they are syntactic adjectives or
nouns rather than verbs.
21	 The feature [to] is added to a VP by the syncategorematic item to that takes a VP
complement and lacks representation in F/A structure. It is a different item from the
homophonous preposition both formally and functionally. Its lexical entry would be:
(i)	 to (infinitive marker)
	 syntax: __ in [VP[to] __, VP[INFIN]]
	 F/A: nil
22	 The notation “%” indicates something that is restricted to certain dialects or regis-
ters.
23	 I am indebted to Yoshio Ueno for assistance with the analysis of these two verb
types.
24	 These two structures assume the following phrase structure rules in addition to the
ones in (14) of Chapter 1:
(i)	 S′[for-to] → Comp[for], S[to]
(ii)	 S[to] → NP, VP[to]
25	 Help also occurs (more normally) with a base-form VP: He helped me succeed,
whereas assist does not.
26	 The morphological function of features like [INFIN] will be made clear in (35) of
Chapter 5.
27	 The basic insight that traditional generative grammar and this non-derivational
model share is that there is a difference between two levels of structure, one closer
to overt form and the other closer to meaning. It should not come as a surprise, then,
that the traditional accounts of the differing grammatical behavior of Raising and
Equi predicates carry over to what is offered here. The identification of syntactic
deep structure with semantic representation was explicit in generative semantics.
In that sense, one could see the present view as a partial vindication of generative
semantics. I depart radically from that tradition in rejecting the idea that the syntac-
tic component serves only to deform and disguise logical structure.
28	 Given the number of degrees of freedom in the analytical space available for
accounting for verb movement, I think it is a fair bet that the number of positions
that have been taken on the treatment of this kind of movement is exactly equal to
the number of investigators who have taken a position on the question. If this is
what explanation is considered to be, I’ll be satisfied with description.
29	 For a contrary view, see Jacobson (1999).
30	 [x] is a “foot feature” in the terminology of GPSG (Gazdar et al. 1985).
31	 I am grateful to an anonymous reviewer of the manuscript of this book for an obser-
vation that suggested this particular formulation of the lexical content of empty be.
That reviewer called my attention to Sag et al. (1985), where empty be is analyzed
as taking a syntactic complement belonging to the otherwise unnecessary category
Pred. There is, however, an independent semantic category of this kind, Fa, which I
have referred to many times already. It is possible in this framework to say that the
complements of be may be any kind of XP in the syntax, but have to be predicates
Notes to pages 64–70  235
of the category Fa with regard to semantic combinatorics. That is just what I have
done in (97).
32	 McCawley provides a counterexample: There were a few persons still his friends
(1988, 18, fn. 8). I do not understand why it is so much better than *There is a sol-
dier a corporal, but it is.
33	 Some technical details remain to be ironed out. Consider the example: There are
three problems with this analysis. Here the word three would seem to be the exis-
tential quantifier or at least part of it, which would give the F/A structure two quan-
tifiers where there is only room for one. I will not pursue such technical problems
here.
34	 This specification suggests that there could be more than one instance of there sanc-
tioned by a single existential be. To my surprise, I found quite a large number of
web examples like there seems there’s no way this could be a coincidence. Those
who are fond of movement will take this to be evidence for cyclic raising. I will
simply accept the implications of the simple formulation in (99).
35	 In my colloquial speech, non-nominative pronouns can occur in certain positions
where prescriptive usage excludes them. The use of reflexives closely follows their
distribution as in the following examples:
(i)	 Who’s going to be minding the shop?
	 Just myself. *Just myself will.
	 (cf. Just me. *Just me will.)
(ii)	 Myself or Tracy will be there. *Myself will be there.
	 (cf. Me or Tracy will be there. *Me will be there.)
36	 Besides pleonastic it, emphatic reflexives and reflexiva tantum are also presumable
exceptions. The reflexive pronoun is arguably meaningless by itself in examples
like The devil himself could not pronounce a title more hateful to mine ear (Shake-
speare) and The man who does not betake himself at once and desperately to saw-
ing is called a loafer…(Thoreau).
The non-possessive pronouns will be taken up again in Chapter 6, sections 6.3.1
and 6.4. More detail on possessives may be found in section 5.3 in Chapter 5.
37	 Some structural features of the difference between plain and reflexive pro-
nouns are clear. Reflexive pronouns in English, for example, generally require a
c-­
commanding antecedent NP in their own clause, and plain pronouns generally
forbid reference to non-pronouns that they both precede and c-command. But since
those structural features determine possible reference, I see no reason why they
could not be referred to in the semantics. The structure of an utterance in which a
pronoun is used is a fact of the world, after all.
38	 Actually, they are one degree less transitive than the corresponding transitive verbs.
See Chapter 3 (17).
39	 The Extended Projection Principle is named so as to make it seem as if it is part of
an improved version of a well-established Projection Principle, though in fact, it
was originally an addendum to the Projection Principle and the Projection Principle
itself has gone out of existence. Furthermore, since the advent of Minimalism, the
EPP itself ceased to exist as a separate principle, though its name survives in the
236  Notes to pages 70–97
term “EPP feature.” EPP features are named so as to make it seem as if they are a
part of a well-established EPP, but the EPP itself seems to have been supplanted by
its reinterpretation in featural terms. For another look askance at the invocation of
the EPP, see Grohmann et al. (2000).
  3	 Role structure
  1	 There are perhaps also roleless predicates such as weather verbs, but a more con-
servative assumption is made in (1).
  2	 This is not to say, of course, that the discourse prominence of all participants is the
same. It is frequently the case, for example, that a single entity is highlighted in the
presentation of an event by a speaker. This can take place by syntactic means (e.g.,
placing a nominal at the beginning of the sentence or in syntactic subject position),
by morphological means (e.g., by the use of highlighting particles or inflections),
or by phonological means (e.g., by stress). It therefore seems desirable to assume
yet another informational level of representation that represents discourse promin-
ence. In this work I will not, however, present an autonomous information-structure
module, though I will discuss in Chapter 7 one aspect of informational structure
and how it can be integrated with the system of independent modules described in
this book. Formulating an autonomous informational structure component is, I feel,
an important next step in advancing the automodular way of thinking of things.
  3	 If one could somehow make oneself old then it would be possible to say I was pur-
posely old (by the time I retired), even though it would make it logically necessary
that I possessed an exceedingly unlikely desire.
  4	 The idea that passives can be dealt with by means of a lexical rule goes back at least
to Wasow (1977).
  5	 The properties of the verb put will be dealt with formally in section 3.8.2 where its
lexical entry is given as (88).
  6	 In particular, it is not necessary to assume that there is obligatory extraposition, a
good thing in the present system, since there can’t be a rule like extraposition.
  7	 For a recent, very clear argument summing up much of the accumulated evidence
in favor of treating control by attending to meaning, see Culicover and Jackendoff
(2006).
  8	 Yoshio Ueno, commenting on the manuscript of this book, pointed to examples
like Try to be respected and counted on by your coworkers. He suggested that the
coreference in these cases is with the highest available role of the subordinate
event. This would necessitate a new notational convention, if not a new mecha-
nism, and while I feel that there might well turn out to be some further utility to
the idea of the highest available role, I will hold off on adopting the idea here, and
suggest instead the mechanism of coercion, as discussed, for example, in Sag and
Pollard (1991).
  9	 Yoshio Ueno (p.c.) also observed that since passive by requires a role structure
agent to correspond to its syntactic object, impersonal it is excluded: I was rained/
snowed on (*by it).
10	 This is a possibility with a verb-particle structure, for which see Chapter 7, sec-
tion 7.5.
Notes to pages 99–112  237
11	 This idea has been developed by several investigators, where it is referred to as “nat-
ural predication.” The reader is referred to Napoli (1989, 97–98) for a list of them.
12	 One feature of the pseudo-passive that has been neglected here is its greatly reduced
acceptability in the presence of a direct object, even one of low patientivity. For
example, the passive Progress was made on the building is better than *The build-
ing was made progress on, despite the fact that the building is clearly more pati-
entive than progress. I will not, however, explore refinements of the treatment of
pseudo-passives that I have provided here.
13	 The angle brackets on both the left and right sides of the arrow indicate that the
element is either present in both the input and output of the rule or absent in both.
14	 See Chapter 5, (37) for a discussion of this feature.
15	 I assume that when it is used with a second object, as in I bought Max a bicycle,
this is the result of a lexical rule that adds a beneficiary NP to the syntactic subcat-
egorization frame of any volitional verb. The semantic effect, though, is to create a
modifier of a predicate:
(i)	 buy		 buy (+BEN)
	 syntax:	 V in [ __, NP]	 V in [ __, NP, NP] )
	 F/A:	 Faa	 Faa = MFa (= for benefit of ANC)
	 RS:	 “buy”, AGT, PAT	 “buy”, AGT, PAT, ANC
16	 A complication in English is the unclear boundary between adjectival passives and
verbal passives. Besides allowing for what looks like agentive by in examples like
(90a), most speakers allow the structural of (Chapter 2 (22)) to mark what is pre-
sumably the complement of an adjective. Additonally, degree adverbials like very,
typical of adjectival modification, are generally allowed. For this speaker, agentive
by and degree modifiers are not terribly compatible, making (i) much more accept-
able than (ii).
(i)	 The child was very terrified of spiders. >>
(ii)	 The child was very terrified by spiders.
But there is clearly a great deal of variation among English speakers, as witness
the lyric of the song Pinned Together, Falling Apart:
(iii)	
I have been terrified by the thought of losing you,
	 So very terrified by the thought of losing you.
The first line strikes me as odd, the second as quite weird.
17	 This assumes, reasonably enough, that the role properties of VPs are inherited
through auxiliaries, though I will not formulate the principle here.
4	 The linear order component
1	 Apparent exceptions arise because of discrepancies between syntactic and morpho-
logical bracketings that make it possible for a lexical head, a preposition, say, to be
incorporated as part of a word. (See Baker 1988a and Sadock 1985a, 1991.) Accord-
ing to the present conception of grammar, however, the head still c-commands its
complement in the syntax.
238  Notes to pages 113–19
  2	 These may stem from historical situations in which the word order was in harmony
with natural or independently justifiable hierarchies, but where subsequent changes
in word order type produce synchronic situations that are inexplicable by reference
to more general principles.
  3	 A similar hierarchy is noted in Dik (1989) under the name of LIPOC (Language
Independent Preferred Order of Constituents). He gives it as: <clitic, pronoun, noun
phrase, adpositional phrase, subordinate clause>. The multi-hierarchy view sug-
gests that this is a conflation of at least two hierarchies, one based on syntactic
complexity per se, and one based on morphological status.
  4	 Two objections that have frequently been made to this definition of syntactic com-
plexity are: (1)  there are cases of prepositional phrases with verb phrases as a
daughter, e.g., about to leave, and (2) there are noun phrases with prepositional
phrases as daughters, e.g., men with moustaches. Both of these complaints are, I
believe, factually dubious. If the structure of about to leave were [PP about [VP to
leave]], with to leave a sister of about in the first example, then to leave ought to be
a possible focus of a pseudo-cleft, as in What he wants is to leave, but I find What
he is about is to leave utterly unacceptable. I am not sure what the structure of a
VP such as be about to leave actually is, but I think it is not one in which VP is a
daughter of PP. As for the structure of the phrase a man with a moustache, I think
it is also reasonably clear that it is not [NP Det man PP], but rather [NP Det [N′ man
[PP with a moustache]]] in which the prepositional phrase is a daughter of N′, not
NP. The phrase-hood of man with a moustache is demonstrated by the possibility
of conjoining it with a parallel N′: any dog with a collar or cat with a bell.
  5	 Der Yiddish-Vinkl July 25, 2003. www.forward.com/articles/7780/.
  6	 www.bistummainz.de/bistum/menschen/glaube_theologie/glaube/glaube_detail.
html?f_action=article&f_article_id=36&f_edition_id=9.
  7	 www.freak-search.com/de/thread/209767/wenn_2_aeltere_herren_urlaub_
machen/2.
  8	 www.ibiblio.net/pub/academic/languages/yiddish/mendele/vol2.066.
  9	 www.youtube.com/watch?v=K5UA2Y19Yh8.
10	 The idea of a separate linearization was clearly “in the air” in the mid-1990s, not
to mention its history in more traditional grammatical studies, particularly studies
of Germanic languages. Within the framework of autolexical syntax it was invoked
in Sadock (1993), and in other frameworks in Blevins (1994), and Kathol (1995),
among others. There seems to be fairly broad support for a mechanism to impose
linear order independently of other grammatical concerns. A separate linear order
component fits better in the present grammatical architecture, however, than it does
within the other conceptions of grammar in which the same sort of idea has sur-
faced.
11	 Though Yiddish is sometimes described as having or allowing V1 order in polar
questions, it is in fact extremely rare and perhaps a daytshmerism, a Germanism.
There is a sentence-initial particle tsi that can be used in polar questions with inver-
sion, but then the word order is, of course, V2. Otherwise polar questions are sig-
naled by intonation alone. I am indebted to Benjamin Sadock (p.c.) for correcting
my understanding of the facts of Yiddish.
Notes to pages 119–31  239
12	 The morphophonemic component will be discussed in Chapter 5, section 5.2.
13	 Yidish-Tish Berlin: http://en-gb.facebook.com/group.php?gid=124860424217056.
14	 http://kehillatisrael.net/docs/yiddish/yiddish_pr.htm.
15	 The example is complicated. The verb is on-hoybn “begin,” a particle–verb com-
bination that together means “start, begin.” The two parts occur together when the
verb is non-finite, but the finite verb portion occurs in second position because of
the demands of a second template that places finite verbs in second position in both
main and subordinate clauses of Yiddish. Since the pronominals follow the finite
verb, they end up sandwiched between the verbal part of the finite verb and the par-
ticle. With a full NP object, the sentence would be Hoybt on mayne tsu traybn dem
zun, “My (wife) begins to nag the (i.e., our) son.”
16	 Inversion is also triggered in a number of other less general cases, such as in ellip-
tical clauses introduced by the subordinating conjunction as (but not the modified
just as), the antecedent of a counterfactual with no subordinating conjunction that
begins with the auxiliary verb had, and somewhat more archaically, counterfactual
were (Yoshio Ueno [p.c.]).There is also a small number of fixed phrases with an
initial verb, e.g., come hell or high water.
17	 For a very useful discussion of some of the basic aspects of conjunction in several
dimensions, see Haspelmath (2004).
18	 The treatment outlined here owes a great deal to the ideas in Gazdar et al. (1985).
19	 The simplification is that (56) does not indicate where the variable (z) is bound.
My assumption is that the early position of the interrogative NP in linear order
is associated with a high position of the corresponding quantifier phrase in F/A
structure. To ensure this it might be useful to employ the long-dead, but recently
revivified idea that illocutionary force is represented in syntactic and/or semantic
structure. A simple question like Where is Grant buried? would have at least a
semantic structure along the lines of “Tell me what x is such that Grant is buried
at x.” Partly because of the powerful arguments mounted against inclusion of il-
locutionary force markers in syntacto-semantic structure when I supported that
idea, I will not adopt the idea here. More importantly, the spirit of automodular-
ism strongly suggests that illocutionary force itself should be described in a sep-
arate dimension with its own atoms and its own principles of combination. Illo-
cutionary force can, after all, be indicated by word order, inflectional morphology,
syntactic particles, and intonation, while the basic structure of illocutionary force
remains constant. I do not develop such a component in this book or elsewhere,
even though its utility has already been defended in Eilfort (1989) and has been
put to use in explaining mismatches between intonational contours and syntactic
structures in Bagchi (2011).
20	 Jacobson (2000) also takes relative pronouns to be pronouns, but her conception of
that category is radically different from mine.
21	 In this case the reference seems to be entirely a matter of grammar, suggesting that
the coreference condition ought to be in F/A structure rather than the more psycho-
logically oriented role structure. However, when it comes to ordinary pronouns,
definite NPs, and so forth, it seems more reasonable to state the condition as part of
cognitive content in RS, since the reference depends heavily on pragmatic factors.
240  Notes to pages 132–56
22	 Though Danish prescriptive grammar excludes examples like this, it is acceptable
for many speakers.
23	 This analysis makes adjectives pseudo-subordinate in the sense of Yuasa and
Sadock (2002). Their position in syntax is subordinate to the nouns they modify,
but their meaning is compositionally coordinate.
24	 I hardly need to point out that the grammatical reading of this sentence is irrelevant
to the point at hand.
25	 In Chapter 7 the iconic tendency for old information to precede new information
will be discussed, but that tendency should not be confused with the antecedent–
anaphor relation that is considered here. The old-before-new generalization holds
between information that has already been mentioned and different information
that has not yet been mentioned. But in cases of anaphora of the kind we see in (90),
the antecedent and the anaphor have the same referent. Within a single sentence the
two are equally accessible, so a different hierarchy is functioning, one in which the
antecedent outranks the anaphor.
26	 I feel quite sure that simply counting crossed NP nodes and homologous nodes
in other dimensions is too crude a way of modeling the Complex NP Constraint.
Clearly the fact that the NP is part of a large NP, and so on for the other components
is the relevant structural fact, just as Ross suggested.
5	 Morphology and morphophonology
1	 Borer (1988) also advocated for an independent morphological module.
2	 Neither is it the case that every segmentable piece of a phonological word is a mor-
phological part of that word. There are “simple clitics” in the terminology of Zwicky
(1977) that are simply reduced phonologically but are not parts of larger morpholog-
ical words.
3	 A possible example in English is the affix –ish as discussed in Kuzmack (2007).
4	 Yuhara (in press), extending the analysis in Yuhara (2008), provides an essentially
identical analysis of productive causatives in Japanese.
5	 Intransitive verbs in West Greenlandic form verb phrases that combine with a single,
absolutive-case NP to form a clause. Transitive verbs form verb phrases that com-
bine with an absolutive-case NP and an ergative-case NP to form a clause. There are
two corresponding morphological features as well, since intransitive and transitive
verb stems inflect differently and are subject to certain different derivational pro-
cesses.
6	 Recall that non-relational nouns and intransitive verbs belong to the same function-
argument category. Their different positions in F/A structure follow from their syn-
tactic differences and the correspondence principles. See the discussion of the noun
carpenter in Chapter 2 (10) and section 2.9 on quantification.
7	 See Anderson (1992) for arguments in favor of this morpheme-less view of mor-
phology, which he formalizes very differently from the treatment here.
8	 I will consign the distribution of these alloforms to phonologists.
9	 It is possible that the independent specification of the syntactic position of the clitic
follows from the fact that it is a morphophonological suffix. Without offending the
principle of Conservation of C-command, it would have to either precede or follow the
NP that it combines with. If it were a phrase-initial element (as lexical heads usually
Notes to pages 156–68  241
	 are in English), there would be an unnecessary mismatch between the position of
the clitic in morphophonology and its position in syntax. That mismatch disappears
if the clitic follows its syntactic phrase in the LOC. Here I will simply stipulate
the syntactic position, leaving open the possibility of deriving it from more gen-
eral principles. In any case, the treatment offered here does away with the need for
features with special properties like the edge features of Lapointe (1990), Miller
(1991), and Lapointe (1992).
10	 This F/A specification in effect makes forms such as yours quantifiers. That ana-
lysis seems plausible for uses as subjects and objects, like Yours is still at the clean-
er’s, where the restrictor of the quantifier is contextually determined, but it is not as
attractive for the predicate nominal use, i.e., This shirt is yours. It would be nice to
analyze the pronoun in such positions as predicative, meaning something like “This
shirt belongs to you.” Producing a respectable analysis of that kind is yet another
task I will have to leave for a later time.
11	 An interesting feature of the various senses of past tense, then, is that they are
continually demoted, so to speak, from F/A structure to syntactic structure to mor-
phological structure. In some cases this progressive demotion continues even to
morphophonology as in strong verbs such as sang, where the manifestation of tense
appears within the word. The sequence semantics, syntax, morphology, phonology
is a natural one, of course, roughly a progression from more to less abstract, or from
more cognitively oriented to more physically oriented levels of representation. See
section 7.1 of Chapter 7.
12	 This formulation was suggested by Michael Erlewine (p.c.). An alternative, which
I have not considered here, would be to simply list the finite auxiliary forms in the
lexicon as members of V[TNS].
13	 I worry about this statement because it endows lexical entries with the ability to
refer to information that is not limited to their sisters. A purely lexical treatment
would list modals in the lexicon as V[TNS]s that are subcategorized for a bare
infinitive VP. The lexical alternative would miss the generalization that the tense
element counts as a propositional modifier, but since there is only a small number
of auxiliaries, keeping the power of the syntax manageable might be worth the cost
of losing the generalization.
14	 Since it is unclear whether there really are ordinary past tenses of modals I have
specified the present tense in all cases. The only candidate for a genuine past tense
is the use of could in examples such as I could do this yesterday. It, then, would per-
haps deserve a special entry with morphological PAST and therefore also semantic
PAST.
15	 The fact that the subject will follow the higher V[TNS] is an instance of the The
A-over-A Principle of Ross (1967a), following Chomsky (1964):
	 “The A-over-A Principle: In a structure … [A… [A… ] … ] …, if a structural de-
scription refers to A ambiguously, then that structural description can only analyze the
higher, more inclusive, node A.”
16	 Ordinarily the subject cannot be farther away than the first position after the elem-
ents ordered by the template because of the Generalized Interface Principle of
Sadock and Schiller (1993) and the correspondence principles of Chapter 2 that
follow from it. Other forces having to do with discoursal weight of information,
however, can motivate the placement of the subject even later in the string, so that
242  Notes to pages 168–85
it no longer intervenes between tense and the verb. Thus existential there sentences
such as There appeared a genie and presentational sentences like Into the pond
jumped the frog are also governed by the template in (48) but do not distinguish
auxiliaries and non-auxiliaries since the subject is positioned after the main verb.
17	 The possibility of inversion with all verbs in all other Germanic languages might be
handled in several ways, all of them simpler than what has to be done to describe
English. That is reasonable in view of the distinctions between main and auxiliary
verb in English and the lack of such a distinction in the other Germanic languages.
The tense element in German,Yiddish, Dutch, and Scandinavian might select a VP
with the Feature [TNS], which will always be realized as inflection on the main
verb, just as is the case in English with non-finite forms of the verb, the infinitive
and the participles.
18	 Be is also an auxiliary and is meaningless in some of its uses but it does not select
infinitive VPs. With present or passive participial VPs there is an indirect effect on
meaning because the participles differ in meaning from the stems. Therefore in
neither case will the result be identical in terms of combinatoric semantics as the
simple active form. Auxiliary do, on the other hand, does not even have an indirect
effect on semantic form.
19	 It is possible to avoid the more complex form with the empty auxiliary by leaving
the interrogative element in situ, thus sidestepping inversion, but the word order
Mendel sang what? has unwanted discoursal properties.
20	 For reasons that escape me, the extra effort seems worth it on airplanes, where
examples such as the following, from a United Airlines flight to Paris, commonly
occur without stress on empty do: “Ladies and gentlemen, this does conclude the
video portion on board our flight.”
21	 In the framework that McCawley worked in, it is actually a deep syntactic past
tense, but his deep structure syntax is my autonomous F/A structure. The difference
is that for him one of the levels – surface syntax – is interpreted off the deep syn-
tactic (i.e., semantic) level of representation.
22	 See Mittwoch (2008) for a much more modern and nuanced view.
23	 This field is the equivalent of functional composition in semantically based theories
such as categorical grammar (Steedman 1997). An important difference is that in
the theory developed here, this is not a generally available rule that composes any
two consecutive functions into one, but must be stated lexically for the few sorts of
phenomena that require it.
6	 Gaps and other defective elements
1	 The morphological case features NOM in this lexical entry and ACC in the next entry
are matched by corresponding syntactic features by the feature osmosis principle
discussed in section 5.3 of Chapter 5.
2	 This section repeats material that is found in Sadock (2001).
3	 This particular example displays two ellipsis sites. Besides the extraordinary stem
ellipsis, there is the otherwise fairly common absence of the usual inflectional
	 material, here presumably –tunga, indicative, first person singular. The stem omis-
sion has much of the feel of VP ellipsis and the inflectional omission is something
Notes to pages 185–209  243
	 like the telegraphic omission of pronouns in a language such as English. Example
(6) might be better translated as “Don’t want to.”
  4	 CTG is the contingent mood in Inuktitut, what I have called the past subordinate
in Sadock (2003b). It marks clauses that often have the meaning “because S” or
“when (in the past) S.”
  5	 Example (8) with its anaphoric device as the stem of a derived word documents a
kind of invasion of an anaphoric island that is quite normal in the Inuit Arctic.
  6	 For a nice discussion of some of the peculiarities of VP elision, see Johnson (2001).
  7	 My judgment concerning the acceptability of this example was confirmed by my
trusted assistant, Gail Sadock. Even if I don’t have a clue, she often has.
  8	 I find this terminology misleading because (1) all semantic arguments refer, not
just “referring expressions,” (2) reflexives can be just as much pronominal as “pro-
nominals,” and finally, (3) both plain and reflexive pronouns are anaphoric in the
traditional sense of referring back to something else.
  9	 Some languages present a fourth category of long-distance reflexives, which con-
trasts with the close reflexives. (See, for example, the discussion of the reflexive
person in West Greenlandic in Sadock 2003b.) Other languages, Haitian Creole
(Kreyòl Ayisyen), for example, do not contrast reflexive and non-reflexive gram-
matically. On the basis of such differences, we might postulate a universal set of
anaphoric types that languages select from.
10	 See McCawley (1988, 351).
11	 The than clause may then optionally be further extraposed as with relative clauses.
The result would be:
i.	 More papers were published by Jones than Smith expected.
12	 There is certainly a nuanced difference between tough-movement constructions
like This violin is easy to play and similar sentences with pleonastic subjects like It
is easy to play this violin, but that difference seems to me to be a pragmatic impli-
cature, rather than a matter of semantic entailments.
13	 An important exception will be noted in Chapter 8.
7	 Conflict resolution
1	 As a non-phonologist I have avoided discussing automatic phonology to this point,
and will not have much to say about it subsequently. In any case, it is clear that rules
of sound belong in their own component. In every language there is a phonotactics
just as much as there is a morphotactics, syntactics, and so on. Moreover, it is rare
for a force deriving from another module to alter phonological organization, but it is
common for the reverse to be true.
2	 The order of the components on the generative grammatical assembly line is so
problematic that, as pointed out in Sadock (1991), a number of alternative concep-
tions of it have been offered. In my view, the difficulty of determining the correct
order of the various modules results from the fact that there is no order at all; the
modules are connected in parallel rather than in series.
3	 Sakshaug (1999) suggests putting closely adjacent, smaller components such as
­
morphology and morphophonology, F/A structure and role structure, into larger
244  Notes to pages 209–17
	 modules. For the subcomponents of these groupings she coined the felicitous term
“modulettes.” Her suggestion was based largely on the greater mutual interactions
between modulettes within a module than between modules. It is not clear to me,
however, that the interactional possibilities are not handled just as well by recog-
nizing an order of strength among all of the components.
  4	 A Google search produced 35 examples of the string “spoke to someone by tele-
phone” and 29 examples of “spoke by telephone to someone.” In every one of the
examples in the latter class, someone was part of a longer phrase, an example of
which is (7a).
  5	 For an example of how the weighting of competing forces can account for judg-
ments of relative acceptability, see Sadock (1998a).
  6	 Perhaps, asYoshio Ueno has suggested in private comments on a draft of this book,
the Dowtian proto-role definitions can be adjusted so as to make recipients and
beneficiaries outrank themes in the competition for proto-patienthood.
  7	 This order is grammatical for some speakers of British English.
  8	 I am assuming that the preposition plays no role in F/A structure, though that
assumption is irrelevant to the point being made here.
  9	 Some speakers resolve the conflict between the Complexity and Weight hierarchies
by coercing verbs like return to occur in the [–NP NP] frame, as in the following
excerpted from a letter written by J. D. Hooker to Darwin in 1844: “… they have
not yet returned me the notes drawings &c Botanical & others which I gave up as
per order.” (www.darwinproject.ac.uk/darwinletters/calendar/entry-734.html.)
10	 The intermediate position of particles on the Complexity scale may have something
to do with their semantic complexity rather than with syntactic Complexity. In an
example like We gave the book back there is a role structure goal to which the book
moves that is understood from context. That account would not extend to idiomatic
verb–particle constructions where the particle does not have a representation in role
structure at all. For now, then, the position of particles in the Syntactic Complexity
Hierarchy is stipulative.
11	 I have replaced Bolinger’s stigmata, namely question marks, with the “better than”
notation.
12	 There are contexts where this example is certainly fine in a context where the box
contrasts with the bundle, but that fact supports the point that is made here.
13	 Prince’s taxonomy is actually more fine grained than what we see in (30). In full
detail it is as follows:
Assumed Familiarity
New Inferable Evoked
Unused Brand-new Non-containing Containing Textually Situationally
Brand-new
Anchored
Brand-new
Unanchored
Notes to pages 217–30  245
	 The three-way classification given here will do for the sake of illustration, though.
I will leave it to the reader to determine whether Particle Shift responds to the sub-
categories that Prince proposes.
14	 On other important views of the role of discourse properties in grammar, see Lam-
brecht (1994) and Erteschik-Shir (1997). In the latter work, the author recognizes
the independence of information structure from phonology and syntax, and there-
fore concludes that her focus structure is an “interface component” rather than a
module. That conclusion would not be adopted in an automodular framework when
information structure is more officially incorporated.
8	 Some final observations
1	 A degenerate solution in quantum mechanics is one of several different solutions to
the wave equation.
2	 This sentence was constructed in consultation with Ted Cohen, esthetician, racon-
teur, and noted student of cowboy pool.
246
Bibliography
Abbott, Barbara. 2011. Out of control: the semantics of some infinitival VP comple-
ments. In Yuasa, Bagchi, and Beals (eds.): 229–242.
Alexiadou, Artemis and Elena Anagnostopoulou. 2002. Raising without infinitives and
the role of agreement. In Artemis Alexiadou, Elena Anagnostopoulou, Sjef Bar-
biers, and Hans-Martin Gärtner (eds.) Dimensions of Movement: from Features to
Remnants. Linguistik Aktuell/Linguistics Today, Bd. 48: 17–30, Amsterdam: John
Benjamins.
Allen, Barbara, Donna Gardiner, and Donald G. Frantz 1984. Noun incorporation in
Southern Tiwa. International Journal of American Linguistics 50: 292–311.
Anderson, Stephen 1982. Where’s Morphology? Linguistic Inquiry 13: 571–612.
  1992. A-Morphous Morphology. Cambridge, UK: Cambridge University Press.
Andrews, Avery D. 1996. Semantic case-stacking and inside-out unification. Australian
Journal of Linguistics 16: 1–55.
Aoun, Joseph and Audrey Li 1993. Syntax of Scope. Cambridge, MA: MIT Press.
Bagchi, Tista 1993a. Clausal Subordination in Bangla: A Cross-Modular Approach.
Doctoral dissertation, University of Chicago.
  1993b. Control, reflexives, and automodularity in Bangla imperfective participial
complements. Proceedings of the Annual Meeting of the Chicago Linguistics So-
ciety 29: 17–32.
  2011. Towards an intonational–illocutionary interface. In EtsuyoYuasa, Tista Bagchi,
and Katharine P. Beals (eds.) Pragmatics and Autolexical Grammar: In Honor of
Jerry Sadock: 107–22. Amsterdam: John Benjamins.
Baker, Mark C. 1988a. Incorporation: A Theory of Grammatical Function Changing.
Chicago: University of Chicago Press.
  1988b. Comments on the paper by Sadock. In Diane Brentari, Steven. G. Lapointe,
and Patrick M. Farrell (eds.) Morphology and its Relation to Phonology and
Syntax. Stanford, CA: CSLI Publications.
  1990. Pronominal inflection and the morphology–syntax interface. Proceedings of
the Annual Meeting of the Chicago Linguistics Society 26: 25–48.
  1997. Review of Jerrold M. Sadock, Autolexical Syntax. Language 73: 847–49.
Behagel, Otto 1909/10. Beziehungen zwischen Umfang und Reihenfolge von Satzglie-
dern. Indogermanische Forschungen 25: 110–42.
Berman, Adrienne 1973. A constraint on tough-movement. Proceedings of the Annual
Meeting of the Chicago Linguistics Society 9: 34–43.
Bibliography  247
Bhatt, Rajesh 1999. Covert Modality in Non-finite Contexts. Doctoral dissertation, Uni-
versity of Pennsylvania.
Bhatt, Rakesh Mohan 1999. Verb Movement and the Syntax of Kashmiri: Studies in
Natural Language and Linguistic Theory 46. Dordrecht, Boston: Kluwer.
Bittner, Maria and Ken Hale 1996. Ergativity: toward a theory of a heterogeneous class.
Linguistic Inquiry 27: 531–604.
Blevins, James P. 1994. Derived constituent order in unbounded dependency construc-
tions. Journal of Linguistics 30: 349–409.
Bloomfield, Leonard 1926. A set of postulates for the science of language. Language
2(3): 153–64.
Bolinger, Dwight 1971. The Phrasal Verb in English. Cambridge, MA: Harvard
­
University Press.
Borer, Hagit 1988. On the morphological parallelism between compounds and con-
structs. In Geert Booij and Jaap van Marle (eds.) Yearbook of Morphology: 45–65.
Dordrecht: Foris.
Börjars, Kersti E. 1997. One (more) reason why we need morphology. In Wolfgang U.
Dressler, Martin Prinzhorn, and John R. Rennison (eds.) Advances in Morphology:
111–29. Berlin, New York: Mouton de Gruyter.
Bresnan, Joan 1982. Control and complementation. In Joan Bresnan (ed.) The Mental
Representation of Grammatical Relations: 282–390. Cambridge, MA: MIT Press.
Brody, Michael 1993. q-theory and arguments. Linguistic Inquiry 24: 1–23.
Bruccoli, Matthew J. (ed.) 1989. The Short Stories of F. Scott Fitzgerald: A New Col-
lection. New York: Scribner.
Carden, Guy 1973. English Quantifiers: Logical Structure and Linguistic Variation.
Tokyo: Taishukan.
Chafe, Wallace L. 1994. Discourse, Consciousness, and Time: The Flow and Displace-
ment of Conscious Experience in Speaking and Writing. Chicago: University of
Chicago Press.
Chelliah, Shobhana 1995. An autolexical account of voicing assimilation in Manipuri.
In Schiller, Steinberg, and Need (eds.): 11–30.
Chomsky, Noam 1957. Syntactic Structures. The Hague: Mouton.
  1964. The logical basis of linguistic theory. In H. Lunt (ed.) Proceedings of the
Ninth International Congress of Linguistics: 981–83. The Hague: Mouton.
  1965. Aspects of the Theory of Syntax. Cambridge, MA: MIT Press.
  1975 (1955). The Logical Structure of Linguistic Theory. Chicago: University of Chi-
cago Press.
  1977. On Wh-movement. In Peter Culicover, Thomas Wasow, and Adrian Akmajian
(eds.) Formal Syntax: 77–132. New York: Academic Press.
  1979 (1951). Morphophonemics of Modern Hebrew. New York: Garland.
  1981. Lectures on Government and Binding. Dordrecht: Foris Publications.
  1986. Barriers. Cambridge, MA: MIT Press.
  1991. Linguistics and cognitive science: problems and mysteries. In Asa Kasher (ed.)
The Chomskyan Turn: 26–53. Cambridge, MA: Blackwell.
  1993. A minimalist program for linguistic theory. In Kenneth Hale and Samuel Jay
Keyser (eds.) The View from Building 20: Essays in Linguistics in Honor of Syl-
vain Bromberger: 1–52. Cambridge, MA: MIT Press. Reprinted 1995 in Noam
248  Bibliography
Chomsky, The Minimalist Program (Current Studies in Linguistics): 167–219.
Cambridge, MA: MIT Press.
  2001. Derivation by phase. In Michael Kenstowicz (ed.) Ken Hale: A Life in Lan-
guage: 1–52. Cambridge, MA: MIT Press.
Chomsky, Noam and Howard Lasnik 1977. Filters and control. Linguistic Inquiry 8:
425–504.
  1993. The theory of principles and parameters. In Joachim Jacobs, Arnim von
Stechow, Wolfgang Sternefeld, and Theo Vennemann (eds.) Syntax: An Inter-
national Handbook of Contemporary Research: 506–568. Berlin: de Gruyter.
Claiborne, Craig 1966. New York Times Cookbook. New York: Harper & Row.
Colarusso, John 1992. A Grammar of the Kabardian Language. Calgary: University of
Calgary Press.
Cooper, Robin 1983. Quantification and Syntactic Theory. Dordrecht, Boston: D.
Reidel.
Cooper, William E. and John Robert Ross 1975. World order. Papers from the Regional
Meeting of the Chicago Linguistic Society 11, Parasession: 63–111.
Corbett, Greville G. 2006. Agreement. Cambridge, UK: Cambridge University Press.
Cresswell, M. J. 1973. Logics and Languages. London: Methuen.
Culicover, Peter W. and Ray S. Jackendoff 1997. Semantic subordination despite syn-
tactic coordination. Linguistic Inquiry 28: 195–218.
  2005. Simpler Syntax. Oxford: Oxford University Press.
  2006. Turn control over to the semantics! Syntax 9: 131–52.
Daniels, Michael W. 2005. Generalized ID/LP Grammar: A Formalism for Parsing
Linearization-Based HPSG Grammars. Doctoral dissertation, The Ohio State Uni-
versity.
de Reuse, Willem Joseph 1988. The morphology/semantics interface: an autolexical
treatment of Eskimo verbal affix order. In Diane Brentari, Gary N. Larson, and
Lynne A. MacLeod (eds) Proceedings of the Annual Meeting of the Chicago Lin-
guistics Society 24: 112–25.
  1994. Siberian Yupik Eskimo: The Language and its Contacts with Chukchi. Salt
Lake City: University of Utah Press.
Diesing, Molly 1990. Verb movement and the subject position inYiddish. Natural Lan-
guage & Linguistic Theory 8: 41–79.
Dik, Ayzik-Meyer 1993. Der yoyred. Chulyot: Journal of Yiddish Research 1: 43–49.
Cited at: www.ibiblio.org/pub/academic/languages/yiddish/tmr/TMR01.019.
Dik, Simon C. 1989. The Theory of Functional Grammar. Dordrecht: Foris Publica-
tions.
Dixon, Robert M. W. 1991. A New Approach to English Grammar, on Semantic Prin-
ciples. Oxford, UK: Clarendon Press; New York: Oxford University Press.
  1994. Ergativity. Cambridge, UK: Cambridge University Press.
Dowty, David R. 1982. Grammatical relations and Montague grammar. In Pauline
Jacobson and Geoffrey K. Pullum (eds.) The Nature of Syntactic Representation:
79–130. Dordrecht: D. Reidel.
  1991. Thematic proto-roles and argument selection. Language 67: 547–619.
Edelman, Gerald M. and Joseph A. Gally 2001. Degeneracy and complexity in biolog-
ical systems. PNAS 98, no. 24: 13763–68.
Bibliography  249
Eggert, Randy 2002. Disconcordance: The Syntax, Semantics, and Pragmatics of Or-
agreement. Doctoral dissertation, University of Chicago.
Eilfort, William 1989. The illocutionary module. Paper presented at the Workshop on
Autolexical Syntax, University of Chicago, April 1989.
Eilfort, William and Eric Schiller 1990. Pragmatics and grammar: cross-modular rela-
tions in autolexical theory. Proceedings of the Annual Meeting of the Chicago
Linguistics Society 26: 125–35.
Einarsson, Stefán 1949. Icelandic: Grammar, Texts, Glossary, 2nd edition. Baltimore,
MD: Johns Hopkins Press.
Emonds, Joseph 1972. A reformulation of certain syntactic transformations. In Stanley
Peters (ed.) Goals of Linguistic Theory: 21–63. Englewood Cliffs, NJ: Prentice-Hall.
  1976. A Transformational Approach to English Syntax: Root, Structure-Preserving,
and Local Transformations. New York: Academic Press.
Erades, P. A. 1961. Points of modern English syntax XL. English Studies 42: 56–60.
Erteschik-Shir, Nomi 1997. The Dynamics of Focus Structure. Cambridge, UK and
New York: Cambridge University Press.
Faarlund, Jan Terje 1995. Autostructural analysis of semantic roles. In Schiller, Stein-
berg, and Need (eds.): 31–86.
Farkas, Donka 1986. On obligatory control. Linguistics and Philosophy 11: 27–58.
Farkas, Donka and Jerrold M. Sadock 1989. Preverb climbing in Hungarian. Language
65: 318–38.
Filip, Hana 1996. Psychological predicates and the syntax–semantics interface. In
Adele E. Goldberg (ed.) Conceptual Structure, Discourse and Language: 131–47.
Stanford, CA: Center for the Study of Language and Information.
Fillmore, Charles J. 1963. The position of embedding transformations in a grammar.
Word 19: 208–31.
  1968. The case for case. In Emmon Bach and Robert Harms (eds.) Universals in Lin-
guistic Theory: 1–88. New York: Holt, Rinehart, and Winston.
  1976. Frame semantics and the nature of language. Annals of the New York Academy
of Sciences: Conference on the Origin and Development of Language and Speech,
Volume 280: 20–32.
  1977. Scenes-and-frames semantics. In Antonio Zampolli (ed.) Fundamental Stud-
ies in Computer Science: Linguistic Structures Processing 5: 55–88. Amsterdam:
North Holland Publishing.
  1982. Frame semantics. In In-Seok Yang (ed.) Linguistics in the Morning Calm:
111–37. Seoul: Hanshin Publishing.
Firbas, Jan 1992. Functional Sentence Perspective in Written and Spoken Communica-
tion. Cambridge, UK: Cambridge University Press.
Fodor, Jerry A. 1983. Modularity of Mind: An Essay on Faculty Psychology. Cam-
bridge, MA: MIT Press.
Foley, William A. and Robert D. Van Valin, Jr. 1984. Functional Syntax and Universal
Grammar. Cambridge, UK: Cambridge University Press.
Fortescue, Michael 1984. West Greenlandic. London: Croom Helm.
Francis, Elaine J. 1998. When form and meaning come apart: quantificational nouns,
predicate nominal, and locative subjects in English. Proceedings of the Annual
Meeting of the Chicago Linguistics Society 24: 159–70.
250  Bibliography
  1999. Variation within Lexical Categories. Doctoral dissertation, University of Chi-
cago.
  2011. Constraining mismatch in grammar and in sentence comprehension: the role of
default correspondences. In Yuasa, Bagchi, and Beals (eds.): 279–298.
Francis, Elaine J., and Stephen Matthews 2005. A multi-dimensional approach to the
category ‘verb’ in Cantonese. Journal of Linguistics 41: 269–305.
Francis, Elaine J. and Laura A. Michaelis (eds.) 2003. Mismatch: Form–Function In-
congruity and the Architecture of Grammar. Stanford, CA: CSLI Publications.
Franklin, Amy, Anastasia Giannakidou, and Susan Goldin-Meadow 2011. Negation
as structure building in a home sign system. In Yuasa, Bagchi, and Beals (eds.):
261–278.
Franklin, Karl J. 1992. Review of Autolexical Syntax: A Theory of Parallel Grammati-
cal Representations. Notes on Linguistics 57: 61–62.
Frantz, Donald G. 1993. Review: autolexical syntax. Canadian Journal of Linguistics
38: 95–96.
Fraser, Bruce 1976. The Verb–Particle Combination in English. The Hague: Mouton.
Frege, Gottlob 1892. Über Sinn und Bedeutung. Zeitschrift für Philosophie und
philosophische Kritik 100: 25–50. Translated as, On sense and reference. In
Peter Geach and Max Black (eds.) 1952. Translations from the Philosophical
Writings of Gottlob Frege: 56–78, Oxford: Basil Blackwell. Also in Donald
Davidson and Gilbert Harmon (eds.) 1975. The Logic of Grammar: 116–28.
Encino: Dickenson.
Gazdar, Gerald 1981. Unbounded dependencies and coordinate structure. Linguistic
Inquiry 12: 151–84.
Gazdar, Gerald, Ewan Klein, Geoffrey K. Pullum, and Ivan A. Sag 1985. Generalized
Phrase Structure Grammar. Oxford: Blackwell.
Givon, Talmy 1978. Definiteness and referentiality. In Joseph H. Greenberg, Charles A.
Ferguson, and Edith A. Moravcsik (eds.) Universals of Human Language, Vol. IV:
291–330. Stanford, CA: Stanford University Press.
Goldberg, Adele 1995. Constructions: A Construction Grammar Approach to Argument
Structure. Chicago: University of Chicago Press.
Graczyk, Randolph 1991. Incorporation and Cliticization in Crow Morphosyntax. Doc-
toral dissertation, University of Chicago.
Grano, Thomas 2006. “Me and her” meets “he and I”: case, person, and linear ordering
in English coordinated pronouns. Undergraduate honors thesis, Stanford Univer-
sity.
Green, Georgia M. 1971a. Unspeakable sentences: book I. Linguistic Inquiry 2:
560–61.
  1971b. Unspeakable sentences: book II. Linguistic Inquiry 2: 601.
  1974. Semantics and Syntactic Regularity. Bloomington: Indiana University Press.
Gries, Stefan Thomas 2003. Multifactorial Analysis in Corpus Linguistics: A Study of
Particle Placement. London, New York: Continuum Press.
Grohmann, Kleanthes K., John Drury, and Juan Carlos Castillo 2000. No more EPP.
In Roger Billery and Brook Lillehauge (eds.) Proceedings of the Nineteenth West
Coast Conference on Formal Linguistics: 153–66. Somerville, MA: Cascadilla
Press.
Bibliography  251
Grözinger, Elvira 2008. Unser Rebbe, unser Stalin: jiddische Lieder aus den St. Peters-
burger Sammlungen von Moishe Beregowski (1892–1961) und Sofia Magid (1892–
1954). Wiesbaden: Harrassowitz.
Gruber, Jeffrey S. 1965. Studies in Lexical Relations. Doctoral dissertation, Cambridge,
MA: Massachusetts Institute of Technology.
Haegeman, Liliane 1991. Introduction to Government and Binding Theory. Malden,
MA: Blackwell.
  1994. Introduction to Government and Binding Theory, Second Edition. Malden,
MA: Blackwell.
Hagman, Roy S. 1977. Nama Hottentot Grammar. Bloomington: Research Center for
Language and Semiotic Studies, Indiana University.
Haiman, John (ed.) 1985. Iconicity in Syntax. Amsterdam: John Benjamins.
Halio, Jay L. and Ben Siegel 1997. Daughters of Valor: Contemporary Jewish Ameri-
can Women Writers. Newark: University of Delaware Press.
Halle, Morris and Alec Marantz 1993. Distributed morphology and the pieces of inflec-
tion. In Kenneth Hale and S. Jay Keyser (eds.) The View from Building 20: 111–76.
Cambridge, MA: MIT Press.
Harrington, J. P. 1910. An introductory paper on the Tiwa language, dialect of Taos,
New Mexico. American Anthropologist 12: 11–48.
Harris, Zellig 1951. Methods in Structural Linguistics. Chicago: University of Chicago
Press.
Hasplemath, Martin 2004. Coordinating constructions: an overview. In Martin
Haspelmath (ed.) Coordinating Constructions. Typological Studies in Language
58: 3–40. Amsterdam: John Benjamins.
Hawkins, John A. 1994. A Performance Theory of Order and Constituency. Cambridge,
UK: Cambridge University Press.
Heim, Irene and Angelika Kratzer 1998. Semantics in Generative Grammar. Malden,
MA: Blackwell.
Henke, Georg and Frank Schwarz 2006. Latium mit Rom. Bielefeld: Reise Know-How-
Verlag. Cited at: www.faz.net/s/RubEE93A17440484368BED13FE90371C0C4/
Doc~EBDC4C8464D6440E88440441798C403B4~ATpl~Ecommon~Scontent.
html?rss_googlefeed_reise.
Hicks, Glyn 2009. Tough-constructions and their derivations. Linguistic Inquiry 40:
535–66.
Higgins, Derrick 1998. Parsing parallel grammatical representation. COLING-ACL ’98:
545–49. Montreal: Morgan Kaufmann Publishers.
  2011. Evidence for grammatical multi-modularity from a corpus of non-native
essays. In Yuasa, Bagchi, and Beals (eds.): 299–314.
Holisky, Dee Ann 1987. The case of the intransitive subject in Tsova-Tush (Batsbi).
Lingua 71: 103–32.
Holmberg, Anders 2000. Am I unscientific? A reply to Lappin, Levine, and Johnson.
Natural Language & Linguistic Theory 18: 837–42.
Hopper, Paul J. and Sandra A. Thompson 1980. Transitivity in grammar and discourse.
Language 56: 251–319.
  1984. The discourse basis for lexical categories in universal grammar. Language 60:
703–52.
252  Bibliography
Horn, Laurence R. 1981. A pragmatic approach to certain ambiguities. Linguistics and
Philosophy 4: 321–58.
  1989. A Natural History of Negation. Chicago: University of Chicago Press.
Hornstein, Norbert 1990. As Time Goes By. Cambridge, MA: MIT Press.
Hornstein, Norbert, Jairo Nunes, and Kleanthes K. Grohmann 2005. Understanding
Minimalism. Cambridge, UK and New York: Cambridge University Press.
Hotta, Syugo 1998. Multi-Dimensional Word Formation in Japanese. Doctoral Disser-
tation, University of Chicago.
Hübsch, Reinhard (ed.) 2002. “Hört die Signale!”: die Deutschlandpolitik von KPD/
SED und SPD: 1945–1970. Berlin: Akademieverlag.
Jackendoff, Ray 1969. An interpretive theory of negation. Foundations of Language 5:
218–41.
  1972. Semantic Interpretation in Generative Grammar. Cambridge, MA: MIT
Press.
  1997. The Architecture of the Language Faculty. Cambridge, MA: MIT Press.
  2002. Foundations of Language: Brain, Meaning, Evolution. Oxford: Oxford Uni-
versity Press.
Jackendoff, Ray and Peter W. Culicover 2003. The semantic basis of control in English.
Language 79: 517–56.
Jacobson, Pauline 1999. Towards a variable-free semantics. Linguistics and Philosophy
22: 117–85.
  2000. Extraction out of tough. Snippets – Issue 1. www.ledonline.it/snippets/allegati/
snippets1003.pdf.
  2006. I can’t seem to figure this out. In Betty J. Birner and Gregory Ward (eds.)
Drawing the Boundaries of Meaning: Neo-Gricean Studies in Pragmatics and
Semantics in Honor of Laurence R. Horn. Studies in Language Companion Series,
Volume LXXX: 157–177. Amsterdam: John Benjamins.
Johnson, Kyle 2001. What VP ellipsis can do, what it can’t, but not why. In Mark Bal-
tin and Chris Collins (eds.) The Handbook of Contemporary Syntactic Theory:
439–79. Malden, MA. Blackwell.
Jones, Michael A. 1983. Getting ‘tough’ with Wh-movement. Journal of Linguistics
19: 129–59.
Kathman, David 1994. The Morphosyntax of Complex Verb Agreement. Doctoral Dis-
sertation, University of Chicago.
  1995. Control in autolexical syntax. In Schiller, Steinberg, and Need (eds.): 103–29.
Kathol, Andreas 1995. Linearization-Based German Syntax. Doctoral dissertation, The
Ohio State University.
Kayne, Richard S. 1994. The Antisymmetry of Syntax. Cambridge, MA: MIT Press.
Keenan, Edward 1976. Towards a Universal Definition of ‘Subject’. In Charles Li (ed.)
Subject and Topic: 303–33. New York: Academic Press.
Keenan, E. L. and L. M. Faltz 1978. Logical Types for Natural Language. UCLA
Occasional Papers in Linguistics 3. Los Angeles: UCLA Department of
­
Linguistics.
Kendall, Sue Ann and James Hye-Suk Yoon 1986. Sentence particles as evidence for
morphosyntactic interaction with pragmatics. Studies in the Linguistic Sciences
26: 55–75.
Bibliography  253
Kennedy, Christopher 1998. Local dependencies in comparative deletion. Proceedings
of WCCFL 17: 375–89.
Kennedy, Christopher and Jason Merchant 2000. The case of the ‘missing case’ and
the secret case. In Sandy Chung, Jim McCloskey, and Nathan Sanders (eds.) Jorge
Hankamer WebFest: http://ling.ucsc.edu/Jorge/.
Kihm, Alain. Aspects de l’incorporation en wolof: essai comparé des approches mini-
maliste et autolexicale. Recherches linguistiques de Vincennes 23: 7–24.
Kiparsky, Paul 1973. ‘Elsewhere’ in phonology. In Stephen R. Anderson and Paul Kip-
arsky (eds.) A Festschrift for Morris Halle: 93–106. NewYork: Holt, Rinehart, and
Winston.
Kluender, Robert 1992. Deriving island constraints from principles of predication. In
Helen Goodluck and Michael Rochemont (eds.) Island Contraints: Theory, Acqui-
sition and Processing: 241–79. Dordrecht: Kluwer.
Krifka, Manfred 1992. Thematic relations as links between nominal reference and tem-
poral constitution. In Ivan Sag and Anna Szabolcsi (eds.) Lexical Matters: 29–53.
Stanford, CA: Center for the Study of Language and Information.
  2004. Semantics below and above speech acts. Web paper: http://amor.rz.hu-berlin.
de/~h2816i3x/StanfordLecture2004.pdf.
Kuzmack, Stefanie 2007. Ish: A New Case of Antigrammaticalization. Unpublished pres-
entation, Linguistic Society of America 2007 Annual Meeting. Brief abstract in
Meeting Handbook at www.lsadc.org/info/pdf_files/2007_MeetingHandbook.pdf.
Ladefoged, Peter and Ian Maddieson 1996. The Sounds of the World’s Languages.
Malden, MA: Blackwell.
Lakoff, George 1969. On derivational constraints. Papers from the Regional Meeting of
the Chicago Linguistic Society 5: 117–39.
  1970. Repartee, or a reply to negation, conjunction and quantifiers. Foundations of
Language 6: 389–422.
  1984. There-constructions: A Case Study in Grammatical Construction Theory and
Prototype Theory. Berkeley Cognitive Science Report No. 18. Berkeley: Institute
of Human Learning.
Lambrecht, Knud 1994. Information Structure and Sentence Form: Topic, Focus, and
the Mental Representation of Discourse Referents. Cambridge, UK: Cambridge
University Press.
Langacker, Ronald 1969. On pronominalization and the chain of command. In David A.
Reibel and Sanford A. Schane (eds.) Modern Studies in English: 160–186. Engle-
wood Cliffs, NJ: Prentice-Hall.
  1987. Foundations of Cognitive Grammar, Volume I, Theoretical Prerequisites. Stan-
ford, CA: Stanford University Press.
  1990. Concept, Image, and Symbol: The Cognitive Basis of Grammar. Berlin: Mou-
ton de Gruyter.
Langendoen, D. Terrence 1970. The ‘can’t seem to’ construction. Linguistic Inquiry 1:
25–35.
Lapointe, Steven G. 1980. A Theory of Grammatical Agreement. Unpublished doctoral
dissertation, University of Massachusetts, Amherst .
254  Bibliography
  1987. Some extensions of the autolexical approach to structural mismatches. In
Geoffrey Huck and Almerindo Ojeda (eds.) Discontinuous Constituency: Syntax
and Semantics, Vol. XX. New York: Academic Press.
  1988. Constraints on autolexical analyses. Linguistic Analysis 18: 123–55.
  1990. Edge features in GPSG. Proceedings of the Annual Meeting of the Chicago
Linguistics Society 26: 221–35.
  1991. Korean verb markers and autolexical theory. In M. Alexander and M. Dressler
(eds.) Proceedings of FLSM-II, University of Michigan Papers in Linguistics:
144–162. Ann Arbor: University of Michigan Department of Linguistics.
  1992. Life on the EDGE: arguments in favor of an autolexical account of edge inflec-
tions. Papers from the Regional Meeting of the Chicago Linguistic Society 28:
318–32.
  1995. On deriving the government constraint for incorporation and inflection. In
Schiller, Steinberg, and Need (eds.): 131–87.
  1998. Distinguishing types of morphosyntactic cooccurrences: mismatch reso-
lution. Proceedings of the Annual Meeting of the Chicago Linguistics Society 24:
181–201.
Lappin, Shalom and Michael McCord 1990. A syntactic filter on pronominal anaphora
for slot grammar. Computational Linguistics 16: 135–42.
Lasnik, Howard 2003. Minimalist Investigations in Linguistic Theory. London and New
York: Routledge.
Lawler, John 1974. Ample negatives. Papers from the Regional Meeting of the Chicago
Linguistic Society 10: 1–24.
Lees, Robert B. 1960b. A multiply ambiguous adjectival construction in English. Lan-
guage 36: 207–21.
Levin, Beth 1993. English Verb Classes and Alternations: A Preliminary Investigation.
Chicago: University of Chicago Press.
Levin, Beth and Malka Rappaport-Hovav 2005. Argument Realization. Cambridge,
UK: Cambridge University Press.
López, M. Dolores Jiménez 2006. A grammar systems approach to natural language
grammar. Linguistics and Philosophy 29: 419–54.
Luka, Barbara 2011. Autolexical grammar and language processing: mismatch and
resolution in the cognitive representation of syntactic and semantic knowledge. In
Yuasa, Bagchi, and Beals (eds.): 315–336.
Marantz, Alec 1984. On the Nature of Grammatical Relations. Cambridge, MA: MIT
Press.
Martin, Jack B. 1988. Subtractive morphology as dissociation. Proceedings of the Sev-
enth West Coast Conference on Formal Linguistics: 229–40. Stanford, CA: CSLI.
McCawley, James D. 1970. English as a VSO language. Language 46: 286–99.
  1971. Tense and time reference in English. In Charles J. Fillmore and D. Terence
Langendoen (eds.) Studies in Linguistic Semantics: 96–113. New York: Holt,
Rinehart, and Winston. Reprinted in James D. McCawley 1973. Grammar and
Meaning: Papers on Syntactic and Semantic Topics: 257–76. Tokyo: Taishu-
kan.
  1981. Everything that Linguists Have Always Wanted to Know about Logic, But Were
Ashamed to Ask. Chicago: University of Chicago Press.
Bibliography  255
  1982. Parentheticals and discontinuous constituent structure. Linguistic Inquiry 13:
91–106.
  1988. The Syntactic Phenomena of English, Volumes I and II. Chicago: University
of Chicago Press.
McCloskey, James and Peter Sells 1988. Control and A-chains in Modern Irish. Natural
Language & Linguistic Theory 6: 143–89.
Merchant, Jason 2001. The Syntax of Silence: Sluicing, Islands, and the Theory of Ellip-
sis. Oxford: Oxford University Press.
  2011. Aleut case matters. In Yuasa, Bagchi, and Beals (eds.): 193–212.
Miller, Philip H. 1991. Clitics and Constituents in Phrase Structure Grammar. Doctoral
dissertation, University of Utrecht.
Mittwoch, Anita 2008. The English resultative perfect and its relationship to the
experiential perfect and the simple past tense. Linguistics and Philosophy 31:
323–51.
Mohanan, Tara 1995. Wordhood and lexicality: noun incorporation in Hindi. Natural
Language & Linguistic Theory 13: 75–134.
Montague, Richard 1974. Formal Philosophy: Selected Papers of Richard Montague,
edited and with an introduction by Richmond H. Thomason. New Haven: Yale
University Press.
Moravcsik, Edith A. 1993. Why is syntax complicated? In Mushira Eid and Gregory
K. Iverson (eds.) Principles and Prediction: The Analysis of Natural Language.
Papers in Honor of Gerald Sanders: 73–92. Amsterdam: John Benjamins.
Napoli, Donna Jo 1989. Predication Theory: A Case Study for Indexing Theory. Cam-
bridge, UK: Cambridge University Press.
Need, Barbara 1991. Negation in English, an autolexical account of the historical
changes. Proceedings of the Annual Meeting of the Chicago Linguistics Society
27: 207–17.
  1992. Liberated modifiers: an autolexical account of modifiers found outside the NP.
Proceedings of the Annual Meeting, Berkeley Linguistic Society 18: 192–203.
Need, Barbara and Eric Schiller 1990. What was, and what happened to, the subjunctive
in English? Proceedings of the Annual Meeting of the Chicago Linguistics Society
26: 323–32.
  1992. The liberation of minor categories: such a nice idea! Proceedings of the Annual
Meeting of the Chicago Linguistics Society 28: 484–98.
  1993. A unified diachronic explanation of the development of Modern English
modals. Proceedings of the Annual Meeting of the Chicago Linguistics Society
29: 297–310.
  1994. An autolexical account of variation. Proceedings of the Annual Meeting of the
Chicago Linguistics Society: 218–31.
Newmeyer, Frederick J. 1972. The insertion of idioms. Papers from the Regional Meet-
ing of the Chicago Linguistic Society 8: 294–302.
  2011. English derived nominals in three frameworks. In Yuasa, Bagchi, and Beals
(eds.): 213–228.
Nunberg, Geoffrey, Ivan Sag, and Thomas Wasow 1994. Idioms. Language 70: 491–
538.
256  Bibliography
Ojeda, Almerindo E. 1986. Algunas observaciones sobre la declinación española.
Revista Argentina de Lingüìstica 2(1): 22–37.
  1989. An autolexical account to Spanish comitative pronouns. Hispanic Linguistics
2: 321–34.
Parker, Frank, Kathryn Riley, and Charles F. Meyer 1990. Untriggered reflexive pro-
nouns in English. American Speech 65: 50–69.
Partee, Barbara H. 1970. Negation, conjunction and quantifiers: syntax vs. semantics.
Foundations of Language 6: 153–65.
Partee, Barbara H. and H. L. W. Hendricks 1997. Montague grammar. In Johan van
Benthem and Alice ter Meulen (eds.) Handbook of Logic and Language: 5–92.
Cambridge, MA: MIT Press.
Pensalfini, Rob 2001. Part of speech mismatches in modular grammar: new evidence
from Jingulu. Linguistic Variation Yearbook 1: 209–27.
Perlmutter, David M. 1971. Deep and Surface Structure Constraints in Syntax. New
York: Holt, Rinehart, and Winston.
  1978. Impersonal passives and the unaccusative hypothesis. Proceedings of the
Fourth Annual Meeting of the Berkeley Linguistics Society: 157–89.
Peterson, Peter 2004. Non-restrictive relatives and other non-syntagmatic relations in
a lexical-functional framework. In Miriam Butt and Tracy Holloway King (eds.)
Proceedings of the LFG ’04 Conference: 391–97. Stanford, CA: CSLI Publica-
tions. http://csli-publications.stanford.edu/LFG/9/lfg04peterson.pdf.
Pinker, Steven and Ray Jackendoff 2005. The faculty of language: what’s special about
it? Cognition 95: 201–36.
Pollard, Carl Jesse and Ivan A. Sag 1994. Head-Driven Phrase Structure Grammar.
Chicago: University of Chicago Press.
Postal, Paul M. 1970. On coreferential complement subject deletion. Linguistic Inquiry
1: 439–500.
  1974. On Raising. Cambridge, MA: MIT Press.
  1998. Three Investigations of Extraction. Cambridge, MA: MIT Press.
Postal, Paul M. and John R. Ross 1971. ¡Tough movement, si, tough deletion, no! Lin-
guistic Inquiry 2: 544–46.
Potsdam, Eric and Jeffrey Runner 2001. Richard returns: copy raising and its implications.
Papers from the Regional Meeting of the Chicago Linguistic Society 37: 453–68.
Prince, Ellen 1981. Toward a taxonomy of given-new information. In Peter Cole (ed.)
Radical Pragmatics: 223–56. New York: Academic Press.
  1993. On the discourse functions of syntactic form in Yiddish: expletive es and
Subject-Postposing. In David Goldberg, Marvin I. Herzog, Barbara Kirschenblatt-
Gimblett, and Dan Goldberg (eds.) The Field of Yiddish, 5th Collection. Studies in
Yiddish Language, Folklore, and Literature: 59–86. Evanston, IL and New York:
Northwestern University Press/YIVO.
Pullum, Geoffrey K. 1979. Rule Interaction and the Organization of a Grammar. New
York: Garland.
Pullum, Geoffrey K. and Arnold M. Zwicky 1986. Phonological resolution of syntactic
feature conflict. Language 62: 751–73.
Pustejovsky, James 1995. The Generative Lexicon. Cambridge, MA: MIT Press.
Bibliography  257
  1996. Aspectual coercion and logical polysemy. In Branimir Boguraev (ed.) Lex-
ical Semantics: The Problem of Polysemy: 133–62. Oxford: Clarendon Press.
Quirk, Randolph 1965. Descriptive statement and serial relation. Language 41:
205–17.
Radford, Andrew 1997. Syntactic Theory and the Structure of English: A Minimalist
Approach. Cambridge, UK: Cambridge University Press.
Reichenbach, Hans 1947. Elements of Symbolic Logic. New York: Macmillan.
Reinhart, Tanya 1981. Definite NP-anaphora and c-command domains. Linguistic
Inquiry 12: 605–35.
Reynolds, Saeko 2005. A Multimodular Analysis of Japanese Quantifiers. Doctoral Dis-
sertation, University of Chicago.
Richards, Norvin 1998. In full pursuit of the unspeakable. Proceedings of the North
Eastern Linguistics Society 28: 153–68.
Rickford, John R. 1999. African American Vernacular English: Features, Evolution,
Educational Implications. Malden, MA: Blackwell.
van Riemsdijk, Henk 1998. Head movement and adjacency. Natural Language & Lin-
guistic Theory 16: 633–78.
Rischel, Jørgen 1974. Topics in West Greenlandic Phonology. Copenhagen: Akademisk
Forlag.
Rogers,Andy 1974.A transderivational constraint on Richard? Papers from the Regional
Meeting of the Chicago Linguistic Society 10: 551–58.
Ross, John Robert (Haj) 1967a. Constraints on Variables in Syntax. Bloomington: Indi-
ana University Linguistics Club. Full text available from ERIC: www.eric.ed.gov.
  1967b. On the cyclic nature of English pronominalization. In To Honor Roman Jako-
bson: Essays on the Occasion of his Seventieth Birthday: 1,669–82. The Hague:
Mouton. Reprinted in David A. Reibel and Sanford A. Schane (eds.) 1969. Modern
Studies in English: 187–200. Englewood Cliffs, NJ: Prentice-Hall.
  1971. Act. In Donald Davidson and Gilbert Harmon (eds.) Semantics of Natural Lan-
guage: 70–126. Dordrecht: D. Reidel.
  2011. An automodular perspective on the frozenness of pseudoclefts, and vice versa.
In Yuasa, Bagchi, and Beals (eds.), 2011, pp. 243–60.
Sadock, Jerrold M. 1974. Toward a Linguistic Theory of Speech Acts. New York: Aca-
demic Press.
  1975. Read at your own risk: syntactic and semantic horrors you can find in your
medicine chest. Papers from the Regional Meeting of the Chicago Linguistic Soci-
ety 10: 599–607.
  1983. The necessary overlapping of grammatical components. Papers from the Re-
gional Meeting of the Chicago Linguistic Society 18, Parasession: 198–221.
  1984. The polyredundant lexicon. Papers from the Regional Meeting of the Chicago
Linguistic Society 20, Parasession: 250–69.
  1985a. Autolexical syntax: a theory of noun incorporation and similar phenomena.
Natural Language & Lingusitic Theory 3: 379–440.
  1985b. The Southern Tiwa incorporability hierarchy. International Journal of Ameri-
can Linguistics 51: 568–72.
  1986.An autolexical view of pronouns, anaphora, and agreement. In University of Chi-
cago Working Papers in Linguistics 2: 143–64. Chicago: University of Chicago.
258  Bibliography
  1987. Discontinuity in autolexical and autosemantic syntax. In Geoffrey J. Huck and
Almerindo E. Ojeda (eds.) Syntax and Semantics Volume XX: Discontinuous Con-
stituency: 283–303. New York: Academic Press.
  1988a. A multi-modular view of agreement. Papers from the Regional Meeting of the
Chicago Linguistic Society 24: 258–77.
  1988b. The autolexical classification of lexemes. In Michael Hammond and Michael
Noonan (eds.) Theoretical Morphology: 271–90. New York: Academic Press.
  1990a. A trimodular account of Yiddish syntax. Studies in the Linguistic Sciences
20: 31–50.
  1990b. Parts of speech in autolexical syntax. Proceedings of the Sixteenth Annual
Meeting of the Berkeley Linguistics Society: 269–81.
  1991. Autolexical Syntax: A Theory of Parallel Grammatical Representations. Chi-
cago: University of Chicago Press.
  1992a. A paper on Yiddish for James D. McCawley. In Diane Brentari, Gary N. Lar-
son, and Lynne A. MacLeod (eds.), The Joy of Grammar: 323–28. Amsterdam:
John Benjamins.
  1992b. Cyclic rules without derivations. Proceedings of the Annual Meeting of the
Chicago Linguistics Society 28: 237–63.
  1993. Scandinavian surfotax. Runes and Representations: Proceedings of Scandi­
LingFest 1: 74–87. University of Chicago Department of Linguistics.
  1994. Reflexive reference in West Greenlandic. In John A. Goldsmith, Salikoko Muf-
wene, Barbara Need, and David Testen (eds.) Contemporary Linguistics, Vol. I:
137–60. University of Chicago Department of Linguistics.
  1995. A multi-hierarchy view of clitics. Proceedings of the Annual Meeting of the
Chicago Linguistics Society 31, Parasession: 258–79.
  1996a. Autolexical syntax. In Keith Brown and Jim Miller (eds.) Concise Encyclo-
pedia of Syntactic Theories: 15–19. Oxford: Pergamon.
  1996b. The lexicon as bridge between phrase structure components. In J. Rooryck
and L. Zaring (eds.) Phrase Structure and the Lexicon, Studies in Natural Lan-
guage and Linguistic Theory 33: 173–85. Dordrecht: Kluwer.
  1998a. Grammatical tension. Papers from the Regional Meeting of the Chicago Lin-
guistic Society 34, The Panels: 179–98.
  1998b. On the autonomy of compounding morphology. In Diane Brentari and Steven
G. Lapointe (eds.) Morphology and its Relation to Phonology and Syntax: 161–87.
Stanford, CA: CSLI Publications.
  2001. How special are Eskimo-Aleut languages? Papers from the Regional Meeting
of the Chicago Linguistic Society 37, The Panels: 263–76.
  2003a. Mismatches in autonomous modular versus derivational grammars. In Francis
and Michaelis (eds.): 333–54.
  2003b. A Grammar of Kalaallisut (West Greenlandic Inuttut). Munich: Lincom
Europa.
  2005. Optimal morphology. In C. Orhan Orgun and Peter Sells (eds.) Morphology
and the Web of Grammar: Essays in Memory of Steven G. Lapointe: 83–94. Stan-
ford, CA: CSLI Publications.
Sadock, Jerrold M. and Eric Schiller 1993. The generalized interface principle. Papers
from the Regional Meeting of the Chicago Linguistic Society 29: 391–401.
Bibliography  259
Sag, Ivan A. 1980. Deletion and Logical Form. New York: Garland.
Sag, IvanA., Gerald Gazdar, ThomasWasow, and StevenWeisler 1985. Coordination and
how to distinguish categories. Natural Language & Linguistic Theory 3: 117–71.
Sag, Ivan A., Philip Hofmeister, and Neal Snider 2009. Processing complexity in sub-
jacency violations: the complex noun phrase constraint. Papers from the Regional
Meeting of the Chicago Linguistic Society 43: 215–29.
Sag, Ivan A. and Carl Pollard 1991. An integrated theory of complement control. Lan-
guage 67: 63–113.
Sakshaug, Laila. 1997. Aspects of an autolexical analysis of Norwegian compound
deverbal nouns, focusing on the intramodular matches and mismatches of the
semantic module. Motskrift 2: 41–56.
  1998. Tone assignment in Norwegian compounds: An autolexical account of an intra-
modular mismatch. Proceedings of the Annual Meeting of the Chicago Linguistics
Society 34: 347–362.
  1999. Norwegian Compound Deverbal Nouns: An Autolexical Analysis in Morph-
ology, Syntax, and Semantics. Doctoral dissertation, Trondheim: Norwegian Uni-
versity of Science and Technology.
Sapir, Edward 1921. Language: An Introduction to the Study of Speech. New York:
Harcourt Brace.
Schachter, Paul 1977. Constraints on coordination. Language 53: 86–103.
Schiller, Eric 1989a. On the phrase structure of serial verb constructions. Proceedings
of the Annual Meeting of the Chicago Linguistics Society 25: 405–19.
  1989b. Syntactic polysemy and underspecification in the lexicon. In K. Hall, M.
Meachan, and R. Sapiro (eds.) Proceedings of the Fifteenth Annual Meeting,
Berkeley Linguistic Society: 278–90.
  1990a. Focus and the discourse dimension in autolexical theory. Proceedings of the
Eastern States Conference on Linguistics 7: 249–59.
  1990b. On the definition and distribution of serial verb constructions. When verbs col-
lide: Papers from the 1990 Ohio State Mini-Conference on Serial Verbs, Ohio State
University Working Papers in Linguistics 39: 34–64.
  1990c. The typology of serial verb constructions. Proceedings of the Annual Meeting
of the Chicago Linguistics Society 26: 393–406.
  1991. An Autolexical Account of Subordinating Serial Verb Constructions. Doctoral
dissertation, University of Chicago.
  1992a. Infixes: clitics at the morphophonological level. Proceedings of the Annual
Meeting of the Chicago Linguistics Society 28: 472–83.
  1992b. Some autolexical solutions to problems of ‘parts of speech’ in Southeast
Asian languages. In Martha E. Ratliff (ed.) 1st Meeting of the Southeast Asian Lin-
guistics Society: 397–415. Tempe: Arizona State University Press.
  1995a. Expressives: inside or outside grammar? Proceedings of the Annual Meeting
of the Chicago Linguistics Society 31: 441–50.
  1995b. Not yes, not no: the zen of Khmer discourse particles. Proceedings of the
Twenty-First Annual Meeting of the Berkeley Linguistic Society: 107–13.
  1996. Performatives in autolexical grammar. Proceedings of the Annual Meeting of
the Chicago Linguistics Society 32: 311–18.
260  Bibliography
Schiller, Eric, Elisa Steinberg, and Barbara Need (eds.) 1995. Autolexical Theory: Ideas
and Methods. The Hague: Mouton de Gruyter.
Schneider, Robinson H. 1995. Toward a tri-modular analysis of -ly adverbs. In Schiller,
Steinberg, and Need (eds.): 207–39.
Seppänen, Aimo and Jennifer Herriman 2002. Extraposed subjects vs. postverbal com-
plements: on the so-called obligatory extraposition. Studia Neophilologica 74:
30–59.
Sholem Aleykhem 1925. Der daytsh. Ale Verk fun Sholem-Aleykhem, Vol IX: Oreme un
Freylekhe, Ershtes Bukh: 131–48. New York: Sholem-Aleykhem Folksfond.
Smessaert, Hans 1988. An Autolexical Syntax Approach to Pronominal Cliticization in
West Flemish. Master’s essay, University of Chicago.
  1995. Pronominal cliticization in West Flemish. In Schiller, Steinberg, and Need
(eds.): 241–89.
  2011. Wait’ll (you hear) the next one: a case for an enclitic preposition and comple-
mentizer. In Yuasa, Bagchi, and Beals (eds.): 175–192.
Soames, Scott and David M. Perlmutter 1979. Syntactic Argumentation and the Struc-
ture of English. Berkeley: University of California Press.
Speas, Peggy and Carol Tenny 2003. Configurational properties of point of view roles.
In Anne-Marie DiSciullo (ed.) Asymmetry in Grammar: 315–43. Amsterdam: John
Benjamins.
Spencer, Andrew 1991. Morphological Theory: An Introduction to Word Structure in
Generative Grammar. Cambridge, MA: Basil Blackwell.
  1993. The morphology–syntax interface. Journal of Linguistics 29: 143–56.
Sprott, Robert W. 1992. Jemez Syntax. Doctoral dissertation, University of Chicago.
Steedman, Mark 1997. Surface Structure and Interpretation. Cambridge, MA: MIT
Press.
Steinberg, Elisa 1991. A form of Spanish negation: negation without negatives.
­
Proceedings of the Annual Meeting of the Chicago Linguistics Society 27:
291–309.
Steinberg, Elisa and Alexander F. Caskey 1988. The syntax and semantics of gender
(dis)agreement: an autolexical approach. Proceedings of the Annual Meeting of the
Chicago Linguistics Society 24: 291–303.
Stowell, Tim 1981. Origins of Phrase Structure. Doctoral dissertation, Massachusetts
Institute of Technology.
Stump, Gregory T. 1995. Two types of mismatch between morphology and semantics.
In Schiller, Steinberg, and Need (eds.): 291–318.
Sugioka, Yoko 2011. Nominalization affixes and multi-modularity of word formation.
In Yuasa, Bagchi, and Beals (eds.): 143–162.
Suzuki, Hisami 2002. Multi-modularity in Computational Grammar. Doctoral disserta-
tion, University of Chicago.
Swift, Mary and Shanley E. M. Allen 2002. Verb base elision in Inuktitut conversational
discourse. International Journal of American Linguistics 37: 133–56.
Talmy, Leonard 1975. Semantics and syntax of motion. In John P. Kimball (ed.) Syntax
and Semantics 4: 81–238. New York: Academic Press.
Ueno, Yoshio 1994. Grammatical Functions and Clause Structure in Japanese. Doc-
toral dissertation, University of Chicago.
Bibliography  261
Ura, Hiroyuki 1998. Checking, economy, and copy-raising in Igbo. Linguistic Analysis
28: 67–88.
Van Valin, Robert 1977. Aspects of Lakhota Syntax. Doctoral dissertation, University
of California, Berkeley.
Vikner, Sten 1995. Verb Movement and Expletive Subjects in the Germanic Languages.
New York: Oxford University Press.
Wasow, Thomas 1977. Transformations and the lexicon. In Peter W. Culicover, Thomas
Wasow, and Adrian Akmajian (eds.) Formal Syntax: 327–60. NewYork: Academic
Press.
  1997. Remarks on grammatical weight. Language Variation and Change 9: 81–105.
Wasow, Thomas and Jennifer Arnold 2003. Post-verbal constituent ordering in English.
In Günther Rohdenburg and Britta Mondorf (eds.) Determinants of Grammatical
Variation in English: 119–54. Berlin: Mouton de Gruyter.
Whorf, Benjamin Lee 1956. Language, Thought and Reality: Selected Writings of Ben-
jamin Lee Whorf. Ed. by John B. Carroll. Cambridge, MA: Technology Press.
Woodbury, Anthony C. 1996. On restricting the role of morphology in autolexical syn-
tax. In Schiller, Steinberg, and Need (eds.): 319–64.
  2011. Atkan Aleut “unclitic” pronouns and definiteness: a multimodular analysis. In
Yuasa, Bagchi, and Beals (eds.): 125–142.
Wyss, Dieter 1997. Kain: Eine Phänomenologie und Psychopathologie des Bösen.
Würzburg: Königshausen & Neumann.
Yuasa, Etsuyo 1996. Categorial mismatch: an autolexical account of formal nouns in
Japanese. Proceedings of the Annual Meeting of the Chicago Linguistics Society
32: 423–31.
  1997. An autolexical account of subordination–coordination mismatches. Abstract.
Linguistic Society of America Meeting Handbook: 87.
  1998. Subordinate Clauses in Japanese. Doctoral dissertation, University of
­
Chicago.
  2005a. An autolexical account of variation in grammatical relations. Proceedings of
the Annual Meeting of the Chicago Linguistic Society 41: 285–99.
  2005b. Modularity in Language. Constructional and Categorial Mismatch in Syntax
and Semantics. Berlin: Mouton de Gruyter.
Yuasa, Etsuyo and Elaine J. Francis 2003. Categorial mismatch in a multi-modular the-
ory of grammar. In Francis and Michaelis (eds.): 179–227.
Yuasa, Etsuyo and Jerry M. Sadock 2002. Pseudo-subordination: a mismatch between
syntax and semantics. Journal of Linguistics 38: 87–111.
Yuasa, Etsuyo, Tista Bagchi, and Katherine Beals 2011. Introduction. InYuasa, Bagchi,
and Beals (eds.): XIII–XVIII.
Yuasa, Etsuyo, Tista Bagchi, and Katharine Beals (eds.) to appear. Pragmatics and
Autolexical Grammar: In Honor of Jerry Sadock. Amsterdam: John Benjamins.
Yuhara, Ichiro 2008. A Multimodular Approach to Case Assignment in Japanese: A Study
of Complex and Stative Predicates. Doctoral dissertation, University of Chicago.
  2011. Japanese productive causative sentences are not biclausal (but in fact bipropo-
sitional and this is not a mere notational variant). Reports of the Keio Institute of
Cultural and Linguistic Studies 42: 93–114.
262  Bibliography
Zwicky, Arnold M. 1977 On Clitics. Bloomington: Indiana University Linguistics
Club.
  1986. Incorporating the insights of autolexical syntax. The Ohio State University
Working Papers in Linguistics 32: 139–43.
Zwicky, Arnold M. and Geoffrey K. Pullum 1983. Cliticization vs. inflection: English
n’t. Language 59: 502–13.
263
Ā-movement 198, 200
A-movement 198
A-over-A principle 241n15
acceptability, graded 13, 93, 98–100, 138,
142–45, 203–04, 211–16, 218
Accessibility 217, 218
actives 73, 79–80, 109–10
adjectives 20, 21
and relative clauses 133–36
tough movement 201
agentive nominalization 153
agentive passives 94–96
agentless passive (English) 152–53, 184
morphological operation 152
agricola (Latin “farmer”) 151, 155
Alabama language 153–54
all hell 59
Allen, Shanley 185–86
a(n) (empty article) 29
anaphoric devices 71, 139, 189, 190–94
pronominal reference 138–40
and 127–29
Anderson, Stephen (R.) 4, 153
appear 40, 41–42, 68
argument (Arg) in F/A structure 15, 26
articles 29
definite 8, 65, 210
empty 29
enclitic 132
indefinite 183
Aspects of the Theory of Syntax
(Chomsky) 2–3
assert 46
assistance, verbs of 55
autolexical syntax 6
automodular grammar and derivational
grammar 67–72
auxiliary clitics 157–59
auxiliary verbs 160, 166–69
be 242n18
and contracted negation 178
do “support” 124, 169–70, 242n18
have 170–74
modal auxiliaries 149–50, 167, 169, 241n13
aware 56
away 228
Bagchi, Tista 137
Baker, Mark C. 159
Batsbi see Tsova Tush
be (empty verb) 28–29, 171, 188
and adjectives 134–35
auxiliary 242n18
and existential there 63–66
insertion 30–32
beat (it) 32–33
Behagel, Otto 211
believe 52–53, 66
active and passive 84
bicicletta (bicycle) (Italian) 154
Binding Theory 129, 191, 193
Bloomfield, Leonard 12
both … and 127–28
buy active and passive 82, 83, 101–02
by 94–96
c-command 35, 233n14
and anaphora 139, 191–93
and linear order 112–13
can’t 179
can’t seem to 18–19
Carden, Guy 140
carpenter 28–29, 240n6
Case Grammar 81
case marking strategies 74–79
Case Theory 25, 68–69, 70
Index
264  Index
categorial correspondence 12, 24
categorial redundancy 26–29
Certainty Principle 23, 200
Chomsky, Noam 1, 3, 162, 207, 225
Aspects of the Theory of Syntax 2–3
Binding Theory 191
and formalism 7
Logical Structure of Linguistic Theory,
The 2
Minimalist Program 1–2, 3, 10
Morphophonemics of Modern Hebrew 1
PRO Theorem 71
Syntactic Structures 2
and tough movement 200
claim 44, 46, 47
cylic interactions 49–50
and role structure 77
and VP gaps 194
Clausal Subject Principle 70–71
clitics and cliticization 148, 149, 155–59
cogitated 161
commercial transaction frame 101–03
comparative deletion 187
comparative gap see gaps, Kennedy–Merchant
comparative
Complex NP Constraint 123, 142–45
Complexity see Syntactic Complexity ­
Hierarchy
concreteness 7–9
conjunctions 124–30
bipartite conjunctions 127–28
Conservation of C-command 35, 41, 43, 50,
112, 240n9
Conservation of Dominance 35
Conservation of Linear Order 233n16
Construction Grammar 26, 231n1 to
­
Introduction, n2 to Chapter 1, n3 to
Chapter 2
contractions, negative 177–81
Cooper storage 62
Coordinate Structure Constraint 123, 129–30,
138
and relative clauses 131
copy raising 87, 88
coreference/non-coreference principles
191–92
coreferent complement subject deletion
see RHO
cost 102
coverage 10–11, 223
CTF (commercial transaction frame) 102–03
Culicover, Peter W. 7, 48, 75, 130, 223–24
cyclic rules 2–3, 49–52, 84–86
Danish definite article 132, 136
relative clauses 132, 136
word order 119
dative movement 213–15
deep structure 3–4, 85, 232n6
definite articles 8, 65, 210
degeneracy and redundancy 225–27
deletion 30, 48–49, 174, 187–89, 204, 213
dependencies, long-distance 122–24
see also Ā–movement
derivational grammar (and automodular
­
grammar) 67–72
derivational morphology 148
did 124
Dik, Ayzik-Mayer 116, 238n3
disharmony islands 138–45
dispose of 33–34
Dixon, R.M.W. 74
do
-insertion 13, 204
and not 175–77
and n’t 178
“support” 169–70
Dowty, David R. 13, 20, 76, 94
dream 142–45
dump 103–04
Dutch 118–19
easy 199–200, 201
ECP (Empty Category Principle) 8–9
Edelman, Gerald M. 226, 227
Eilfort, William 137
Emonds, Joseph 165
empirical content 9–10
empty articles 29
ECP (Empty Category Principle) 8–9
EPP (Extended Projection Principle) 70–71
Equi NP deletion see RHO
Equi and Raising predicates 57–60
Erlewine, Michael 241n10
esn (Yiddish “eat”) 108
Exclusion Principle 23
existential quantifiers see quantifiers
existential there see there, existential
expect 52–53, 197–98
explicitness 229
extensional (intersective) adjectives 133–35
Index  265
extinguish 183
extraposition 38–39, 220, 233n20, 236n6
F/A structure 12, 14–20, 208–09
and relative clauses 132–33
and role structure 78, 90–91
and tough movement 199–201
and the VP gap 189
functors 15–17
modifiers 17–18
quantifiers 58–63
Faarlund, Jan Terje 76
factive verbs 36–37, 218–20
fall 107
faln (Yiddish “fall”) 108
Faltz, L.M. 128
family 226–27
fear 105
feature osmosis 154–55
feminines 155
Filip, Hana 105–06
fill 103–04
Fillmore, Charles 2, 4, 75, 101
find 84, 85
fiskur (Icelandic “fish”) 184–85
Fodor, Jerry 4
fond 135
for in commercial transaction frame 103
formalizability 7, 67, 101, 229–30
former 135
found 84, 85
fragments 186
Francis, Elaine J. 150
Frege, Gottlob 28
French clitic template 114
frighten 105–07
fritter away 218
fun 150
function-argument structure see F/A structure
functional duplication 227
Gally, Joseph A. 226, 227
gapping 186
gaps 13, 184–85, 186–87, 204
Kennedy–Merchant comparative 194–98
VP 186, 187–90
tough movement 187, 198, 201
Gazdar, Gerald 128, 130
Generalized Interface Principle 241–42
generative grammar 1–2
geometric correspondence 12, 24, 34–35
German 98
auxiliaries 109
dative movement 214
linear order 116–18, 119
Germanic languages 118–21, 242n17
see also Danish, Dutch, German, Icelandic,
Yiddish
give 213–15
GB (Government and Binding) 3, 10, 62,
68–69
GPSG 61, 115
and dative movement 213
graded acceptability judgments see acceptabil-
ity, graded
Great Chain of Speaking 205–09, 222
Greek 87, 90
Green, Georgia 221
Gries, Stefan Thomas 215
Gruber, Jeffrey S. 75
haben (German “have”) 109
Haegeman, Liliane 71
hafta 158
Haitian Creole 158, 243n9
hard 201
have 83, 170–74, 188
hay wagon example 103–05
headway 203
Heavy NP Shift 211–13
Hicks, Glyn 10–11, 203
hobn (Yiddish “have”) 107
Hofmeister, Philip 123
Holisky, Dee Ann 107
Holmberg, Anders 10
hope for 53–54
Hopi 232n7
Horn, Laurence R. 18, 219–20
Hornstein, Norbert 171
Icelandic 184–85
Igbo 86–87
incorporation 11, 13, 159–60, 224
indefinite articles 183
ineffability 220–22
inflection, morphological 28, 60, 63, 87, 90,
148–49, 163–64, 171–75, 177–78, 185
influence 55
influence, verbs of 55–56
insertion 204
266  Index
and the interface 30–34
intending, verbs of 45
intensional adjectives 135
interaction, rule 2–4
interface system 12, 24–25
category correspondence/redundancy 12,
24, 26–29
and derivational grammar 67–72
existential there 63–66
functors belonging to F/A category Fpaa 44
geometrical correspondence 12, 24, 34–35
insertion and deletion 30–34
lexical correspondence 12, 24, 25
propositional modifiers 35–44
quantification 58–59, 60–63
Raising and Equi predicates 57–60
reflexive and non-reflexive pronouns 66–67
intermodular defaults 37, 44–45
Intermodular Lexical Correspondence
­
Principle 12, 25–26, 41–42
into 33
intonation 18, 127, 136–37, 155, 219–20
Inuit languages 149, 159
Inuktitut 185–86
Kalaallisut (West Greenlandic Inuttut)
19–20, 79, 149, 153, 224
inversion 168, 239n16
Germanic languages 242n17
Irish 86–87
island constraints 138–45, 198, 200–01,
220–21
it (pleonastic) 32–33, 38, 39–40, 41, 65, 197
Italian 154–55
Jackendoff, Ray 7, 11, 13, 48, 75–76, 130,
141, 223–25
Jacobson, Pauline 18
Japanese 78–80, 240n4
judgments, graded acceptability see accept-
ability
Kalaallisut (West Greenlandic Inuttut) 19–20,
79, 149
Kashmiri 118
Kathman, David 11
Kayne, Richard S. 115
Keenan, Edward L. 113, 128
Kennedy, Christopher 195–98
Kennedy–Merchant comparative gap 194–98
kick the bucket 98
Lakhota 107
Lakoff, George 140, 141
Langacker, R. 138
Langendoen, D. Terrence 18
Language Independent Preferred Order of
Constituents (LIPOC) 238n3
Lappin, Shalom 191
Lasnik, Howard 3
Latin 151, 155, 159
Lawler, John 18
Lees, Robert B. 2
Levin, Beth 110
lexical correspondence see Intermodular
­
Lexical Correspondence Principle
lightning 232n7
likely 42–44
linear order 13, 111, 145–46, 207, 209–11
component 111–46
and conjunctions 124–30
disharmony islands 138–45
English, verb second 121–22
Germanic 118–19, 120–21
language particular 113–18
long-distance dependencies 122–24
and possessive clitics 156
relative clauses 130–37
and tough movement 203
Linguistic Gravity 211, 233–34n20
see also Weight Hierarchy
LIPOC (Language Independent Preferred
Order of Constituents) 238n3
’ll 157–58
load 103–04
LOC (Linear Order Component) see linear
order
logical structure, grammar of, see F/A
­
structure
Logical Structure of Linguistic Theory, The
(Chomsky) 2
long-distance dependencies 122–24
look into 33
–lu (Inuit conjunctive clitic) 159
McCawley, James D. 14, 30, 60, 161, 162,
171–72, 174, 192–93, 196
McCord, Michael 191
Macedonian 210
make 55–56
Marantz, Alec 94
Martin, Jack B. 153
Index  267
Merchant, Jason 87–88, 187, 195–98
Merge 3
Minimalist Program 1–2, 3, 10–11, 62, 69,
235n39
MMF (material movement frame) 103–04
Modular Affinity 209
Modularity of Grammar Hypothesis 4–6
Montague Grammar 14–15
more 195–96
morphological classes
of processes 148
of stems 149–50
null stem 185–87
Morphophonemics of Modern Hebrew
(­
Chomsky) 1
morphophonology 13, 150–54
Morphosyntactic Association 165–66
Morphosyntactic Cliticization 165
Morphosyntactic Incorporation 160, 165
mustn’t 179–81
N′ (aka NP) ellipsis 186
Napoli, Donna Jo 94, 237n11
natural predication 237n11
need 189
Need, Barbara 6
negation 174–81
contraction 177–81
scope of 140–41
Newmeyer, Frederick J. 203
non-coreference/coreference principles
191–92
non-factive verbs 37–39
non-reflexive 66–67, 191–92
non-restrictive relative clauses 136–37
nor 127, 128–29
not 174–81, 207
play with a full deck 98
NP ellipsis see N′ ellipsis
NP (noun phrase)
conjoined 221–22
funny 203–04
gap 196–98
Heavy NP Shift 211–13
and Particle Shift 216–17
n’t 141, 179–81
Nunberg, Geoffrey, et al. 59
object controlled Equi verbs 54
obligatory control see RHO
observe 149–50
of (functional) 33–34, 56
possessive 157
old-before-new 240n25
or 125, 127–29
order, linear see linear order
osmosis, feature 154–55, 242n1
ought 189
Partee, Barbara 140
Particle Shift 215–18
Passive Lexical Rule 83–84, 96–97
passives 73, 78–84, 109–10, 206–07
agentive 94–96
agentless 152–53, 184
pseudo- 96–100
past 152
past tense 163–64
pay 102
perceiving, verbs of 45, 46
Perlmutter, David M. 107, 114
permission, verbs of 55
persuade 57
and role structure 84
phones tapped 220
Pinker, Steven 225
plausibility 11–12
play 31–32
not play with a full deck 98
POSS 156–57
possessives
clitics 156, 158
and conjoined NP 221–22
pronouns 157
predicates, psyche 105–07
prepositions 104
phrases 211–16
pres 163
present tense 163–64
Prince, Ellen 217
Principles and Parameters 3, 62, 115
PRO 48, 98, 110, 204
versus RHO 71–72
promise 90–94
pronominal reference see anaphoric devices
pronouns
destressed second person 155
and ineffability 221–22
first person 221
order in Germanic 120–21
268  Index
order in Spanish and French
possessive 157
pronominal reference see anaphoric devices
reflexive/non-reflexive 66–67, 189–90
relative 131–32
and VP gaps 192–94
you 155–56
propositional modifiers 35–44
proto-roles 13, 74, 76, 94
pseudo-passives 96–100
psych predicates 105–07
Pullum, Geoffrey K. 165, 177
purposely 80–81
Pustejovsky, James 51
put 151
and role structure 77, 83–84, 104–05
quantifiers 58–59, 60–63, 80, 133, 205–06,
235n33
existential 29, 59, 62, 63–65, 232n11
more 195–96
and there insertion 65
and word order 140–42
–que (Latin conjunctive clitic) 159
Quirk, Randolph 18
Radford, Andrew 162
Raising 69–70
and Equi predicates 57–60
and role structure 84
to-object, verbs 52–54
to-subject 24–25, 40–43
ran 151
Rappaport-Hovav, Malka 110
redundancy 24, 26–29, 189, 225–26
referring expressions 190–94
reflexives/non-reflexives 66–67, 191–92
relative clauses 130–37
Relative Syntactic Complexity 115
Revised Passive Rule 100
RHO 47–49, 184, 204
and PRO 71–72
and role structure 86–90
van Riemsdijk, Henk 165
right (adverbial modifier) 227–28
rodent 150
Rogers, Andy 87
Role Hierarchy 81–82
role structure (RS) 12–13, 49, 73–74, 109–10,
208–09
and case marking 74–78
and conjunctions 124
and cyclic transformations 84–86
miscellaneous classes of predicates 100–09
passives 73, 78–84, 94–100, 109–10
and promise 90–94
pseudo-passives 96–100
and RHO 86–90
Romance languages 113–14
French 114
Italian 154–55
Spanish 114
Ross, John Robert 123, 129, 130, 138, 142,
145
Rule of Functional Application 16
rule interaction 2–4, 84–85
S-Structure 3
Sadock, Gail 243n7
Sag, Ivan, et al. 64, 123
saganaki 183
sang 163
Sapir, Edward 208–09
say 89
saying, verbs of 45
Scandinavian languages 119, 132, 136
see also Danish, Icelandic
Schiller, Eric 6, 11, 154, 232n12, 241–42n16
seem 37–39, 40, 42–44
cyclic interactions 50–51
and Raising 70
and RHO 87–88
and Theta Criterion 68
sell 101–02
servus (Latin “servant”) 151
Sholem Aleykhem 120
Shortest Movement Condition (SMC) 9
Simpler Syntax (Culicover and Jackendoff)
224
sing 97–98, 107, 152, 167, 175
sluicing 186, 187
sneeze 26, 68, 77
Snider, Neal 123
South Slavic 159
South Tiwa 159–60
Spell Out 3
spill the beans 98, 203–04
Steinberg, Elisa 6
stink 37, 39
and role structure 77
Index  269
stripping 186
Structure of English Nominalizations
(Lees) 2
subject 217
semantic 19–20, 34, 54, 56–59, 233n13
syntactic 20, 78, 90, 197–200, 233n13
subject-controlled Equi verbs 24–25, 54, 84
swept 151
Swift, Mary 185–86
Syntactic Complexity Hierarchy 115–16
and dative movement 214–15
and Heavy NP Shift 211–13
and Particle Shift 216
Syntactic Structures (Chomsky) 2
Syntactic Weight 211–13
and dative movement 214–15
syntax 12
component 20–22
take 26, 77, 123–24, 200–02
Tarramiut see Inuktitut
telegraphic omission 186, 242–43n3
tense 160–66
than 195–96, 243n11
them 190
themselves 190
there
existential 63–66, 241–42n16
and role structure 77–78
Theta roles 25, 67–68, 70–71, 94
thinking, verbs of 45
to
infinitive marker 188–89, 234n21
preposition 213
tough movement 10–11, 187, 198–204
trade 152
transitive/intransitive verbs, and category cor-
respondence 26–29
try 45, 88, 89
trying, verbs of 45
Tsova Tush 74–75, 107
Ueno, Yoshio 236n8, 236n9
unaccusatives 107–09
unergatives 107–09
verbs
of assistance 55
auxiliary see auxiliary verbs
and the existential there 63–66
factive 36–37
of influence 55–56
of intending 45
non-factive 37–39
object-controlled Equi 54
of perceiving 45, 46, 55, 56
of permission 55
position
in English 121–22
in Germanic languages 118–19
raising-to-object 52–54
of saying 45
of thinking 45
transitive/intransitive 26–29
of trying 45
Visser’s generalization 92–94
voice 73
see also actives, passives
VP ellipsis (gap) 186, 187–90, 192–94
wanna 158
Wechsler, Stephen 59
Weight Hierarchy 211, 213–16, 219, 244n9
see also Linguistic Gravity
went 151
West Greenlandic Inuttut (Kalaallisut)
19–20, 79, 149, 153, 224
WH-elements 121–24, 131, 136–37,
168–69, 177, 196–97, 200–03
WH-islands 145, 200
WH-movement 198
see also dependencies, unbounded, long-
distance dependencies
what 123, 197–98
who 131
Whorf, Benjamin Lee 232n7
with 104
word, different senses of 147
yearn for 53–54
Yiddish 107–09
linear order 116–17, 119
pronouns 120–21
you 155–56
Yuasa, Etsuyo 121, 130
zayn (Yiddish “be”) 107–09
Zwicky, Arnold M. 177
